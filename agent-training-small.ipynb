{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "7e46ed22-9a8a-47cd-b5a3-6f5ba6266c48",
     "kernelId": "5e510cf9-b812-45aa-981c-e863398f7a6f"
    }
   },
   "source": [
    "## Environment setup\n",
    "\n",
    "Prepare `pytorch-1.5.1`, `cuda-10.1`, and `cudnn-v7.6.5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 1,
     "id": "cf97ab4e-fb5d-4f7b-87a3-7e056fb84503",
     "kernelId": "5e510cf9-b812-45aa-981c-e863398f7a6f",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Mar 15 08:35:31 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro RTX 5000     Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| 33%   27C    P8     8W / 230W |      0MiB / 16125MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "8968cf20-7c52-4d3f-9044-5c318a718317",
     "kernelId": "5e510cf9-b812-45aa-981c-e863398f7a6f",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'off-belief-small'...\n",
      "remote: Enumerating objects: 226, done.\u001b[K\n",
      "remote: Counting objects: 100% (226/226), done.\u001b[K\n",
      "remote: Compressing objects: 100% (160/160), done.\u001b[K\n",
      "remote: Total 226 (delta 64), reused 221 (delta 59), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (226/226), 4.26 MiB | 7.97 MiB/s, done.\n",
      "Resolving deltas: 100% (64/64), done.\n",
      "Submodule 'third_party/pybind11' (https://github.com/pybind/pybind11.git) registered for path 'third_party/pybind11'\n",
      "Cloning into '/notebooks/off-belief-small/third_party/pybind11'...\n",
      "remote: Enumerating objects: 23417, done.        \n",
      "remote: Counting objects: 100% (1292/1292), done.        \n",
      "remote: Compressing objects: 100% (505/505), done.        \n",
      "remote: Total 23417 (delta 809), reused 1051 (delta 716), pack-reused 22125        \n",
      "Receiving objects: 100% (23417/23417), 8.54 MiB | 11.41 MiB/s, done.\n",
      "Resolving deltas: 100% (16229/16229), done.\n",
      "Submodule path 'third_party/pybind11': checked out 'a1b71df137e015d44f7e31f7b6d4807253fb7871'\n",
      "Submodule 'tools/clang' (https://github.com/wjakob/clang-cindex-python3) registered for path 'third_party/pybind11/tools/clang'\n",
      "Cloning into '/notebooks/off-belief-small/third_party/pybind11/tools/clang'...\n",
      "remote: Enumerating objects: 368, done.        \n",
      "remote: Counting objects: 100% (13/13), done.        \n",
      "remote: Compressing objects: 100% (12/12), done.        \n",
      "remote: Total 368 (delta 3), reused 6 (delta 1), pack-reused 355        \n",
      "Receiving objects: 100% (368/368), 159.34 KiB | 602.00 KiB/s, done.\n",
      "Resolving deltas: 100% (154/154), done.\n",
      "Submodule path 'third_party/pybind11/tools/clang': checked out '6a00cbc4a9b8e68b71caf7f774b3f9c753ae84d5'\n"
     ]
    }
   ],
   "source": [
    "!git clone --recursive git@github.com:ScrapPaper/off-belief-small.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "9dad9a65-9dae-44c9-b937-c1ea5851abf8",
     "kernelId": "5e510cf9-b812-45aa-981c-e863398f7a6f",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2018 NVIDIA Corporation\n",
      "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
      "Cuda compilation tools, release 10.0, V10.0.130\n",
      "#define CUDNN_MAJOR 7\n",
      "#define CUDNN_MINOR 6\n",
      "#define CUDNN_PATCHLEVEL 2\n",
      "--\n",
      "#define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\n",
      "\n",
      "#include \"driver_types.h\"\n",
      "-rw-r--r-- 1 root root 15672664 Feb  6  2019 /usr/local/cuda-10.0/compat/libcuda.so.410.104\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version # cuda-10.1\n",
    "!cat /usr/include/cudnn.h | grep CUDNN_MAJOR -A 2 # cudnn-v7.6.5\n",
    "!ls -al /usr/local/cuda-10.0/compat/libcuda.so.410.104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "87a1f28d-7d68-42ff-8307-c5326f4b268d",
     "kernelId": "5e510cf9-b812-45aa-981c-e863398f7a6f",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lrwxrwxrwx 1 root root       20 Mar 15 08:21 /usr/lib/x86_64-linux-gnu/libcuda.so.1 -> libcuda.so.460.91.03\n",
      "-rw-r--r-- 1 root root 15672664 Feb  6  2019 /usr/lib/x86_64-linux-gnu/libcuda.so.410.104\n",
      "-rw-r--r-- 1 root root        0 Nov 24  2020 /usr/lib/x86_64-linux-gnu/libcuda.so.450.36.06\n",
      "-rw-r--r-- 1 root root 21795104 Jul  2  2021 /usr/lib/x86_64-linux-gnu/libcuda.so.460.91.03\n"
     ]
    }
   ],
   "source": [
    "!ls -al /usr/lib/x86_64-linux-gnu/libcuda.so.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T01:42:27.315645Z",
     "iopub.status.busy": "2022-05-10T01:42:27.315345Z",
     "iopub.status.idle": "2022-05-10T01:44:12.737938Z",
     "shell.execute_reply": "2022-05-10T01:44:12.736813Z",
     "shell.execute_reply.started": "2022-05-10T01:42:27.315604Z"
    },
    "gradient": {
     "editing": false,
     "execution_count": 2,
     "id": "87ebcc50-d499-4f7d-a930-9e50d80b68f4",
     "kernelId": "5e510cf9-b812-45aa-981c-e863398f7a6f",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic InRelease [242 kB]               \u001b[0m\u001b[33m\n",
      "Get:3 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [909 kB]\n",
      "Get:4 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\u001b[0m\u001b[33m\n",
      "Get:5 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [21.1 kB]\n",
      "Get:6 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1498 kB]\n",
      "Get:7 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2734 kB]33m\u001b[33m\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]      \u001b[0m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\n",
      "Get:9 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.9 kB][33m\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]   \u001b[0m\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 Packages [1344 kB]   \u001b[0m\u001b[33m\u001b[33m\n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic/restricted amd64 Packages [13.5 kB]m\u001b[33m\u001b[33m\u001b[33m\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic/universe amd64 Packages [11.3 MB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 Packages [186 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2272 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3168 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [942 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.8 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [12.9 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [12.2 kB]\n",
      "Fetched 25.0 MB in 3s (7399 kB/s)33m                          \u001b[0m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "144 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "build-essential is already the newest version (12.4ubuntu1).\n",
      "The following additional packages will be installed:\n",
      "  libpq5 libssl1.1\n",
      "Suggested packages:\n",
      "  postgresql-doc-10 libssl-doc\n",
      "The following NEW packages will be installed:\n",
      "  libffi-dev libpq-dev libpq5\n",
      "The following packages will be upgraded:\n",
      "  libssl-dev libssl1.1 openssl\n",
      "3 upgraded, 3 newly installed, 0 to remove and 141 not upgraded.\n",
      "Need to get 3967 kB of archives.\n",
      "After this operation, 1858 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libssl-dev amd64 1.1.1-1ubuntu2.1~18.04.17 [1568 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libssl1.1 amd64 1.1.1-1ubuntu2.1~18.04.17 [1302 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 openssl amd64 1.1.1-1ubuntu2.1~18.04.17 [614 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpq5 amd64 10.19-0ubuntu0.18.04.1 [108 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpq-dev amd64 10.19-0ubuntu0.18.04.1 [219 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libffi-dev amd64 3.2.1-8 [156 kB]\n",
      "Fetched 3967 kB in 0s (14.8 MB/s)  \u001b[0m\u001b[33m\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 6.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Preconfiguring packages ...\n",
      "\n",
      "(Reading database ... 18426 files and directories currently installed.)\n",
      "Preparing to unpack .../0-libssl-dev_1.1.1-1ubuntu2.1~18.04.17_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  3%]\u001b[49m\u001b[39m [#.........................................................] \u001b8Unpacking libssl-dev:amd64 (1.1.1-1ubuntu2.1~18.04.17) over (1.1.1-1ubuntu2.1~18.04.4) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  6%]\u001b[49m\u001b[39m [###.......................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 10%]\u001b[49m\u001b[39m [#####.....................................................] \u001b8Preparing to unpack .../1-libssl1.1_1.1.1-1ubuntu2.1~18.04.17_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 13%]\u001b[49m\u001b[39m [#######...................................................] \u001b8Unpacking libssl1.1:amd64 (1.1.1-1ubuntu2.1~18.04.17) over (1.1.1-1ubuntu2.1~18.04.4) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 16%]\u001b[49m\u001b[39m [#########.................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 19%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Preparing to unpack .../2-openssl_1.1.1-1ubuntu2.1~18.04.17_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 23%]\u001b[49m\u001b[39m [#############.............................................] \u001b8Unpacking openssl (1.1.1-1ubuntu2.1~18.04.17) over (1.1.1-1ubuntu2.1~18.04.4) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 26%]\u001b[49m\u001b[39m [##############............................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 29%]\u001b[49m\u001b[39m [################..........................................] \u001b8Selecting previously unselected package libpq5:amd64.\n",
      "Preparing to unpack .../3-libpq5_10.19-0ubuntu0.18.04.1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 32%]\u001b[49m\u001b[39m [##################........................................] \u001b8Unpacking libpq5:amd64 (10.19-0ubuntu0.18.04.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 35%]\u001b[49m\u001b[39m [####################......................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 39%]\u001b[49m\u001b[39m [######################....................................] \u001b8Selecting previously unselected package libpq-dev.\n",
      "Preparing to unpack .../4-libpq-dev_10.19-0ubuntu0.18.04.1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 42%]\u001b[49m\u001b[39m [########################..................................] \u001b8Unpacking libpq-dev (10.19-0ubuntu0.18.04.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 45%]\u001b[49m\u001b[39m [##########################................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 48%]\u001b[49m\u001b[39m [############################..............................] \u001b8Selecting previously unselected package libffi-dev:amd64.\n",
      "Preparing to unpack .../5-libffi-dev_3.2.1-8_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 52%]\u001b[49m\u001b[39m [#############################.............................] \u001b8Unpacking libffi-dev:amd64 (3.2.1-8) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 55%]\u001b[49m\u001b[39m [###############################...........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 58%]\u001b[49m\u001b[39m [#################################.........................] \u001b8Setting up libffi-dev:amd64 (3.2.1-8) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 61%]\u001b[49m\u001b[39m [###################################.......................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 65%]\u001b[49m\u001b[39m [#####################################.....................] \u001b8Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libvdpau_nvidia.so.450.36.06 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libvdpau_nvidia.so.1 is empty, not checked.\n",
      "Setting up libssl1.1:amd64 (1.1.1-1ubuntu2.1~18.04.17) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 68%]\u001b[49m\u001b[39m [#######################################...................] \u001b8debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
      "debconf: falling back to frontend: Readline\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 71%]\u001b[49m\u001b[39m [#########################################.................] \u001b8Setting up openssl (1.1.1-1ubuntu2.1~18.04.17) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 74%]\u001b[49m\u001b[39m [###########################################...............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 77%]\u001b[49m\u001b[39m [############################################..............] \u001b8Setting up libssl-dev:amd64 (1.1.1-1ubuntu2.1~18.04.17) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 81%]\u001b[49m\u001b[39m [##############################################............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 84%]\u001b[49m\u001b[39m [################################################..........] \u001b8Setting up libpq5:amd64 (10.19-0ubuntu0.18.04.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 87%]\u001b[49m\u001b[39m [##################################################........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 90%]\u001b[49m\u001b[39m [####################################################......] \u001b8Setting up libpq-dev (10.19-0ubuntu0.18.04.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 94%]\u001b[49m\u001b[39m [######################################################....] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 97%]\u001b[49m\u001b[39m [########################################################..] \u001b8Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libvdpau_nvidia.so.450.36.06 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libvdpau_nvidia.so.1 is empty, not checked.\n",
      "\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  dbus dh-python libapparmor1 libdbus-1-3 libpython3-dev libpython3.7\n",
      "  libpython3.7-dev libpython3.7-minimal libpython3.7-stdlib python-pip-whl\n",
      "  python3-asn1crypto python3-cffi-backend python3-crypto python3-cryptography\n",
      "  python3-dev python3-idna python3-keyring python3-keyrings.alt\n",
      "  python3-pkg-resources python3-secretstorage python3-setuptools python3-six\n",
      "  python3-wheel python3-xdg python3.7 python3.7-minimal\n",
      "Suggested packages:\n",
      "  default-dbus-session-bus | dbus-session-bus python-crypto-doc\n",
      "  python-cryptography-doc python3-cryptography-vectors gnome-keyring\n",
      "  libkf5wallet-bin gir1.2-gnomekeyring-1.0 python-secretstorage-doc\n",
      "  python-setuptools-doc python3.7-venv binfmt-support\n",
      "The following NEW packages will be installed:\n",
      "  dbus dh-python libapparmor1 libpython3-dev libpython3.7 libpython3.7-dev\n",
      "  libpython3.7-minimal libpython3.7-stdlib python-pip-whl python3-asn1crypto\n",
      "  python3-cffi-backend python3-crypto python3-cryptography python3-dev\n",
      "  python3-idna python3-keyring python3-keyrings.alt python3-pip\n",
      "  python3-pkg-resources python3-secretstorage python3-setuptools python3-six\n",
      "  python3-wheel python3-xdg python3.7 python3.7-dev python3.7-minimal\n",
      "The following packages will be upgraded:\n",
      "  libdbus-1-3\n",
      "1 upgraded, 27 newly installed, 0 to remove and 140 not upgraded.\n",
      "Need to get 52.7 MB of archives.\n",
      "After this operation, 99.8 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdbus-1-3 amd64 1.12.2-1ubuntu1.3 [175 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libapparmor1 amd64 2.12-4ubuntu5.1 [31.3 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 dbus amd64 1.12.2-1ubuntu1.3 [150 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 dh-python all 3.20180325ubuntu2 [89.2 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpython3-dev amd64 3.6.7-1~18.04 [7328 B]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip-whl all 9.0.1-2.3~ubuntu1.18.04.5 [1653 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-asn1crypto all 0.24.0-1 [72.8 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-cffi-backend amd64 1.11.5-1 [64.6 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-crypto amd64 2.6.1-8ubuntu2 [244 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-idna all 2.6-1 [32.5 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-six all 1.11.0-2 [11.4 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-cryptography amd64 2.1.4-1ubuntu1.4 [220 kB]\n",
      "Get:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.7-minimal amd64 3.7.13-1+bionic3 [589 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-dev amd64 3.6.7-1~18.04 [1288 B]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-secretstorage all 2.3.1-2 [12.1 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-keyring all 10.6.0-1 [26.7 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-keyrings.alt all 3.0-1 [16.6 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-pip all 9.0.1-2.3~ubuntu1.18.04.5 [114 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pkg-resources all 39.0.1-2 [98.8 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-setuptools all 39.0.1-2 [248 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-wheel all 0.30.0-0.2 [36.5 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-xdg all 0.25-4ubuntu1.1 [31.3 kB]\n",
      "Get:23 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.7-minimal amd64 3.7.13-1+bionic3 [1725 kB]\n",
      "Get:24 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.7-stdlib amd64 3.7.13-1+bionic3 [1772 kB]\n",
      "Get:25 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.7 amd64 3.7.13-1+bionic3 [1526 kB]\n",
      "Get:26 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.7-dev amd64 3.7.13-1+bionic3 [42.9 MB]\n",
      "Get:27 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.7 amd64 3.7.13-1+bionic3 [359 kB]\n",
      "Get:28 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.7-dev amd64 3.7.13-1+bionic3 [501 kB]\n",
      "Fetched 52.7 MB in 6s (8139 kB/s)                                              \u001b[0m\u001b[33m\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 28.)\n",
      "debconf: falling back to frontend: Readline\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package libpython3.7-minimal:amd64.\n",
      "(Reading database ... 18495 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libpython3.7-minimal_3.7.13-1+bionic3_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8Unpacking libpython3.7-minimal:amd64 (3.7.13-1+bionic3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  1%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  2%]\u001b[49m\u001b[39m [#.........................................................] \u001b8Selecting previously unselected package python3.7-minimal.\n",
      "Preparing to unpack .../01-python3.7-minimal_3.7.13-1+bionic3_amd64.deb ...\n",
      "Unpacking python3.7-minimal (3.7.13-1+bionic3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  4%]\u001b[49m\u001b[39m [##........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  4%]\u001b[49m\u001b[39m [##........................................................] \u001b8Preparing to unpack .../02-libdbus-1-3_1.12.2-1ubuntu1.3_amd64.deb ...\n",
      "Unpacking libdbus-1-3:amd64 (1.12.2-1ubuntu1.3) over (1.12.2-1ubuntu1.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  6%]\u001b[49m\u001b[39m [###.......................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  6%]\u001b[49m\u001b[39m [###.......................................................] \u001b8Selecting previously unselected package libapparmor1:amd64.\n",
      "Preparing to unpack .../03-libapparmor1_2.12-4ubuntu5.1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  7%]\u001b[49m\u001b[39m [####......................................................] \u001b8Unpacking libapparmor1:amd64 (2.12-4ubuntu5.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  9%]\u001b[49m\u001b[39m [####......................................................] \u001b8Selecting previously unselected package dbus.\n",
      "Preparing to unpack .../04-dbus_1.12.2-1ubuntu1.3_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  9%]\u001b[49m\u001b[39m [#####.....................................................] \u001b8Unpacking dbus (1.12.2-1ubuntu1.3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 11%]\u001b[49m\u001b[39m [######....................................................] \u001b8Selecting previously unselected package dh-python.\n",
      "Preparing to unpack .../05-dh-python_3.20180325ubuntu2_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 11%]\u001b[49m\u001b[39m [######....................................................] \u001b8Unpacking dh-python (3.20180325ubuntu2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 12%]\u001b[49m\u001b[39m [######....................................................] \u001b8Selecting previously unselected package libpython3-dev:amd64.\n",
      "Preparing to unpack .../06-libpython3-dev_3.6.7-1~18.04_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 13%]\u001b[49m\u001b[39m [#######...................................................] \u001b8Unpacking libpython3-dev:amd64 (3.6.7-1~18.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 14%]\u001b[49m\u001b[39m [########..................................................] \u001b8Selecting previously unselected package libpython3.7-stdlib:amd64.\n",
      "Preparing to unpack .../07-libpython3.7-stdlib_3.7.13-1+bionic3_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 16%]\u001b[49m\u001b[39m [#########.................................................] \u001b8Unpacking libpython3.7-stdlib:amd64 (3.7.13-1+bionic3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 16%]\u001b[49m\u001b[39m [#########.................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 17%]\u001b[49m\u001b[39m [#########.................................................] \u001b8Selecting previously unselected package libpython3.7:amd64.\n",
      "Preparing to unpack .../08-libpython3.7_3.7.13-1+bionic3_amd64.deb ...\n",
      "Unpacking libpython3.7:amd64 (3.7.13-1+bionic3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 18%]\u001b[49m\u001b[39m [##########................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 19%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Selecting previously unselected package libpython3.7-dev:amd64.\n",
      "Preparing to unpack .../09-libpython3.7-dev_3.7.13-1+bionic3_amd64.deb ...\n",
      "Unpacking libpython3.7-dev:amd64 (3.7.13-1+bionic3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 21%]\u001b[49m\u001b[39m [###########...............................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 21%]\u001b[49m\u001b[39m [############..............................................] \u001b8Selecting previously unselected package python-pip-whl.\n",
      "Preparing to unpack .../10-python-pip-whl_9.0.1-2.3~ubuntu1.18.04.5_all.deb ...\n",
      "Unpacking python-pip-whl (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 23%]\u001b[49m\u001b[39m [#############.............................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 23%]\u001b[49m\u001b[39m [#############.............................................] \u001b8Selecting previously unselected package python3-asn1crypto.\n",
      "Preparing to unpack .../11-python3-asn1crypto_0.24.0-1_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 24%]\u001b[49m\u001b[39m [#############.............................................] \u001b8Unpacking python3-asn1crypto (0.24.0-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 26%]\u001b[49m\u001b[39m [##############............................................] \u001b8Selecting previously unselected package python3-cffi-backend.\n",
      "Preparing to unpack .../12-python3-cffi-backend_1.11.5-1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 26%]\u001b[49m\u001b[39m [###############...........................................] \u001b8Unpacking python3-cffi-backend (1.11.5-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 28%]\u001b[49m\u001b[39m [################..........................................] \u001b8Selecting previously unselected package python3-crypto.\n",
      "Preparing to unpack .../13-python3-crypto_2.6.1-8ubuntu2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 28%]\u001b[49m\u001b[39m [################..........................................] \u001b8Unpacking python3-crypto (2.6.1-8ubuntu2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 29%]\u001b[49m\u001b[39m [################..........................................] \u001b8Selecting previously unselected package python3-idna.\n",
      "Preparing to unpack .../14-python3-idna_2.6-1_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 30%]\u001b[49m\u001b[39m [#################.........................................] \u001b8Unpacking python3-idna (2.6-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 31%]\u001b[49m\u001b[39m [##################........................................] \u001b8Selecting previously unselected package python3-six.\n",
      "Preparing to unpack .../15-python3-six_1.11.0-2_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 33%]\u001b[49m\u001b[39m [##################........................................] \u001b8Unpacking python3-six (1.11.0-2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 33%]\u001b[49m\u001b[39m [###################.......................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 34%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Selecting previously unselected package python3-cryptography.\n",
      "Preparing to unpack .../16-python3-cryptography_2.1.4-1ubuntu1.4_amd64.deb ...\n",
      "Unpacking python3-cryptography (2.1.4-1ubuntu1.4) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 35%]\u001b[49m\u001b[39m [####################......................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 36%]\u001b[49m\u001b[39m [####################......................................] \u001b8Selecting previously unselected package python3-dev.\n",
      "Preparing to unpack .../17-python3-dev_3.6.7-1~18.04_amd64.deb ...\n",
      "Unpacking python3-dev (3.6.7-1~18.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 38%]\u001b[49m\u001b[39m [#####################.....................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 38%]\u001b[49m\u001b[39m [######################....................................] \u001b8Selecting previously unselected package python3-secretstorage.\n",
      "Preparing to unpack .../18-python3-secretstorage_2.3.1-2_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 39%]\u001b[49m\u001b[39m [######################....................................] \u001b8Unpacking python3-secretstorage (2.3.1-2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Selecting previously unselected package python3-keyring.\n",
      "Preparing to unpack .../19-python3-keyring_10.6.0-1_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 41%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Unpacking python3-keyring (10.6.0-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 43%]\u001b[49m\u001b[39m [########################..................................] \u001b8Selecting previously unselected package python3-keyrings.alt.\n",
      "Preparing to unpack .../20-python3-keyrings.alt_3.0-1_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 43%]\u001b[49m\u001b[39m [#########################.................................] \u001b8Unpacking python3-keyrings.alt (3.0-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 45%]\u001b[49m\u001b[39m [#########################.................................] \u001b8Selecting previously unselected package python3-pip.\n",
      "Preparing to unpack .../21-python3-pip_9.0.1-2.3~ubuntu1.18.04.5_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 45%]\u001b[49m\u001b[39m [##########################................................] \u001b8Unpacking python3-pip (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 46%]\u001b[49m\u001b[39m [##########################................................] \u001b8Selecting previously unselected package python3-pkg-resources.\n",
      "Preparing to unpack .../22-python3-pkg-resources_39.0.1-2_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 48%]\u001b[49m\u001b[39m [###########################...............................] \u001b8Unpacking python3-pkg-resources (39.0.1-2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 48%]\u001b[49m\u001b[39m [###########################...............................] \u001b8Selecting previously unselected package python3-setuptools.\n",
      "Preparing to unpack .../23-python3-setuptools_39.0.1-2_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 50%]\u001b[49m\u001b[39m [############################..............................] \u001b8Unpacking python3-setuptools (39.0.1-2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 50%]\u001b[49m\u001b[39m [#############################.............................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 51%]\u001b[49m\u001b[39m [#############################.............................] \u001b8Selecting previously unselected package python3-wheel.\n",
      "Preparing to unpack .../24-python3-wheel_0.30.0-0.2_all.deb ...\n",
      "Unpacking python3-wheel (0.30.0-0.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 52%]\u001b[49m\u001b[39m [##############################............................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 53%]\u001b[49m\u001b[39m [##############################............................] \u001b8Selecting previously unselected package python3-xdg.\n",
      "Preparing to unpack .../25-python3-xdg_0.25-4ubuntu1.1_all.deb ...\n",
      "Unpacking python3-xdg (0.25-4ubuntu1.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 55%]\u001b[49m\u001b[39m [###############################...........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 55%]\u001b[49m\u001b[39m [################################..........................] \u001b8Selecting previously unselected package python3.7.\n",
      "Preparing to unpack .../26-python3.7_3.7.13-1+bionic3_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 56%]\u001b[49m\u001b[39m [################################..........................] \u001b8Unpacking python3.7 (3.7.13-1+bionic3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 57%]\u001b[49m\u001b[39m [#################################.........................] \u001b8Selecting previously unselected package python3.7-dev.\n",
      "Preparing to unpack .../27-python3.7-dev_3.7.13-1+bionic3_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 58%]\u001b[49m\u001b[39m [#################################.........................] \u001b8Unpacking python3.7-dev (3.7.13-1+bionic3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8Setting up python-pip-whl (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8Processing triggers for mime-support (3.60ubuntu1) ...\n",
      "Setting up python3-cffi-backend (1.11.5-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 62%]\u001b[49m\u001b[39m [###################################.......................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 62%]\u001b[49m\u001b[39m [####################################......................] \u001b8Setting up python3-crypto (2.6.1-8ubuntu2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 63%]\u001b[49m\u001b[39m [####################################......................] \u001b8Setting up python3-idna (2.6-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 65%]\u001b[49m\u001b[39m [#####################################.....................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 65%]\u001b[49m\u001b[39m [#####################################.....................] \u001b8Setting up python3-xdg (0.25-4ubuntu1.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 67%]\u001b[49m\u001b[39m [######################################....................] \u001b8Setting up python3-six (1.11.0-2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 67%]\u001b[49m\u001b[39m [#######################################...................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 68%]\u001b[49m\u001b[39m [#######################################...................] \u001b8Setting up python3-wheel (0.30.0-0.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 70%]\u001b[49m\u001b[39m [########################################..................] \u001b8Setting up libpython3.7-minimal:amd64 (3.7.13-1+bionic3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 70%]\u001b[49m\u001b[39m [########################################..................] \u001b8Setting up python3-pkg-resources (39.0.1-2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 72%]\u001b[49m\u001b[39m [#########################################.................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 72%]\u001b[49m\u001b[39m [#########################################.................] \u001b8Setting up python3.7-minimal (3.7.13-1+bionic3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 73%]\u001b[49m\u001b[39m [##########################################................] \u001b8Setting up python3-asn1crypto (0.24.0-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 74%]\u001b[49m\u001b[39m [###########################################...............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 75%]\u001b[49m\u001b[39m [###########################################...............] \u001b8Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libvdpau_nvidia.so.450.36.06 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libvdpau_nvidia.so.1 is empty, not checked.\n",
      "Setting up libapparmor1:amd64 (2.12-4ubuntu5.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 77%]\u001b[49m\u001b[39m [############################################..............] \u001b8Setting up python3-pip (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 77%]\u001b[49m\u001b[39m [############################################..............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 78%]\u001b[49m\u001b[39m [#############################################.............] \u001b8Setting up python3-setuptools (39.0.1-2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 79%]\u001b[49m\u001b[39m [##############################################............] \u001b8Setting up dh-python (3.20180325ubuntu2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8Setting up libdbus-1-3:amd64 (1.12.2-1ubuntu1.3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 82%]\u001b[49m\u001b[39m [###############################################...........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 82%]\u001b[49m\u001b[39m [###############################################...........] \u001b8Setting up libpython3-dev:amd64 (3.6.7-1~18.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 84%]\u001b[49m\u001b[39m [################################################..........] \u001b8Setting up python3-cryptography (2.1.4-1ubuntu1.4) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 84%]\u001b[49m\u001b[39m [################################################..........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 85%]\u001b[49m\u001b[39m [#################################################.........] \u001b8Setting up libpython3.7-stdlib:amd64 (3.7.13-1+bionic3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 87%]\u001b[49m\u001b[39m [##################################################........] \u001b8Setting up python3-keyrings.alt (3.0-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 87%]\u001b[49m\u001b[39m [##################################################........] \u001b8Setting up python3-dev (3.6.7-1~18.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 89%]\u001b[49m\u001b[39m [###################################################.......] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 89%]\u001b[49m\u001b[39m [###################################################.......] \u001b8Setting up python3.7 (3.7.13-1+bionic3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 90%]\u001b[49m\u001b[39m [####################################################......] \u001b8Setting up libpython3.7:amd64 (3.7.13-1+bionic3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 91%]\u001b[49m\u001b[39m [#####################################################.....] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 92%]\u001b[49m\u001b[39m [#####################################################.....] \u001b8Setting up libpython3.7-dev:amd64 (3.7.13-1+bionic3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 94%]\u001b[49m\u001b[39m [######################################################....] \u001b8Setting up dbus (1.12.2-1ubuntu1.3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 94%]\u001b[49m\u001b[39m [######################################################....] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 95%]\u001b[49m\u001b[39m [#######################################################...] \u001b8Setting up python3-secretstorage (2.3.1-2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 96%]\u001b[49m\u001b[39m [#######################################################...] \u001b8Setting up python3-keyring (10.6.0-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 97%]\u001b[49m\u001b[39m [########################################################..] \u001b8Setting up python3.7-dev (3.7.13-1+bionic3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 99%]\u001b[49m\u001b[39m [#########################################################.] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 99%]\u001b[49m\u001b[39m [#########################################################.] \u001b8Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libvdpau_nvidia.so.450.36.06 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libvdpau_nvidia.so.1 is empty, not checked.\n",
      "\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "python3.7 is already the newest version (3.7.13-1+bionic3).\n",
      "python3.7 set to manually installed.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 140 not upgraded.\n",
      "update-alternatives: using /usr/bin/python3.6 to provide /usr/bin/python3 (python3) in auto mode\n",
      "update-alternatives: using /usr/bin/python3.7 to provide /usr/bin/python3 (python3) in auto mode\n",
      "\u001b[33mCache entry deserialization failed, entry ignored\u001b[0m\n",
      "Collecting pip\n",
      "  Downloading https://files.pythonhosted.org/packages/4d/16/0a14ca596f30316efd412a60bdfac02a7259bf8673d4d917dc60b9a21812/pip-22.0.4-py3-none-any.whl (2.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.1MB 639kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 9.0.1\n",
      "    Not uninstalling pip at /usr/lib/python3/dist-packages, outside environment /usr\n",
      "Successfully installed pip-22.0.4\n",
      "Collecting cython\n",
      "  Downloading Cython-0.29.28-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: cython\n",
      "Successfully installed cython-0.29.28\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.5.1+cu101\n",
      "  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp37-cp37m-linux_x86_64.whl (704.4 MB)\n",
      "Collecting torchvision==0.6.1+cu101\n",
      "  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.1%2Bcu101-cp37-cp37m-linux_x86_64.whl (6.6 MB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pillow>=4.1.1\n",
      "  Downloading Pillow-9.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "Building wheels for collected packages: future\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=493275 sha256=8c5d1242232c21054dff50bb666f027894509125f9c9d5f686b4f44f890e30ec\n",
      "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
      "Successfully built future\n",
      "Installing collected packages: pillow, numpy, future, torch, torchvision\n",
      "Successfully installed future-0.18.2 numpy-1.21.6 pillow-9.1.0 torch-1.5.1+cu101 torchvision-0.6.1+cu101\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting psutil\n",
      "  Downloading psutil-5.9.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.7/280.7 KB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cmake==3.15.3\n",
      "  Downloading cmake-3.15.3-py3-none-manylinux2010_x86_64.whl (16.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: cmake, psutil\n",
      "Successfully installed cmake-3.15.3 psutil-5.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!apt update\n",
    "!apt install -y build-essential libpq-dev libssl-dev openssl libffi-dev\n",
    "!apt install -y python3-pip python3.7-dev\n",
    "!apt install python3.7\n",
    "!update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.6 1\n",
    "!update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 2\n",
    "!update-alternatives --set python3 /usr/bin/python3.7\n",
    "!ln -sf /usr/bin/python3 /usr/local/bin/python\n",
    "!ln -sf /usr/bin/python3 /usr/local/bin/python3\n",
    "!python -m pip install --upgrade pip\n",
    "!python -m pip install cython\n",
    "!python -m pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html --progress-bar off\n",
    "!python -m pip install psutil cmake==3.15.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T01:44:24.432642Z",
     "iopub.status.busy": "2022-05-10T01:44:24.432357Z",
     "iopub.status.idle": "2022-05-10T01:44:24.437820Z",
     "shell.execute_reply": "2022-05-10T01:44:24.437148Z",
     "shell.execute_reply.started": "2022-05-10T01:44:24.432598Z"
    },
    "gradient": {
     "editing": false,
     "execution_count": 3,
     "id": "a24b9eca-d5b0-472d-a032-1e7675343956",
     "kernelId": "5e510cf9-b812-45aa-981c-e863398f7a6f",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OMP_NUM_THREADS=1\n"
     ]
    }
   ],
   "source": [
    "# avoid tensor operation using all cpu cores\n",
    "%env OMP_NUM_THREADS 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "dd678b16-6eef-4ebb-9cbf-de5d192bf339",
     "kernelId": "5e510cf9-b812-45aa-981c-e863398f7a6f"
    }
   },
   "source": [
    "## Compile learning environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T01:47:37.453408Z",
     "iopub.status.busy": "2022-05-10T01:47:37.453080Z",
     "iopub.status.idle": "2022-05-10T01:49:45.302085Z",
     "shell.execute_reply": "2022-05-10T01:49:45.300991Z",
     "shell.execute_reply.started": "2022-05-10T01:47:37.453363Z"
    },
    "gradient": {
     "editing": false,
     "execution_count": 12,
     "id": "c947b8d8-3989-4948-9f25-7c9fa40f4c30",
     "kernelId": "5e510cf9-b812-45aa-981c-e863398f7a6f",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/off-belief-small\n",
      "/notebooks/off-belief-small/build\n",
      "-- The C compiler identification is GNU 7.4.0\n",
      "-- The CXX compiler identification is GNU 7.4.0\n",
      "-- Check for working C compiler: /usr/bin/cc\n",
      "-- Check for working C compiler: /usr/bin/cc -- works\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++\n",
      "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "Traceback (most recent call last):\n",
      "  File \"/notebooks/off-belief-small/get_pybind_flags.py\", line 5, in <module>\n",
      "    val = getattr(torch._C, f\"_PYBIND11_{name}\")\n",
      "AttributeError: module 'torch._C' has no attribute '_PYBIND11_COMPILER_TYPE'\n",
      "-- Found PythonInterp: /usr/bin/python3.7 (found suitable version \"3.7.13\", minimum required is \"3.7\") \n",
      "-- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython3.7m.so (found suitable version \"3.7.13\", minimum required is \"3.7\") \n",
      "-- Looking for pthread.h\n",
      "-- Looking for pthread.h - found\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed\n",
      "-- Looking for pthread_create in pthreads\n",
      "-- Looking for pthread_create in pthreads - not found\n",
      "-- Looking for pthread_create in pthread\n",
      "-- Looking for pthread_create in pthread - found\n",
      "-- Found Threads: TRUE  \n",
      "-- Found CUDA: /usr/local/cuda (found version \"10.0\") \n",
      "-- Caffe2: CUDA detected: 10.0\n",
      "-- Caffe2: CUDA nvcc is: /usr/local/cuda/bin/nvcc\n",
      "-- Caffe2: CUDA toolkit directory: /usr/local/cuda\n",
      "-- Caffe2: Header version is: 10.0\n",
      "-- Found CUDNN: /usr/lib/x86_64-linux-gnu/libcudnn.so  \n",
      "-- Found cuDNN: v7.6.2  (include: /usr/include, library: /usr/lib/x86_64-linux-gnu/libcudnn.so)\n",
      "-- Autodetected CUDA architecture(s):  5.2\n",
      "-- Added CUDA NVCC flags for: -gencode;arch=compute_52,code=sm_52\n",
      "-- Found torch: /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch.so  \n",
      "-- Found PythonInterp: /usr/bin/python3.7 (found version \"3.7.13\") \n",
      "-- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython3.7m.so\n",
      "-- pybind11 v2.3.dev1\n",
      "-- Performing Test HAS_FLTO\n",
      "-- Performing Test HAS_FLTO - Success\n",
      "-- LTO enabled\n",
      "-- Caffe2: CUDA detected: 10.0\n",
      "-- Caffe2: CUDA nvcc is: /usr/local/cuda/bin/nvcc\n",
      "-- Caffe2: CUDA toolkit directory: /usr/local/cuda\n",
      "-- Caffe2: Header version is: 10.0\n",
      "-- Found cuDNN: v7.6.2  (include: /usr/include, library: /usr/lib/x86_64-linux-gnu/libcudnn.so)\n",
      "-- Autodetected CUDA architecture(s):  5.2\n",
      "-- Added CUDA NVCC flags for: -gencode;arch=compute_52,code=sm_52\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /notebooks/off-belief-small/build\n",
      "\u001b[35m\u001b[1mScanning dependencies of target rela_lib\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target hanabi\u001b[0m\n",
      "[ 11%] \u001b[32mBuilding CXX object hanabi-learning-environment/hanabi_lib/CMakeFiles/hanabi.dir/hanabi_hand.cc.o\u001b[0m\n",
      "[ 15%] \u001b[32mBuilding CXX object hanabi-learning-environment/hanabi_lib/CMakeFiles/hanabi.dir/hanabi_card.cc.o\u001b[0m\n",
      "[ 15%] \u001b[32mBuilding CXX object hanabi-learning-environment/hanabi_lib/CMakeFiles/hanabi.dir/hanabi_history_item.cc.o\u001b[0m\n",
      "[ 38%] \u001b[32mBuilding CXX object hanabi-learning-environment/hanabi_lib/CMakeFiles/hanabi.dir/hanabi_game.cc.o\u001b[0m\n",
      "[ 38%] \u001b[32mBuilding CXX object hanabi-learning-environment/hanabi_lib/CMakeFiles/hanabi.dir/hanabi_move.cc.o\u001b[0m\n",
      "[ 38%] \u001b[32mBuilding CXX object hanabi-learning-environment/hanabi_lib/CMakeFiles/hanabi.dir/hanabi_observation.cc.o\u001b[0m\n",
      "[ 38%] \u001b[32mBuilding CXX object hanabi-learning-environment/hanabi_lib/CMakeFiles/hanabi.dir/hanabi_state.cc.o\u001b[0m\n",
      "[ 38%] \u001b[32mBuilding CXX object hanabi-learning-environment/hanabi_lib/CMakeFiles/hanabi.dir/canonical_encoders.cc.o\u001b[0m\n",
      "[ 38%] \u001b[32mBuilding CXX object hanabi-learning-environment/hanabi_lib/CMakeFiles/hanabi.dir/util.cc.o\u001b[0m\n",
      "[ 38%] \u001b[32mBuilding CXX object rela/CMakeFiles/rela_lib.dir/transition.cc.o\u001b[0m\n",
      "[ 42%] \u001b[32mBuilding CXX object rela/CMakeFiles/rela_lib.dir/batcher.cc.o\u001b[0m\n",
      "[ 50%] \u001b[32mBuilding CXX object rela/CMakeFiles/rela_lib.dir/batch_runner.cc.o\u001b[0m\n",
      "[ 46%] \u001b[32mBuilding CXX object rela/CMakeFiles/rela_lib.dir/context.cc.o\u001b[0m\n",
      "[ 53%] \u001b[32m\u001b[1mLinking CXX static library libhanabi.a\u001b[0m\n",
      "[ 53%] Built target hanabi\n",
      "\u001b[35m\u001b[1mScanning dependencies of target game_example\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target pyhanabi\u001b[0m\n",
      "[ 57%] \u001b[32mBuilding CXX object hanabi-learning-environment/CMakeFiles/game_example.dir/game_example.cc.o\u001b[0m\n",
      "[ 61%] \u001b[32mBuilding CXX object hanabi-learning-environment/CMakeFiles/pyhanabi.dir/pyhanabi.cc.o\u001b[0m\n",
      "[ 65%] \u001b[32m\u001b[1mLinking CXX executable game_example\u001b[0m\n",
      "[ 65%] Built target game_example\n",
      "[ 69%] \u001b[32m\u001b[1mLinking CXX shared library libpyhanabi.so\u001b[0m\n",
      "In file included from \u001b[01m\u001b[K/notebooks/off-belief-small/rela/batch_runner.cc:7:0\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/notebooks/off-belief-small/rela/batch_runner.h:17:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Krela::BatchRunner\u001b[m\u001b[K’ declared with greater visibility than the type of its field ‘\u001b[01m\u001b[Krela::BatchRunner::pyModel_\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wattributes\u001b[m\u001b[K]\n",
      " class \u001b[01;35m\u001b[KBatchRunner\u001b[m\u001b[K {\n",
      "       \u001b[01;35m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
      "[ 69%] Built target pyhanabi\n",
      "[ 73%] \u001b[32m\u001b[1mLinking CXX static library librela_lib.a\u001b[0m\n",
      "[ 73%] Built target rela_lib\n",
      "\u001b[35m\u001b[1mScanning dependencies of target rela\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target hanalearn\u001b[0m\n",
      "[ 92%] \u001b[32mBuilding CXX object CMakeFiles/hanalearn.dir/rlcc/utils.cc.o\u001b[0m\n",
      "[ 92%] \u001b[32mBuilding CXX object rela/CMakeFiles/rela.dir/pybind.cc.o\u001b[0m\n",
      "[ 92%] \u001b[32mBuilding CXX object CMakeFiles/hanalearn.dir/rlcc/clone_data_generator.cc.o\u001b[0m\n",
      "[ 92%] \u001b[32mBuilding CXX object CMakeFiles/hanalearn.dir/rlcc/r2d2_actor.cc.o\u001b[0m\n",
      "[ 92%] \u001b[32mBuilding CXX object CMakeFiles/hanalearn.dir/rlcc/pybind.cc.o\u001b[0m\n",
      "\u001b[01m\u001b[K/notebooks/off-belief-small/rlcc/r2d2_actor.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid R2D2Actor::observeBeforeAct(const HanabiEnv&)\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K/notebooks/off-belief-small/rlcc/r2d2_actor.cc:222:28:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[KcardCount\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      "     auto [privV0, cardCount\u001b[01;35m\u001b[K]\u001b[m\u001b[K =\n",
      "                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "[ 96%] \u001b[32m\u001b[1mLinking CXX shared module rela.cpython-37m-x86_64-linux-gnu.so\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX shared module hanalearn.cpython-37m-x86_64-linux-gnu.so\u001b[0m\n",
      "[100%] Built target rela\n",
      "[100%] Built target hanalearn\n"
     ]
    }
   ],
   "source": [
    "%cd /notebooks/off-belief-small/\n",
    "!rm -rf build\n",
    "!mkdir build\n",
    "%cd build\n",
    "!cmake ..\n",
    "!make -j10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "9839be2f-b884-41ff-818c-41d35740f9c5",
     "kernelId": "5e510cf9-b812-45aa-981c-e863398f7a6f"
    }
   },
   "source": [
    "## Perform reinforcement learning\n",
    "\n",
    "* **iql.sh**\n",
    "```c\n",
    "num_thread:          80   -> 8 // (quad-core CPU)\n",
    "batchsize:           128  -> 64\n",
    "act_device:          c:1  -> c:0 // (only 1 GPU)\n",
    "belief_device:       c:1  -> c:0\n",
    "rnn_hid_dim:         512  -> 256 // (reduced complexity for Hanabi-Small)\n",
    "```\n",
    "\n",
    "* **belief_obl0.sh**\n",
    "```c\n",
    "num_thread:          80   -> 8 // (quad-core CPU)\n",
    "num_game_per_thread: 80   -> 40 // (reduce CPU load)\n",
    "batchsize:           128  -> 64\n",
    "hid_dim:             512  -> 256 // (reduced complexity for Hanabi-Small)\n",
    "act_device:          c:1  -> c:0 // (only 1 GPU)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T01:59:15.051015Z",
     "iopub.status.busy": "2022-05-10T01:59:15.050716Z",
     "iopub.status.idle": "2022-05-10T01:59:15.057727Z",
     "shell.execute_reply": "2022-05-10T01:59:15.056672Z",
     "shell.execute_reply.started": "2022-05-10T01:59:15.050961Z"
    },
    "gradient": {
     "editing": false,
     "execution_count": 14,
     "id": "c7757ea6-da8e-4ace-9745-3411eafac18a",
     "kernelId": "5e510cf9-b812-45aa-981c-e863398f7a6f",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/off-belief-small/pyhanabi\n"
     ]
    }
   ],
   "source": [
    "%cd ../pyhanabi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T02:02:47.580453Z",
     "iopub.status.busy": "2022-05-10T02:02:47.580108Z",
     "iopub.status.idle": "2022-05-10T02:02:50.170124Z",
     "shell.execute_reply": "2022-05-10T02:02:50.169232Z",
     "shell.execute_reply.started": "2022-05-10T02:02:47.580395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright (c) Facebook, Inc. and its affiliates.\n",
      "# All rights reserved.\n",
      "#\n",
      "# This source code is licensed under the license found in the\n",
      "# LICENSE file in the root directory of this source tree.\n",
      "#\n",
      "#!/bin/bash\n",
      "python selfplay.py \\\n",
      "       --save_dir /notebooks/models \\\n",
      "       --num_thread 8 \\\n",
      "       --num_game_per_thread 80 \\\n",
      "       --method iql \\\n",
      "       --sad 0 \\\n",
      "       --lr 6.25e-05 \\\n",
      "       --eps 1.5e-05 \\\n",
      "       --gamma 0.999 \\\n",
      "       --seed 2254257 \\\n",
      "       --burn_in_frames 10000 \\\n",
      "       --replay_buffer_size 100000 \\\n",
      "       --batchsize 64 \\\n",
      "       --epoch_len 1000 \\\n",
      "       --num_epoch 2000 \\\n",
      "       --num_player 2 \\\n",
      "       --net lstm \\\n",
      "       --num_lstm_layer 2 \\\n",
      "       --multi_step 3 \\\n",
      "       --train_device cuda:0 \\\n",
      "       --act_device cuda:0 \\\n",
      "       --belief_device cuda:0 \\\n",
      "       --rnn_hid_dim 256 \\\n"
     ]
    }
   ],
   "source": [
    "# iql\n",
    "!cp -n scripts/iql.sh scripts/iql.sh.old\n",
    "!sed -r -e \"s/(--save_dir)[^\\\\]*/\\\\1 \\\\/notebooks\\\\/models /g\" \\\\\n",
    "        -e \"s/(--num_thread)[^\\\\]*/\\\\1 8 /g\" \\\\\n",
    "        -e \"s/(--batchsize)[^\\\\]*/\\\\1 64 /g\" \\\\\n",
    "        -e \"s/(--act_device)[^\\\\]*/\\\\1 cuda:0 /g\" \\\\\n",
    "        scripts/iql.sh.old > scripts/iql.sh\n",
    "!echo \"       --belief_device cuda:0 \\\\\" >> scripts/iql.sh\n",
    "!echo \"       --rnn_hid_dim 256 \\\\\" >> scripts/iql.sh\n",
    "!cat scripts/iql.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T02:04:32.398446Z",
     "iopub.status.busy": "2022-05-10T02:04:32.398150Z",
     "iopub.status.idle": "2022-05-10T02:04:34.097142Z",
     "shell.execute_reply": "2022-05-10T02:04:34.096078Z",
     "shell.execute_reply.started": "2022-05-10T02:04:32.398401Z"
    },
    "gradient": {
     "editing": false,
     "execution_count": 15,
     "id": "760c7a03-1e9a-4456-ba7e-b088ad67b996",
     "kernelId": "5e510cf9-b812-45aa-981c-e863398f7a6f",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright (c) Facebook, Inc. and its affiliates.\n",
      "# All rights reserved.\n",
      "#\n",
      "# This source code is licensed under the license found in the\n",
      "# LICENSE file in the root directory of this source tree.\n",
      "#\n",
      "#!/bin/bash\n",
      "python train_belief.py \\\n",
      "       --save_dir /notebooks/belief_obl0 \\\n",
      "       --num_thread 8 \\\n",
      "       --num_game_per_thread 40 \\\n",
      "       --batchsize 64 \\\n",
      "       --lr 6.25e-05 \\\n",
      "       --eps 1.5e-05 \\\n",
      "       --grad_clip 5 \\\n",
      "       --hid_dim 256 \\\n",
      "       --burn_in_frames 10000 \\\n",
      "       --replay_buffer_size 100000 \\\n",
      "       --epoch_len 1000 \\\n",
      "       --num_epoch 500 \\\n",
      "       --train_device cuda:0 \\\n",
      "       --act_device cuda:0 \\\n",
      "       --explore 1 \\\n",
      "       --policy exps/iql/model0.pthw \\\n",
      "       --seed 2254257 \\\n",
      "       --num_player 2 \\\n",
      "       --shuffle_color 0 \\\n",
      "       --rand 1 \\\n"
     ]
    }
   ],
   "source": [
    "# belief\n",
    "!cp -n scripts/belief_obl0.sh scripts/belief_obl0.sh.old\n",
    "!sed -r -e \"s/(--save_dir)[^\\\\]*/\\\\1 \\\\/notebooks\\\\/belief_obl0 /g\" \\\\\n",
    "        -e \"s/(--num_thread)[^\\\\]*/\\\\1 8 /g\" \\\\\n",
    "        -e \"s/(--num_game_per_thread)[^\\\\]*/\\\\1 40 /g\" \\\\\n",
    "        -e \"s/(--batchsize)[^\\\\]*/\\\\1 64 /g\" \\\\\n",
    "        -e \"s/(--hid_dim)[^\\\\]*/\\\\1 256 /g\" \\\\\n",
    "        -e \"s/(--act_device)[^\\\\]*/\\\\1 cuda:0 /g\" \\\\\n",
    "        scripts/belief_obl0.sh.old > scripts/belief_obl0.sh\n",
    "!cat scripts/belief_obl0.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 17,
     "id": "732f3eb9-9723-4265-a6ea-bfc4fcf94349",
     "kernelId": "5e510cf9-b812-45aa-981c-e863398f7a6f",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'act_device': 'cuda:0',\n",
      " 'batchsize': 64,\n",
      " 'burn_in_frames': 10000,\n",
      " 'clone_bot': 0,\n",
      " 'dataset': '',\n",
      " 'epoch_len': 1000,\n",
      " 'eps': 1.5e-05,\n",
      " 'explore': 1,\n",
      " 'fc_only': 0,\n",
      " 'grad_clip': 5.0,\n",
      " 'hid_dim': 256,\n",
      " 'inf_data_loop': 0,\n",
      " 'load_model': 0,\n",
      " 'lr': 6.25e-05,\n",
      " 'max_len': 80,\n",
      " 'num_epoch': 500,\n",
      " 'num_game_per_thread': 40,\n",
      " 'num_player': 2,\n",
      " 'num_thread': 8,\n",
      " 'policy': 'exps/iql/model0.pthw',\n",
      " 'prefetch': 3,\n",
      " 'rand': 1,\n",
      " 'replay_buffer_size': 100000,\n",
      " 'save_dir': '/notebooks/belief_obl0',\n",
      " 'seed': 2254257,\n",
      " 'shuffle_color': 0,\n",
      " 'train_device': 'cuda:0'}\n",
      "loading file from:  exps/iql/model0.pthw\n",
      "feature_size: (191, 171, 151)\n",
      "explore eps: [1]\n",
      "avg explore eps: 1.0\n",
      "no boltzmann act\n",
      "ActGroup created\n",
      "Finished creating 8 threads with 320 games and 8 actors\n",
      "warming up replay buffer: 0\n",
      "warming up replay buffer: 1374\n",
      "warming up replay buffer: 3002\n",
      "warming up replay buffer: 4571\n",
      "warming up replay buffer: 6022\n",
      "warming up replay buffer: 7477\n",
      "warming up replay buffer: 8903\n",
      "Success, Done\n",
      "=======================\n",
      "beginning of epoch:  0\n",
      "available: 23.357 GB, used: 5.344 GB, free: 15.839 GB\n",
      "EPOCH: 0\n",
      "mean score: 0.00\n",
      "Speed: train: 1772.8, buffer_add: 1484.1, buffer_size: 53578\n",
      "Total Time: 0H 00M 36S, 36s\n",
      "Total Sample: train: 64K, buffer: 53.578K\n",
      "[0] Time spent = 36.69 s\n",
      "0:grad_norm  [1000]: avg:   0.7542, min:   0.2606[ 487], max:   2.1536[ 934]\n",
      "0:loss       [1000]: avg:   9.3913, min:   6.9238[ 858], max:  12.5939[ 110]\n",
      "0:xent_pred  [1000]: avg:   2.2674, min:   2.1745[ 983], max:   2.3579[ 691]\n",
      "0:xent_v0    [1000]: avg:   1.9134, min:   1.7831[ 996], max:   2.0811[ 758]\n",
      "===================\n",
      "beginning of epoch:  1\n",
      "available: 17.349 GB, used: 11.351 GB, free: 9.821 GB\n",
      "EPOCH: 1\n",
      "mean score: 0.00\n",
      "Speed: train: 1734.5, buffer_add: 1160.1, buffer_size: 96383\n",
      "Total Time: 0H 01M 13S, 73s\n",
      "Total Sample: train: 128K, buffer: 96.383K\n",
      "[1] Time spent = 37.89 s\n",
      "1:grad_norm  [1000]: avg:   1.5738, min:   0.5369[ 105], max:   5.2966[ 985]\n",
      "1:loss       [1000]: avg:   9.2065, min:   6.3376[ 100], max:  13.0992[  34]\n",
      "1:xent_pred  [1000]: avg:   2.2294, min:   2.1241[ 878], max:   2.3204[ 116]\n",
      "1:xent_v0    [1000]: avg:   1.9115, min:   1.7767[ 152], max:   2.1131[ 262]\n",
      "===================\n",
      "beginning of epoch:  2\n",
      "available: 11.483 GB, used: 17.218 GB, free: 3.954 GB\n",
      "EPOCH: 2\n",
      "mean score: 0.00\n",
      "Speed: train: 1761.0, buffer_add: 1108.2, buffer_size: 100035\n",
      "Total Time: 0H 01M 49S, 109s\n",
      "Total Sample: train: 192K, buffer: 136.659K\n",
      "[2] Time spent = 36.92 s\n",
      "2:grad_norm  [1000]: avg:   3.2388, min:   1.0441[ 202], max:   9.7030[ 843]\n",
      "2:loss       [1000]: avg:   8.8327, min:   6.0350[ 733], max:  11.9417[ 258]\n",
      "2:xent_pred  [1000]: avg:   2.1797, min:   2.0591[ 784], max:   2.2964[ 139]\n",
      "2:xent_v0    [1000]: avg:   1.9118, min:   1.7489[ 493], max:   2.0608[ 175]\n",
      "===================\n",
      "beginning of epoch:  3\n",
      "available: 7.278 GB, used: 21.422 GB, free: 226.625 MB\n",
      "EPOCH: 3\n",
      "mean score: 0.00\n",
      "Speed: train: 1850.7, buffer_add: 1051.3, buffer_size: 100027\n",
      "Total Time: 0H 02M 23S, 143s\n",
      "Total Sample: train: 256K, buffer: 173.016K\n",
      "[3] Time spent = 35.38 s\n",
      "3:grad_norm  [1000]: avg:   4.9941, min:   1.6186[  28], max:  14.3920[ 815]\n",
      "3:loss       [1000]: avg:   8.4591, min:   5.7290[ 803], max:  11.6875[ 159]\n",
      "3:xent_pred  [1000]: avg:   2.1206, min:   1.9861[ 540], max:   2.2379[  26]\n",
      "3:xent_v0    [1000]: avg:   1.9135, min:   1.7776[ 540], max:   2.0649[ 908]\n",
      "===================\n",
      "beginning of epoch:  4\n",
      "available: 5.790 GB, used: 22.906 GB, free: 214.773 MB\n",
      "EPOCH: 4\n",
      "mean score: 0.00\n",
      "Speed: train: 1795.6, buffer_add: 1049.1, buffer_size: 100025\n",
      "Total Time: 0H 02M 59S, 179s\n",
      "Total Sample: train: 320K, buffer: 210.41K\n",
      "[4] Time spent = 36.42 s\n",
      "4:grad_norm  [1000]: avg:   7.0061, min:   2.5512[ 617], max:  17.7172[ 532]\n",
      "4:loss       [1000]: avg:   8.0618, min:   5.7952[ 617], max:  10.4818[ 775]\n",
      "4:xent_pred  [1000]: avg:   2.0723, min:   1.9463[ 681], max:   2.2061[ 899]\n",
      "4:xent_v0    [1000]: avg:   1.9164, min:   1.7453[  91], max:   2.1163[ 899]\n",
      "===================\n",
      "beginning of epoch:  5\n",
      "available: 4.328 GB, used: 24.359 GB, free: 252.762 MB\n",
      "EPOCH: 5\n",
      "mean score: 0.00\n",
      "Speed: train: 1769.1, buffer_add: 1047.4, buffer_size: 100032\n",
      "Total Time: 0H 03M 35S, 215s\n",
      "Total Sample: train: 384K, buffer: 248.3K\n",
      "[5] Time spent = 37.13 s\n",
      "5:grad_norm  [1000]: avg:   8.0740, min:   2.9837[ 347], max:  22.4517[ 306]\n",
      "5:loss       [1000]: avg:   7.9181, min:   5.5323[ 684], max:  10.4946[ 524]\n",
      "5:xent_pred  [1000]: avg:   2.0463, min:   1.9118[ 287], max:   2.1736[ 160]\n",
      "5:xent_v0    [1000]: avg:   1.9158, min:   1.7631[ 496], max:   2.0693[ 392]\n",
      "===================\n",
      "beginning of epoch:  6\n",
      "available: 2.926 GB, used: 25.754 GB, free: 234.398 MB\n",
      "EPOCH: 6\n",
      "mean score: 0.00\n",
      "Speed: train: 1851.7, buffer_add: 1057.8, buffer_size: 99998\n",
      "Total Time: 0H 04M 10S, 250s\n",
      "Total Sample: train: 448K, buffer: 284.862K\n",
      "[6] Time spent = 35.37 s\n",
      "6:grad_norm  [1000]: avg:   7.8933, min:   3.0728[ 687], max:  20.9060[ 659]\n",
      "6:loss       [1000]: avg:   7.7896, min:   5.3448[ 423], max:  10.2827[ 516]\n",
      "6:xent_pred  [1000]: avg:   2.0300, min:   1.8768[ 930], max:   2.1579[  45]\n",
      "6:xent_v0    [1000]: avg:   1.9164, min:   1.7715[ 112], max:   2.0409[ 770]\n",
      "===================\n",
      "beginning of epoch:  7\n",
      "available: 2.800 GB, used: 25.880 GB, free: 308.102 MB\n",
      "EPOCH: 7\n",
      "mean score: 0.00\n",
      "Speed: train: 1848.1, buffer_add: 1038.6, buffer_size: 100007\n",
      "Total Time: 0H 04M 44S, 284s\n",
      "Total Sample: train: 512K, buffer: 320.828K\n",
      "[7] Time spent = 35.18 s\n",
      "7:grad_norm  [1000]: avg:   8.1784, min:   3.2290[ 415], max:  22.6263[ 594]\n",
      "7:loss       [1000]: avg:   7.7733, min:   5.6328[ 913], max:  10.7061[  85]\n",
      "7:xent_pred  [1000]: avg:   2.0178, min:   1.8709[ 707], max:   2.1881[ 640]\n",
      "7:xent_v0    [1000]: avg:   1.9148, min:   1.7484[ 604], max:   2.0700[ 699]\n",
      "===================\n",
      "beginning of epoch:  8\n",
      "available: 2.796 GB, used: 25.885 GB, free: 312.148 MB\n",
      "EPOCH: 8\n",
      "mean score: 0.00\n",
      "Speed: train: 1815.2, buffer_add: 1031.4, buffer_size: 100057\n",
      "Total Time: 0H 05M 20S, 320s\n",
      "Total Sample: train: 576K, buffer: 357.192K\n",
      "[8] Time spent = 36.04 s\n",
      "8:grad_norm  [1000]: avg:   7.7281, min:   3.2933[ 447], max:  22.1454[ 739]\n",
      "8:loss       [1000]: avg:   7.6896, min:   5.4841[ 550], max:  11.0991[  74]\n",
      "8:xent_pred  [1000]: avg:   2.0103, min:   1.8697[ 736], max:   2.1849[ 573]\n",
      "8:xent_v0    [1000]: avg:   1.9182, min:   1.7725[ 649], max:   2.0606[ 382]\n",
      "===================\n",
      "beginning of epoch:  9\n",
      "available: 2.803 GB, used: 25.883 GB, free: 338.500 MB\n",
      "EPOCH: 9\n",
      "mean score: 0.00\n",
      "Speed: train: 1838.8, buffer_add: 1043.8, buffer_size: 100021\n",
      "Total Time: 0H 05M 54S, 354s\n",
      "Total Sample: train: 640K, buffer: 393.522K\n",
      "[9] Time spent = 35.64 s\n",
      "9:grad_norm  [1000]: avg:   7.7976, min:   3.1159[ 549], max:  21.4476[ 994]\n",
      "9:loss       [1000]: avg:   7.6457, min:   5.6722[ 837], max:  10.2903[ 117]\n",
      "9:xent_pred  [1000]: avg:   2.0014, min:   1.8555[ 557], max:   2.1920[ 255]\n",
      "9:xent_v0    [1000]: avg:   1.9163, min:   1.7694[ 291], max:   2.1358[ 255]\n",
      "===================\n",
      "beginning of epoch:  10\n",
      "available: 2.794 GB, used: 25.892 GB, free: 359.793 MB\n",
      "EPOCH: 10\n",
      "mean score: 0.00\n",
      "Speed: train: 1843.4, buffer_add: 1031.8, buffer_size: 100019\n",
      "Total Time: 0H 06M 29S, 389s\n",
      "Total Sample: train: 704K, buffer: 429.347K\n",
      "[10] Time spent = 35.53 s\n",
      "10:grad_norm [1000]: avg:   7.1874, min:   3.3173[ 536], max:  18.7901[ 658]\n",
      "10:loss      [1000]: avg:   7.6010, min:   5.4952[ 939], max:  10.1414[ 985]\n",
      "10:xent_pred [1000]: avg:   1.9932, min:   1.8672[ 441], max:   2.1649[ 593]\n",
      "10:xent_v0   [1000]: avg:   1.9158, min:   1.7824[ 658], max:   2.0966[ 593]\n",
      "===================\n",
      "beginning of epoch:  11\n",
      "available: 2.802 GB, used: 25.884 GB, free: 714.848 MB\n",
      "EPOCH: 11\n",
      "mean score: 0.00\n",
      "Speed: train: 1826.3, buffer_add: 1037.9, buffer_size: 100033\n",
      "Total Time: 0H 07M 04S, 424s\n",
      "Total Sample: train: 768K, buffer: 465.72K\n",
      "[11] Time spent = 35.79 s\n",
      "11:grad_norm [1000]: avg:   6.9774, min:   2.9189[ 403], max:  18.1589[ 748]\n",
      "11:loss      [1000]: avg:   7.5624, min:   5.7121[ 150], max:  10.6821[ 157]\n",
      "11:xent_pred [1000]: avg:   1.9872, min:   1.8471[ 731], max:   2.1654[ 447]\n",
      "11:xent_v0   [1000]: avg:   1.9128, min:   1.7603[ 113], max:   2.0791[ 447]\n",
      "===================\n",
      "beginning of epoch:  12\n",
      "available: 2.790 GB, used: 25.895 GB, free: 837.711 MB\n",
      "EPOCH: 12\n",
      "mean score: 0.00\n",
      "Speed: train: 1841.1, buffer_add: 1023.4, buffer_size: 100054\n",
      "Total Time: 0H 07M 39S, 459s\n",
      "Total Sample: train: 832K, buffer: 501.295K\n",
      "[12] Time spent = 35.60 s\n",
      "12:grad_norm [1000]: avg:   6.8490, min:   2.8129[ 173], max:  16.5106[ 415]\n",
      "12:loss      [1000]: avg:   7.5825, min:   5.5586[ 382], max:  10.0100[ 212]\n",
      "12:xent_pred [1000]: avg:   1.9824, min:   1.8281[ 695], max:   2.1402[  47]\n",
      "12:xent_v0   [1000]: avg:   1.9126, min:   1.7694[ 254], max:   2.0717[  47]\n",
      "===================\n",
      "beginning of epoch:  13\n",
      "available: 2.799 GB, used: 25.885 GB, free: 1.273 GB\n",
      "EPOCH: 13\n",
      "mean score: 0.00\n",
      "Speed: train: 1847.8, buffer_add: 1034.4, buffer_size: 100034\n",
      "Total Time: 0H 08M 14S, 494s\n",
      "Total Sample: train: 896K, buffer: 537.121K\n",
      "[13] Time spent = 35.50 s\n",
      "13:grad_norm [1000]: avg:   6.5004, min:   3.2321[ 276], max:  19.2328[  19]\n",
      "13:loss      [1000]: avg:   7.5323, min:   5.7064[ 246], max:   9.7396[ 136]\n",
      "13:xent_pred [1000]: avg:   1.9795, min:   1.8454[ 826], max:   2.1385[ 882]\n",
      "13:xent_v0   [1000]: avg:   1.9125, min:   1.7678[ 180], max:   2.0725[ 882]\n",
      "===================\n",
      "beginning of epoch:  14\n",
      "available: 2.790 GB, used: 25.896 GB, free: 1.289 GB\n",
      "EPOCH: 14\n",
      "mean score: 0.00\n",
      "Speed: train: 1820.3, buffer_add: 1035.8, buffer_size: 100023\n",
      "Total Time: 0H 08M 49S, 529s\n",
      "Total Sample: train: 960K, buffer: 573.537K\n",
      "[14] Time spent = 35.86 s\n",
      "14:grad_norm [1000]: avg:   6.2527, min:   2.0487[ 529], max:  15.4458[ 523]\n",
      "14:loss      [1000]: avg:   7.5356, min:   4.9989[ 529], max:   9.9080[ 732]\n",
      "14:xent_pred [1000]: avg:   1.9774, min:   1.8260[ 847], max:   2.1543[ 535]\n",
      "14:xent_v0   [1000]: avg:   1.9135, min:   1.7618[ 847], max:   2.0716[ 606]\n",
      "===================\n",
      "beginning of epoch:  15\n",
      "available: 2.795 GB, used: 25.891 GB, free: 1.349 GB\n",
      "EPOCH: 15\n",
      "mean score: 0.00\n",
      "Speed: train: 1809.4, buffer_add: 1027.6, buffer_size: 100021\n",
      "Total Time: 0H 09M 24S, 564s\n",
      "Total Sample: train: 1.024M, buffer: 609.885K\n",
      "[15] Time spent = 36.18 s\n",
      "15:grad_norm [1000]: avg:   6.1683, min:   3.1009[ 456], max:  18.3116[ 153]\n",
      "15:loss      [1000]: avg:   7.5054, min:   5.2682[ 970], max:   9.7684[ 443]\n",
      "15:xent_pred [1000]: avg:   1.9741, min:   1.8381[ 975], max:   2.1251[ 915]\n",
      "15:xent_v0   [1000]: avg:   1.9122, min:   1.7581[ 438], max:   2.0673[ 915]\n",
      "===================\n",
      "beginning of epoch:  16\n",
      "available: 2.796 GB, used: 25.890 GB, free: 1.349 GB\n",
      "EPOCH: 16\n",
      "mean score: 0.00\n",
      "Speed: train: 1835.7, buffer_add: 1038.4, buffer_size: 100016\n",
      "Total Time: 0H 09M 59S, 599s\n",
      "Total Sample: train: 1.088M, buffer: 646.088K\n",
      "[16] Time spent = 35.62 s\n",
      "16:grad_norm [1000]: avg:   6.0256, min:   2.6537[ 790], max:  13.6153[  29]\n",
      "16:loss      [1000]: avg:   7.4558, min:   5.4280[ 790], max:   9.9953[ 511]\n",
      "16:xent_pred [1000]: avg:   1.9739, min:   1.7971[ 857], max:   2.1225[ 726]\n",
      "16:xent_v0   [1000]: avg:   1.9144, min:   1.7054[ 857], max:   2.0754[ 726]\n",
      "===================\n",
      "beginning of epoch:  17\n",
      "available: 2.782 GB, used: 25.905 GB, free: 1.343 GB\n",
      "EPOCH: 17\n",
      "mean score: 0.00\n",
      "Speed: train: 1839.5, buffer_add: 1031.6, buffer_size: 100036\n",
      "Total Time: 0H 10M 34S, 634s\n",
      "Total Sample: train: 1.152M, buffer: 681.978K\n",
      "[17] Time spent = 35.71 s\n",
      "17:grad_norm [1000]: avg:   5.9787, min:   2.6547[ 487], max:  15.2291[ 482]\n",
      "17:loss      [1000]: avg:   7.4875, min:   5.5070[ 427], max:   9.9747[ 763]\n",
      "17:xent_pred [1000]: avg:   1.9693, min:   1.8265[  14], max:   2.1345[ 527]\n",
      "17:xent_v0   [1000]: avg:   1.9128, min:   1.7525[  14], max:   2.0889[ 527]\n",
      "===================\n",
      "beginning of epoch:  18\n",
      "available: 2.799 GB, used: 25.887 GB, free: 1.359 GB\n",
      "EPOCH: 18\n",
      "mean score: 0.00\n",
      "Speed: train: 1846.0, buffer_add: 1028.0, buffer_size: 100016\n",
      "Total Time: 0H 11M 09S, 669s\n",
      "Total Sample: train: 1.216M, buffer: 717.618K\n",
      "[18] Time spent = 35.50 s\n",
      "18:grad_norm [1000]: avg:   5.9065, min:   2.6328[ 660], max:  15.3595[ 900]\n",
      "18:loss      [1000]: avg:   7.4859, min:   5.4335[ 771], max:  10.4632[ 488]\n",
      "18:xent_pred [1000]: avg:   1.9671, min:   1.7961[ 360], max:   2.1348[ 789]\n",
      "18:xent_v0   [1000]: avg:   1.9125, min:   1.7343[ 360], max:   2.0696[ 839]\n",
      "===================\n",
      "beginning of epoch:  19\n",
      "available: 2.797 GB, used: 25.891 GB, free: 1.459 GB\n",
      "EPOCH: 19\n",
      "mean score: 0.00\n",
      "Speed: train: 1818.3, buffer_add: 1048.6, buffer_size: 100058\n",
      "Total Time: 0H 11M 44S, 704s\n",
      "Total Sample: train: 1.28M, buffer: 754.525K\n",
      "[19] Time spent = 35.47 s\n",
      "19:grad_norm [1000]: avg:   5.7882, min:   2.5155[ 107], max:  13.9548[ 675]\n",
      "19:loss      [1000]: avg:   7.5062, min:   5.4665[ 143], max:   9.7624[ 222]\n",
      "19:xent_pred [1000]: avg:   1.9629, min:   1.8264[ 408], max:   2.1183[ 236]\n",
      "19:xent_v0   [1000]: avg:   1.9096, min:   1.7729[ 408], max:   2.0867[ 236]\n",
      "===================\n",
      "beginning of epoch:  20\n",
      "available: 2.800 GB, used: 25.889 GB, free: 1.460 GB\n",
      "EPOCH: 20\n",
      "mean score: 0.00\n",
      "Speed: train: 1829.5, buffer_add: 1011.8, buffer_size: 100053\n",
      "Total Time: 0H 12M 19S, 739s\n",
      "Total Sample: train: 1.344M, buffer: 789.921K\n",
      "[20] Time spent = 35.64 s\n",
      "20:grad_norm [1000]: avg:   5.6282, min:   2.9092[ 914], max:  14.4088[  75]\n",
      "20:loss      [1000]: avg:   7.4528, min:   5.5671[ 829], max:   9.7221[ 499]\n",
      "20:xent_pred [1000]: avg:   1.9649, min:   1.7922[ 424], max:   2.1193[ 715]\n",
      "20:xent_v0   [1000]: avg:   1.9140, min:   1.7255[ 424], max:   2.0599[ 715]\n",
      "===================\n",
      "beginning of epoch:  21\n",
      "available: 2.795 GB, used: 25.894 GB, free: 1.488 GB\n",
      "EPOCH: 21\n",
      "mean score: 0.00\n",
      "Speed: train: 1808.8, buffer_add: 1025.9, buffer_size: 100014\n",
      "Total Time: 0H 12M 54S, 774s\n",
      "Total Sample: train: 1.408M, buffer: 826.22K\n",
      "[21] Time spent = 36.27 s\n",
      "21:grad_norm [1000]: avg:   5.5691, min:   2.9581[ 141], max:  12.8911[ 821]\n",
      "21:loss      [1000]: avg:   7.4286, min:   5.4037[ 997], max:  10.0718[ 220]\n",
      "21:xent_pred [1000]: avg:   1.9654, min:   1.8075[ 464], max:   2.0911[ 346]\n",
      "21:xent_v0   [1000]: avg:   1.9159, min:   1.7723[ 464], max:   2.0426[ 315]\n",
      "===================\n",
      "beginning of epoch:  22\n",
      "available: 2.804 GB, used: 25.885 GB, free: 1.495 GB\n",
      "EPOCH: 22\n",
      "mean score: 0.00\n",
      "Speed: train: 1844.1, buffer_add: 1037.3, buffer_size: 100028\n",
      "Total Time: 0H 13M 29S, 809s\n",
      "Total Sample: train: 1.472M, buffer: 862.219K\n",
      "[22] Time spent = 35.53 s\n",
      "22:grad_norm [1000]: avg:   5.4929, min:   2.9832[ 806], max:  11.4326[ 772]\n",
      "22:loss      [1000]: avg:   7.4073, min:   5.4727[  74], max:   9.9438[ 757]\n",
      "22:xent_pred [1000]: avg:   1.9618, min:   1.7736[ 178], max:   2.0892[ 179]\n",
      "22:xent_v0   [1000]: avg:   1.9147, min:   1.7349[ 125], max:   2.0431[ 839]\n",
      "===================\n",
      "beginning of epoch:  23\n",
      "available: 2.798 GB, used: 25.891 GB, free: 1.519 GB\n",
      "EPOCH: 23\n",
      "mean score: 0.00\n",
      "Speed: train: 1832.7, buffer_add: 1042.4, buffer_size: 100026\n",
      "Total Time: 0H 14M 04S, 844s\n",
      "Total Sample: train: 1.536M, buffer: 898.62K\n",
      "[23] Time spent = 35.83 s\n",
      "23:grad_norm [1000]: avg:   5.4750, min:   2.8901[ 930], max:  17.0826[  72]\n",
      "23:loss      [1000]: avg:   7.3531, min:   5.4548[ 930], max:  10.3627[ 985]\n",
      "23:xent_pred [1000]: avg:   1.9615, min:   1.8089[ 217], max:   2.1271[ 425]\n",
      "23:xent_v0   [1000]: avg:   1.9155, min:   1.7801[ 725], max:   2.0430[ 382]\n",
      "===================\n",
      "beginning of epoch:  24\n",
      "available: 2.782 GB, used: 25.907 GB, free: 1.518 GB\n",
      "EPOCH: 24\n",
      "mean score: 0.00\n",
      "Speed: train: 1847.3, buffer_add: 1047.2, buffer_size: 100039\n",
      "Total Time: 0H 14M 38S, 878s\n",
      "Total Sample: train: 1.6M, buffer: 934.902K\n",
      "[24] Time spent = 34.90 s\n",
      "24:grad_norm [1000]: avg:   5.3594, min:   2.8550[ 740], max:  12.7068[ 949]\n",
      "24:loss      [1000]: avg:   7.4385, min:   5.6148[ 485], max:   9.7710[ 277]\n",
      "24:xent_pred [1000]: avg:   1.9591, min:   1.8256[ 442], max:   2.1267[ 439]\n",
      "24:xent_v0   [1000]: avg:   1.9141, min:   1.7734[ 442], max:   2.0755[ 623]\n",
      "===================\n",
      "beginning of epoch:  25\n",
      "available: 2.786 GB, used: 25.903 GB, free: 1.520 GB\n",
      "EPOCH: 25\n",
      "mean score: 0.00\n",
      "Speed: train: 1836.0, buffer_add: 1007.5, buffer_size: 100003\n",
      "Total Time: 0H 15M 13S, 913s\n",
      "Total Sample: train: 1.664M, buffer: 970.023K\n",
      "[25] Time spent = 35.21 s\n",
      "25:grad_norm [1000]: avg:   5.5306, min:   2.9761[ 274], max:  11.4297[ 212]\n",
      "25:loss      [1000]: avg:   7.4582, min:   5.6269[ 506], max:   9.3243[ 676]\n",
      "25:xent_pred [1000]: avg:   1.9546, min:   1.7951[   7], max:   2.1068[ 207]\n",
      "25:xent_v0   [1000]: avg:   1.9105, min:   1.7564[   7], max:   2.0566[  40]\n",
      "===================\n",
      "beginning of epoch:  26\n",
      "available: 2.790 GB, used: 25.900 GB, free: 1.564 GB\n",
      "EPOCH: 26\n",
      "mean score: 0.00\n",
      "Speed: train: 1864.2, buffer_add: 1013.1, buffer_size: 100051\n",
      "Total Time: 0H 15M 48S, 948s\n",
      "Total Sample: train: 1.728M, buffer: 1.005M\n",
      "[26] Time spent = 34.89 s\n",
      "26:grad_norm [1000]: avg:   5.4286, min:   2.7093[ 506], max:  11.5573[ 442]\n",
      "26:loss      [1000]: avg:   7.4340, min:   5.4423[ 687], max:   9.7924[ 235]\n",
      "26:xent_pred [1000]: avg:   1.9536, min:   1.8109[ 733], max:   2.1036[ 855]\n",
      "26:xent_v0   [1000]: avg:   1.9109, min:   1.7491[ 733], max:   2.0704[ 855]\n",
      "===================\n",
      "beginning of epoch:  27\n",
      "available: 2.792 GB, used: 25.896 GB, free: 1.614 GB\n",
      "EPOCH: 27\n",
      "mean score: 0.00\n",
      "Speed: train: 1860.4, buffer_add: 1017.9, buffer_size: 100005\n",
      "Total Time: 0H 16M 22S, 982s\n",
      "Total Sample: train: 1.792M, buffer: 1.04M\n",
      "[27] Time spent = 34.90 s\n",
      "27:grad_norm [1000]: avg:   5.3807, min:   2.8733[ 262], max:  11.1053[ 627]\n",
      "27:loss      [1000]: avg:   7.4069, min:   5.5235[ 959], max:  10.4441[ 238]\n",
      "27:xent_pred [1000]: avg:   1.9551, min:   1.7807[ 681], max:   2.0838[ 107]\n",
      "27:xent_v0   [1000]: avg:   1.9141, min:   1.7327[ 681], max:   2.0444[ 320]\n",
      "===================\n",
      "beginning of epoch:  28\n",
      "available: 2.793 GB, used: 25.888 GB, free: 1.735 GB\n",
      "EPOCH: 28\n",
      "mean score: 0.00\n",
      "Speed: train: 1826.5, buffer_add: 1034.8, buffer_size: 100042\n",
      "Total Time: 0H 16M 57S, 1017s\n",
      "Total Sample: train: 1.856M, buffer: 1.076M\n",
      "[28] Time spent = 35.70 s\n",
      "28:grad_norm [1000]: avg:   5.3111, min:   2.7798[ 749], max:  13.1162[ 276]\n",
      "28:loss      [1000]: avg:   7.3959, min:   5.6525[  99], max:   9.8596[ 563]\n",
      "28:xent_pred [1000]: avg:   1.9536, min:   1.8203[ 663], max:   2.0975[ 275]\n",
      "28:xent_v0   [1000]: avg:   1.9141, min:   1.7610[ 663], max:   2.0505[ 929]\n",
      "===================\n",
      "beginning of epoch:  29\n",
      "available: 2.797 GB, used: 25.883 GB, free: 1.781 GB\n",
      "EPOCH: 29\n",
      "mean score: 0.00\n",
      "Speed: train: 1865.4, buffer_add: 1020.8, buffer_size: 100031\n",
      "Total Time: 0H 17M 31S, 1051s\n",
      "Total Sample: train: 1.92M, buffer: 1.111M\n",
      "[29] Time spent = 35.40 s\n",
      "29:grad_norm [1000]: avg:   5.1713, min:   2.7214[ 671], max:   9.9138[ 123]\n",
      "29:loss      [1000]: avg:   7.3566, min:   5.0119[ 671], max:  10.0322[  64]\n",
      "29:xent_pred [1000]: avg:   1.9534, min:   1.7892[ 604], max:   2.1454[ 790]\n",
      "29:xent_v0   [1000]: avg:   1.9142, min:   1.7663[ 604], max:   2.1351[ 790]\n",
      "===================\n",
      "beginning of epoch:  30\n",
      "available: 2.793 GB, used: 25.887 GB, free: 1.865 GB\n",
      "EPOCH: 30\n",
      "mean score: 0.00\n",
      "Speed: train: 1887.7, buffer_add: 1032.1, buffer_size: 100028\n",
      "Total Time: 0H 18M 05S, 1085s\n",
      "Total Sample: train: 1.984M, buffer: 1.146M\n",
      "[30] Time spent = 34.70 s\n",
      "30:grad_norm [1000]: avg:   5.0339, min:   2.6011[ 602], max:  10.5716[ 348]\n",
      "30:loss      [1000]: avg:   7.3377, min:   4.8728[ 339], max:  10.3232[ 604]\n",
      "30:xent_pred [1000]: avg:   1.9536, min:   1.7972[ 640], max:   2.1004[ 118]\n",
      "30:xent_v0   [1000]: avg:   1.9159, min:   1.7640[ 640], max:   2.0702[ 125]\n",
      "===================\n",
      "beginning of epoch:  31\n",
      "available: 2.798 GB, used: 25.883 GB, free: 2.001 GB\n",
      "EPOCH: 31\n",
      "mean score: 0.00\n",
      "Speed: train: 1871.5, buffer_add: 1020.5, buffer_size: 100039\n",
      "Total Time: 0H 18M 39S, 1119s\n",
      "Total Sample: train: 2.048M, buffer: 1.181M\n",
      "[31] Time spent = 34.46 s\n",
      "31:grad_norm [1000]: avg:   5.0243, min:   2.4856[ 834], max:   9.6462[ 196]\n",
      "31:loss      [1000]: avg:   7.3651, min:   5.2248[ 240], max:   9.9112[ 276]\n",
      "31:xent_pred [1000]: avg:   1.9508, min:   1.7723[ 105], max:   2.1075[  57]\n",
      "31:xent_v0   [1000]: avg:   1.9127, min:   1.7368[ 105], max:   2.0587[  57]\n",
      "===================\n",
      "beginning of epoch:  32\n",
      "available: 2.785 GB, used: 25.896 GB, free: 2.009 GB\n",
      "EPOCH: 32\n",
      "mean score: 0.00\n",
      "Speed: train: 1795.9, buffer_add: 1006.0, buffer_size: 100010\n",
      "Total Time: 0H 19M 15S, 1155s\n",
      "Total Sample: train: 2.112M, buffer: 1.217M\n",
      "[32] Time spent = 36.55 s\n",
      "32:grad_norm [1000]: avg:   4.9482, min:   2.5381[ 289], max:   9.9000[ 463]\n",
      "32:loss      [1000]: avg:   7.3123, min:   5.3019[ 615], max:   9.6824[ 692]\n",
      "32:xent_pred [1000]: avg:   1.9524, min:   1.8021[ 219], max:   2.0935[ 276]\n",
      "32:xent_v0   [1000]: avg:   1.9156, min:   1.7656[ 219], max:   2.0767[ 276]\n",
      "===================\n",
      "beginning of epoch:  33\n",
      "available: 2.791 GB, used: 25.889 GB, free: 2.042 GB\n",
      "EPOCH: 33\n",
      "mean score: 0.00\n",
      "Speed: train: 1838.9, buffer_add: 1033.1, buffer_size: 100028\n",
      "Total Time: 0H 19M 50S, 1190s\n",
      "Total Sample: train: 2.176M, buffer: 1.253M\n",
      "[33] Time spent = 35.49 s\n",
      "33:grad_norm [1000]: avg:   4.9121, min:   2.3381[ 549], max:   9.4224[ 768]\n",
      "33:loss      [1000]: avg:   7.2725, min:   5.3435[ 832], max:   9.9405[ 570]\n",
      "33:xent_pred [1000]: avg:   1.9523, min:   1.8206[ 823], max:   2.1154[ 531]\n",
      "33:xent_v0   [1000]: avg:   1.9154, min:   1.7698[ 823], max:   2.0626[ 531]\n",
      "===================\n",
      "beginning of epoch:  34\n",
      "available: 2.797 GB, used: 25.883 GB, free: 2.067 GB\n",
      "EPOCH: 34\n",
      "mean score: 0.00\n",
      "Speed: train: 1857.7, buffer_add: 1019.5, buffer_size: 100008\n",
      "Total Time: 0H 20M 24S, 1224s\n",
      "Total Sample: train: 2.24M, buffer: 1.288M\n",
      "[34] Time spent = 34.80 s\n",
      "34:grad_norm [1000]: avg:   4.9730, min:   2.6490[ 379], max:   9.4761[ 956]\n",
      "34:loss      [1000]: avg:   7.3707, min:   4.8415[ 183], max:   9.8336[ 882]\n",
      "34:xent_pred [1000]: avg:   1.9500, min:   1.8340[ 998], max:   2.0831[ 601]\n",
      "34:xent_v0   [1000]: avg:   1.9149, min:   1.8004[ 921], max:   2.0498[ 777]\n",
      "===================\n",
      "beginning of epoch:  35\n",
      "available: 2.797 GB, used: 25.883 GB, free: 2.112 GB\n",
      "EPOCH: 35\n",
      "mean score: 0.00\n",
      "Speed: train: 1873.5, buffer_add: 1016.4, buffer_size: 100009\n",
      "Total Time: 0H 20M 58S, 1258s\n",
      "Total Sample: train: 2.304M, buffer: 1.323M\n",
      "[35] Time spent = 34.44 s\n",
      "35:grad_norm [1000]: avg:   4.8907, min:   2.2851[ 357], max:  11.0931[ 985]\n",
      "35:loss      [1000]: avg:   7.3157, min:   5.0666[ 357], max:   9.4234[ 393]\n",
      "35:xent_pred [1000]: avg:   1.9510, min:   1.8093[ 479], max:   2.0909[ 613]\n",
      "35:xent_v0   [1000]: avg:   1.9158, min:   1.7643[ 153], max:   2.0579[ 613]\n",
      "===================\n",
      "beginning of epoch:  36\n",
      "available: 2.786 GB, used: 25.894 GB, free: 2.081 GB\n",
      "EPOCH: 36\n",
      "mean score: 0.00\n",
      "Speed: train: 1907.9, buffer_add: 978.3, buffer_size: 100027\n",
      "Total Time: 0H 21M 32S, 1292s\n",
      "Total Sample: train: 2.368M, buffer: 1.355M\n",
      "[36] Time spent = 34.08 s\n",
      "36:grad_norm [1000]: avg:   4.8894, min:   2.5630[ 968], max:   9.1109[ 582]\n",
      "36:loss      [1000]: avg:   7.3384, min:   5.5006[ 678], max:   9.5950[ 699]\n",
      "36:xent_pred [1000]: avg:   1.9490, min:   1.7879[  55], max:   2.1093[ 714]\n",
      "36:xent_v0   [1000]: avg:   1.9150, min:   1.7665[  55], max:   2.0747[ 379]\n",
      "===================\n",
      "beginning of epoch:  37\n",
      "available: 2.746 GB, used: 25.915 GB, free: 2.420 GB\n",
      "EPOCH: 37\n",
      "mean score: 0.00\n",
      "Speed: train: 1839.2, buffer_add: 994.3, buffer_size: 100016\n",
      "Total Time: 0H 22M 07S, 1327s\n",
      "Total Sample: train: 2.432M, buffer: 1.39M\n",
      "[37] Time spent = 35.22 s\n",
      "37:grad_norm [1000]: avg:   4.8792, min:   2.5692[ 533], max:   8.6028[ 640]\n",
      "37:loss      [1000]: avg:   7.3206, min:   5.0830[ 533], max:   9.8324[ 909]\n",
      "37:xent_pred [1000]: avg:   1.9467, min:   1.7766[ 614], max:   2.0882[ 486]\n",
      "37:xent_v0   [1000]: avg:   1.9132, min:   1.7375[ 875], max:   2.0707[ 744]\n",
      "===================\n",
      "beginning of epoch:  38\n",
      "available: 2.782 GB, used: 25.880 GB, free: 2.543 GB\n",
      "EPOCH: 38\n",
      "mean score: 0.00\n",
      "Speed: train: 1853.1, buffer_add: 1012.6, buffer_size: 100021\n",
      "Total Time: 0H 22M 41S, 1361s\n",
      "Total Sample: train: 2.496M, buffer: 1.425M\n",
      "[38] Time spent = 35.22 s\n",
      "38:grad_norm [1000]: avg:   4.7545, min:   2.6071[ 385], max:   9.5470[ 627]\n",
      "38:loss      [1000]: avg:   7.3071, min:   5.3361[ 680], max:   9.6456[ 550]\n",
      "38:xent_pred [1000]: avg:   1.9476, min:   1.7976[ 151], max:   2.0988[ 853]\n",
      "38:xent_v0   [1000]: avg:   1.9156, min:   1.7639[ 964], max:   2.0706[ 625]\n",
      "===================\n",
      "beginning of epoch:  39\n",
      "available: 2.773 GB, used: 25.889 GB, free: 2.598 GB\n",
      "EPOCH: 39\n",
      "mean score: 0.00\n",
      "Speed: train: 1844.1, buffer_add: 1021.7, buffer_size: 100016\n",
      "Total Time: 0H 23M 16S, 1396s\n",
      "Total Sample: train: 2.56M, buffer: 1.46M\n",
      "[39] Time spent = 35.01 s\n",
      "39:grad_norm [1000]: avg:   4.7780, min:   2.2428[ 942], max:   8.8205[ 316]\n",
      "39:loss      [1000]: avg:   7.3128, min:   5.4384[ 823], max:   9.6063[ 587]\n",
      "39:xent_pred [1000]: avg:   1.9471, min:   1.7988[  34], max:   2.0973[ 114]\n",
      "39:xent_v0   [1000]: avg:   1.9159, min:   1.7615[  34], max:   2.0687[ 114]\n",
      "===================\n",
      "beginning of epoch:  40\n",
      "available: 2.782 GB, used: 25.892 GB, free: 2.571 GB\n",
      "EPOCH: 40\n",
      "mean score: 0.00\n",
      "Speed: train: 1840.1, buffer_add: 1011.2, buffer_size: 100055\n",
      "Total Time: 0H 23M 51S, 1431s\n",
      "Total Sample: train: 2.624M, buffer: 1.496M\n",
      "[40] Time spent = 35.16 s\n",
      "40:grad_norm [1000]: avg:   4.7734, min:   2.5764[ 838], max:   8.3691[ 309]\n",
      "40:loss      [1000]: avg:   7.3255, min:   5.4512[ 472], max:   9.6267[ 958]\n",
      "40:xent_pred [1000]: avg:   1.9489, min:   1.7900[ 399], max:   2.1188[ 123]\n",
      "40:xent_v0   [1000]: avg:   1.9177, min:   1.7527[ 330], max:   2.0669[ 123]\n",
      "===================\n",
      "beginning of epoch:  41\n",
      "available: 2.781 GB, used: 25.884 GB, free: 2.610 GB\n",
      "EPOCH: 41\n",
      "mean score: 0.01\n",
      "Speed: train: 1851.0, buffer_add: 1016.5, buffer_size: 100030\n",
      "Total Time: 0H 24M 25S, 1465s\n",
      "Total Sample: train: 2.688M, buffer: 1.531M\n",
      "[41] Time spent = 34.93 s\n",
      "41:grad_norm [1000]: avg:   4.7269, min:   2.5725[ 220], max:   8.6251[ 959]\n",
      "41:loss      [1000]: avg:   7.3388, min:   5.4928[ 717], max:  10.0503[ 233]\n",
      "41:xent_pred [1000]: avg:   1.9419, min:   1.8008[ 415], max:   2.0875[ 144]\n",
      "41:xent_v0   [1000]: avg:   1.9116, min:   1.7678[ 415], max:   2.0604[ 605]\n",
      "===================\n",
      "beginning of epoch:  42\n",
      "available: 2.781 GB, used: 25.883 GB, free: 2.627 GB\n",
      "EPOCH: 42\n",
      "mean score: 0.00\n",
      "Speed: train: 1887.5, buffer_add: 1014.8, buffer_size: 100013\n",
      "Total Time: 0H 24M 59S, 1499s\n",
      "Total Sample: train: 2.752M, buffer: 1.565M\n",
      "[42] Time spent = 34.34 s\n",
      "42:grad_norm [1000]: avg:   4.7572, min:   2.3276[ 323], max:  10.2686[  17]\n",
      "42:loss      [1000]: avg:   7.3284, min:   5.0519[ 300], max:   9.8902[ 928]\n",
      "42:xent_pred [1000]: avg:   1.9492, min:   1.7886[  70], max:   2.1263[ 593]\n",
      "42:xent_v0   [1000]: avg:   1.9196, min:   1.7538[ 116], max:   2.1046[ 593]\n",
      "===================\n",
      "beginning of epoch:  43\n",
      "available: 2.775 GB, used: 25.886 GB, free: 2.606 GB\n",
      "EPOCH: 43\n",
      "mean score: 0.00\n",
      "Speed: train: 1821.0, buffer_add: 1017.9, buffer_size: 100063\n",
      "Total Time: 0H 25M 34S, 1534s\n",
      "Total Sample: train: 2.816M, buffer: 1.601M\n",
      "[43] Time spent = 35.93 s\n",
      "43:grad_norm [1000]: avg:   4.7647, min:   2.6905[ 459], max:   9.1051[  69]\n",
      "43:loss      [1000]: avg:   7.3043, min:   5.2634[ 595], max:   9.6076[ 343]\n",
      "43:xent_pred [1000]: avg:   1.9413, min:   1.8003[ 170], max:   2.0728[ 416]\n",
      "43:xent_v0   [1000]: avg:   1.9127, min:   1.7761[ 170], max:   2.0508[ 595]\n",
      "===================\n",
      "beginning of epoch:  44\n",
      "available: 2.785 GB, used: 25.876 GB, free: 2.700 GB\n",
      "EPOCH: 44\n",
      "mean score: 0.00\n",
      "Speed: train: 1835.4, buffer_add: 1027.2, buffer_size: 100050\n",
      "Total Time: 0H 26M 09S, 1569s\n",
      "Total Sample: train: 2.88M, buffer: 1.637M\n",
      "[44] Time spent = 35.73 s\n",
      "44:grad_norm [1000]: avg:   4.7587, min:   2.7587[ 622], max:   8.8872[ 728]\n",
      "44:loss      [1000]: avg:   7.2954, min:   5.2288[  98], max:   9.7218[ 925]\n",
      "44:xent_pred [1000]: avg:   1.9425, min:   1.7871[ 873], max:   2.0908[ 524]\n",
      "44:xent_v0   [1000]: avg:   1.9152, min:   1.7728[ 917], max:   2.0666[ 851]\n",
      "===================\n",
      "beginning of epoch:  45\n",
      "available: 2.786 GB, used: 25.881 GB, free: 2.679 GB\n",
      "EPOCH: 45\n",
      "mean score: 0.00\n",
      "Speed: train: 1869.5, buffer_add: 1025.7, buffer_size: 100063\n",
      "Total Time: 0H 26M 44S, 1604s\n",
      "Total Sample: train: 2.944M, buffer: 1.672M\n",
      "[45] Time spent = 34.64 s\n",
      "45:grad_norm [1000]: avg:   4.7410, min:   2.3670[ 381], max:   8.5326[ 500]\n",
      "45:loss      [1000]: avg:   7.2990, min:   5.2913[   8], max:   9.7818[ 380]\n",
      "45:xent_pred [1000]: avg:   1.9414, min:   1.7945[ 749], max:   2.0740[   8]\n",
      "45:xent_v0   [1000]: avg:   1.9145, min:   1.7548[ 531], max:   2.0574[ 386]\n",
      "===================\n",
      "beginning of epoch:  46\n",
      "available: 2.783 GB, used: 25.884 GB, free: 2.679 GB\n",
      "EPOCH: 46\n",
      "mean score: 0.00\n",
      "Speed: train: 1864.4, buffer_add: 1019.7, buffer_size: 100039\n",
      "Total Time: 0H 27M 18S, 1638s\n",
      "Total Sample: train: 3.008M, buffer: 1.707M\n",
      "[46] Time spent = 34.69 s\n",
      "46:grad_norm [1000]: avg:   4.6876, min:   2.5781[ 610], max:   8.5445[ 284]\n",
      "46:loss      [1000]: avg:   7.3071, min:   5.2635[ 332], max:  10.0910[ 775]\n",
      "46:xent_pred [1000]: avg:   1.9418, min:   1.7676[ 296], max:   2.1116[ 332]\n",
      "46:xent_v0   [1000]: avg:   1.9150, min:   1.7519[ 296], max:   2.0732[ 332]\n",
      "===================\n",
      "beginning of epoch:  47\n",
      "available: 2.784 GB, used: 25.888 GB, free: 2.665 GB\n",
      "EPOCH: 47\n",
      "mean score: 0.00\n",
      "Speed: train: 1749.9, buffer_add: 965.0, buffer_size: 100022\n",
      "Total Time: 0H 27M 54S, 1674s\n",
      "Total Sample: train: 3.072M, buffer: 1.742M\n",
      "[47] Time spent = 37.33 s\n",
      "47:grad_norm [1000]: avg:   4.6704, min:   2.5663[ 408], max:   8.5237[  83]\n",
      "47:loss      [1000]: avg:   7.2427, min:   5.3866[  46], max:   9.5243[ 442]\n",
      "47:xent_pred [1000]: avg:   1.9413, min:   1.7894[ 154], max:   2.0875[ 393]\n",
      "47:xent_v0   [1000]: avg:   1.9165, min:   1.7664[ 154], max:   2.0519[ 393]\n",
      "===================\n",
      "beginning of epoch:  48\n",
      "available: 2.785 GB, used: 25.883 GB, free: 2.661 GB\n",
      "EPOCH: 48\n",
      "mean score: 0.00\n",
      "Speed: train: 1784.2, buffer_add: 973.2, buffer_size: 100018\n",
      "Total Time: 0H 28M 30S, 1710s\n",
      "Total Sample: train: 3.136M, buffer: 1.777M\n",
      "[48] Time spent = 36.14 s\n",
      "48:grad_norm [1000]: avg:   4.7449, min:   2.7932[ 927], max:   8.3157[ 537]\n",
      "48:loss      [1000]: avg:   7.3180, min:   5.3731[ 344], max:   9.6083[   8]\n",
      "48:xent_pred [1000]: avg:   1.9404, min:   1.7991[ 896], max:   2.0895[ 383]\n",
      "48:xent_v0   [1000]: avg:   1.9151, min:   1.7834[ 542], max:   2.0593[ 294]\n",
      "===================\n",
      "beginning of epoch:  49\n",
      "available: 2.786 GB, used: 25.876 GB, free: 2.697 GB\n",
      "EPOCH: 49\n",
      "mean score: 0.00\n",
      "Speed: train: 1809.4, buffer_add: 985.4, buffer_size: 100013\n",
      "Total Time: 0H 29M 06S, 1746s\n",
      "Total Sample: train: 3.2M, buffer: 1.812M\n",
      "[49] Time spent = 36.40 s\n",
      "49:grad_norm [1000]: avg:   4.6514, min:   2.8725[ 945], max:   9.1789[ 826]\n",
      "49:loss      [1000]: avg:   7.2661, min:   5.0611[ 552], max:   9.5359[ 849]\n",
      "49:xent_pred [1000]: avg:   1.9377, min:   1.7495[  99], max:   2.1060[ 830]\n",
      "49:xent_v0   [1000]: avg:   1.9135, min:   1.7390[  99], max:   2.0676[ 830]\n",
      "===================\n",
      "beginning of epoch:  50\n",
      "available: 2.780 GB, used: 25.882 GB, free: 2.684 GB\n",
      "EPOCH: 50\n",
      "mean score: 0.00\n",
      "Speed: train: 1832.6, buffer_add: 1002.2, buffer_size: 100049\n",
      "Total Time: 0H 29M 41S, 1781s\n",
      "Total Sample: train: 3.264M, buffer: 1.847M\n",
      "[50] Time spent = 35.34 s\n",
      "50:grad_norm [1000]: avg:   4.7162, min:   2.5199[ 872], max:   7.8185[ 284]\n",
      "50:loss      [1000]: avg:   7.3132, min:   5.2797[ 110], max:   9.4040[ 878]\n",
      "50:xent_pred [1000]: avg:   1.9352, min:   1.7834[ 216], max:   2.0826[ 177]\n",
      "50:xent_v0   [1000]: avg:   1.9119, min:   1.7753[ 216], max:   2.0586[ 177]\n",
      "===================\n",
      "beginning of epoch:  51\n",
      "available: 2.773 GB, used: 25.881 GB, free: 2.729 GB\n",
      "EPOCH: 51\n",
      "mean score: 0.00\n",
      "Speed: train: 1811.5, buffer_add: 974.2, buffer_size: 100138\n",
      "Total Time: 0H 30M 16S, 1816s\n",
      "Total Sample: train: 3.328M, buffer: 1.881M\n",
      "[51] Time spent = 35.78 s\n",
      "51:grad_norm [1000]: avg:   4.6592, min:   2.7105[ 608], max:   8.5891[ 735]\n",
      "51:loss      [1000]: avg:   7.3055, min:   5.3588[ 838], max:   9.6493[ 910]\n",
      "51:xent_pred [1000]: avg:   1.9370, min:   1.7826[ 220], max:   2.0653[ 648]\n",
      "51:xent_v0   [1000]: avg:   1.9133, min:   1.7545[ 220], max:   2.0447[ 648]\n",
      "===================\n",
      "beginning of epoch:  52\n",
      "available: 2.778 GB, used: 25.877 GB, free: 2.710 GB\n",
      "EPOCH: 52\n",
      "mean score: 0.00\n",
      "Speed: train: 1862.1, buffer_add: 996.6, buffer_size: 100016\n",
      "Total Time: 0H 30M 50S, 1850s\n",
      "Total Sample: train: 3.392M, buffer: 1.916M\n",
      "[52] Time spent = 35.37 s\n",
      "52:grad_norm [1000]: avg:   4.5541, min:   2.4822[ 799], max:   8.4125[ 972]\n",
      "52:loss      [1000]: avg:   7.2591, min:   5.2802[ 406], max:   9.3858[ 336]\n",
      "52:xent_pred [1000]: avg:   1.9376, min:   1.7726[ 474], max:   2.0792[ 654]\n",
      "52:xent_v0   [1000]: avg:   1.9149, min:   1.7533[ 474], max:   2.0789[ 654]\n",
      "===================\n",
      "beginning of epoch:  53\n",
      "available: 2.776 GB, used: 25.889 GB, free: 2.608 GB\n",
      "EPOCH: 53\n",
      "mean score: 0.00\n",
      "Speed: train: 1846.5, buffer_add: 1008.6, buffer_size: 100030\n",
      "Total Time: 0H 31M 25S, 1885s\n",
      "Total Sample: train: 3.456M, buffer: 1.951M\n",
      "[53] Time spent = 34.86 s\n",
      "53:grad_norm [1000]: avg:   4.5382, min:   2.4476[ 845], max:   8.3484[ 519]\n",
      "53:loss      [1000]: avg:   7.3105, min:   5.1799[ 655], max:   9.8413[ 644]\n",
      "53:xent_pred [1000]: avg:   1.9364, min:   1.8045[  72], max:   2.0917[ 798]\n",
      "53:xent_v0   [1000]: avg:   1.9138, min:   1.7761[ 422], max:   2.0645[ 405]\n",
      "===================\n",
      "beginning of epoch:  54\n",
      "available: 2.770 GB, used: 25.889 GB, free: 2.677 GB\n",
      "EPOCH: 54\n",
      "mean score: 0.00\n",
      "Speed: train: 1837.5, buffer_add: 984.0, buffer_size: 100011\n",
      "Total Time: 0H 32M 00S, 1920s\n",
      "Total Sample: train: 3.52M, buffer: 1.985M\n",
      "[54] Time spent = 35.65 s\n",
      "54:grad_norm [1000]: avg:   4.4950, min:   2.3531[ 744], max:   8.0250[ 149]\n",
      "54:loss      [1000]: avg:   7.2478, min:   5.4329[ 391], max:  10.0665[ 264]\n",
      "54:xent_pred [1000]: avg:   1.9396, min:   1.8082[ 729], max:   2.0707[ 630]\n",
      "54:xent_v0   [1000]: avg:   1.9181, min:   1.7784[ 551], max:   2.0553[ 160]\n",
      "===================\n",
      "beginning of epoch:  55\n",
      "available: 2.772 GB, used: 25.886 GB, free: 2.693 GB\n",
      "EPOCH: 55\n",
      "mean score: 0.00\n",
      "Speed: train: 1831.0, buffer_add: 990.8, buffer_size: 100042\n",
      "Total Time: 0H 32M 35S, 1955s\n",
      "Total Sample: train: 3.584M, buffer: 2.02M\n",
      "[55] Time spent = 35.40 s\n",
      "55:grad_norm [1000]: avg:   4.5468, min:   2.2139[ 402], max:   7.9594[ 353]\n",
      "55:loss      [1000]: avg:   7.3059, min:   5.2420[ 568], max:  10.5118[   7]\n",
      "55:xent_pred [1000]: avg:   1.9343, min:   1.7827[ 953], max:   2.1038[ 168]\n",
      "55:xent_v0   [1000]: avg:   1.9130, min:   1.7572[ 572], max:   2.0722[ 312]\n",
      "===================\n",
      "beginning of epoch:  56\n",
      "available: 2.775 GB, used: 25.886 GB, free: 2.702 GB\n",
      "EPOCH: 56\n",
      "mean score: 0.00\n",
      "Speed: train: 1776.5, buffer_add: 960.3, buffer_size: 100018\n",
      "Total Time: 0H 33M 11S, 1991s\n",
      "Total Sample: train: 3.648M, buffer: 2.054M\n",
      "[56] Time spent = 36.35 s\n",
      "56:grad_norm [1000]: avg:   4.5568, min:   2.1235[ 463], max:   7.9931[ 802]\n",
      "56:loss      [1000]: avg:   7.3110, min:   5.3360[ 463], max:   9.8532[ 317]\n",
      "56:xent_pred [1000]: avg:   1.9324, min:   1.7851[ 611], max:   2.0670[ 529]\n",
      "56:xent_v0   [1000]: avg:   1.9111, min:   1.7694[ 611], max:   2.0456[ 529]\n",
      "===================\n",
      "beginning of epoch:  57\n",
      "available: 2.760 GB, used: 25.898 GB, free: 2.677 GB\n",
      "EPOCH: 57\n",
      "mean score: 0.00\n",
      "Speed: train: 1778.5, buffer_add: 957.6, buffer_size: 100025\n",
      "Total Time: 0H 33M 47S, 2027s\n",
      "Total Sample: train: 3.712M, buffer: 2.089M\n",
      "[57] Time spent = 36.44 s\n",
      "57:grad_norm [1000]: avg:   4.4712, min:   2.3865[ 505], max:   8.0825[ 953]\n",
      "57:loss      [1000]: avg:   7.3009, min:   5.4929[ 201], max:   9.8861[ 103]\n",
      "57:xent_pred [1000]: avg:   1.9324, min:   1.7880[ 940], max:   2.0947[ 340]\n",
      "57:xent_v0   [1000]: avg:   1.9132, min:   1.7804[ 510], max:   2.0737[ 340]\n",
      "===================\n",
      "beginning of epoch:  58\n",
      "available: 2.768 GB, used: 25.895 GB, free: 2.659 GB\n",
      "EPOCH: 58\n",
      "mean score: 0.00\n",
      "Speed: train: 1772.1, buffer_add: 952.4, buffer_size: 100003\n",
      "Total Time: 0H 34M 23S, 2063s\n",
      "Total Sample: train: 3.776M, buffer: 2.123M\n",
      "[58] Time spent = 36.50 s\n",
      "58:grad_norm [1000]: avg:   4.4939, min:   2.4957[ 779], max:   7.8153[ 858]\n",
      "58:loss      [1000]: avg:   7.2736, min:   5.2262[ 549], max:   9.1943[ 313]\n",
      "58:xent_pred [1000]: avg:   1.9313, min:   1.7882[ 841], max:   2.1115[ 121]\n",
      "58:xent_v0   [1000]: avg:   1.9124, min:   1.7698[ 841], max:   2.0848[ 121]\n",
      "===================\n",
      "beginning of epoch:  59\n",
      "available: 2.774 GB, used: 25.889 GB, free: 2.682 GB\n",
      "EPOCH: 59\n",
      "mean score: 0.00\n",
      "Speed: train: 1785.7, buffer_add: 943.8, buffer_size: 100025\n",
      "Total Time: 0H 34M 59S, 2099s\n",
      "Total Sample: train: 3.84M, buffer: 2.157M\n",
      "[59] Time spent = 36.24 s\n",
      "59:grad_norm [1000]: avg:   4.4891, min:   2.4207[ 270], max:   7.9296[ 611]\n",
      "59:loss      [1000]: avg:   7.2607, min:   5.1644[ 340], max:   9.8092[ 585]\n",
      "59:xent_pred [1000]: avg:   1.9330, min:   1.7826[ 520], max:   2.1577[ 507]\n",
      "59:xent_v0   [1000]: avg:   1.9149, min:   1.7646[ 520], max:   2.1097[ 507]\n",
      "===================\n",
      "beginning of epoch:  60\n",
      "available: 2.785 GB, used: 25.886 GB, free: 2.667 GB\n",
      "EPOCH: 60\n",
      "mean score: 0.00\n",
      "Speed: train: 1730.8, buffer_add: 938.5, buffer_size: 100001\n",
      "Total Time: 0H 35M 36S, 2136s\n",
      "Total Sample: train: 3.904M, buffer: 2.191M\n",
      "[60] Time spent = 37.30 s\n",
      "60:grad_norm [1000]: avg:   4.5053, min:   2.5400[ 532], max:   7.8494[ 438]\n",
      "60:loss      [1000]: avg:   7.2950, min:   5.1116[ 661], max:   9.7015[ 105]\n",
      "60:xent_pred [1000]: avg:   1.9261, min:   1.7804[ 953], max:   2.0819[ 872]\n",
      "60:xent_v0   [1000]: avg:   1.9088, min:   1.7625[ 527], max:   2.0679[ 872]\n",
      "===================\n",
      "beginning of epoch:  61\n",
      "available: 2.786 GB, used: 25.876 GB, free: 2.691 GB\n",
      "EPOCH: 61\n",
      "mean score: 0.00\n",
      "Speed: train: 1733.3, buffer_add: 925.7, buffer_size: 100055\n",
      "Total Time: 0H 36M 13S, 2173s\n",
      "Total Sample: train: 3.968M, buffer: 2.226M\n",
      "[61] Time spent = 37.81 s\n",
      "61:grad_norm [1000]: avg:   4.5001, min:   2.6299[ 693], max:   7.5688[ 999]\n",
      "61:loss      [1000]: avg:   7.2311, min:   5.4413[ 824], max:   9.3384[ 315]\n",
      "61:xent_pred [1000]: avg:   1.9276, min:   1.7940[ 320], max:   2.1006[ 914]\n",
      "61:xent_v0   [1000]: avg:   1.9109, min:   1.7818[ 320], max:   2.0766[ 914]\n",
      "===================\n",
      "beginning of epoch:  62\n",
      "available: 2.773 GB, used: 25.885 GB, free: 2.699 GB\n",
      "EPOCH: 62\n",
      "mean score: 0.00\n",
      "Speed: train: 1722.1, buffer_add: 930.5, buffer_size: 100038\n",
      "Total Time: 0H 36M 50S, 2210s\n",
      "Total Sample: train: 4.032M, buffer: 2.26M\n",
      "[62] Time spent = 37.62 s\n",
      "62:grad_norm [1000]: avg:   4.5125, min:   2.5007[ 536], max:   8.1102[ 252]\n",
      "62:loss      [1000]: avg:   7.2518, min:   5.0842[ 280], max:   9.4418[ 763]\n",
      "62:xent_pred [1000]: avg:   1.9284, min:   1.7777[ 289], max:   2.0689[ 501]\n",
      "62:xent_v0   [1000]: avg:   1.9116, min:   1.7588[ 289], max:   2.0646[ 501]\n",
      "===================\n",
      "beginning of epoch:  63\n",
      "available: 2.765 GB, used: 25.896 GB, free: 2.667 GB\n",
      "EPOCH: 63\n",
      "mean score: 0.00\n",
      "Speed: train: 1707.2, buffer_add: 917.7, buffer_size: 100019\n",
      "Total Time: 0H 37M 27S, 2247s\n",
      "Total Sample: train: 4.096M, buffer: 2.295M\n",
      "[63] Time spent = 37.98 s\n",
      "63:grad_norm [1000]: avg:   4.5255, min:   2.3783[ 174], max:   7.9706[  39]\n",
      "63:loss      [1000]: avg:   7.2582, min:   5.0922[ 492], max:   9.6444[ 973]\n",
      "63:xent_pred [1000]: avg:   1.9315, min:   1.7873[ 643], max:   2.0749[ 674]\n",
      "63:xent_v0   [1000]: avg:   1.9155, min:   1.7619[ 643], max:   2.0696[ 674]\n",
      "===================\n",
      "beginning of epoch:  64\n",
      "available: 2.769 GB, used: 25.888 GB, free: 2.691 GB\n",
      "EPOCH: 64\n",
      "mean score: 0.00\n",
      "Speed: train: 1709.8, buffer_add: 912.8, buffer_size: 100018\n",
      "Total Time: 0H 38M 05S, 2285s\n",
      "Total Sample: train: 4.16M, buffer: 2.329M\n",
      "[64] Time spent = 37.83 s\n",
      "64:grad_norm [1000]: avg:   4.5265, min:   2.4788[ 579], max:   8.4600[ 790]\n",
      "64:loss      [1000]: avg:   7.2758, min:   5.3519[ 351], max:   9.6079[ 350]\n",
      "64:xent_pred [1000]: avg:   1.9254, min:   1.7896[ 703], max:   2.1067[ 239]\n",
      "64:xent_v0   [1000]: avg:   1.9098, min:   1.7757[ 963], max:   2.0991[ 239]\n",
      "===================\n",
      "beginning of epoch:  65\n",
      "available: 2.780 GB, used: 25.881 GB, free: 2.683 GB\n",
      "EPOCH: 65\n",
      "mean score: 0.00\n",
      "Speed: train: 1725.2, buffer_add: 914.2, buffer_size: 100026\n",
      "Total Time: 0H 38M 42S, 2322s\n",
      "Total Sample: train: 4.224M, buffer: 2.363M\n",
      "[65] Time spent = 37.55 s\n",
      "65:grad_norm [1000]: avg:   4.4771, min:   2.5636[ 308], max:   8.5121[  69]\n",
      "65:loss      [1000]: avg:   7.2560, min:   5.0970[ 960], max:   9.8490[ 386]\n",
      "65:xent_pred [1000]: avg:   1.9313, min:   1.7737[ 790], max:   2.1094[ 223]\n",
      "65:xent_v0   [1000]: avg:   1.9160, min:   1.7495[ 790], max:   2.0831[ 158]\n",
      "===================\n",
      "beginning of epoch:  66\n",
      "available: 2.776 GB, used: 25.889 GB, free: 2.697 GB\n",
      "EPOCH: 66\n",
      "mean score: 0.02\n",
      "Speed: train: 1729.3, buffer_add: 922.0, buffer_size: 100037\n",
      "Total Time: 0H 39M 19S, 2359s\n",
      "Total Sample: train: 4.288M, buffer: 2.397M\n",
      "[66] Time spent = 37.70 s\n",
      "66:grad_norm [1000]: avg:   4.4489, min:   2.5322[ 727], max:   8.8147[ 113]\n",
      "66:loss      [1000]: avg:   7.2201, min:   4.9689[ 727], max:   9.8434[ 479]\n",
      "66:xent_pred [1000]: avg:   1.9301, min:   1.7636[ 806], max:   2.0706[ 230]\n",
      "66:xent_v0   [1000]: avg:   1.9158, min:   1.7604[ 806], max:   2.0640[ 230]\n",
      "===================\n",
      "beginning of epoch:  67\n",
      "available: 2.774 GB, used: 25.885 GB, free: 2.704 GB\n",
      "EPOCH: 67\n",
      "mean score: 0.00\n",
      "Speed: train: 1738.7, buffer_add: 932.9, buffer_size: 100018\n",
      "Total Time: 0H 39M 56S, 2396s\n",
      "Total Sample: train: 4.352M, buffer: 2.431M\n",
      "[67] Time spent = 37.18 s\n",
      "67:grad_norm [1000]: avg:   4.4501, min:   2.4628[ 551], max:   9.4287[ 107]\n",
      "67:loss      [1000]: avg:   7.2473, min:   5.4193[ 542], max:   9.7940[ 975]\n",
      "67:xent_pred [1000]: avg:   1.9304, min:   1.7904[ 502], max:   2.0980[ 942]\n",
      "67:xent_v0   [1000]: avg:   1.9163, min:   1.7789[ 502], max:   2.0699[ 942]\n",
      "===================\n",
      "beginning of epoch:  68\n",
      "available: 2.779 GB, used: 25.880 GB, free: 2.649 GB\n",
      "EPOCH: 68\n",
      "mean score: 0.00\n",
      "Speed: train: 1727.1, buffer_add: 922.0, buffer_size: 100028\n",
      "Total Time: 0H 40M 33S, 2433s\n",
      "Total Sample: train: 4.416M, buffer: 2.465M\n",
      "[68] Time spent = 37.44 s\n",
      "68:grad_norm [1000]: avg:   4.4594, min:   2.3973[ 970], max:   7.6215[   4]\n",
      "68:loss      [1000]: avg:   7.3106, min:   5.2845[ 531], max:  10.4513[ 964]\n",
      "68:xent_pred [1000]: avg:   1.9260, min:   1.7514[ 575], max:   2.0800[ 549]\n",
      "68:xent_v0   [1000]: avg:   1.9119, min:   1.7472[ 575], max:   2.0559[ 549]\n",
      "===================\n",
      "beginning of epoch:  69\n",
      "available: 2.770 GB, used: 25.891 GB, free: 2.710 GB\n",
      "EPOCH: 69\n",
      "mean score: 0.00\n",
      "Speed: train: 1792.3, buffer_add: 932.9, buffer_size: 100013\n",
      "Total Time: 0H 41M 08S, 2468s\n",
      "Total Sample: train: 4.48M, buffer: 2.499M\n",
      "[69] Time spent = 35.95 s\n",
      "69:grad_norm [1000]: avg:   4.4259, min:   2.7524[ 153], max:   7.0364[ 159]\n",
      "69:loss      [1000]: avg:   7.2697, min:   5.1683[ 215], max:   9.9059[ 785]\n",
      "69:xent_pred [1000]: avg:   1.9258, min:   1.7676[ 990], max:   2.0824[ 667]\n",
      "69:xent_v0   [1000]: avg:   1.9125, min:   1.7592[ 990], max:   2.0695[ 722]\n",
      "===================\n",
      "beginning of epoch:  70\n",
      "available: 2.776 GB, used: 25.884 GB, free: 2.709 GB\n",
      "EPOCH: 70\n",
      "mean score: 0.00\n",
      "Speed: train: 1839.6, buffer_add: 1008.0, buffer_size: 100022\n",
      "Total Time: 0H 41M 43S, 2503s\n",
      "Total Sample: train: 4.544M, buffer: 2.534M\n",
      "[70] Time spent = 35.23 s\n",
      "70:grad_norm [1000]: avg:   4.4758, min:   2.7742[ 235], max:   8.5403[ 899]\n",
      "70:loss      [1000]: avg:   7.2620, min:   5.2989[ 603], max:   9.4561[ 946]\n",
      "70:xent_pred [1000]: avg:   1.9229, min:   1.7876[ 715], max:   2.0686[ 254]\n",
      "70:xent_v0   [1000]: avg:   1.9097, min:   1.7764[ 167], max:   2.0558[ 993]\n",
      "===================\n",
      "beginning of epoch:  71\n",
      "available: 2.769 GB, used: 25.894 GB, free: 2.671 GB\n",
      "EPOCH: 71\n",
      "mean score: 0.00\n",
      "Speed: train: 1841.4, buffer_add: 1018.3, buffer_size: 100119\n",
      "Total Time: 0H 42M 18S, 2538s\n",
      "Total Sample: train: 4.608M, buffer: 2.569M\n",
      "[71] Time spent = 35.22 s\n",
      "71:grad_norm [1000]: avg:   4.4398, min:   2.7713[ 611], max:   8.4775[ 987]\n",
      "71:loss      [1000]: avg:   7.2740, min:   5.6731[  80], max:   9.8230[ 191]\n",
      "71:xent_pred [1000]: avg:   1.9267, min:   1.7628[ 846], max:   2.0917[ 263]\n",
      "71:xent_v0   [1000]: avg:   1.9138, min:   1.7512[ 999], max:   2.0873[ 545]\n",
      "===================\n",
      "beginning of epoch:  72\n",
      "available: 2.775 GB, used: 25.879 GB, free: 2.714 GB\n",
      "EPOCH: 72\n",
      "mean score: 0.00\n",
      "Speed: train: 1869.9, buffer_add: 1027.0, buffer_size: 100024\n",
      "Total Time: 0H 42M 52S, 2572s\n",
      "Total Sample: train: 4.672M, buffer: 2.604M\n",
      "[72] Time spent = 34.62 s\n",
      "72:grad_norm [1000]: avg:   4.3776, min:   2.6327[ 365], max:   7.3333[ 572]\n",
      "72:loss      [1000]: avg:   7.2523, min:   5.4737[ 472], max:   9.8004[ 794]\n",
      "72:xent_pred [1000]: avg:   1.9268, min:   1.7882[ 495], max:   2.0615[  23]\n",
      "72:xent_v0   [1000]: avg:   1.9142, min:   1.7772[  71], max:   2.0529[  23]\n",
      "===================\n",
      "beginning of epoch:  73\n",
      "available: 2.772 GB, used: 25.886 GB, free: 2.646 GB\n",
      "EPOCH: 73\n",
      "mean score: 0.00\n",
      "Speed: train: 1852.3, buffer_add: 1014.2, buffer_size: 100025\n",
      "Total Time: 0H 43M 27S, 2607s\n",
      "Total Sample: train: 4.736M, buffer: 2.639M\n",
      "[73] Time spent = 34.99 s\n",
      "73:grad_norm [1000]: avg:   4.3836, min:   2.5062[ 954], max:   8.6974[ 575]\n",
      "73:loss      [1000]: avg:   7.2925, min:   5.3824[ 997], max:   9.5465[ 155]\n",
      "73:xent_pred [1000]: avg:   1.9232, min:   1.7822[  60], max:   2.0669[ 271]\n",
      "73:xent_v0   [1000]: avg:   1.9099, min:   1.7688[  60], max:   2.0490[ 271]\n",
      "===================\n",
      "beginning of epoch:  74\n",
      "available: 2.774 GB, used: 25.888 GB, free: 2.689 GB\n",
      "EPOCH: 74\n",
      "mean score: 0.00\n",
      "Speed: train: 1855.2, buffer_add: 1019.5, buffer_size: 100012\n",
      "Total Time: 0H 44M 01S, 2641s\n",
      "Total Sample: train: 4.8M, buffer: 2.674M\n",
      "[74] Time spent = 35.46 s\n",
      "74:grad_norm [1000]: avg:   4.2785, min:   2.3963[ 625], max:   8.3896[ 212]\n",
      "74:loss      [1000]: avg:   7.2097, min:   5.0341[ 165], max:   9.7034[ 745]\n",
      "74:xent_pred [1000]: avg:   1.9249, min:   1.7684[  47], max:   2.0547[ 793]\n",
      "74:xent_v0   [1000]: avg:   1.9124, min:   1.7650[  47], max:   2.0354[ 786]\n",
      "===================\n",
      "beginning of epoch:  75\n",
      "available: 2.774 GB, used: 25.885 GB, free: 2.684 GB\n",
      "EPOCH: 75\n",
      "mean score: 0.00\n",
      "Speed: train: 1876.8, buffer_add: 1031.0, buffer_size: 100043\n",
      "Total Time: 0H 44M 35S, 2675s\n",
      "Total Sample: train: 4.864M, buffer: 2.71M\n",
      "[75] Time spent = 34.57 s\n",
      "75:grad_norm [1000]: avg:   4.3041, min:   2.6834[ 833], max:   7.0960[  58]\n",
      "75:loss      [1000]: avg:   7.2629, min:   5.2711[ 331], max:  10.1746[ 121]\n",
      "75:xent_pred [1000]: avg:   1.9255, min:   1.7801[ 825], max:   2.0861[ 142]\n",
      "75:xent_v0   [1000]: avg:   1.9125, min:   1.7719[ 552], max:   2.0719[ 142]\n",
      "===================\n",
      "beginning of epoch:  76\n",
      "available: 2.767 GB, used: 25.888 GB, free: 2.704 GB\n",
      "EPOCH: 76\n",
      "mean score: 0.00\n",
      "Speed: train: 1856.1, buffer_add: 1008.4, buffer_size: 100038\n",
      "Total Time: 0H 45M 10S, 2710s\n",
      "Total Sample: train: 4.928M, buffer: 2.744M\n",
      "[76] Time spent = 35.18 s\n",
      "76:grad_norm [1000]: avg:   4.2336, min:   2.4597[ 164], max:   7.5198[ 424]\n",
      "76:loss      [1000]: avg:   7.2191, min:   5.4831[ 642], max:   9.6626[ 752]\n",
      "76:xent_pred [1000]: avg:   1.9242, min:   1.7192[ 817], max:   2.0681[ 552]\n",
      "76:xent_v0   [1000]: avg:   1.9115, min:   1.7073[ 817], max:   2.0503[ 355]\n",
      "===================\n",
      "beginning of epoch:  77\n",
      "available: 2.776 GB, used: 25.887 GB, free: 2.678 GB\n",
      "EPOCH: 77\n",
      "mean score: 0.00\n",
      "Speed: train: 1865.3, buffer_add: 1040.7, buffer_size: 100063\n",
      "Total Time: 0H 45M 44S, 2744s\n",
      "Total Sample: train: 4.992M, buffer: 2.78M\n",
      "[77] Time spent = 34.75 s\n",
      "77:grad_norm [1000]: avg:   4.2860, min:   2.3605[   0], max:   7.4221[ 838]\n",
      "77:loss      [1000]: avg:   7.2644, min:   5.2028[ 632], max:   9.7589[ 720]\n",
      "77:xent_pred [1000]: avg:   1.9237, min:   1.7761[  98], max:   2.0656[ 902]\n",
      "77:xent_v0   [1000]: avg:   1.9111, min:   1.7687[ 602], max:   2.0619[ 902]\n",
      "===================\n",
      "beginning of epoch:  78\n",
      "available: 2.773 GB, used: 25.887 GB, free: 2.655 GB\n",
      "EPOCH: 78\n",
      "mean score: 0.00\n",
      "Speed: train: 1858.2, buffer_add: 1023.8, buffer_size: 100078\n",
      "Total Time: 0H 46M 19S, 2779s\n",
      "Total Sample: train: 5.056M, buffer: 2.815M\n",
      "[78] Time spent = 34.83 s\n",
      "78:grad_norm [1000]: avg:   4.2614, min:   2.4490[ 216], max:   7.2583[ 990]\n",
      "78:loss      [1000]: avg:   7.2578, min:   5.5234[ 216], max:   9.9322[  74]\n",
      "78:xent_pred [1000]: avg:   1.9241, min:   1.7851[ 424], max:   2.0729[ 795]\n",
      "78:xent_v0   [1000]: avg:   1.9123, min:   1.7773[ 424], max:   2.0620[ 795]\n",
      "===================\n",
      "beginning of epoch:  79\n",
      "available: 2.776 GB, used: 25.882 GB, free: 2.673 GB\n",
      "EPOCH: 79\n",
      "mean score: 0.00\n",
      "Speed: train: 1841.0, buffer_add: 1020.2, buffer_size: 100046\n",
      "Total Time: 0H 46M 53S, 2813s\n",
      "Total Sample: train: 5.12M, buffer: 2.851M\n",
      "[79] Time spent = 35.09 s\n",
      "79:grad_norm [1000]: avg:   4.2291, min:   2.4383[ 829], max:   6.6821[ 642]\n",
      "79:loss      [1000]: avg:   7.2850, min:   5.2605[ 111], max:   9.7805[ 993]\n",
      "79:xent_pred [1000]: avg:   1.9242, min:   1.7797[  85], max:   2.0989[ 253]\n",
      "79:xent_v0   [1000]: avg:   1.9124, min:   1.7638[ 473], max:   2.0905[ 253]\n",
      "===================\n",
      "beginning of epoch:  80\n",
      "available: 2.771 GB, used: 25.887 GB, free: 2.658 GB\n",
      "EPOCH: 80\n",
      "mean score: 0.00\n",
      "Speed: train: 1881.5, buffer_add: 1013.4, buffer_size: 100051\n",
      "Total Time: 0H 47M 27S, 2847s\n",
      "Total Sample: train: 5.184M, buffer: 2.885M\n",
      "[80] Time spent = 34.40 s\n",
      "80:grad_norm [1000]: avg:   4.1881, min:   2.3486[ 723], max:   8.0461[ 683]\n",
      "80:loss      [1000]: avg:   7.2421, min:   5.1602[ 609], max:   9.6365[ 462]\n",
      "80:xent_pred [1000]: avg:   1.9254, min:   1.7791[ 229], max:   2.0898[ 223]\n",
      "80:xent_v0   [1000]: avg:   1.9139, min:   1.7783[ 229], max:   2.0675[ 223]\n",
      "===================\n",
      "beginning of epoch:  81\n",
      "available: 2.769 GB, used: 25.888 GB, free: 2.678 GB\n",
      "EPOCH: 81\n",
      "mean score: 0.00\n",
      "Speed: train: 1860.8, buffer_add: 1017.6, buffer_size: 100009\n",
      "Total Time: 0H 48M 02S, 2882s\n",
      "Total Sample: train: 5.248M, buffer: 2.92M\n",
      "[81] Time spent = 35.34 s\n",
      "81:grad_norm [1000]: avg:   4.1506, min:   2.2631[ 955], max:   7.0322[ 710]\n",
      "81:loss      [1000]: avg:   7.2101, min:   5.3725[ 370], max:   9.5091[ 483]\n",
      "81:xent_pred [1000]: avg:   1.9257, min:   1.7821[  24], max:   2.0712[ 989]\n",
      "81:xent_v0   [1000]: avg:   1.9144, min:   1.7728[  24], max:   2.0615[ 663]\n",
      "===================\n",
      "beginning of epoch:  82\n",
      "available: 2.772 GB, used: 25.886 GB, free: 2.682 GB\n",
      "EPOCH: 82\n",
      "mean score: 0.00\n",
      "Speed: train: 1841.6, buffer_add: 1022.0, buffer_size: 100005\n",
      "Total Time: 0H 48M 36S, 2916s\n",
      "Total Sample: train: 5.312M, buffer: 2.956M\n",
      "[82] Time spent = 35.16 s\n",
      "82:grad_norm [1000]: avg:   4.1466, min:   2.5352[ 650], max:   7.4035[ 631]\n",
      "82:loss      [1000]: avg:   7.2156, min:   5.3753[  97], max:   9.2595[ 160]\n",
      "82:xent_pred [1000]: avg:   1.9251, min:   1.7799[ 354], max:   2.0895[ 964]\n",
      "82:xent_v0   [1000]: avg:   1.9145, min:   1.7821[ 158], max:   2.0721[ 964]\n",
      "===================\n",
      "beginning of epoch:  83\n",
      "available: 2.773 GB, used: 25.889 GB, free: 2.730 GB\n",
      "EPOCH: 83\n",
      "mean score: 0.00\n",
      "Speed: train: 1869.3, buffer_add: 1017.4, buffer_size: 100020\n",
      "Total Time: 0H 49M 11S, 2951s\n",
      "Total Sample: train: 5.376M, buffer: 2.991M\n",
      "[83] Time spent = 34.61 s\n",
      "83:grad_norm [1000]: avg:   4.1323, min:   2.4387[ 951], max:   6.8529[ 922]\n",
      "83:loss      [1000]: avg:   7.2133, min:   5.2843[ 984], max:   9.8715[  94]\n",
      "83:xent_pred [1000]: avg:   1.9264, min:   1.7848[ 671], max:   2.0887[ 636]\n",
      "83:xent_v0   [1000]: avg:   1.9156, min:   1.7706[ 922], max:   2.0678[ 636]\n",
      "===================\n",
      "beginning of epoch:  84\n",
      "available: 2.772 GB, used: 25.888 GB, free: 2.670 GB\n",
      "EPOCH: 84\n",
      "mean score: 0.00\n",
      "Speed: train: 1864.3, buffer_add: 1022.1, buffer_size: 100030\n",
      "Total Time: 0H 49M 45S, 2985s\n",
      "Total Sample: train: 5.44M, buffer: 3.026M\n",
      "[84] Time spent = 35.12 s\n",
      "84:grad_norm [1000]: avg:   4.0888, min:   2.3201[ 845], max:   6.6507[ 779]\n",
      "84:loss      [1000]: avg:   7.2076, min:   5.2771[ 322], max:   9.7263[ 596]\n",
      "84:xent_pred [1000]: avg:   1.9257, min:   1.7648[ 844], max:   2.0926[ 899]\n",
      "84:xent_v0   [1000]: avg:   1.9146, min:   1.7463[ 844], max:   2.0610[ 358]\n",
      "===================\n",
      "beginning of epoch:  85\n",
      "available: 2.766 GB, used: 25.894 GB, free: 2.634 GB\n",
      "EPOCH: 85\n",
      "mean score: 0.00\n",
      "Speed: train: 1871.3, buffer_add: 1040.8, buffer_size: 100038\n",
      "Total Time: 0H 50M 19S, 3019s\n",
      "Total Sample: train: 5.504M, buffer: 3.061M\n",
      "[85] Time spent = 34.48 s\n",
      "85:grad_norm [1000]: avg:   4.1309, min:   2.6255[ 142], max:   6.7419[ 440]\n",
      "85:loss      [1000]: avg:   7.2102, min:   5.1561[ 270], max:   9.8659[ 560]\n",
      "85:xent_pred [1000]: avg:   1.9249, min:   1.7610[ 543], max:   2.0639[ 803]\n",
      "85:xent_v0   [1000]: avg:   1.9140, min:   1.7483[ 543], max:   2.0528[ 120]\n",
      "===================\n",
      "beginning of epoch:  86\n",
      "available: 2.772 GB, used: 25.888 GB, free: 2.651 GB\n",
      "EPOCH: 86\n",
      "mean score: 0.00\n",
      "Speed: train: 1871.9, buffer_add: 1020.2, buffer_size: 100045\n",
      "Total Time: 0H 50M 53S, 3053s\n",
      "Total Sample: train: 5.568M, buffer: 3.096M\n",
      "[86] Time spent = 34.70 s\n",
      "86:grad_norm [1000]: avg:   4.0982, min:   2.3859[ 654], max:   6.8283[ 881]\n",
      "86:loss      [1000]: avg:   7.2359, min:   4.8311[ 901], max:   9.7942[  60]\n",
      "86:xent_pred [1000]: avg:   1.9263, min:   1.7829[ 474], max:   2.0721[ 835]\n",
      "86:xent_v0   [1000]: avg:   1.9152, min:   1.7692[ 317], max:   2.0592[ 835]\n",
      "===================\n",
      "beginning of epoch:  87\n",
      "available: 2.776 GB, used: 25.887 GB, free: 2.697 GB\n",
      "EPOCH: 87\n",
      "mean score: 0.00\n",
      "Speed: train: 1827.8, buffer_add: 1014.5, buffer_size: 100008\n",
      "Total Time: 0H 51M 28S, 3088s\n",
      "Total Sample: train: 5.632M, buffer: 3.132M\n",
      "[87] Time spent = 35.91 s\n",
      "87:grad_norm [1000]: avg:   4.0995, min:   2.2618[ 126], max:   8.1252[ 875]\n",
      "87:loss      [1000]: avg:   7.2024, min:   5.3353[ 913], max:   9.9422[ 875]\n",
      "87:xent_pred [1000]: avg:   1.9252, min:   1.7694[ 962], max:   2.1071[ 716]\n",
      "87:xent_v0   [1000]: avg:   1.9145, min:   1.7701[ 962], max:   2.0865[ 716]\n",
      "===================\n",
      "beginning of epoch:  88\n",
      "available: 2.776 GB, used: 25.882 GB, free: 2.701 GB\n",
      "EPOCH: 88\n",
      "mean score: 0.00\n",
      "Speed: train: 1829.9, buffer_add: 1015.6, buffer_size: 100025\n",
      "Total Time: 0H 52M 03S, 3123s\n",
      "Total Sample: train: 5.696M, buffer: 3.167M\n",
      "[88] Time spent = 35.46 s\n",
      "88:grad_norm [1000]: avg:   4.0679, min:   2.2758[ 258], max:   7.0792[  61]\n",
      "88:loss      [1000]: avg:   7.2613, min:   5.2221[ 547], max:   9.9958[ 107]\n",
      "88:xent_pred [1000]: avg:   1.9245, min:   1.7769[ 340], max:   2.0529[ 255]\n",
      "88:xent_v0   [1000]: avg:   1.9136, min:   1.7679[ 477], max:   2.0320[ 996]\n",
      "===================\n",
      "beginning of epoch:  89\n",
      "available: 2.772 GB, used: 25.888 GB, free: 2.701 GB\n",
      "EPOCH: 89\n",
      "mean score: 0.00\n",
      "Speed: train: 1897.4, buffer_add: 1025.2, buffer_size: 100037\n",
      "Total Time: 0H 52M 37S, 3157s\n",
      "Total Sample: train: 5.76M, buffer: 3.202M\n",
      "[89] Time spent = 34.18 s\n",
      "89:grad_norm [1000]: avg:   4.0494, min:   2.1531[ 480], max:   8.0650[ 860]\n",
      "89:loss      [1000]: avg:   7.2264, min:   5.2100[  82], max:   9.5076[ 731]\n",
      "89:xent_pred [1000]: avg:   1.9213, min:   1.7715[ 274], max:   2.0679[ 239]\n",
      "89:xent_v0   [1000]: avg:   1.9112, min:   1.7642[ 274], max:   2.0516[ 239]\n",
      "===================\n",
      "beginning of epoch:  90\n",
      "available: 2.769 GB, used: 25.894 GB, free: 2.637 GB\n",
      "EPOCH: 90\n",
      "mean score: 0.00\n",
      "Speed: train: 1841.7, buffer_add: 1026.0, buffer_size: 100023\n",
      "Total Time: 0H 53M 12S, 3192s\n",
      "Total Sample: train: 5.824M, buffer: 3.238M\n",
      "[90] Time spent = 35.20 s\n",
      "90:grad_norm [1000]: avg:   4.0500, min:   2.2975[ 942], max:   9.0096[ 362]\n",
      "90:loss      [1000]: avg:   7.2365, min:   5.2680[ 807], max:   9.4508[ 923]\n",
      "90:xent_pred [1000]: avg:   1.9234, min:   1.7527[ 338], max:   2.0636[ 365]\n",
      "90:xent_v0   [1000]: avg:   1.9130, min:   1.7478[ 260], max:   2.0670[ 365]\n",
      "===================\n",
      "beginning of epoch:  91\n",
      "available: 2.763 GB, used: 25.898 GB, free: 2.637 GB\n",
      "EPOCH: 91\n",
      "mean score: 0.00\n",
      "Speed: train: 1831.4, buffer_add: 1014.1, buffer_size: 100022\n",
      "Total Time: 0H 53M 47S, 3227s\n",
      "Total Sample: train: 5.888M, buffer: 3.273M\n",
      "[91] Time spent = 35.25 s\n",
      "91:grad_norm [1000]: avg:   4.0174, min:   2.3411[ 693], max:   7.1520[ 145]\n",
      "91:loss      [1000]: avg:   7.2115, min:   5.5055[ 958], max:   9.8138[ 518]\n",
      "91:xent_pred [1000]: avg:   1.9268, min:   1.7707[ 964], max:   2.0781[ 859]\n",
      "91:xent_v0   [1000]: avg:   1.9160, min:   1.7665[ 964], max:   2.0613[ 904]\n",
      "===================\n",
      "beginning of epoch:  92\n",
      "available: 2.767 GB, used: 25.899 GB, free: 2.668 GB\n",
      "EPOCH: 92\n",
      "mean score: 0.00\n",
      "Speed: train: 1875.8, buffer_add: 1005.0, buffer_size: 100059\n",
      "Total Time: 0H 54M 21S, 3261s\n",
      "Total Sample: train: 5.952M, buffer: 3.307M\n",
      "[92] Time spent = 34.62 s\n",
      "92:grad_norm [1000]: avg:   4.0074, min:   2.4502[ 190], max:   6.4338[ 213]\n",
      "92:loss      [1000]: avg:   7.2524, min:   5.4844[ 366], max:   9.5081[ 680]\n",
      "92:xent_pred [1000]: avg:   1.9259, min:   1.7340[ 835], max:   2.0738[ 389]\n",
      "92:xent_v0   [1000]: avg:   1.9156, min:   1.7207[ 835], max:   2.0609[ 596]\n",
      "===================\n",
      "beginning of epoch:  93\n",
      "available: 2.765 GB, used: 25.893 GB, free: 2.706 GB\n",
      "EPOCH: 93\n",
      "mean score: 0.00\n",
      "Speed: train: 1851.3, buffer_add: 1019.4, buffer_size: 100018\n",
      "Total Time: 0H 54M 56S, 3296s\n",
      "Total Sample: train: 6.016M, buffer: 3.342M\n",
      "[93] Time spent = 35.37 s\n",
      "93:grad_norm [1000]: avg:   3.9562, min:   2.3212[ 694], max:   7.8043[ 611]\n",
      "93:loss      [1000]: avg:   7.1688, min:   5.1267[ 772], max:  10.0385[ 428]\n",
      "93:xent_pred [1000]: avg:   1.9246, min:   1.7863[ 712], max:   2.0722[ 708]\n",
      "93:xent_v0   [1000]: avg:   1.9155, min:   1.7874[ 712], max:   2.0736[ 708]\n",
      "===================\n",
      "beginning of epoch:  94\n",
      "available: 2.768 GB, used: 25.892 GB, free: 2.653 GB\n",
      "EPOCH: 94\n",
      "mean score: 0.00\n",
      "Speed: train: 1851.7, buffer_add: 1023.0, buffer_size: 100028\n",
      "Total Time: 0H 55M 30S, 3330s\n",
      "Total Sample: train: 6.08M, buffer: 3.378M\n",
      "[94] Time spent = 34.96 s\n",
      "94:grad_norm [1000]: avg:   3.9594, min:   2.1641[  83], max:   6.8278[ 576]\n",
      "94:loss      [1000]: avg:   7.2041, min:   5.4218[  24], max:  10.1467[ 716]\n",
      "94:xent_pred [1000]: avg:   1.9238, min:   1.7857[ 434], max:   2.0890[  40]\n",
      "94:xent_v0   [1000]: avg:   1.9133, min:   1.7664[ 911], max:   2.0875[  40]\n",
      "===================\n",
      "beginning of epoch:  95\n",
      "available: 2.773 GB, used: 25.895 GB, free: 2.647 GB\n",
      "EPOCH: 95\n",
      "mean score: 0.00\n",
      "Speed: train: 1865.8, buffer_add: 1019.7, buffer_size: 100064\n",
      "Total Time: 0H 56M 04S, 3364s\n",
      "Total Sample: train: 6.144M, buffer: 3.413M\n",
      "[95] Time spent = 35.10 s\n",
      "95:grad_norm [1000]: avg:   3.8900, min:   1.9776[ 825], max:   6.5541[ 196]\n",
      "95:loss      [1000]: avg:   7.1745, min:   5.2467[ 351], max:   9.6765[  49]\n",
      "95:xent_pred [1000]: avg:   1.9251, min:   1.7639[ 616], max:   2.0684[ 924]\n",
      "95:xent_v0   [1000]: avg:   1.9153, min:   1.7605[ 616], max:   2.0594[ 924]\n",
      "===================\n",
      "beginning of epoch:  96\n",
      "available: 2.771 GB, used: 25.896 GB, free: 2.604 GB\n",
      "EPOCH: 96\n",
      "mean score: 0.00\n",
      "Speed: train: 1882.9, buffer_add: 1018.8, buffer_size: 100010\n",
      "Total Time: 0H 56M 38S, 3398s\n",
      "Total Sample: train: 6.208M, buffer: 3.447M\n",
      "[96] Time spent = 34.32 s\n",
      "96:grad_norm [1000]: avg:   3.9623, min:   2.4722[ 476], max:   7.7773[  70]\n",
      "96:loss      [1000]: avg:   7.2337, min:   5.5304[ 707], max:   9.3758[ 245]\n",
      "96:xent_pred [1000]: avg:   1.9259, min:   1.7319[ 388], max:   2.1009[  23]\n",
      "96:xent_v0   [1000]: avg:   1.9161, min:   1.7367[ 388], max:   2.0934[  23]\n",
      "===================\n",
      "beginning of epoch:  97\n",
      "available: 2.778 GB, used: 25.885 GB, free: 2.669 GB\n",
      "EPOCH: 97\n",
      "mean score: 0.00\n",
      "Speed: train: 1853.0, buffer_add: 1012.1, buffer_size: 100007\n",
      "Total Time: 0H 57M 13S, 3433s\n",
      "Total Sample: train: 6.272M, buffer: 3.482M\n",
      "[97] Time spent = 34.91 s\n",
      "97:grad_norm [1000]: avg:   3.9303, min:   2.0273[ 218], max:   7.3377[ 510]\n",
      "97:loss      [1000]: avg:   7.2292, min:   5.1666[ 218], max:   9.8560[ 717]\n",
      "97:xent_pred [1000]: avg:   1.9198, min:   1.7657[ 579], max:   2.0604[ 196]\n",
      "97:xent_v0   [1000]: avg:   1.9100, min:   1.7510[ 579], max:   2.0512[ 196]\n",
      "===================\n",
      "beginning of epoch:  98\n",
      "available: 2.775 GB, used: 25.882 GB, free: 2.720 GB\n",
      "EPOCH: 98\n",
      "mean score: 0.00\n",
      "Speed: train: 1873.7, buffer_add: 1018.4, buffer_size: 100040\n",
      "Total Time: 0H 57M 47S, 3467s\n",
      "Total Sample: train: 6.336M, buffer: 3.517M\n",
      "[98] Time spent = 34.50 s\n",
      "98:grad_norm [1000]: avg:   3.9566, min:   2.1769[ 395], max:   6.2146[ 842]\n",
      "98:loss      [1000]: avg:   7.2318, min:   5.4559[ 684], max:   9.5541[ 961]\n",
      "98:xent_pred [1000]: avg:   1.9210, min:   1.7593[ 114], max:   2.0904[ 678]\n",
      "98:xent_v0   [1000]: avg:   1.9117, min:   1.7679[ 114], max:   2.0652[ 678]\n",
      "===================\n",
      "beginning of epoch:  99\n",
      "available: 2.779 GB, used: 25.874 GB, free: 2.732 GB\n",
      "EPOCH: 99\n",
      "mean score: 0.00\n",
      "Speed: train: 1895.2, buffer_add: 1020.0, buffer_size: 100097\n",
      "Total Time: 0H 58M 21S, 3501s\n",
      "Total Sample: train: 6.4M, buffer: 3.552M\n",
      "[99] Time spent = 34.32 s\n",
      "99:grad_norm [1000]: avg:   3.8366, min:   2.2860[ 904], max:   6.1111[ 743]\n",
      "99:loss      [1000]: avg:   7.1793, min:   5.2582[ 672], max:   9.0204[ 206]\n",
      "99:xent_pred [1000]: avg:   1.9235, min:   1.7610[ 183], max:   2.0580[ 981]\n",
      "99:xent_v0   [1000]: avg:   1.9143, min:   1.7544[ 183], max:   2.0482[ 626]\n",
      "===================\n",
      "beginning of epoch:  100\n",
      "available: 2.767 GB, used: 25.890 GB, free: 2.722 GB\n",
      "EPOCH: 100\n",
      "mean score: 0.00\n",
      "Speed: train: 1872.4, buffer_add: 1016.9, buffer_size: 100024\n",
      "Total Time: 0H 58M 55S, 3535s\n",
      "Total Sample: train: 6.464M, buffer: 3.586M\n",
      "[100] Time spent = 34.79 s\n",
      "100:grad_norm[1000]: avg:   3.8120, min:   2.1752[ 785], max:   8.7414[ 563]\n",
      "100:loss     [1000]: avg:   7.2032, min:   5.4300[ 885], max:   9.4747[ 134]\n",
      "100:xent_pred[1000]: avg:   1.9234, min:   1.7865[ 512], max:   2.0871[ 854]\n",
      "100:xent_v0  [1000]: avg:   1.9143, min:   1.7784[ 512], max:   2.0704[ 854]\n",
      "===================\n",
      "beginning of epoch:  101\n",
      "available: 2.769 GB, used: 25.888 GB, free: 2.653 GB\n",
      "EPOCH: 101\n",
      "mean score: 0.00\n",
      "Speed: train: 1856.2, buffer_add: 1028.8, buffer_size: 100026\n",
      "Total Time: 0H 59M 29S, 3569s\n",
      "Total Sample: train: 6.528M, buffer: 3.622M\n",
      "[101] Time spent = 34.96 s\n",
      "101:grad_norm[1000]: avg:   3.8297, min:   1.8940[ 194], max:   6.0833[ 450]\n",
      "101:loss     [1000]: avg:   7.1824, min:   5.4297[ 331], max:  10.0470[ 892]\n",
      "101:xent_pred[1000]: avg:   1.9244, min:   1.7796[  44], max:   2.0709[ 398]\n",
      "101:xent_v0  [1000]: avg:   1.9146, min:   1.7755[ 519], max:   2.0528[ 398]\n",
      "===================\n",
      "beginning of epoch:  102\n",
      "available: 2.772 GB, used: 25.883 GB, free: 2.702 GB\n",
      "EPOCH: 102\n",
      "mean score: 0.00\n",
      "Speed: train: 1838.8, buffer_add: 1031.3, buffer_size: 100002\n",
      "Total Time: 1H 00M 04S, 3604s\n",
      "Total Sample: train: 6.592M, buffer: 3.658M\n",
      "[102] Time spent = 35.22 s\n",
      "102:grad_norm[1000]: avg:   3.8457, min:   2.2057[ 250], max:   7.1383[ 433]\n",
      "102:loss     [1000]: avg:   7.2190, min:   5.1921[ 285], max:   9.3810[ 957]\n",
      "102:xent_pred[1000]: avg:   1.9228, min:   1.7443[ 510], max:   2.0838[ 123]\n",
      "102:xent_v0  [1000]: avg:   1.9135, min:   1.7371[ 510], max:   2.0725[ 123]\n",
      "===================\n",
      "beginning of epoch:  103\n",
      "available: 2.775 GB, used: 25.883 GB, free: 2.690 GB\n",
      "EPOCH: 103\n",
      "mean score: 0.00\n",
      "Speed: train: 1868.7, buffer_add: 1018.0, buffer_size: 100030\n",
      "Total Time: 1H 00M 39S, 3639s\n",
      "Total Sample: train: 6.656M, buffer: 3.693M\n",
      "[103] Time spent = 34.74 s\n",
      "103:grad_norm[1000]: avg:   3.8328, min:   2.2285[ 109], max:   6.5593[ 869]\n",
      "103:loss     [1000]: avg:   7.2379, min:   5.2987[ 185], max:   9.5520[  33]\n",
      "103:xent_pred[1000]: avg:   1.9237, min:   1.7797[ 187], max:   2.0721[ 428]\n",
      "103:xent_v0  [1000]: avg:   1.9141, min:   1.7659[ 187], max:   2.0649[ 428]\n",
      "===================\n",
      "beginning of epoch:  104\n",
      "available: 2.776 GB, used: 25.879 GB, free: 2.710 GB\n",
      "EPOCH: 104\n",
      "mean score: 0.00\n",
      "Speed: train: 1831.3, buffer_add: 1026.5, buffer_size: 100029\n",
      "Total Time: 1H 01M 13S, 3673s\n",
      "Total Sample: train: 6.72M, buffer: 3.729M\n",
      "[104] Time spent = 35.47 s\n",
      "104:grad_norm[1000]: avg:   3.8268, min:   2.0063[ 760], max:   6.3518[ 362]\n",
      "104:loss     [1000]: avg:   7.2597, min:   5.1024[ 283], max:   9.5254[ 326]\n",
      "104:xent_pred[1000]: avg:   1.9199, min:   1.7465[ 801], max:   2.0846[ 631]\n",
      "104:xent_v0  [1000]: avg:   1.9104, min:   1.7379[ 801], max:   2.0846[ 631]\n",
      "===================\n",
      "beginning of epoch:  105\n",
      "available: 2.776 GB, used: 25.883 GB, free: 2.714 GB\n",
      "EPOCH: 105\n",
      "mean score: 0.00\n",
      "Speed: train: 1881.0, buffer_add: 1007.7, buffer_size: 100025\n",
      "Total Time: 1H 01M 48S, 3708s\n",
      "Total Sample: train: 6.784M, buffer: 3.763M\n",
      "[105] Time spent = 34.46 s\n",
      "105:grad_norm[1000]: avg:   3.7661, min:   2.1569[ 914], max:   6.4091[ 317]\n",
      "105:loss     [1000]: avg:   7.1991, min:   5.1734[  59], max:   9.5504[  15]\n",
      "105:xent_pred[1000]: avg:   1.9231, min:   1.7521[  95], max:   2.1045[  40]\n",
      "105:xent_v0  [1000]: avg:   1.9142, min:   1.7437[  95], max:   2.0720[  40]\n",
      "===================\n",
      "beginning of epoch:  106\n",
      "available: 2.775 GB, used: 25.882 GB, free: 2.714 GB\n",
      "EPOCH: 106\n",
      "mean score: 0.00\n",
      "Speed: train: 1842.9, buffer_add: 1014.8, buffer_size: 100051\n",
      "Total Time: 1H 02M 22S, 3742s\n",
      "Total Sample: train: 6.848M, buffer: 3.798M\n",
      "[106] Time spent = 35.26 s\n",
      "106:grad_norm[1000]: avg:   3.7861, min:   2.1608[ 768], max:   6.5860[ 114]\n",
      "106:loss     [1000]: avg:   7.2203, min:   5.2642[ 329], max:   9.7545[ 734]\n",
      "106:xent_pred[1000]: avg:   1.9248, min:   1.7463[  51], max:   2.0664[ 161]\n",
      "106:xent_v0  [1000]: avg:   1.9162, min:   1.7414[  51], max:   2.0678[ 161]\n",
      "===================\n",
      "beginning of epoch:  107\n",
      "available: 2.776 GB, used: 25.887 GB, free: 2.719 GB\n",
      "EPOCH: 107\n",
      "mean score: 0.00\n",
      "Speed: train: 1866.1, buffer_add: 1018.6, buffer_size: 100018\n",
      "Total Time: 1H 02M 57S, 3777s\n",
      "Total Sample: train: 6.912M, buffer: 3.833M\n",
      "[107] Time spent = 34.74 s\n",
      "107:grad_norm[1000]: avg:   3.7465, min:   2.0606[ 820], max:   6.1664[ 452]\n",
      "107:loss     [1000]: avg:   7.2093, min:   5.2271[ 935], max:   9.8931[ 452]\n",
      "107:xent_pred[1000]: avg:   1.9241, min:   1.7635[ 332], max:   2.0866[ 360]\n",
      "107:xent_v0  [1000]: avg:   1.9151, min:   1.7615[ 332], max:   2.0642[ 956]\n",
      "===================\n",
      "beginning of epoch:  108\n",
      "available: 2.773 GB, used: 25.891 GB, free: 2.680 GB\n",
      "EPOCH: 108\n",
      "mean score: 0.00\n",
      "Speed: train: 1844.8, buffer_add: 1017.8, buffer_size: 100032\n",
      "Total Time: 1H 03M 31S, 3811s\n",
      "Total Sample: train: 6.976M, buffer: 3.868M\n",
      "[108] Time spent = 35.11 s\n",
      "108:grad_norm[1000]: avg:   3.7300, min:   2.1032[ 673], max:   6.2136[ 792]\n",
      "108:loss     [1000]: avg:   7.2190, min:   5.1276[ 668], max:   9.2743[ 339]\n",
      "108:xent_pred[1000]: avg:   1.9233, min:   1.7583[ 346], max:   2.0806[  25]\n",
      "108:xent_v0  [1000]: avg:   1.9147, min:   1.7498[ 346], max:   2.0632[  25]\n",
      "===================\n",
      "beginning of epoch:  109\n",
      "available: 2.767 GB, used: 25.891 GB, free: 2.661 GB\n",
      "EPOCH: 109\n",
      "mean score: 0.00\n",
      "Speed: train: 1865.4, buffer_add: 1014.0, buffer_size: 100031\n",
      "Total Time: 1H 04M 06S, 3846s\n",
      "Total Sample: train: 7.04M, buffer: 3.903M\n",
      "[109] Time spent = 34.71 s\n",
      "109:grad_norm[1000]: avg:   3.7727, min:   2.1074[ 778], max:   6.7805[ 742]\n",
      "109:loss     [1000]: avg:   7.2674, min:   5.4634[ 302], max:   9.6394[  21]\n",
      "109:xent_pred[1000]: avg:   1.9226, min:   1.7703[ 168], max:   2.0702[ 531]\n",
      "109:xent_v0  [1000]: avg:   1.9142, min:   1.7548[ 168], max:   2.0568[  52]\n",
      "===================\n",
      "beginning of epoch:  110\n",
      "available: 2.773 GB, used: 25.891 GB, free: 2.660 GB\n",
      "EPOCH: 110\n",
      "mean score: 0.00\n",
      "Speed: train: 1854.8, buffer_add: 1008.1, buffer_size: 100027\n",
      "Total Time: 1H 04M 40S, 3880s\n",
      "Total Sample: train: 7.104M, buffer: 3.938M\n",
      "[110] Time spent = 34.94 s\n",
      "110:grad_norm[1000]: avg:   3.7228, min:   2.2153[ 212], max:   6.9884[ 951]\n",
      "110:loss     [1000]: avg:   7.1778, min:   5.3407[ 198], max:   9.7545[ 705]\n",
      "110:xent_pred[1000]: avg:   1.9200, min:   1.7712[ 547], max:   2.0569[  42]\n",
      "110:xent_v0  [1000]: avg:   1.9114, min:   1.7705[ 739], max:   2.0528[  42]\n",
      "===================\n",
      "beginning of epoch:  111\n",
      "available: 2.781 GB, used: 25.885 GB, free: 2.672 GB\n",
      "EPOCH: 111\n",
      "mean score: 0.00\n",
      "Speed: train: 1855.4, buffer_add: 1014.6, buffer_size: 100021\n",
      "Total Time: 1H 05M 15S, 3915s\n",
      "Total Sample: train: 7.168M, buffer: 3.973M\n",
      "[111] Time spent = 34.94 s\n",
      "111:grad_norm[1000]: avg:   3.7000, min:   2.2975[ 161], max:   6.3502[ 109]\n",
      "111:loss     [1000]: avg:   7.1746, min:   5.3640[ 492], max:   9.6658[  68]\n",
      "111:xent_pred[1000]: avg:   1.9214, min:   1.7675[ 818], max:   2.0496[ 151]\n",
      "111:xent_v0  [1000]: avg:   1.9126, min:   1.7704[ 254], max:   2.0492[ 862]\n",
      "===================\n",
      "beginning of epoch:  112\n",
      "available: 2.783 GB, used: 25.879 GB, free: 2.694 GB\n",
      "EPOCH: 112\n",
      "mean score: 0.00\n",
      "Speed: train: 1869.4, buffer_add: 1016.7, buffer_size: 100007\n",
      "Total Time: 1H 05M 49S, 3949s\n",
      "Total Sample: train: 7.232M, buffer: 4.008M\n",
      "[112] Time spent = 35.34 s\n",
      "112:grad_norm[1000]: avg:   3.7423, min:   2.2731[ 982], max:  10.6836[ 769]\n",
      "112:loss     [1000]: avg:   7.1715, min:   5.2376[  55], max:   9.9272[ 184]\n",
      "112:xent_pred[1000]: avg:   1.9222, min:   1.7869[ 134], max:   2.0870[ 426]\n",
      "112:xent_v0  [1000]: avg:   1.9135, min:   1.7707[ 134], max:   2.0726[ 426]\n",
      "===================\n",
      "beginning of epoch:  113\n",
      "available: 2.781 GB, used: 25.876 GB, free: 2.645 GB\n",
      "EPOCH: 113\n",
      "mean score: 0.00\n",
      "Speed: train: 1861.6, buffer_add: 1033.7, buffer_size: 100041\n",
      "Total Time: 1H 06M 23S, 3983s\n",
      "Total Sample: train: 7.296M, buffer: 4.043M\n",
      "[113] Time spent = 34.72 s\n",
      "113:grad_norm[1000]: avg:   3.7193, min:   2.1999[ 790], max:   7.7934[ 480]\n",
      "113:loss     [1000]: avg:   7.1757, min:   5.3036[ 163], max:   9.2013[ 925]\n",
      "113:xent_pred[1000]: avg:   1.9208, min:   1.7486[  82], max:   2.0571[ 260]\n",
      "113:xent_v0  [1000]: avg:   1.9125, min:   1.7455[  82], max:   2.0510[ 260]\n",
      "===================\n",
      "beginning of epoch:  114\n",
      "available: 2.780 GB, used: 25.879 GB, free: 2.662 GB\n",
      "EPOCH: 114\n",
      "mean score: 0.00\n",
      "Speed: train: 1832.8, buffer_add: 1010.4, buffer_size: 100008\n",
      "Total Time: 1H 06M 58S, 4018s\n",
      "Total Sample: train: 7.36M, buffer: 4.078M\n",
      "[114] Time spent = 35.55 s\n",
      "114:grad_norm[1000]: avg:   3.7047, min:   2.0725[ 348], max:   6.3714[ 833]\n",
      "114:loss     [1000]: avg:   7.1410, min:   5.0899[ 598], max:   9.6035[ 205]\n",
      "114:xent_pred[1000]: avg:   1.9221, min:   1.7636[ 339], max:   2.0825[ 852]\n",
      "114:xent_v0  [1000]: avg:   1.9139, min:   1.7507[ 339], max:   2.0737[ 937]\n",
      "===================\n",
      "beginning of epoch:  115\n",
      "available: 2.772 GB, used: 25.885 GB, free: 2.722 GB\n",
      "EPOCH: 115\n",
      "mean score: 0.00\n",
      "Speed: train: 1854.3, buffer_add: 1026.1, buffer_size: 100041\n",
      "Total Time: 1H 07M 33S, 4053s\n",
      "Total Sample: train: 7.424M, buffer: 4.114M\n",
      "[115] Time spent = 35.13 s\n",
      "115:grad_norm[1000]: avg:   3.7064, min:   2.1936[  75], max:   7.2135[ 331]\n",
      "115:loss     [1000]: avg:   7.2308, min:   5.3606[ 616], max:   9.2954[ 702]\n",
      "115:xent_pred[1000]: avg:   1.9199, min:   1.7731[ 951], max:   2.1037[ 764]\n",
      "115:xent_v0  [1000]: avg:   1.9120, min:   1.7591[ 951], max:   2.0942[ 764]\n",
      "===================\n",
      "beginning of epoch:  116\n",
      "available: 2.776 GB, used: 25.882 GB, free: 2.704 GB\n",
      "EPOCH: 116\n",
      "mean score: 0.00\n",
      "Speed: train: 1838.7, buffer_add: 1011.6, buffer_size: 100048\n",
      "Total Time: 1H 08M 07S, 4087s\n",
      "Total Sample: train: 7.488M, buffer: 4.149M\n",
      "[116] Time spent = 35.10 s\n",
      "116:grad_norm[1000]: avg:   3.7266, min:   2.1275[ 137], max:   7.4133[ 892]\n",
      "116:loss     [1000]: avg:   7.2823, min:   5.4937[ 644], max:  10.3529[ 892]\n",
      "116:xent_pred[1000]: avg:   1.9199, min:   1.7006[ 746], max:   2.0658[ 586]\n",
      "116:xent_v0  [1000]: avg:   1.9117, min:   1.7026[ 746], max:   2.0621[ 586]\n",
      "===================\n",
      "beginning of epoch:  117\n",
      "available: 2.775 GB, used: 25.880 GB, free: 2.729 GB\n",
      "EPOCH: 117\n",
      "mean score: 0.00\n",
      "Speed: train: 1820.9, buffer_add: 989.4, buffer_size: 100010\n",
      "Total Time: 1H 08M 43S, 4123s\n",
      "Total Sample: train: 7.552M, buffer: 4.184M\n",
      "[117] Time spent = 35.55 s\n",
      "117:grad_norm[1000]: avg:   3.6960, min:   2.2230[ 342], max:   6.0241[  86]\n",
      "117:loss     [1000]: avg:   7.2865, min:   5.2321[ 324], max:   9.8833[ 906]\n",
      "117:xent_pred[1000]: avg:   1.9196, min:   1.7704[ 887], max:   2.0614[ 632]\n",
      "117:xent_v0  [1000]: avg:   1.9114, min:   1.7655[ 887], max:   2.0553[ 632]\n",
      "===================\n",
      "beginning of epoch:  118\n",
      "available: 2.773 GB, used: 25.889 GB, free: 2.697 GB\n",
      "EPOCH: 118\n",
      "mean score: 0.00\n",
      "Speed: train: 1845.9, buffer_add: 1016.3, buffer_size: 100052\n",
      "Total Time: 1H 09M 17S, 4157s\n",
      "Total Sample: train: 7.616M, buffer: 4.219M\n",
      "[118] Time spent = 35.12 s\n",
      "118:grad_norm[1000]: avg:   3.6598, min:   2.1575[ 879], max:   6.0094[ 192]\n",
      "118:loss     [1000]: avg:   7.2426, min:   5.5790[ 672], max:   9.6440[ 688]\n",
      "118:xent_pred[1000]: avg:   1.9213, min:   1.7709[ 319], max:   2.0647[ 809]\n",
      "118:xent_v0  [1000]: avg:   1.9128, min:   1.7597[  31], max:   2.0491[ 502]\n",
      "===================\n",
      "beginning of epoch:  119\n",
      "available: 2.773 GB, used: 25.889 GB, free: 2.701 GB\n",
      "EPOCH: 119\n",
      "mean score: 0.00\n",
      "Speed: train: 1846.6, buffer_add: 1007.0, buffer_size: 100054\n",
      "Total Time: 1H 09M 52S, 4192s\n",
      "Total Sample: train: 7.68M, buffer: 4.254M\n",
      "[119] Time spent = 35.13 s\n",
      "119:grad_norm[1000]: avg:   3.6263, min:   1.8300[ 284], max:   6.4516[ 568]\n",
      "119:loss     [1000]: avg:   7.2314, min:   4.8738[ 889], max:   9.5570[ 568]\n",
      "119:xent_pred[1000]: avg:   1.9194, min:   1.7674[ 134], max:   2.0818[ 515]\n",
      "119:xent_v0  [1000]: avg:   1.9112, min:   1.7620[ 134], max:   2.0762[ 515]\n",
      "===================\n",
      "beginning of epoch:  120\n",
      "available: 2.780 GB, used: 25.872 GB, free: 2.739 GB\n",
      "EPOCH: 120\n",
      "mean score: 0.00\n",
      "Speed: train: 1894.3, buffer_add: 1008.3, buffer_size: 100023\n",
      "Total Time: 1H 10M 26S, 4226s\n",
      "Total Sample: train: 7.744M, buffer: 4.288M\n",
      "[120] Time spent = 34.62 s\n",
      "120:grad_norm[1000]: avg:   3.6199, min:   2.0760[ 398], max:   7.0886[ 268]\n",
      "120:loss     [1000]: avg:   7.1561, min:   5.1585[ 398], max:   9.6986[ 613]\n",
      "120:xent_pred[1000]: avg:   1.9243, min:   1.7631[ 619], max:   2.0938[ 646]\n",
      "120:xent_v0  [1000]: avg:   1.9165, min:   1.7547[ 619], max:   2.0882[ 646]\n",
      "===================\n",
      "beginning of epoch:  121\n",
      "available: 2.765 GB, used: 25.889 GB, free: 2.690 GB\n",
      "EPOCH: 121\n",
      "mean score: 0.00\n",
      "Speed: train: 1847.7, buffer_add: 1013.4, buffer_size: 100021\n",
      "Total Time: 1H 11M 00S, 4260s\n",
      "Total Sample: train: 7.808M, buffer: 4.323M\n",
      "[121] Time spent = 35.08 s\n",
      "121:grad_norm[1000]: avg:   3.6575, min:   1.7020[ 164], max:   5.8163[ 135]\n",
      "121:loss     [1000]: avg:   7.2013, min:   4.9687[ 164], max:   9.4075[ 133]\n",
      "121:xent_pred[1000]: avg:   1.9225, min:   1.7807[ 900], max:   2.0536[ 221]\n",
      "121:xent_v0  [1000]: avg:   1.9145, min:   1.7722[ 900], max:   2.0519[ 574]\n",
      "===================\n",
      "beginning of epoch:  122\n",
      "available: 2.774 GB, used: 25.882 GB, free: 2.697 GB\n",
      "EPOCH: 122\n",
      "mean score: 0.00\n",
      "Speed: train: 1839.6, buffer_add: 1006.6, buffer_size: 100001\n",
      "Total Time: 1H 11M 35S, 4295s\n",
      "Total Sample: train: 7.872M, buffer: 4.358M\n",
      "[122] Time spent = 35.20 s\n",
      "122:grad_norm[1000]: avg:   3.6627, min:   2.0553[ 913], max:   6.2680[ 556]\n",
      "122:loss     [1000]: avg:   7.2222, min:   5.3440[ 395], max:   9.5502[ 451]\n",
      "122:xent_pred[1000]: avg:   1.9243, min:   1.7602[ 855], max:   2.0728[ 270]\n",
      "122:xent_v0  [1000]: avg:   1.9157, min:   1.7546[ 855], max:   2.0694[ 407]\n",
      "===================\n",
      "beginning of epoch:  123\n",
      "available: 2.774 GB, used: 25.882 GB, free: 2.686 GB\n",
      "EPOCH: 123\n",
      "mean score: 0.00\n",
      "Speed: train: 1836.8, buffer_add: 1011.1, buffer_size: 100023\n",
      "Total Time: 1H 12M 10S, 4330s\n",
      "Total Sample: train: 7.936M, buffer: 4.393M\n",
      "[123] Time spent = 35.25 s\n",
      "123:grad_norm[1000]: avg:   3.6054, min:   2.1621[ 958], max:   6.0053[ 404]\n",
      "123:loss     [1000]: avg:   7.2316, min:   5.3567[ 237], max:   9.7397[ 612]\n",
      "123:xent_pred[1000]: avg:   1.9233, min:   1.7663[ 256], max:   2.0635[ 466]\n",
      "123:xent_v0  [1000]: avg:   1.9157, min:   1.7612[ 256], max:   2.0642[ 466]\n",
      "===================\n",
      "beginning of epoch:  124\n",
      "available: 2.780 GB, used: 25.881 GB, free: 2.704 GB\n",
      "EPOCH: 124\n",
      "mean score: 0.00\n",
      "Speed: train: 1877.1, buffer_add: 1015.5, buffer_size: 100006\n",
      "Total Time: 1H 12M 44S, 4364s\n",
      "Total Sample: train: 8M, buffer: 4.428M\n",
      "[124] Time spent = 34.43 s\n",
      "124:grad_norm[1000]: avg:   3.5851, min:   2.1970[ 248], max:   6.1733[ 362]\n",
      "124:loss     [1000]: avg:   7.2287, min:   5.3799[ 747], max:   9.9476[ 456]\n",
      "124:xent_pred[1000]: avg:   1.9199, min:   1.7734[ 773], max:   2.0846[ 961]\n",
      "124:xent_v0  [1000]: avg:   1.9128, min:   1.7676[ 773], max:   2.0787[ 961]\n",
      "===================\n",
      "beginning of epoch:  125\n",
      "available: 2.774 GB, used: 25.886 GB, free: 2.697 GB\n",
      "EPOCH: 125\n",
      "mean score: 0.00\n",
      "Speed: train: 1894.1, buffer_add: 1011.1, buffer_size: 100024\n",
      "Total Time: 1H 13M 18S, 4398s\n",
      "Total Sample: train: 8.064M, buffer: 4.462M\n",
      "[125] Time spent = 34.24 s\n",
      "125:grad_norm[1000]: avg:   3.5713, min:   1.9808[ 354], max:   6.6698[ 837]\n",
      "125:loss     [1000]: avg:   7.2065, min:   4.8764[ 913], max:   9.5808[  63]\n",
      "125:xent_pred[1000]: avg:   1.9213, min:   1.7629[ 632], max:   2.0747[ 520]\n",
      "125:xent_v0  [1000]: avg:   1.9139, min:   1.7491[ 632], max:   2.0826[ 520]\n",
      "===================\n",
      "beginning of epoch:  126\n",
      "available: 2.766 GB, used: 25.889 GB, free: 2.736 GB\n",
      "EPOCH: 126\n",
      "mean score: 0.00\n",
      "Speed: train: 1865.7, buffer_add: 1013.3, buffer_size: 100018\n",
      "Total Time: 1H 13M 52S, 4432s\n",
      "Total Sample: train: 8.128M, buffer: 4.497M\n",
      "[126] Time spent = 34.95 s\n",
      "126:grad_norm[1000]: avg:   3.5425, min:   2.0832[ 242], max:   6.2692[ 837]\n",
      "126:loss     [1000]: avg:   7.1327, min:   5.2295[ 629], max:   9.7246[ 954]\n",
      "126:xent_pred[1000]: avg:   1.9247, min:   1.7882[ 604], max:   2.0583[ 995]\n",
      "126:xent_v0  [1000]: avg:   1.9171, min:   1.7851[  74], max:   2.0530[ 189]\n",
      "===================\n",
      "beginning of epoch:  127\n",
      "available: 2.772 GB, used: 25.884 GB, free: 2.720 GB\n",
      "EPOCH: 127\n",
      "mean score: 0.00\n",
      "Speed: train: 1868.3, buffer_add: 1017.4, buffer_size: 100042\n",
      "Total Time: 1H 14M 26S, 4466s\n",
      "Total Sample: train: 8.192M, buffer: 4.532M\n",
      "[127] Time spent = 34.69 s\n",
      "127:grad_norm[1000]: avg:   3.5525, min:   2.1196[ 380], max:   5.6231[ 879]\n",
      "127:loss     [1000]: avg:   7.1729, min:   5.1808[ 688], max:   9.3753[ 695]\n",
      "127:xent_pred[1000]: avg:   1.9245, min:   1.7211[ 888], max:   2.0780[ 933]\n",
      "127:xent_v0  [1000]: avg:   1.9173, min:   1.7194[ 888], max:   2.0657[ 367]\n",
      "===================\n",
      "beginning of epoch:  128\n",
      "available: 2.778 GB, used: 25.886 GB, free: 2.673 GB\n",
      "EPOCH: 128\n",
      "mean score: 0.00\n",
      "Speed: train: 1863.8, buffer_add: 1013.6, buffer_size: 100023\n",
      "Total Time: 1H 15M 01S, 4501s\n",
      "Total Sample: train: 8.256M, buffer: 4.567M\n",
      "[128] Time spent = 34.70 s\n",
      "128:grad_norm[1000]: avg:   3.5888, min:   2.0893[ 705], max:   6.5903[ 696]\n",
      "128:loss     [1000]: avg:   7.2480, min:   5.3683[ 353], max:  10.2001[ 556]\n",
      "128:xent_pred[1000]: avg:   1.9198, min:   1.7783[ 335], max:   2.1137[ 407]\n",
      "128:xent_v0  [1000]: avg:   1.9125, min:   1.7761[ 335], max:   2.1026[ 407]\n",
      "===================\n",
      "beginning of epoch:  129\n",
      "available: 2.776 GB, used: 25.883 GB, free: 2.699 GB\n",
      "EPOCH: 129\n",
      "mean score: 0.00\n",
      "Speed: train: 1896.2, buffer_add: 1006.8, buffer_size: 100032\n",
      "Total Time: 1H 15M 34S, 4534s\n",
      "Total Sample: train: 8.32M, buffer: 4.601M\n",
      "[129] Time spent = 34.07 s\n",
      "129:grad_norm[1000]: avg:   3.5694, min:   1.9339[ 592], max:   7.1363[ 778]\n",
      "129:loss     [1000]: avg:   7.2228, min:   5.1925[ 494], max:   9.1987[ 169]\n",
      "129:xent_pred[1000]: avg:   1.9207, min:   1.7848[ 886], max:   2.0678[ 546]\n",
      "129:xent_v0  [1000]: avg:   1.9132, min:   1.7762[ 923], max:   2.0551[ 546]\n",
      "===================\n",
      "beginning of epoch:  130\n",
      "available: 2.772 GB, used: 25.883 GB, free: 2.714 GB\n",
      "EPOCH: 130\n",
      "mean score: 0.00\n",
      "Speed: train: 1874.7, buffer_add: 1013.4, buffer_size: 100033\n",
      "Total Time: 1H 16M 09S, 4569s\n",
      "Total Sample: train: 8.384M, buffer: 4.635M\n",
      "[130] Time spent = 34.55 s\n",
      "130:grad_norm[1000]: avg:   3.5338, min:   2.1258[  43], max:   6.2707[ 810]\n",
      "130:loss     [1000]: avg:   7.2038, min:   5.0060[ 683], max:   9.6383[ 198]\n",
      "130:xent_pred[1000]: avg:   1.9198, min:   1.7801[ 507], max:   2.0820[ 115]\n",
      "130:xent_v0  [1000]: avg:   1.9124, min:   1.7762[ 507], max:   2.0666[ 115]\n",
      "===================\n",
      "beginning of epoch:  131\n",
      "available: 2.774 GB, used: 25.890 GB, free: 2.736 GB\n",
      "EPOCH: 131\n",
      "mean score: 0.00\n",
      "Speed: train: 1817.4, buffer_add: 1011.8, buffer_size: 100052\n",
      "Total Time: 1H 16M 44S, 4604s\n",
      "Total Sample: train: 8.448M, buffer: 4.671M\n",
      "[131] Time spent = 35.68 s\n",
      "131:grad_norm[1000]: avg:   3.5268, min:   1.9662[ 648], max:   6.2295[ 189]\n",
      "131:loss     [1000]: avg:   7.1735, min:   4.9049[ 648], max:   9.5573[ 776]\n",
      "131:xent_pred[1000]: avg:   1.9236, min:   1.7731[ 696], max:   2.0707[ 648]\n",
      "131:xent_v0  [1000]: avg:   1.9164, min:   1.7681[ 917], max:   2.0597[ 648]\n",
      "===================\n",
      "beginning of epoch:  132\n",
      "available: 2.760 GB, used: 25.896 GB, free: 2.713 GB\n",
      "EPOCH: 132\n",
      "mean score: 0.00\n",
      "Speed: train: 1845.8, buffer_add: 1016.3, buffer_size: 100039\n",
      "Total Time: 1H 17M 18S, 4638s\n",
      "Total Sample: train: 8.512M, buffer: 4.706M\n",
      "[132] Time spent = 35.08 s\n",
      "132:grad_norm[1000]: avg:   3.5012, min:   2.0334[ 196], max:   6.7859[ 571]\n",
      "132:loss     [1000]: avg:   7.1782, min:   5.2937[ 935], max:   9.4745[ 723]\n",
      "132:xent_pred[1000]: avg:   1.9202, min:   1.7621[ 507], max:   2.0860[ 210]\n",
      "132:xent_v0  [1000]: avg:   1.9125, min:   1.7525[ 507], max:   2.0728[ 210]\n",
      "===================\n",
      "beginning of epoch:  133\n",
      "available: 2.757 GB, used: 25.904 GB, free: 2.703 GB\n",
      "EPOCH: 133\n",
      "mean score: 0.00\n",
      "Speed: train: 1864.1, buffer_add: 1008.2, buffer_size: 100019\n",
      "Total Time: 1H 17M 53S, 4673s\n",
      "Total Sample: train: 8.576M, buffer: 4.741M\n",
      "[133] Time spent = 34.90 s\n",
      "133:grad_norm[1000]: avg:   3.5127, min:   2.0324[ 498], max:   5.8112[ 719]\n",
      "133:loss     [1000]: avg:   7.2200, min:   5.2938[ 707], max:   9.5254[ 167]\n",
      "133:xent_pred[1000]: avg:   1.9220, min:   1.7916[ 847], max:   2.0705[ 898]\n",
      "133:xent_v0  [1000]: avg:   1.9145, min:   1.7755[ 961], max:   2.0576[ 898]\n",
      "===================\n",
      "beginning of epoch:  134\n",
      "available: 2.760 GB, used: 25.900 GB, free: 2.683 GB\n",
      "EPOCH: 134\n",
      "mean score: 0.00\n",
      "Speed: train: 1864.1, buffer_add: 1013.6, buffer_size: 100043\n",
      "Total Time: 1H 18M 27S, 4707s\n",
      "Total Sample: train: 8.64M, buffer: 4.775M\n",
      "[134] Time spent = 34.79 s\n",
      "134:grad_norm[1000]: avg:   3.4963, min:   1.8551[ 436], max:   5.6011[  33]\n",
      "134:loss     [1000]: avg:   7.2171, min:   4.9639[ 436], max:   9.9331[  95]\n",
      "134:xent_pred[1000]: avg:   1.9210, min:   1.7528[ 896], max:   2.0729[ 734]\n",
      "134:xent_v0  [1000]: avg:   1.9132, min:   1.7402[ 896], max:   2.0668[ 436]\n",
      "===================\n",
      "beginning of epoch:  135\n",
      "available: 2.770 GB, used: 25.885 GB, free: 2.713 GB\n",
      "EPOCH: 135\n",
      "mean score: 0.00\n",
      "Speed: train: 1851.0, buffer_add: 1014.7, buffer_size: 100035\n",
      "Total Time: 1H 19M 02S, 4742s\n",
      "Total Sample: train: 8.704M, buffer: 4.811M\n",
      "[135] Time spent = 35.04 s\n",
      "135:grad_norm[1000]: avg:   3.5181, min:   1.9225[  67], max:   6.3891[ 884]\n",
      "135:loss     [1000]: avg:   7.1842, min:   5.2665[  88], max:   9.5702[ 615]\n",
      "135:xent_pred[1000]: avg:   1.9219, min:   1.7442[ 943], max:   2.0704[ 692]\n",
      "135:xent_v0  [1000]: avg:   1.9147, min:   1.7474[ 720], max:   2.0646[ 692]\n",
      "===================\n",
      "beginning of epoch:  136\n",
      "available: 2.768 GB, used: 25.891 GB, free: 2.680 GB\n",
      "EPOCH: 136\n",
      "mean score: 0.00\n",
      "Speed: train: 1827.2, buffer_add: 1019.5, buffer_size: 100033\n",
      "Total Time: 1H 19M 37S, 4777s\n",
      "Total Sample: train: 8.768M, buffer: 4.846M\n",
      "[136] Time spent = 35.48 s\n",
      "136:grad_norm[1000]: avg:   3.4310, min:   1.9983[ 255], max:   5.6862[ 491]\n",
      "136:loss     [1000]: avg:   7.1544, min:   5.3254[ 199], max:   9.4702[ 228]\n",
      "136:xent_pred[1000]: avg:   1.9217, min:   1.7608[ 675], max:   2.0594[ 221]\n",
      "136:xent_v0  [1000]: avg:   1.9146, min:   1.7537[ 675], max:   2.0469[ 146]\n",
      "===================\n",
      "beginning of epoch:  137\n",
      "available: 2.760 GB, used: 25.896 GB, free: 2.685 GB\n",
      "EPOCH: 137\n",
      "mean score: 0.00\n",
      "Speed: train: 1882.6, buffer_add: 1002.9, buffer_size: 100015\n",
      "Total Time: 1H 20M 11S, 4811s\n",
      "Total Sample: train: 8.832M, buffer: 4.88M\n",
      "[137] Time spent = 34.73 s\n",
      "137:grad_norm[1000]: avg:   3.4352, min:   1.9857[ 292], max:   8.7797[ 727]\n",
      "137:loss     [1000]: avg:   7.1142, min:   5.3873[ 920], max:   9.2972[ 255]\n",
      "137:xent_pred[1000]: avg:   1.9264, min:   1.7736[ 597], max:   2.0834[ 245]\n",
      "137:xent_v0  [1000]: avg:   1.9193, min:   1.7734[ 597], max:   2.0577[ 245]\n",
      "===================\n",
      "beginning of epoch:  138\n",
      "available: 2.754 GB, used: 25.898 GB, free: 2.648 GB\n",
      "EPOCH: 138\n",
      "mean score: 0.00\n",
      "Speed: train: 1876.4, buffer_add: 1020.3, buffer_size: 100008\n",
      "Total Time: 1H 20M 45S, 4845s\n",
      "Total Sample: train: 8.896M, buffer: 4.915M\n",
      "[138] Time spent = 34.55 s\n",
      "138:grad_norm[1000]: avg:   3.4777, min:   1.9265[ 843], max:   6.0001[ 639]\n",
      "138:loss     [1000]: avg:   7.1722, min:   5.3987[ 279], max:   9.3965[ 353]\n",
      "138:xent_pred[1000]: avg:   1.9205, min:   1.7717[ 775], max:   2.1022[ 557]\n",
      "138:xent_v0  [1000]: avg:   1.9133, min:   1.7656[ 775], max:   2.0881[ 557]\n",
      "===================\n",
      "beginning of epoch:  139\n",
      "available: 2.769 GB, used: 25.886 GB, free: 2.667 GB\n",
      "EPOCH: 139\n",
      "mean score: 0.00\n",
      "Speed: train: 1849.9, buffer_add: 1011.6, buffer_size: 100022\n",
      "Total Time: 1H 21M 19S, 4879s\n",
      "Total Sample: train: 8.96M, buffer: 4.95M\n",
      "[139] Time spent = 35.07 s\n",
      "139:grad_norm[1000]: avg:   3.4533, min:   1.9483[ 421], max:   6.1584[ 787]\n",
      "139:loss     [1000]: avg:   7.1868, min:   5.3291[ 622], max:   9.8934[ 162]\n",
      "139:xent_pred[1000]: avg:   1.9178, min:   1.7811[  12], max:   2.1151[ 512]\n",
      "139:xent_v0  [1000]: avg:   1.9109, min:   1.7701[ 855], max:   2.1085[ 512]\n",
      "===================\n",
      "beginning of epoch:  140\n",
      "available: 2.774 GB, used: 25.882 GB, free: 2.708 GB\n",
      "EPOCH: 140\n",
      "mean score: 0.00\n",
      "Speed: train: 1857.0, buffer_add: 1021.6, buffer_size: 100029\n",
      "Total Time: 1H 21M 54S, 4914s\n",
      "Total Sample: train: 9.024M, buffer: 4.985M\n",
      "[140] Time spent = 34.87 s\n",
      "140:grad_norm[1000]: avg:   3.4694, min:   2.0041[ 861], max:   6.4203[ 257]\n",
      "140:loss     [1000]: avg:   7.1658, min:   5.0381[ 384], max:   9.6701[ 904]\n",
      "140:xent_pred[1000]: avg:   1.9200, min:   1.7859[ 804], max:   2.0706[ 512]\n",
      "140:xent_v0  [1000]: avg:   1.9127, min:   1.7746[ 904], max:   2.0692[ 512]\n",
      "===================\n",
      "beginning of epoch:  141\n",
      "available: 2.772 GB, used: 25.887 GB, free: 2.692 GB\n",
      "EPOCH: 141\n",
      "mean score: 0.00\n",
      "Speed: train: 1873.0, buffer_add: 1019.4, buffer_size: 100030\n",
      "Total Time: 1H 22M 28S, 4948s\n",
      "Total Sample: train: 9.088M, buffer: 5.02M\n",
      "[141] Time spent = 34.62 s\n",
      "141:grad_norm[1000]: avg:   3.4795, min:   2.0618[ 463], max:   6.1074[ 238]\n",
      "141:loss     [1000]: avg:   7.2220, min:   5.2372[ 734], max:   9.8120[ 132]\n",
      "141:xent_pred[1000]: avg:   1.9187, min:   1.7719[ 643], max:   2.0927[ 366]\n",
      "141:xent_v0  [1000]: avg:   1.9114, min:   1.7667[ 643], max:   2.0995[ 366]\n",
      "===================\n",
      "beginning of epoch:  142\n",
      "available: 2.772 GB, used: 25.889 GB, free: 2.689 GB\n",
      "EPOCH: 142\n",
      "mean score: 0.00\n",
      "Speed: train: 1877.9, buffer_add: 1023.6, buffer_size: 100014\n",
      "Total Time: 1H 23M 02S, 4982s\n",
      "Total Sample: train: 9.152M, buffer: 5.055M\n",
      "[142] Time spent = 34.50 s\n",
      "142:grad_norm[1000]: avg:   3.4466, min:   1.8653[  18], max:   6.6893[ 861]\n",
      "142:loss     [1000]: avg:   7.2045, min:   4.7603[  18], max:   9.7416[ 632]\n",
      "142:xent_pred[1000]: avg:   1.9189, min:   1.7805[  57], max:   2.0837[ 943]\n",
      "142:xent_v0  [1000]: avg:   1.9121, min:   1.7666[  57], max:   2.0820[ 943]\n",
      "===================\n",
      "beginning of epoch:  143\n",
      "available: 2.768 GB, used: 25.894 GB, free: 2.672 GB\n",
      "EPOCH: 143\n",
      "mean score: 0.00\n",
      "Speed: train: 1837.3, buffer_add: 1015.8, buffer_size: 100023\n",
      "Total Time: 1H 23M 37S, 5017s\n",
      "Total Sample: train: 9.216M, buffer: 5.09M\n",
      "[143] Time spent = 35.30 s\n",
      "143:grad_norm[1000]: avg:   3.4695, min:   1.8529[ 899], max:   5.5560[ 163]\n",
      "143:loss     [1000]: avg:   7.2860, min:   5.3446[  42], max:   9.9627[ 728]\n",
      "143:xent_pred[1000]: avg:   1.9183, min:   1.7632[ 161], max:   2.0675[ 672]\n",
      "143:xent_v0  [1000]: avg:   1.9121, min:   1.7576[ 161], max:   2.0618[ 672]\n",
      "===================\n",
      "beginning of epoch:  144\n",
      "available: 2.763 GB, used: 25.900 GB, free: 2.678 GB\n",
      "EPOCH: 144\n",
      "mean score: 0.00\n",
      "Speed: train: 1858.1, buffer_add: 1012.5, buffer_size: 100016\n",
      "Total Time: 1H 24M 11S, 5051s\n",
      "Total Sample: train: 9.28M, buffer: 5.125M\n",
      "[144] Time spent = 34.83 s\n",
      "144:grad_norm[1000]: avg:   3.4460, min:   1.8360[  80], max:   5.8328[ 870]\n",
      "144:loss     [1000]: avg:   7.2297, min:   5.3307[ 558], max:   9.4686[ 526]\n",
      "144:xent_pred[1000]: avg:   1.9201, min:   1.7616[ 688], max:   2.0583[ 261]\n",
      "144:xent_v0  [1000]: avg:   1.9127, min:   1.7539[ 688], max:   2.0623[ 261]\n",
      "===================\n",
      "beginning of epoch:  145\n",
      "available: 2.763 GB, used: 25.897 GB, free: 2.735 GB\n",
      "EPOCH: 145\n",
      "mean score: 0.00\n",
      "Speed: train: 1839.0, buffer_add: 1007.8, buffer_size: 100047\n",
      "Total Time: 1H 24M 46S, 5086s\n",
      "Total Sample: train: 9.344M, buffer: 5.16M\n",
      "[145] Time spent = 35.18 s\n",
      "145:grad_norm[1000]: avg:   3.4134, min:   1.7655[ 107], max:   5.8973[ 105]\n",
      "145:loss     [1000]: avg:   7.2229, min:   4.6983[ 107], max:   9.7678[ 930]\n",
      "145:xent_pred[1000]: avg:   1.9204, min:   1.7704[ 458], max:   2.1014[ 125]\n",
      "145:xent_v0  [1000]: avg:   1.9136, min:   1.7708[ 458], max:   2.0816[ 125]\n",
      "===================\n",
      "beginning of epoch:  146\n",
      "available: 2.768 GB, used: 25.895 GB, free: 2.680 GB\n",
      "EPOCH: 146\n",
      "mean score: 0.00\n",
      "Speed: train: 1870.9, buffer_add: 1004.5, buffer_size: 100022\n",
      "Total Time: 1H 25M 20S, 5120s\n",
      "Total Sample: train: 9.408M, buffer: 5.195M\n",
      "[146] Time spent = 34.64 s\n",
      "146:grad_norm[1000]: avg:   3.4213, min:   1.8999[ 196], max:   5.5477[ 160]\n",
      "146:loss     [1000]: avg:   7.2258, min:   4.9497[ 441], max:   9.0162[ 534]\n",
      "146:xent_pred[1000]: avg:   1.9204, min:   1.7736[ 283], max:   2.0672[ 695]\n",
      "146:xent_v0  [1000]: avg:   1.9130, min:   1.7721[ 283], max:   2.0640[ 407]\n",
      "===================\n",
      "beginning of epoch:  147\n",
      "available: 2.774 GB, used: 25.883 GB, free: 2.738 GB\n",
      "EPOCH: 147\n",
      "mean score: 0.00\n",
      "Speed: train: 1843.0, buffer_add: 998.7, buffer_size: 100031\n",
      "Total Time: 1H 25M 55S, 5155s\n",
      "Total Sample: train: 9.472M, buffer: 5.229M\n",
      "[147] Time spent = 35.10 s\n",
      "147:grad_norm[1000]: avg:   3.3771, min:   1.9881[ 945], max:   6.6043[ 738]\n",
      "147:loss     [1000]: avg:   7.2194, min:   5.2745[ 421], max:   9.6311[ 644]\n",
      "147:xent_pred[1000]: avg:   1.9175, min:   1.7767[ 243], max:   2.0708[  49]\n",
      "147:xent_v0  [1000]: avg:   1.9109, min:   1.7660[ 256], max:   2.0669[  49]\n",
      "===================\n",
      "beginning of epoch:  148\n",
      "available: 2.769 GB, used: 25.892 GB, free: 2.685 GB\n",
      "EPOCH: 148\n",
      "mean score: 0.00\n",
      "Speed: train: 1815.1, buffer_add: 964.6, buffer_size: 100031\n",
      "Total Time: 1H 26M 30S, 5190s\n",
      "Total Sample: train: 9.536M, buffer: 5.263M\n",
      "[148] Time spent = 35.68 s\n",
      "148:grad_norm[1000]: avg:   3.3941, min:   1.7852[ 235], max:   5.3894[ 870]\n",
      "148:loss     [1000]: avg:   7.2012, min:   5.1560[ 730], max:   9.2036[ 923]\n",
      "148:xent_pred[1000]: avg:   1.9206, min:   1.7630[ 100], max:   2.1011[ 940]\n",
      "148:xent_v0  [1000]: avg:   1.9142, min:   1.7713[ 100], max:   2.0976[ 940]\n",
      "===================\n",
      "beginning of epoch:  149\n",
      "available: 2.774 GB, used: 25.890 GB, free: 2.637 GB\n",
      "EPOCH: 149\n",
      "mean score: 0.00\n",
      "Speed: train: 1826.8, buffer_add: 992.8, buffer_size: 100056\n",
      "Total Time: 1H 27M 05S, 5225s\n",
      "Total Sample: train: 9.6M, buffer: 5.298M\n",
      "[149] Time spent = 35.48 s\n",
      "149:grad_norm[1000]: avg:   3.4355, min:   1.9449[ 627], max:   5.5902[ 128]\n",
      "149:loss     [1000]: avg:   7.2181, min:   5.4471[  62], max:   9.4304[ 876]\n",
      "149:xent_pred[1000]: avg:   1.9199, min:   1.7704[  99], max:   2.0489[ 735]\n",
      "149:xent_v0  [1000]: avg:   1.9135, min:   1.7695[  28], max:   2.0372[ 724]\n",
      "===================\n",
      "beginning of epoch:  150\n",
      "available: 2.772 GB, used: 25.889 GB, free: 2.694 GB\n",
      "EPOCH: 150\n",
      "mean score: 0.00\n",
      "Speed: train: 1846.6, buffer_add: 1023.8, buffer_size: 100018\n",
      "Total Time: 1H 27M 40S, 5260s\n",
      "Total Sample: train: 9.664M, buffer: 5.334M\n",
      "[150] Time spent = 35.14 s\n",
      "150:grad_norm[1000]: avg:   3.4155, min:   1.9083[  54], max:   9.8260[ 911]\n",
      "150:loss     [1000]: avg:   7.2442, min:   5.2549[ 251], max:   9.6011[ 920]\n",
      "150:xent_pred[1000]: avg:   1.9185, min:   1.7743[ 371], max:   2.0527[ 970]\n",
      "150:xent_v0  [1000]: avg:   1.9122, min:   1.7657[ 920], max:   2.0538[ 970]\n",
      "===================\n",
      "beginning of epoch:  151\n",
      "available: 2.762 GB, used: 25.900 GB, free: 2.654 GB\n",
      "EPOCH: 151\n",
      "mean score: 0.00\n",
      "Speed: train: 1861.7, buffer_add: 1026.4, buffer_size: 100036\n",
      "Total Time: 1H 28M 15S, 5295s\n",
      "Total Sample: train: 9.728M, buffer: 5.369M\n",
      "[151] Time spent = 34.65 s\n",
      "151:grad_norm[1000]: avg:   3.3990, min:   2.0099[ 755], max:   6.7466[  14]\n",
      "151:loss     [1000]: avg:   7.2345, min:   5.4606[ 547], max:  10.2958[ 864]\n",
      "151:xent_pred[1000]: avg:   1.9209, min:   1.7598[ 714], max:   2.0710[ 358]\n",
      "151:xent_v0  [1000]: avg:   1.9139, min:   1.7614[ 714], max:   2.0682[ 476]\n",
      "===================\n",
      "beginning of epoch:  152\n",
      "available: 2.771 GB, used: 25.892 GB, free: 2.687 GB\n",
      "EPOCH: 152\n",
      "mean score: 0.00\n",
      "Speed: train: 1856.5, buffer_add: 1014.7, buffer_size: 100042\n",
      "Total Time: 1H 28M 49S, 5329s\n",
      "Total Sample: train: 9.792M, buffer: 5.404M\n",
      "[152] Time spent = 34.90 s\n",
      "152:grad_norm[1000]: avg:   3.3733, min:   1.7174[  51], max:   8.0340[ 369]\n",
      "152:loss     [1000]: avg:   7.2481, min:   4.9018[ 303], max:   9.8913[ 528]\n",
      "152:xent_pred[1000]: avg:   1.9175, min:   1.7591[ 104], max:   2.0608[ 810]\n",
      "152:xent_v0  [1000]: avg:   1.9108, min:   1.7563[ 104], max:   2.0545[ 810]\n",
      "===================\n",
      "beginning of epoch:  153\n",
      "available: 2.771 GB, used: 25.892 GB, free: 2.694 GB\n",
      "EPOCH: 153\n",
      "mean score: 0.00\n",
      "Speed: train: 1816.6, buffer_add: 1010.0, buffer_size: 100021\n",
      "Total Time: 1H 29M 24S, 5364s\n",
      "Total Sample: train: 9.856M, buffer: 5.44M\n",
      "[153] Time spent = 35.63 s\n",
      "153:grad_norm[1000]: avg:   3.3638, min:   2.0770[ 210], max:   5.6125[ 785]\n",
      "153:loss     [1000]: avg:   7.1913, min:   5.3780[ 804], max:   9.3715[ 785]\n",
      "153:xent_pred[1000]: avg:   1.9209, min:   1.7578[  90], max:   2.0854[ 455]\n",
      "153:xent_v0  [1000]: avg:   1.9139, min:   1.7452[  90], max:   2.0719[ 455]\n",
      "===================\n",
      "beginning of epoch:  154\n",
      "available: 2.763 GB, used: 25.900 GB, free: 2.677 GB\n",
      "EPOCH: 154\n",
      "mean score: 0.00\n",
      "Speed: train: 1819.8, buffer_add: 971.7, buffer_size: 100063\n",
      "Total Time: 1H 29M 59S, 5399s\n",
      "Total Sample: train: 9.92M, buffer: 5.474M\n",
      "[154] Time spent = 35.59 s\n",
      "154:grad_norm[1000]: avg:   3.3661, min:   1.8793[ 429], max:   5.6048[ 401]\n",
      "154:loss     [1000]: avg:   7.1883, min:   5.4917[ 868], max:   9.6862[ 410]\n",
      "154:xent_pred[1000]: avg:   1.9209, min:   1.6886[ 241], max:   2.0892[ 785]\n",
      "154:xent_v0  [1000]: avg:   1.9139, min:   1.6793[ 241], max:   2.0841[ 785]\n",
      "===================\n",
      "beginning of epoch:  155\n",
      "available: 2.769 GB, used: 25.884 GB, free: 2.771 GB\n",
      "EPOCH: 155\n",
      "mean score: 0.00\n",
      "Speed: train: 1844.7, buffer_add: 1010.0, buffer_size: 100036\n",
      "Total Time: 1H 30M 34S, 5434s\n",
      "Total Sample: train: 9.984M, buffer: 5.509M\n",
      "[155] Time spent = 35.12 s\n",
      "155:grad_norm[1000]: avg:   3.3291, min:   1.9600[ 831], max:   5.7540[ 865]\n",
      "155:loss     [1000]: avg:   7.1867, min:   5.2800[ 843], max:   9.3513[ 498]\n",
      "155:xent_pred[1000]: avg:   1.9184, min:   1.7624[ 586], max:   2.0826[ 754]\n",
      "155:xent_v0  [1000]: avg:   1.9109, min:   1.7624[ 586], max:   2.0842[ 754]\n",
      "===================\n",
      "beginning of epoch:  156\n",
      "available: 2.769 GB, used: 25.890 GB, free: 2.701 GB\n",
      "EPOCH: 156\n",
      "mean score: 0.00\n",
      "Speed: train: 1824.3, buffer_add: 1019.5, buffer_size: 100082\n",
      "Total Time: 1H 31M 09S, 5469s\n",
      "Total Sample: train: 10.048M, buffer: 5.545M\n",
      "[156] Time spent = 35.55 s\n",
      "156:grad_norm[1000]: avg:   3.3519, min:   1.9260[ 675], max:   8.5898[ 525]\n",
      "156:loss     [1000]: avg:   7.2386, min:   5.5245[ 926], max:   9.5139[ 890]\n",
      "156:xent_pred[1000]: avg:   1.9193, min:   1.7674[ 829], max:   2.0786[ 762]\n",
      "156:xent_v0  [1000]: avg:   1.9122, min:   1.7464[ 829], max:   2.0729[ 762]\n",
      "===================\n",
      "beginning of epoch:  157\n",
      "available: 2.772 GB, used: 25.885 GB, free: 2.726 GB\n",
      "EPOCH: 157\n",
      "mean score: 0.00\n",
      "Speed: train: 1842.0, buffer_add: 1007.5, buffer_size: 100088\n",
      "Total Time: 1H 31M 44S, 5504s\n",
      "Total Sample: train: 10.112M, buffer: 5.58M\n",
      "[157] Time spent = 35.13 s\n",
      "157:grad_norm[1000]: avg:   3.3262, min:   2.0722[ 196], max:   7.6141[ 322]\n",
      "157:loss     [1000]: avg:   7.2355, min:   5.4124[ 784], max:   9.3150[ 936]\n",
      "157:xent_pred[1000]: avg:   1.9175, min:   1.7694[ 264], max:   2.0866[ 948]\n",
      "157:xent_v0  [1000]: avg:   1.9107, min:   1.7538[ 503], max:   2.0694[ 948]\n",
      "===================\n",
      "beginning of epoch:  158\n",
      "available: 2.765 GB, used: 25.887 GB, free: 2.739 GB\n",
      "EPOCH: 158\n",
      "mean score: 0.00\n",
      "Speed: train: 1817.5, buffer_add: 973.7, buffer_size: 100031\n",
      "Total Time: 1H 32M 19S, 5539s\n",
      "Total Sample: train: 10.176M, buffer: 5.614M\n",
      "[158] Time spent = 35.76 s\n",
      "158:grad_norm[1000]: avg:   3.3389, min:   2.0719[ 564], max:   6.5264[ 145]\n",
      "158:loss     [1000]: avg:   7.1704, min:   5.4219[ 824], max:   9.6051[ 203]\n",
      "158:xent_pred[1000]: avg:   1.9200, min:   1.7843[ 290], max:   2.0754[ 588]\n",
      "158:xent_v0  [1000]: avg:   1.9134, min:   1.7858[ 883], max:   2.0626[ 588]\n",
      "===================\n",
      "beginning of epoch:  159\n",
      "available: 2.765 GB, used: 25.900 GB, free: 2.637 GB\n",
      "EPOCH: 159\n",
      "mean score: 0.00\n",
      "Speed: train: 1832.1, buffer_add: 994.3, buffer_size: 100082\n",
      "Total Time: 1H 32M 54S, 5574s\n",
      "Total Sample: train: 10.24M, buffer: 5.649M\n",
      "[159] Time spent = 35.36 s\n",
      "159:grad_norm[1000]: avg:   3.3307, min:   1.9830[ 913], max:   5.7487[ 290]\n",
      "159:loss     [1000]: avg:   7.2175, min:   4.8536[ 869], max:  10.1808[ 927]\n",
      "159:xent_pred[1000]: avg:   1.9193, min:   1.7667[ 479], max:   2.0758[ 742]\n",
      "159:xent_v0  [1000]: avg:   1.9122, min:   1.7624[ 479], max:   2.0590[ 448]\n",
      "===================\n",
      "beginning of epoch:  160\n",
      "available: 2.766 GB, used: 25.901 GB, free: 2.634 GB\n",
      "EPOCH: 160\n",
      "mean score: 0.00\n",
      "Speed: train: 1829.0, buffer_add: 968.7, buffer_size: 100065\n",
      "Total Time: 1H 33M 29S, 5609s\n",
      "Total Sample: train: 10.304M, buffer: 5.683M\n",
      "[160] Time spent = 35.44 s\n",
      "160:grad_norm[1000]: avg:   3.3358, min:   1.9313[ 223], max:   6.0882[ 405]\n",
      "160:loss     [1000]: avg:   7.2234, min:   4.9573[ 226], max:   9.7321[ 894]\n",
      "160:xent_pred[1000]: avg:   1.9194, min:   1.7196[ 474], max:   2.0682[ 869]\n",
      "160:xent_v0  [1000]: avg:   1.9128, min:   1.7072[ 474], max:   2.0672[ 869]\n",
      "===================\n",
      "beginning of epoch:  161\n",
      "available: 2.756 GB, used: 25.903 GB, free: 2.682 GB\n",
      "EPOCH: 161\n",
      "mean score: 0.00\n",
      "Speed: train: 1876.2, buffer_add: 1022.4, buffer_size: 100015\n",
      "Total Time: 1H 34M 03S, 5643s\n",
      "Total Sample: train: 10.368M, buffer: 5.717M\n",
      "[161] Time spent = 34.55 s\n",
      "161:grad_norm[1000]: avg:   3.2501, min:   2.0134[ 768], max:   6.2958[ 315]\n",
      "161:loss     [1000]: avg:   7.2072, min:   5.0488[ 483], max:  10.3728[ 421]\n",
      "161:xent_pred[1000]: avg:   1.9192, min:   1.7924[ 364], max:   2.0800[ 847]\n",
      "161:xent_v0  [1000]: avg:   1.9135, min:   1.7748[ 428], max:   2.0777[ 847]\n",
      "===================\n",
      "beginning of epoch:  162\n",
      "available: 2.767 GB, used: 25.898 GB, free: 2.707 GB\n",
      "EPOCH: 162\n",
      "mean score: 0.00\n",
      "Speed: train: 1824.6, buffer_add: 1028.3, buffer_size: 100030\n",
      "Total Time: 1H 34M 38S, 5678s\n",
      "Total Sample: train: 10.432M, buffer: 5.753M\n",
      "[162] Time spent = 35.47 s\n",
      "162:grad_norm[1000]: avg:   3.2928, min:   1.9681[ 790], max:   6.0314[ 252]\n",
      "162:loss     [1000]: avg:   7.1671, min:   4.8430[ 228], max:   9.8070[  21]\n",
      "162:xent_pred[1000]: avg:   1.9200, min:   1.7293[ 639], max:   2.0684[ 414]\n",
      "162:xent_v0  [1000]: avg:   1.9141, min:   1.7180[ 639], max:   2.0661[ 625]\n",
      "===================\n",
      "beginning of epoch:  163\n",
      "available: 2.759 GB, used: 25.903 GB, free: 2.643 GB\n",
      "EPOCH: 163\n",
      "mean score: 0.00\n",
      "Speed: train: 1852.0, buffer_add: 1004.7, buffer_size: 100009\n",
      "Total Time: 1H 35M 13S, 5713s\n",
      "Total Sample: train: 10.496M, buffer: 5.788M\n",
      "[163] Time spent = 34.90 s\n",
      "163:grad_norm[1000]: avg:   3.2477, min:   1.7423[ 239], max:   5.2572[ 405]\n",
      "163:loss     [1000]: avg:   7.1425, min:   5.2762[ 774], max:   9.8200[ 924]\n",
      "163:xent_pred[1000]: avg:   1.9211, min:   1.7372[ 281], max:   2.0659[ 239]\n",
      "163:xent_v0  [1000]: avg:   1.9150, min:   1.7347[ 281], max:   2.0625[ 239]\n",
      "===================\n",
      "beginning of epoch:  164\n",
      "available: 2.764 GB, used: 25.893 GB, free: 2.743 GB\n",
      "EPOCH: 164\n",
      "mean score: 0.00\n",
      "Speed: train: 1869.0, buffer_add: 999.9, buffer_size: 100089\n",
      "Total Time: 1H 35M 47S, 5747s\n",
      "Total Sample: train: 10.56M, buffer: 5.822M\n",
      "[164] Time spent = 34.81 s\n",
      "164:grad_norm[1000]: avg:   3.2893, min:   1.8328[ 738], max:   6.8995[ 452]\n",
      "164:loss     [1000]: avg:   7.1983, min:   5.0752[ 738], max:   9.2536[ 712]\n",
      "164:xent_pred[1000]: avg:   1.9186, min:   1.7285[ 104], max:   2.0605[ 686]\n",
      "164:xent_v0  [1000]: avg:   1.9126, min:   1.7211[ 104], max:   2.0521[ 686]\n",
      "===================\n",
      "beginning of epoch:  165\n",
      "available: 2.752 GB, used: 25.908 GB, free: 2.715 GB\n",
      "EPOCH: 165\n",
      "mean score: 0.00\n",
      "Speed: train: 1885.8, buffer_add: 1017.5, buffer_size: 100028\n",
      "Total Time: 1H 36M 21S, 5781s\n",
      "Total Sample: train: 10.624M, buffer: 5.857M\n",
      "[165] Time spent = 34.37 s\n",
      "165:grad_norm[1000]: avg:   3.2795, min:   1.9056[ 253], max:   6.5323[ 514]\n",
      "165:loss     [1000]: avg:   7.1734, min:   5.2740[ 349], max:   9.1846[ 288]\n",
      "165:xent_pred[1000]: avg:   1.9206, min:   1.7546[ 414], max:   2.0651[ 238]\n",
      "165:xent_v0  [1000]: avg:   1.9146, min:   1.7489[ 414], max:   2.0560[ 238]\n",
      "===================\n",
      "beginning of epoch:  166\n",
      "available: 2.756 GB, used: 25.900 GB, free: 2.644 GB\n",
      "EPOCH: 166\n",
      "mean score: 0.00\n",
      "Speed: train: 1862.3, buffer_add: 1011.5, buffer_size: 100048\n",
      "Total Time: 1H 36M 55S, 5815s\n",
      "Total Sample: train: 10.688M, buffer: 5.892M\n",
      "[166] Time spent = 34.84 s\n",
      "166:grad_norm[1000]: avg:   3.2302, min:   1.9020[ 962], max:   6.2723[ 476]\n",
      "166:loss     [1000]: avg:   7.1335, min:   5.0807[ 139], max:   9.3169[ 940]\n",
      "166:xent_pred[1000]: avg:   1.9225, min:   1.7591[  59], max:   2.0697[ 376]\n",
      "166:xent_v0  [1000]: avg:   1.9162, min:   1.7552[  59], max:   2.0630[ 376]\n",
      "===================\n",
      "beginning of epoch:  167\n",
      "available: 2.754 GB, used: 25.907 GB, free: 2.700 GB\n",
      "EPOCH: 167\n",
      "mean score: 0.00\n",
      "Speed: train: 1844.3, buffer_add: 1003.7, buffer_size: 100030\n",
      "Total Time: 1H 37M 30S, 5850s\n",
      "Total Sample: train: 10.752M, buffer: 5.927M\n",
      "[167] Time spent = 34.82 s\n",
      "167:grad_norm[1000]: avg:   3.2481, min:   2.0506[ 662], max:   5.3784[ 122]\n",
      "167:loss     [1000]: avg:   7.1577, min:   4.9955[ 863], max:   9.7978[ 941]\n",
      "167:xent_pred[1000]: avg:   1.9228, min:   1.7844[ 127], max:   2.0985[ 569]\n",
      "167:xent_v0  [1000]: avg:   1.9169, min:   1.7872[ 127], max:   2.0799[ 569]\n",
      "===================\n",
      "beginning of epoch:  168\n",
      "available: 2.756 GB, used: 25.901 GB, free: 2.691 GB\n",
      "EPOCH: 168\n",
      "mean score: 0.00\n",
      "Speed: train: 1864.5, buffer_add: 1000.7, buffer_size: 100078\n",
      "Total Time: 1H 38M 04S, 5884s\n",
      "Total Sample: train: 10.816M, buffer: 5.961M\n",
      "[168] Time spent = 34.80 s\n",
      "168:grad_norm[1000]: avg:   3.2613, min:   1.9204[ 164], max:   5.7042[ 701]\n",
      "168:loss     [1000]: avg:   7.1980, min:   5.2025[ 696], max:   9.2672[ 251]\n",
      "168:xent_pred[1000]: avg:   1.9176, min:   1.7521[ 352], max:   2.0978[ 926]\n",
      "168:xent_v0  [1000]: avg:   1.9117, min:   1.7554[ 352], max:   2.0743[ 926]\n",
      "===================\n",
      "beginning of epoch:  169\n",
      "available: 2.746 GB, used: 25.907 GB, free: 2.733 GB\n",
      "EPOCH: 169\n",
      "mean score: 0.00\n",
      "Speed: train: 1900.7, buffer_add: 1006.0, buffer_size: 100042\n",
      "Total Time: 1H 38M 38S, 5918s\n",
      "Total Sample: train: 10.88M, buffer: 5.995M\n",
      "[169] Time spent = 34.14 s\n",
      "169:grad_norm[1000]: avg:   3.2876, min:   1.8674[  46], max:   5.5344[ 852]\n",
      "169:loss     [1000]: avg:   7.1723, min:   5.0892[ 324], max:   9.4536[ 308]\n",
      "169:xent_pred[1000]: avg:   1.9194, min:   1.7778[ 308], max:   2.0759[ 290]\n",
      "169:xent_v0  [1000]: avg:   1.9135, min:   1.7708[ 308], max:   2.0734[ 290]\n",
      "===================\n",
      "beginning of epoch:  170\n",
      "available: 2.751 GB, used: 25.904 GB, free: 2.707 GB\n",
      "EPOCH: 170\n",
      "mean score: 0.00\n",
      "Speed: train: 1864.2, buffer_add: 1019.8, buffer_size: 100023\n",
      "Total Time: 1H 39M 12S, 5952s\n",
      "Total Sample: train: 10.944M, buffer: 6.03M\n",
      "[170] Time spent = 34.55 s\n",
      "170:grad_norm[1000]: avg:   3.2760, min:   1.9540[ 219], max:   5.6695[  74]\n",
      "170:loss     [1000]: avg:   7.1626, min:   5.2318[ 993], max:   9.4666[ 631]\n",
      "170:xent_pred[1000]: avg:   1.9204, min:   1.7462[  60], max:   2.0772[ 695]\n",
      "170:xent_v0  [1000]: avg:   1.9148, min:   1.7472[  60], max:   2.0660[  67]\n",
      "===================\n",
      "beginning of epoch:  171\n",
      "available: 2.758 GB, used: 25.906 GB, free: 2.675 GB\n",
      "EPOCH: 171\n",
      "mean score: 0.00\n",
      "Speed: train: 1865.8, buffer_add: 1000.0, buffer_size: 100036\n",
      "Total Time: 1H 39M 47S, 5987s\n",
      "Total Sample: train: 11.008M, buffer: 6.064M\n",
      "[171] Time spent = 34.63 s\n",
      "171:grad_norm[1000]: avg:   3.2684, min:   1.9289[ 961], max:   6.0165[ 911]\n",
      "171:loss     [1000]: avg:   7.1807, min:   5.1406[  98], max:   9.8050[  33]\n",
      "171:xent_pred[1000]: avg:   1.9191, min:   1.7745[ 471], max:   2.0753[  73]\n",
      "171:xent_v0  [1000]: avg:   1.9131, min:   1.7669[ 471], max:   2.0657[  73]\n",
      "===================\n",
      "beginning of epoch:  172\n",
      "available: 2.748 GB, used: 25.912 GB, free: 2.650 GB\n",
      "EPOCH: 172\n",
      "mean score: 0.00\n",
      "Speed: train: 1884.8, buffer_add: 1001.4, buffer_size: 100045\n",
      "Total Time: 1H 40M 21S, 6021s\n",
      "Total Sample: train: 11.072M, buffer: 6.098M\n",
      "[172] Time spent = 34.28 s\n",
      "172:grad_norm[1000]: avg:   3.2599, min:   1.9254[ 512], max:   7.2552[  32]\n",
      "172:loss     [1000]: avg:   7.1828, min:   5.0773[ 219], max:   9.8778[ 486]\n",
      "172:xent_pred[1000]: avg:   1.9206, min:   1.7942[ 771], max:   2.0735[ 748]\n",
      "172:xent_v0  [1000]: avg:   1.9148, min:   1.7738[ 771], max:   2.0573[ 748]\n",
      "===================\n",
      "beginning of epoch:  173\n",
      "available: 2.749 GB, used: 25.912 GB, free: 2.647 GB\n",
      "EPOCH: 173\n",
      "mean score: 0.00\n",
      "Speed: train: 1870.9, buffer_add: 1010.3, buffer_size: 100109\n",
      "Total Time: 1H 40M 55S, 6055s\n",
      "Total Sample: train: 11.136M, buffer: 6.133M\n",
      "[173] Time spent = 34.60 s\n",
      "173:grad_norm[1000]: avg:   3.2817, min:   1.7670[ 645], max:   5.6126[ 796]\n",
      "173:loss     [1000]: avg:   7.2180, min:   5.3047[ 645], max:   9.8367[ 238]\n",
      "173:xent_pred[1000]: avg:   1.9185, min:   1.7745[ 338], max:   2.0942[ 130]\n",
      "173:xent_v0  [1000]: avg:   1.9128, min:   1.7735[ 338], max:   2.0775[ 130]\n",
      "===================\n",
      "beginning of epoch:  174\n",
      "available: 2.754 GB, used: 25.898 GB, free: 2.749 GB\n",
      "EPOCH: 174\n",
      "mean score: 0.00\n",
      "Speed: train: 1831.9, buffer_add: 1011.0, buffer_size: 100047\n",
      "Total Time: 1H 41M 30S, 6090s\n",
      "Total Sample: train: 11.2M, buffer: 6.168M\n",
      "[174] Time spent = 35.32 s\n",
      "174:grad_norm[1000]: avg:   3.2645, min:   1.8376[ 722], max:   5.3758[ 716]\n",
      "174:loss     [1000]: avg:   7.2201, min:   5.2840[ 271], max:   9.6677[ 387]\n",
      "174:xent_pred[1000]: avg:   1.9179, min:   1.7568[ 387], max:   2.1106[ 703]\n",
      "174:xent_v0  [1000]: avg:   1.9119, min:   1.7523[ 241], max:   2.1061[ 703]\n",
      "===================\n",
      "beginning of epoch:  175\n",
      "available: 2.744 GB, used: 25.908 GB, free: 2.707 GB\n",
      "EPOCH: 175\n",
      "mean score: 0.01\n",
      "Speed: train: 1845.3, buffer_add: 1012.2, buffer_size: 100033\n",
      "Total Time: 1H 42M 04S, 6124s\n",
      "Total Sample: train: 11.264M, buffer: 6.203M\n",
      "[175] Time spent = 35.05 s\n",
      "175:grad_norm[1000]: avg:   3.2321, min:   1.7158[ 941], max:  12.3773[ 959]\n",
      "175:loss     [1000]: avg:   7.1565, min:   4.7531[ 941], max:   9.7475[ 145]\n",
      "175:xent_pred[1000]: avg:   1.9201, min:   1.7379[ 434], max:   2.0765[ 974]\n",
      "175:xent_v0  [1000]: avg:   1.9147, min:   1.7363[ 434], max:   2.0756[ 974]\n",
      "===================\n",
      "beginning of epoch:  176\n",
      "available: 2.744 GB, used: 25.916 GB, free: 2.677 GB\n",
      "EPOCH: 176\n",
      "mean score: 0.00\n",
      "Speed: train: 1843.2, buffer_add: 1022.1, buffer_size: 100044\n",
      "Total Time: 1H 42M 39S, 6159s\n",
      "Total Sample: train: 11.328M, buffer: 6.239M\n",
      "[176] Time spent = 35.11 s\n",
      "176:grad_norm[1000]: avg:   3.1959, min:   1.8431[ 968], max:   5.9618[ 759]\n",
      "176:loss     [1000]: avg:   7.1457, min:   5.1502[ 968], max:   9.7844[ 785]\n",
      "176:xent_pred[1000]: avg:   1.9219, min:   1.7649[ 539], max:   2.0802[ 742]\n",
      "176:xent_v0  [1000]: avg:   1.9160, min:   1.7635[ 539], max:   2.0698[ 742]\n",
      "===================\n",
      "beginning of epoch:  177\n",
      "available: 2.748 GB, used: 25.905 GB, free: 2.668 GB\n",
      "EPOCH: 177\n",
      "mean score: 0.00\n",
      "Speed: train: 1835.5, buffer_add: 1018.6, buffer_size: 100007\n",
      "Total Time: 1H 43M 14S, 6194s\n",
      "Total Sample: train: 11.392M, buffer: 6.274M\n",
      "[177] Time spent = 35.24 s\n",
      "177:grad_norm[1000]: avg:   3.2561, min:   1.9713[ 224], max:   5.6940[ 270]\n",
      "177:loss     [1000]: avg:   7.1463, min:   4.7721[ 228], max:   9.4398[ 663]\n",
      "177:xent_pred[1000]: avg:   1.9199, min:   1.7704[ 216], max:   2.0864[ 454]\n",
      "177:xent_v0  [1000]: avg:   1.9139, min:   1.7554[ 216], max:   2.0654[ 828]\n",
      "===================\n",
      "beginning of epoch:  178\n",
      "available: 2.745 GB, used: 25.916 GB, free: 2.688 GB\n",
      "EPOCH: 178\n",
      "mean score: 0.00\n",
      "Speed: train: 1854.2, buffer_add: 1017.4, buffer_size: 100028\n",
      "Total Time: 1H 43M 49S, 6229s\n",
      "Total Sample: train: 11.456M, buffer: 6.309M\n",
      "[178] Time spent = 34.82 s\n",
      "178:grad_norm[1000]: avg:   3.2093, min:   1.7597[ 588], max:   5.7123[ 821]\n",
      "178:loss     [1000]: avg:   7.2008, min:   5.1093[ 709], max:   9.7749[ 343]\n",
      "178:xent_pred[1000]: avg:   1.9186, min:   1.7590[ 184], max:   2.0944[ 359]\n",
      "178:xent_v0  [1000]: avg:   1.9126, min:   1.7454[ 792], max:   2.0784[ 359]\n",
      "===================\n",
      "beginning of epoch:  179\n",
      "available: 2.745 GB, used: 25.912 GB, free: 2.669 GB\n",
      "EPOCH: 179\n",
      "mean score: 0.00\n",
      "Speed: train: 1839.2, buffer_add: 1009.4, buffer_size: 100008\n",
      "Total Time: 1H 44M 23S, 6263s\n",
      "Total Sample: train: 11.52M, buffer: 6.344M\n",
      "[179] Time spent = 35.10 s\n",
      "179:grad_norm[1000]: avg:   3.2249, min:   1.6334[ 775], max:   5.2015[ 129]\n",
      "179:loss     [1000]: avg:   7.1971, min:   5.2114[ 536], max:  10.6781[ 733]\n",
      "179:xent_pred[1000]: avg:   1.9158, min:   1.7575[ 476], max:   2.0758[ 247]\n",
      "179:xent_v0  [1000]: avg:   1.9098, min:   1.7438[ 476], max:   2.0591[ 247]\n",
      "===================\n",
      "beginning of epoch:  180\n",
      "available: 2.752 GB, used: 25.907 GB, free: 2.677 GB\n",
      "EPOCH: 180\n",
      "mean score: 0.00\n",
      "Speed: train: 1858.2, buffer_add: 996.6, buffer_size: 100023\n",
      "Total Time: 1H 44M 58S, 6298s\n",
      "Total Sample: train: 11.584M, buffer: 6.379M\n",
      "[180] Time spent = 34.83 s\n",
      "180:grad_norm[1000]: avg:   3.1767, min:   1.7680[ 573], max:   5.5389[ 662]\n",
      "180:loss     [1000]: avg:   7.1873, min:   5.2207[ 518], max:   9.5513[ 931]\n",
      "180:xent_pred[1000]: avg:   1.9180, min:   1.7740[  47], max:   2.0917[ 518]\n",
      "180:xent_v0  [1000]: avg:   1.9117, min:   1.7706[ 866], max:   2.0715[ 518]\n",
      "===================\n",
      "beginning of epoch:  181\n",
      "available: 2.749 GB, used: 25.913 GB, free: 1.754 GB\n",
      "EPOCH: 181\n",
      "mean score: 0.00\n",
      "Speed: train: 1880.3, buffer_add: 986.0, buffer_size: 100045\n",
      "Total Time: 1H 45M 32S, 6332s\n",
      "Total Sample: train: 11.648M, buffer: 6.412M\n",
      "[181] Time spent = 34.42 s\n",
      "181:grad_norm[1000]: avg:   3.1670, min:   1.9329[ 688], max:   6.0556[ 789]\n",
      "181:loss     [1000]: avg:   7.1886, min:   5.3429[ 703], max:   9.4977[ 152]\n",
      "181:xent_pred[1000]: avg:   1.9168, min:   1.7833[ 240], max:   2.0624[ 470]\n",
      "181:xent_v0  [1000]: avg:   1.9114, min:   1.7671[  91], max:   2.0620[  32]\n",
      "===================\n",
      "beginning of epoch:  182\n",
      "available: 2.748 GB, used: 25.916 GB, free: 1.304 GB\n",
      "EPOCH: 182\n",
      "mean score: 0.00\n",
      "Speed: train: 1853.6, buffer_add: 1014.6, buffer_size: 100040\n",
      "Total Time: 1H 46M 06S, 6366s\n",
      "Total Sample: train: 11.712M, buffer: 6.447M\n",
      "[182] Time spent = 34.97 s\n",
      "182:grad_norm[1000]: avg:   3.1696, min:   1.9596[  53], max:   6.1271[ 797]\n",
      "182:loss     [1000]: avg:   7.1797, min:   5.4127[ 601], max:   9.7429[ 798]\n",
      "182:xent_pred[1000]: avg:   1.9204, min:   1.7584[ 555], max:   2.0665[ 853]\n",
      "182:xent_v0  [1000]: avg:   1.9146, min:   1.7567[ 555], max:   2.0503[ 853]\n",
      "===================\n",
      "beginning of epoch:  183\n",
      "available: 2.752 GB, used: 25.909 GB, free: 1.424 GB\n",
      "EPOCH: 183\n",
      "mean score: 0.00\n",
      "Speed: train: 1858.7, buffer_add: 1022.4, buffer_size: 100011\n",
      "Total Time: 1H 46M 41S, 6401s\n",
      "Total Sample: train: 11.776M, buffer: 6.482M\n",
      "[183] Time spent = 34.76 s\n",
      "183:grad_norm[1000]: avg:   3.2042, min:   1.9168[ 642], max:   5.4830[ 412]\n",
      "183:loss     [1000]: avg:   7.1959, min:   5.0413[ 642], max:   9.7714[ 505]\n",
      "183:xent_pred[1000]: avg:   1.9184, min:   1.7650[ 723], max:   2.0597[  46]\n",
      "183:xent_v0  [1000]: avg:   1.9124, min:   1.7796[ 723], max:   2.0538[  46]\n",
      "===================\n",
      "beginning of epoch:  184\n",
      "available: 2.743 GB, used: 25.916 GB, free: 1.556 GB\n",
      "EPOCH: 184\n",
      "mean score: 0.00\n",
      "Speed: train: 1830.0, buffer_add: 1014.5, buffer_size: 100038\n",
      "Total Time: 1H 47M 16S, 6436s\n",
      "Total Sample: train: 11.84M, buffer: 6.518M\n",
      "[184] Time spent = 35.46 s\n",
      "184:grad_norm[1000]: avg:   3.1961, min:   1.7947[ 484], max:   6.3984[ 594]\n",
      "184:loss     [1000]: avg:   7.1974, min:   5.0522[ 287], max:  10.0940[ 711]\n",
      "184:xent_pred[1000]: avg:   1.9174, min:   1.7517[ 569], max:   2.0768[ 845]\n",
      "184:xent_v0  [1000]: avg:   1.9115, min:   1.7481[ 569], max:   2.0722[ 845]\n",
      "===================\n",
      "beginning of epoch:  185\n",
      "available: 2.749 GB, used: 25.915 GB, free: 1.684 GB\n",
      "EPOCH: 185\n",
      "mean score: 0.00\n",
      "Speed: train: 1811.8, buffer_add: 1014.9, buffer_size: 100025\n",
      "Total Time: 1H 47M 51S, 6471s\n",
      "Total Sample: train: 11.904M, buffer: 6.554M\n",
      "[185] Time spent = 35.65 s\n",
      "185:grad_norm[1000]: avg:   3.1989, min:   1.8288[ 739], max:   5.9659[ 353]\n",
      "185:loss     [1000]: avg:   7.1836, min:   5.3010[ 202], max:   9.8782[ 353]\n",
      "185:xent_pred[1000]: avg:   1.9190, min:   1.7554[ 635], max:   2.1074[ 888]\n",
      "185:xent_v0  [1000]: avg:   1.9135, min:   1.7440[ 635], max:   2.1025[ 888]\n",
      "===================\n",
      "beginning of epoch:  186\n",
      "available: 2.745 GB, used: 25.921 GB, free: 1.709 GB\n",
      "EPOCH: 186\n",
      "mean score: 0.00\n",
      "Speed: train: 1854.7, buffer_add: 1021.3, buffer_size: 100048\n",
      "Total Time: 1H 48M 26S, 6506s\n",
      "Total Sample: train: 11.968M, buffer: 6.589M\n",
      "[186] Time spent = 34.86 s\n",
      "186:grad_norm[1000]: avg:   3.1656, min:   1.9110[ 120], max:   5.6574[ 376]\n",
      "186:loss     [1000]: avg:   7.1622, min:   5.2591[  73], max:   9.6870[ 534]\n",
      "186:xent_pred[1000]: avg:   1.9205, min:   1.7677[  94], max:   2.0704[ 853]\n",
      "186:xent_v0  [1000]: avg:   1.9147, min:   1.7733[ 439], max:   2.0595[ 853]\n",
      "===================\n",
      "beginning of epoch:  187\n",
      "available: 2.746 GB, used: 25.919 GB, free: 1.744 GB\n",
      "EPOCH: 187\n",
      "mean score: 0.00\n",
      "Speed: train: 1807.1, buffer_add: 981.1, buffer_size: 100019\n",
      "Total Time: 1H 49M 01S, 6541s\n",
      "Total Sample: train: 12.032M, buffer: 6.624M\n",
      "[187] Time spent = 35.76 s\n",
      "187:grad_norm[1000]: avg:   3.1449, min:   1.8753[ 266], max:   5.4856[ 707]\n",
      "187:loss     [1000]: avg:   7.1572, min:   5.1579[ 391], max:   9.4360[ 484]\n",
      "187:xent_pred[1000]: avg:   1.9200, min:   1.7741[ 902], max:   2.0725[ 569]\n",
      "187:xent_v0  [1000]: avg:   1.9141, min:   1.7698[ 902], max:   2.0690[ 569]\n",
      "===================\n",
      "beginning of epoch:  188\n",
      "available: 2.746 GB, used: 25.920 GB, free: 1.830 GB\n",
      "EPOCH: 188\n",
      "mean score: 0.00\n",
      "Speed: train: 1864.5, buffer_add: 1017.5, buffer_size: 100041\n",
      "Total Time: 1H 49M 35S, 6575s\n",
      "Total Sample: train: 12.096M, buffer: 6.659M\n",
      "[188] Time spent = 34.70 s\n",
      "188:grad_norm[1000]: avg:   3.1591, min:   1.8268[  42], max:   5.2369[ 843]\n",
      "188:loss     [1000]: avg:   7.1972, min:   5.2919[ 459], max:  10.2418[ 210]\n",
      "188:xent_pred[1000]: avg:   1.9195, min:   1.7649[ 659], max:   2.0687[ 476]\n",
      "188:xent_v0  [1000]: avg:   1.9142, min:   1.7610[ 659], max:   2.0703[ 476]\n",
      "===================\n",
      "beginning of epoch:  189\n",
      "available: 2.739 GB, used: 25.928 GB, free: 1.903 GB\n",
      "EPOCH: 189\n",
      "mean score: 0.00\n",
      "Speed: train: 1861.0, buffer_add: 1020.1, buffer_size: 100028\n",
      "Total Time: 1H 50M 10S, 6610s\n",
      "Total Sample: train: 12.16M, buffer: 6.694M\n",
      "[189] Time spent = 34.57 s\n",
      "189:grad_norm[1000]: avg:   3.1445, min:   1.8176[ 679], max:   5.0598[ 393]\n",
      "189:loss     [1000]: avg:   7.1870, min:   5.2069[ 618], max:   9.8162[  77]\n",
      "189:xent_pred[1000]: avg:   1.9198, min:   1.7224[ 581], max:   2.0676[  38]\n",
      "189:xent_v0  [1000]: avg:   1.9145, min:   1.7261[ 581], max:   2.0543[ 114]\n",
      "===================\n",
      "beginning of epoch:  190\n",
      "available: 2.752 GB, used: 25.920 GB, free: 1.958 GB\n",
      "EPOCH: 190\n",
      "mean score: 0.00\n",
      "Speed: train: 1841.5, buffer_add: 1012.2, buffer_size: 100028\n",
      "Total Time: 1H 50M 44S, 6644s\n",
      "Total Sample: train: 12.224M, buffer: 6.729M\n",
      "[190] Time spent = 35.19 s\n",
      "190:grad_norm[1000]: avg:   3.1271, min:   1.7949[ 645], max:   5.1977[ 240]\n",
      "190:loss     [1000]: avg:   7.1778, min:   5.2123[ 757], max:  10.0189[ 283]\n",
      "190:xent_pred[1000]: avg:   1.9214, min:   1.7725[ 570], max:   2.0708[ 712]\n",
      "190:xent_v0  [1000]: avg:   1.9161, min:   1.7605[ 556], max:   2.0693[ 474]\n",
      "===================\n",
      "beginning of epoch:  191\n",
      "available: 2.751 GB, used: 25.922 GB, free: 1.979 GB\n",
      "EPOCH: 191\n",
      "mean score: 0.00\n",
      "Speed: train: 1874.0, buffer_add: 1021.1, buffer_size: 100031\n",
      "Total Time: 1H 51M 19S, 6679s\n",
      "Total Sample: train: 12.288M, buffer: 6.764M\n",
      "[191] Time spent = 34.50 s\n",
      "191:grad_norm[1000]: avg:   3.1558, min:   1.6683[  68], max:   5.9503[ 132]\n",
      "191:loss     [1000]: avg:   7.1940, min:   5.1363[ 444], max:   9.4980[ 132]\n",
      "191:xent_pred[1000]: avg:   1.9185, min:   1.7342[ 402], max:   2.0660[ 874]\n",
      "191:xent_v0  [1000]: avg:   1.9131, min:   1.7325[ 402], max:   2.0587[ 874]\n",
      "===================\n",
      "beginning of epoch:  192\n",
      "available: 2.753 GB, used: 25.920 GB, free: 1.975 GB\n",
      "EPOCH: 192\n",
      "mean score: 0.00\n",
      "Speed: train: 1857.2, buffer_add: 1021.4, buffer_size: 100040\n",
      "Total Time: 1H 51M 53S, 6713s\n",
      "Total Sample: train: 12.352M, buffer: 6.799M\n",
      "[192] Time spent = 34.92 s\n",
      "192:grad_norm[1000]: avg:   3.1177, min:   1.7312[ 710], max:   5.1130[ 200]\n",
      "192:loss     [1000]: avg:   7.1807, min:   5.5127[ 259], max:  10.0198[ 383]\n",
      "192:xent_pred[1000]: avg:   1.9186, min:   1.7583[ 901], max:   2.0421[ 518]\n",
      "192:xent_v0  [1000]: avg:   1.9136, min:   1.7525[ 901], max:   2.0430[ 423]\n",
      "===================\n",
      "beginning of epoch:  193\n",
      "available: 2.755 GB, used: 25.921 GB, free: 2.009 GB\n",
      "EPOCH: 193\n",
      "mean score: 0.00\n",
      "Speed: train: 1851.3, buffer_add: 1017.5, buffer_size: 100033\n",
      "Total Time: 1H 52M 28S, 6748s\n",
      "Total Sample: train: 12.416M, buffer: 6.834M\n",
      "[193] Time spent = 35.06 s\n",
      "193:grad_norm[1000]: avg:   3.1625, min:   1.7246[ 271], max:   5.3020[  91]\n",
      "193:loss     [1000]: avg:   7.2341, min:   5.3461[ 171], max:   9.9120[ 127]\n",
      "193:xent_pred[1000]: avg:   1.9154, min:   1.7524[ 457], max:   2.0648[ 143]\n",
      "193:xent_v0  [1000]: avg:   1.9101, min:   1.7460[ 457], max:   2.0463[ 143]\n",
      "===================\n",
      "beginning of epoch:  194\n",
      "available: 2.748 GB, used: 25.925 GB, free: 2.088 GB\n",
      "EPOCH: 194\n",
      "mean score: 0.00\n",
      "Speed: train: 1840.5, buffer_add: 1017.8, buffer_size: 100004\n",
      "Total Time: 1H 53M 02S, 6782s\n",
      "Total Sample: train: 12.48M, buffer: 6.87M\n",
      "[194] Time spent = 35.28 s\n",
      "194:grad_norm[1000]: avg:   3.1559, min:   1.8409[ 888], max:   5.4262[ 266]\n",
      "194:loss     [1000]: avg:   7.2180, min:   5.4473[ 318], max:   9.4183[ 160]\n",
      "194:xent_pred[1000]: avg:   1.9155, min:   1.7462[ 887], max:   2.1030[ 854]\n",
      "194:xent_v0  [1000]: avg:   1.9102, min:   1.7431[ 887], max:   2.0812[ 854]\n",
      "===================\n",
      "beginning of epoch:  195\n",
      "available: 2.760 GB, used: 25.915 GB, free: 2.162 GB\n",
      "EPOCH: 195\n",
      "mean score: 0.00\n",
      "Speed: train: 1852.0, buffer_add: 1016.4, buffer_size: 99998\n",
      "Total Time: 1H 53M 37S, 6817s\n",
      "Total Sample: train: 12.544M, buffer: 6.905M\n",
      "[195] Time spent = 35.05 s\n",
      "195:grad_norm[1000]: avg:   3.1624, min:   1.7662[ 298], max:   5.4909[ 358]\n",
      "195:loss     [1000]: avg:   7.2281, min:   5.1349[ 525], max:   9.8500[ 830]\n",
      "195:xent_pred[1000]: avg:   1.9195, min:   1.7593[ 508], max:   2.0606[ 632]\n",
      "195:xent_v0  [1000]: avg:   1.9140, min:   1.7506[ 486], max:   2.0587[ 497]\n",
      "===================\n",
      "beginning of epoch:  196\n",
      "available: 2.760 GB, used: 25.916 GB, free: 2.239 GB\n",
      "EPOCH: 196\n",
      "mean score: 0.00\n",
      "Speed: train: 1863.5, buffer_add: 1008.3, buffer_size: 100027\n",
      "Total Time: 1H 54M 11S, 6851s\n",
      "Total Sample: train: 12.608M, buffer: 6.939M\n",
      "[196] Time spent = 34.88 s\n",
      "196:grad_norm[1000]: avg:   3.1156, min:   1.7666[ 810], max:   5.2325[ 109]\n",
      "196:loss     [1000]: avg:   7.1951, min:   5.2291[ 358], max:   9.4807[ 518]\n",
      "196:xent_pred[1000]: avg:   1.9192, min:   1.7616[ 120], max:   2.0424[ 658]\n",
      "196:xent_v0  [1000]: avg:   1.9141, min:   1.7469[ 120], max:   2.0442[   3]\n",
      "===================\n",
      "beginning of epoch:  197\n",
      "available: 2.767 GB, used: 25.908 GB, free: 2.284 GB\n",
      "EPOCH: 197\n",
      "mean score: 0.00\n",
      "Speed: train: 1872.8, buffer_add: 1014.6, buffer_size: 100028\n",
      "Total Time: 1H 54M 46S, 6886s\n",
      "Total Sample: train: 12.672M, buffer: 6.974M\n",
      "[197] Time spent = 34.53 s\n",
      "197:grad_norm[1000]: avg:   3.1269, min:   1.7495[ 373], max:   5.4471[ 219]\n",
      "197:loss     [1000]: avg:   7.1862, min:   5.2392[ 430], max:   9.4431[ 809]\n",
      "197:xent_pred[1000]: avg:   1.9183, min:   1.7728[ 227], max:   2.0724[ 953]\n",
      "197:xent_v0  [1000]: avg:   1.9130, min:   1.7778[ 858], max:   2.0625[ 953]\n",
      "===================\n",
      "beginning of epoch:  198\n",
      "available: 2.760 GB, used: 25.905 GB, free: 2.379 GB\n",
      "EPOCH: 198\n",
      "mean score: 0.00\n",
      "Speed: train: 1899.5, buffer_add: 1014.9, buffer_size: 100035\n",
      "Total Time: 1H 55M 19S, 6919s\n",
      "Total Sample: train: 12.736M, buffer: 7.008M\n",
      "[198] Time spent = 34.07 s\n",
      "198:grad_norm[1000]: avg:   3.1158, min:   1.9159[ 511], max:   5.3580[  77]\n",
      "198:loss     [1000]: avg:   7.1693, min:   5.0724[ 348], max:   9.4563[ 117]\n",
      "198:xent_pred[1000]: avg:   1.9217, min:   1.7731[   2], max:   2.0884[ 877]\n",
      "198:xent_v0  [1000]: avg:   1.9166, min:   1.7647[   2], max:   2.0755[ 877]\n",
      "===================\n",
      "beginning of epoch:  199\n",
      "available: 2.765 GB, used: 25.901 GB, free: 2.444 GB\n",
      "EPOCH: 199\n",
      "mean score: 0.00\n",
      "Speed: train: 1897.8, buffer_add: 1011.1, buffer_size: 100019\n",
      "Total Time: 1H 55M 53S, 6953s\n",
      "Total Sample: train: 12.8M, buffer: 7.042M\n",
      "[199] Time spent = 34.10 s\n",
      "199:grad_norm[1000]: avg:   3.1021, min:   1.9454[ 714], max:   4.9062[ 377]\n",
      "199:loss     [1000]: avg:   7.1845, min:   5.2315[ 103], max:   9.3383[ 365]\n",
      "199:xent_pred[1000]: avg:   1.9207, min:   1.7748[ 800], max:   2.0821[ 540]\n",
      "199:xent_v0  [1000]: avg:   1.9150, min:   1.7759[ 800], max:   2.0789[ 540]\n",
      "===================\n",
      "beginning of epoch:  200\n",
      "available: 2.757 GB, used: 25.909 GB, free: 2.456 GB\n",
      "EPOCH: 200\n",
      "mean score: 0.00\n",
      "Speed: train: 1859.1, buffer_add: 1009.5, buffer_size: 100007\n",
      "Total Time: 1H 56M 27S, 6987s\n",
      "Total Sample: train: 12.864M, buffer: 7.077M\n",
      "[200] Time spent = 34.96 s\n",
      "200:grad_norm[1000]: avg:   3.0965, min:   1.7097[ 488], max:   5.3080[ 209]\n",
      "200:loss     [1000]: avg:   7.1478, min:   5.0614[ 488], max:   9.8482[ 532]\n",
      "200:xent_pred[1000]: avg:   1.9190, min:   1.7267[ 876], max:   2.0603[  60]\n",
      "200:xent_v0  [1000]: avg:   1.9132, min:   1.7148[ 876], max:   2.0613[  60]\n",
      "===================\n",
      "beginning of epoch:  201\n",
      "available: 2.763 GB, used: 25.898 GB, free: 2.566 GB\n",
      "EPOCH: 201\n",
      "mean score: 0.00\n",
      "Speed: train: 1847.5, buffer_add: 1025.4, buffer_size: 100056\n",
      "Total Time: 1H 57M 02S, 7022s\n",
      "Total Sample: train: 12.928M, buffer: 7.113M\n",
      "[201] Time spent = 35.05 s\n",
      "201:grad_norm[1000]: avg:   3.0903, min:   1.6120[ 655], max:   5.3554[ 613]\n",
      "201:loss     [1000]: avg:   7.2007, min:   5.1628[ 157], max:   9.3104[ 526]\n",
      "201:xent_pred[1000]: avg:   1.9192, min:   1.7478[ 542], max:   2.0545[ 333]\n",
      "201:xent_v0  [1000]: avg:   1.9140, min:   1.7385[ 542], max:   2.0480[  87]\n",
      "===================\n",
      "beginning of epoch:  202\n",
      "available: 2.759 GB, used: 25.902 GB, free: 2.647 GB\n",
      "EPOCH: 202\n",
      "mean score: 0.00\n",
      "Speed: train: 1848.2, buffer_add: 1016.3, buffer_size: 100004\n",
      "Total Time: 1H 57M 37S, 7057s\n",
      "Total Sample: train: 12.992M, buffer: 7.148M\n",
      "[202] Time spent = 34.95 s\n",
      "202:grad_norm[1000]: avg:   3.0670, min:   1.7986[ 744], max:   5.7450[ 708]\n",
      "202:loss     [1000]: avg:   7.1960, min:   5.2342[ 781], max:   9.7822[ 900]\n",
      "202:xent_pred[1000]: avg:   1.9180, min:   1.7337[  98], max:   2.0911[ 242]\n",
      "202:xent_v0  [1000]: avg:   1.9124, min:   1.7354[  98], max:   2.0815[ 582]\n",
      "===================\n",
      "beginning of epoch:  203\n",
      "available: 2.748 GB, used: 25.906 GB, free: 2.679 GB\n",
      "EPOCH: 203\n",
      "mean score: 0.00\n",
      "Speed: train: 1902.2, buffer_add: 1014.8, buffer_size: 100062\n",
      "Total Time: 1H 58M 10S, 7090s\n",
      "Total Sample: train: 13.056M, buffer: 7.182M\n",
      "[203] Time spent = 34.00 s\n",
      "203:grad_norm[1000]: avg:   3.1205, min:   1.7919[  22], max:   5.4075[ 711]\n",
      "203:loss     [1000]: avg:   7.1997, min:   5.4158[ 207], max:   9.6364[ 819]\n",
      "203:xent_pred[1000]: avg:   1.9173, min:   1.7573[  51], max:   2.0463[ 310]\n",
      "203:xent_v0  [1000]: avg:   1.9117, min:   1.7457[  51], max:   2.0451[ 310]\n",
      "===================\n",
      "beginning of epoch:  204\n",
      "available: 2.747 GB, used: 25.905 GB, free: 2.632 GB\n",
      "EPOCH: 204\n",
      "mean score: 0.00\n",
      "Speed: train: 1880.6, buffer_add: 1006.1, buffer_size: 100067\n",
      "Total Time: 1H 58M 44S, 7124s\n",
      "Total Sample: train: 13.12M, buffer: 7.216M\n",
      "[204] Time spent = 34.45 s\n",
      "204:grad_norm[1000]: avg:   3.1166, min:   1.6421[ 268], max:   5.6701[ 910]\n",
      "204:loss     [1000]: avg:   7.2022, min:   5.2367[ 268], max:   9.9190[ 910]\n",
      "204:xent_pred[1000]: avg:   1.9181, min:   1.7640[ 901], max:   2.0717[ 427]\n",
      "204:xent_v0  [1000]: avg:   1.9125, min:   1.7676[ 901], max:   2.0767[ 427]\n",
      "===================\n",
      "beginning of epoch:  205\n",
      "available: 2.744 GB, used: 25.913 GB, free: 2.641 GB\n",
      "EPOCH: 205\n",
      "mean score: 0.00\n",
      "Speed: train: 1856.9, buffer_add: 1009.6, buffer_size: 100049\n",
      "Total Time: 1H 59M 19S, 7159s\n",
      "Total Sample: train: 13.184M, buffer: 7.251M\n",
      "[205] Time spent = 34.94 s\n",
      "205:grad_norm[1000]: avg:   3.1220, min:   1.9630[ 459], max:   5.3804[ 207]\n",
      "205:loss     [1000]: avg:   7.2530, min:   5.1790[ 323], max:   9.5597[ 348]\n",
      "205:xent_pred[1000]: avg:   1.9135, min:   1.7364[ 978], max:   2.0573[ 987]\n",
      "205:xent_v0  [1000]: avg:   1.9082, min:   1.7356[ 978], max:   2.0543[ 937]\n",
      "===================\n",
      "beginning of epoch:  206\n",
      "available: 2.752 GB, used: 25.907 GB, free: 2.639 GB\n",
      "EPOCH: 206\n",
      "mean score: 0.00\n",
      "Speed: train: 1875.9, buffer_add: 1010.2, buffer_size: 100016\n",
      "Total Time: 1H 59M 53S, 7193s\n",
      "Total Sample: train: 13.248M, buffer: 7.285M\n",
      "[206] Time spent = 34.43 s\n",
      "206:grad_norm[1000]: avg:   3.1105, min:   1.7974[ 408], max:   6.4201[ 902]\n",
      "206:loss     [1000]: avg:   7.2474, min:   4.9361[ 408], max:   9.5589[ 750]\n",
      "206:xent_pred[1000]: avg:   1.9144, min:   1.7565[ 381], max:   2.0606[ 752]\n",
      "206:xent_v0  [1000]: avg:   1.9095, min:   1.7644[ 381], max:   2.0562[ 752]\n",
      "===================\n",
      "beginning of epoch:  207\n",
      "available: 2.752 GB, used: 25.905 GB, free: 2.698 GB\n",
      "EPOCH: 207\n",
      "mean score: 0.00\n",
      "Speed: train: 1848.7, buffer_add: 1011.1, buffer_size: 100017\n",
      "Total Time: 2H 00M 28S, 7228s\n",
      "Total Sample: train: 13.312M, buffer: 7.32M\n",
      "[207] Time spent = 35.01 s\n",
      "207:grad_norm[1000]: avg:   3.1034, min:   1.7577[ 270], max:   5.4031[ 582]\n",
      "207:loss     [1000]: avg:   7.2126, min:   5.3181[ 880], max:   9.3168[ 684]\n",
      "207:xent_pred[1000]: avg:   1.9186, min:   1.7516[ 396], max:   2.0759[ 880]\n",
      "207:xent_v0  [1000]: avg:   1.9140, min:   1.7561[ 396], max:   2.0732[ 880]\n",
      "===================\n",
      "beginning of epoch:  208\n",
      "available: 2.745 GB, used: 25.912 GB, free: 2.647 GB\n",
      "EPOCH: 208\n",
      "mean score: 0.00\n",
      "Speed: train: 1830.8, buffer_add: 1015.7, buffer_size: 100027\n",
      "Total Time: 2H 01M 02S, 7262s\n",
      "Total Sample: train: 13.376M, buffer: 7.356M\n",
      "[208] Time spent = 35.31 s\n",
      "208:grad_norm[1000]: avg:   3.1445, min:   1.6916[ 372], max:   5.2269[  95]\n",
      "208:loss     [1000]: avg:   7.2265, min:   5.3158[ 796], max:   9.3884[ 133]\n",
      "208:xent_pred[1000]: avg:   1.9138, min:   1.7486[ 185], max:   2.0356[ 630]\n",
      "208:xent_v0  [1000]: avg:   1.9088, min:   1.7567[ 185], max:   2.0367[ 572]\n",
      "===================\n",
      "beginning of epoch:  209\n",
      "available: 2.756 GB, used: 25.909 GB, free: 2.625 GB\n",
      "EPOCH: 209\n",
      "mean score: 0.00\n",
      "Speed: train: 1890.0, buffer_add: 1006.8, buffer_size: 100021\n",
      "Total Time: 2H 01M 36S, 7296s\n",
      "Total Sample: train: 13.44M, buffer: 7.39M\n",
      "[209] Time spent = 34.28 s\n",
      "209:grad_norm[1000]: avg:   3.1226, min:   1.7201[  45], max:   4.9801[   5]\n",
      "209:loss     [1000]: avg:   7.1881, min:   5.2866[ 249], max:   9.8783[ 296]\n",
      "209:xent_pred[1000]: avg:   1.9151, min:   1.7717[ 220], max:   2.0773[ 818]\n",
      "209:xent_v0  [1000]: avg:   1.9103, min:   1.7679[ 220], max:   2.0769[ 818]\n",
      "===================\n",
      "beginning of epoch:  210\n",
      "available: 2.755 GB, used: 25.914 GB, free: 2.630 GB\n",
      "EPOCH: 210\n",
      "mean score: 0.00\n",
      "Speed: train: 1838.7, buffer_add: 1017.7, buffer_size: 100018\n",
      "Total Time: 2H 02M 11S, 7331s\n",
      "Total Sample: train: 13.504M, buffer: 7.425M\n",
      "[210] Time spent = 34.96 s\n",
      "210:grad_norm[1000]: avg:   3.0821, min:   1.7724[ 769], max:   4.9388[ 812]\n",
      "210:loss     [1000]: avg:   7.1559, min:   5.0958[ 983], max:   9.4378[ 111]\n",
      "210:xent_pred[1000]: avg:   1.9223, min:   1.7679[ 781], max:   2.0992[ 104]\n",
      "210:xent_v0  [1000]: avg:   1.9173, min:   1.7652[ 781], max:   2.0901[ 104]\n",
      "===================\n",
      "beginning of epoch:  211\n",
      "available: 2.758 GB, used: 25.916 GB, free: 2.615 GB\n",
      "EPOCH: 211\n",
      "mean score: 0.00\n",
      "Speed: train: 1858.3, buffer_add: 1007.7, buffer_size: 100014\n",
      "Total Time: 2H 02M 46S, 7366s\n",
      "Total Sample: train: 13.568M, buffer: 7.46M\n",
      "[211] Time spent = 34.89 s\n",
      "211:grad_norm[1000]: avg:   3.0621, min:   1.8699[ 994], max:   4.8860[ 421]\n",
      "211:loss     [1000]: avg:   7.1702, min:   5.4259[ 628], max:   9.9017[ 420]\n",
      "211:xent_pred[1000]: avg:   1.9205, min:   1.7771[ 996], max:   2.0592[ 909]\n",
      "211:xent_v0  [1000]: avg:   1.9156, min:   1.7731[ 996], max:   2.0529[ 533]\n",
      "===================\n",
      "beginning of epoch:  212\n",
      "available: 2.761 GB, used: 25.904 GB, free: 2.679 GB\n",
      "EPOCH: 212\n",
      "mean score: 0.00\n",
      "Speed: train: 1854.1, buffer_add: 1008.0, buffer_size: 100021\n",
      "Total Time: 2H 03M 20S, 7400s\n",
      "Total Sample: train: 13.632M, buffer: 7.495M\n",
      "[212] Time spent = 34.95 s\n",
      "212:grad_norm[1000]: avg:   3.0686, min:   1.8758[ 787], max:   6.5906[  21]\n",
      "212:loss     [1000]: avg:   7.1548, min:   5.3083[ 586], max:   9.1502[ 827]\n",
      "212:xent_pred[1000]: avg:   1.9217, min:   1.7591[  64], max:   2.1387[ 654]\n",
      "212:xent_v0  [1000]: avg:   1.9164, min:   1.7555[  64], max:   2.1464[ 654]\n",
      "===================\n",
      "beginning of epoch:  213\n",
      "available: 2.749 GB, used: 25.908 GB, free: 2.717 GB\n",
      "EPOCH: 213\n",
      "mean score: 0.00\n",
      "Speed: train: 1857.4, buffer_add: 1009.8, buffer_size: 100001\n",
      "Total Time: 2H 03M 55S, 7435s\n",
      "Total Sample: train: 13.696M, buffer: 7.53M\n",
      "[213] Time spent = 34.75 s\n",
      "213:grad_norm[1000]: avg:   3.0901, min:   1.7582[ 759], max:   5.9581[ 859]\n",
      "213:loss     [1000]: avg:   7.1982, min:   5.2965[ 689], max:   9.4144[ 262]\n",
      "213:xent_pred[1000]: avg:   1.9164, min:   1.7593[ 356], max:   2.0742[ 988]\n",
      "213:xent_v0  [1000]: avg:   1.9111, min:   1.7488[ 356], max:   2.0732[ 220]\n",
      "===================\n",
      "beginning of epoch:  214\n",
      "available: 2.761 GB, used: 25.902 GB, free: 2.686 GB\n",
      "EPOCH: 214\n",
      "mean score: 0.00\n",
      "Speed: train: 1872.7, buffer_add: 1007.3, buffer_size: 100010\n",
      "Total Time: 2H 04M 29S, 7469s\n",
      "Total Sample: train: 13.76M, buffer: 7.564M\n",
      "[214] Time spent = 34.54 s\n",
      "214:grad_norm[1000]: avg:   3.0930, min:   1.6846[ 775], max:   6.1401[ 412]\n",
      "214:loss     [1000]: avg:   7.2118, min:   4.9246[ 503], max:   9.4149[ 245]\n",
      "214:xent_pred[1000]: avg:   1.9162, min:   1.7664[ 748], max:   2.0918[ 696]\n",
      "214:xent_v0  [1000]: avg:   1.9113, min:   1.7619[ 748], max:   2.0763[ 696]\n",
      "===================\n",
      "beginning of epoch:  215\n",
      "available: 2.758 GB, used: 25.903 GB, free: 2.617 GB\n",
      "EPOCH: 215\n",
      "mean score: 0.00\n",
      "Speed: train: 1832.8, buffer_add: 1012.3, buffer_size: 100014\n",
      "Total Time: 2H 05M 04S, 7504s\n",
      "Total Sample: train: 13.824M, buffer: 7.599M\n",
      "[215] Time spent = 35.33 s\n",
      "215:grad_norm[1000]: avg:   3.0178, min:   1.5569[ 956], max:   5.3315[ 705]\n",
      "215:loss     [1000]: avg:   7.1451, min:   5.2635[  96], max:  10.1924[ 930]\n",
      "215:xent_pred[1000]: avg:   1.9203, min:   1.7629[ 642], max:   2.1009[ 709]\n",
      "215:xent_v0  [1000]: avg:   1.9154, min:   1.7577[ 645], max:   2.0897[ 709]\n",
      "===================\n",
      "beginning of epoch:  216\n",
      "available: 2.758 GB, used: 25.904 GB, free: 2.564 GB\n",
      "EPOCH: 216\n",
      "mean score: 0.00\n",
      "Speed: train: 1871.3, buffer_add: 1021.2, buffer_size: 100037\n",
      "Total Time: 2H 05M 38S, 7538s\n",
      "Total Sample: train: 13.888M, buffer: 7.634M\n",
      "[216] Time spent = 35.04 s\n",
      "216:grad_norm[1000]: avg:   3.0129, min:   1.4839[ 754], max:   5.0209[ 716]\n",
      "216:loss     [1000]: avg:   7.1233, min:   5.1143[ 836], max:   9.4889[ 749]\n",
      "216:xent_pred[1000]: avg:   1.9228, min:   1.7436[ 924], max:   2.0603[ 562]\n",
      "216:xent_v0  [1000]: avg:   1.9181, min:   1.7435[ 924], max:   2.0535[ 532]\n",
      "===================\n",
      "beginning of epoch:  217\n",
      "available: 2.753 GB, used: 25.904 GB, free: 2.610 GB\n",
      "EPOCH: 217\n",
      "mean score: 0.00\n",
      "Speed: train: 1843.9, buffer_add: 1041.0, buffer_size: 100039\n",
      "Total Time: 2H 06M 13S, 7573s\n",
      "Total Sample: train: 13.952M, buffer: 7.671M\n",
      "[217] Time spent = 35.07 s\n",
      "217:grad_norm[1000]: avg:   3.0130, min:   1.9184[ 919], max:   4.7630[ 852]\n",
      "217:loss     [1000]: avg:   7.1477, min:   5.4057[ 261], max:  10.0396[ 236]\n",
      "217:xent_pred[1000]: avg:   1.9215, min:   1.7504[ 841], max:   2.0662[ 542]\n",
      "217:xent_v0  [1000]: avg:   1.9171, min:   1.7510[ 841], max:   2.0539[ 542]\n",
      "===================\n",
      "beginning of epoch:  218\n",
      "available: 2.756 GB, used: 25.907 GB, free: 2.610 GB\n",
      "EPOCH: 218\n",
      "mean score: 0.00\n",
      "Speed: train: 1864.5, buffer_add: 1014.5, buffer_size: 100022\n",
      "Total Time: 2H 06M 47S, 7607s\n",
      "Total Sample: train: 14.016M, buffer: 7.705M\n",
      "[218] Time spent = 34.82 s\n",
      "218:grad_norm[1000]: avg:   3.0622, min:   1.7496[ 239], max:   6.1633[ 999]\n",
      "218:loss     [1000]: avg:   7.1478, min:   5.0480[ 266], max:  10.4691[ 106]\n",
      "218:xent_pred[1000]: avg:   1.9197, min:   1.7327[ 261], max:   2.0790[ 829]\n",
      "218:xent_v0  [1000]: avg:   1.9156, min:   1.7412[ 261], max:   2.0651[ 829]\n",
      "===================\n",
      "beginning of epoch:  219\n",
      "available: 2.758 GB, used: 25.911 GB, free: 2.617 GB\n",
      "EPOCH: 219\n",
      "mean score: 0.00\n",
      "Speed: train: 1886.3, buffer_add: 1023.5, buffer_size: 100040\n",
      "Total Time: 2H 07M 21S, 7641s\n",
      "Total Sample: train: 14.08M, buffer: 7.74M\n",
      "[219] Time spent = 34.30 s\n",
      "219:grad_norm[1000]: avg:   3.0567, min:   1.8461[ 617], max:   5.2130[  14]\n",
      "219:loss     [1000]: avg:   7.1516, min:   5.1551[ 817], max:   9.1993[ 690]\n",
      "219:xent_pred[1000]: avg:   1.9195, min:   1.7614[ 147], max:   2.0743[ 999]\n",
      "219:xent_v0  [1000]: avg:   1.9153, min:   1.7532[ 147], max:   2.0720[ 350]\n",
      "===================\n",
      "beginning of epoch:  220\n",
      "available: 2.754 GB, used: 25.900 GB, free: 2.700 GB\n",
      "EPOCH: 220\n",
      "mean score: 0.00\n",
      "Speed: train: 1882.6, buffer_add: 1018.2, buffer_size: 100012\n",
      "Total Time: 2H 07M 55S, 7675s\n",
      "Total Sample: train: 14.144M, buffer: 7.775M\n",
      "[220] Time spent = 34.47 s\n",
      "220:grad_norm[1000]: avg:   3.0444, min:   1.6996[ 316], max:   4.8603[ 595]\n",
      "220:loss     [1000]: avg:   7.1861, min:   5.2501[  80], max:   9.3332[ 748]\n",
      "220:xent_pred[1000]: avg:   1.9181, min:   1.7733[ 705], max:   2.0590[ 190]\n",
      "220:xent_v0  [1000]: avg:   1.9136, min:   1.7670[ 705], max:   2.0518[  83]\n",
      "===================\n",
      "beginning of epoch:  221\n",
      "available: 2.755 GB, used: 25.903 GB, free: 2.660 GB\n",
      "EPOCH: 221\n",
      "mean score: 0.00\n",
      "Speed: train: 1860.0, buffer_add: 1007.6, buffer_size: 100049\n",
      "Total Time: 2H 08M 29S, 7709s\n",
      "Total Sample: train: 14.208M, buffer: 7.809M\n",
      "[221] Time spent = 35.00 s\n",
      "221:grad_norm[1000]: avg:   3.0758, min:   1.6152[ 439], max:   5.7911[  56]\n",
      "221:loss     [1000]: avg:   7.2456, min:   4.8550[ 439], max:   9.9774[ 243]\n",
      "221:xent_pred[1000]: avg:   1.9124, min:   1.7781[ 257], max:   2.0842[  67]\n",
      "221:xent_v0  [1000]: avg:   1.9078, min:   1.7762[ 257], max:   2.0953[  67]\n",
      "===================\n",
      "beginning of epoch:  222\n",
      "available: 2.753 GB, used: 25.902 GB, free: 2.658 GB\n",
      "EPOCH: 222\n",
      "mean score: 0.00\n",
      "Speed: train: 1851.8, buffer_add: 1018.1, buffer_size: 100014\n",
      "Total Time: 2H 09M 04S, 7744s\n",
      "Total Sample: train: 14.272M, buffer: 7.845M\n",
      "[222] Time spent = 34.93 s\n",
      "222:grad_norm[1000]: avg:   3.0397, min:   1.7981[ 364], max:   5.5857[ 721]\n",
      "222:loss     [1000]: avg:   7.1977, min:   5.2356[ 752], max:   9.3351[ 767]\n",
      "222:xent_pred[1000]: avg:   1.9199, min:   1.7589[ 447], max:   2.0664[ 790]\n",
      "222:xent_v0  [1000]: avg:   1.9153, min:   1.7483[ 447], max:   2.0584[ 790]\n",
      "===================\n",
      "beginning of epoch:  223\n",
      "available: 2.759 GB, used: 25.906 GB, free: 2.632 GB\n",
      "EPOCH: 223\n",
      "mean score: 0.00\n",
      "Speed: train: 1851.0, buffer_add: 1015.9, buffer_size: 100029\n",
      "Total Time: 2H 09M 38S, 7778s\n",
      "Total Sample: train: 14.336M, buffer: 7.88M\n",
      "[223] Time spent = 35.02 s\n",
      "223:grad_norm[1000]: avg:   3.0292, min:   1.6848[ 841], max:   4.8318[ 667]\n",
      "223:loss     [1000]: avg:   7.1997, min:   5.4952[ 130], max:   9.5016[ 746]\n",
      "223:xent_pred[1000]: avg:   1.9179, min:   1.7692[ 203], max:   2.0768[ 794]\n",
      "223:xent_v0  [1000]: avg:   1.9133, min:   1.7675[ 203], max:   2.0706[ 794]\n",
      "===================\n",
      "beginning of epoch:  224\n",
      "available: 2.758 GB, used: 25.901 GB, free: 2.633 GB\n",
      "EPOCH: 224\n",
      "mean score: 0.00\n",
      "Speed: train: 1883.5, buffer_add: 1010.9, buffer_size: 100063\n",
      "Total Time: 2H 10M 12S, 7812s\n",
      "Total Sample: train: 14.4M, buffer: 7.914M\n",
      "[224] Time spent = 34.35 s\n",
      "224:grad_norm[1000]: avg:   3.0324, min:   1.7411[  77], max:  15.6823[ 775]\n",
      "224:loss     [1000]: avg:   7.1761, min:   5.3054[ 910], max:  10.1215[  14]\n",
      "224:xent_pred[1000]: avg:   1.9195, min:   1.7372[ 440], max:   2.0922[ 660]\n",
      "224:xent_v0  [1000]: avg:   1.9149, min:   1.7466[ 440], max:   2.0830[ 660]\n",
      "===================\n",
      "beginning of epoch:  225\n",
      "available: 2.754 GB, used: 25.909 GB, free: 2.658 GB\n",
      "EPOCH: 225\n",
      "mean score: 0.00\n",
      "Speed: train: 1860.0, buffer_add: 1008.1, buffer_size: 100018\n",
      "Total Time: 2H 10M 47S, 7847s\n",
      "Total Sample: train: 14.464M, buffer: 7.949M\n",
      "[225] Time spent = 34.74 s\n",
      "225:grad_norm[1000]: avg:   2.9872, min:   1.8490[ 708], max:   5.0352[  27]\n",
      "225:loss     [1000]: avg:   7.1479, min:   5.1751[ 481], max:   9.3926[ 822]\n",
      "225:xent_pred[1000]: avg:   1.9190, min:   1.7643[ 322], max:   2.0814[ 625]\n",
      "225:xent_v0  [1000]: avg:   1.9147, min:   1.7615[ 322], max:   2.0645[ 625]\n",
      "===================\n",
      "beginning of epoch:  226\n",
      "available: 2.752 GB, used: 25.904 GB, free: 2.687 GB\n",
      "EPOCH: 226\n",
      "mean score: 0.00\n",
      "Speed: train: 1871.0, buffer_add: 1007.7, buffer_size: 100012\n",
      "Total Time: 2H 11M 21S, 7881s\n",
      "Total Sample: train: 14.528M, buffer: 7.983M\n",
      "[226] Time spent = 34.61 s\n",
      "226:grad_norm[1000]: avg:   2.9682, min:   1.6529[ 229], max:   5.2886[  24]\n",
      "226:loss     [1000]: avg:   7.1430, min:   5.4078[ 706], max:   9.3984[ 725]\n",
      "226:xent_pred[1000]: avg:   1.9199, min:   1.7447[ 878], max:   2.0733[ 339]\n",
      "226:xent_v0  [1000]: avg:   1.9153, min:   1.7367[ 878], max:   2.0659[ 339]\n",
      "===================\n",
      "beginning of epoch:  227\n",
      "available: 2.758 GB, used: 25.900 GB, free: 2.674 GB\n",
      "EPOCH: 227\n",
      "mean score: 0.00\n",
      "Speed: train: 1841.3, buffer_add: 1020.7, buffer_size: 100029\n",
      "Total Time: 2H 11M 56S, 7916s\n",
      "Total Sample: train: 14.592M, buffer: 8.019M\n",
      "[227] Time spent = 35.21 s\n",
      "227:grad_norm[1000]: avg:   3.0034, min:   1.8147[ 178], max:   5.3260[ 525]\n",
      "227:loss     [1000]: avg:   7.2006, min:   5.4638[ 171], max:   9.8288[ 595]\n",
      "227:xent_pred[1000]: avg:   1.9179, min:   1.7808[ 115], max:   2.0687[ 651]\n",
      "227:xent_v0  [1000]: avg:   1.9132, min:   1.7738[ 649], max:   2.0599[ 651]\n",
      "===================\n",
      "beginning of epoch:  228\n",
      "available: 2.745 GB, used: 25.916 GB, free: 2.663 GB\n",
      "EPOCH: 228\n",
      "mean score: 0.00\n",
      "Speed: train: 1846.1, buffer_add: 1016.8, buffer_size: 100013\n",
      "Total Time: 2H 12M 30S, 7950s\n",
      "Total Sample: train: 14.656M, buffer: 8.054M\n",
      "[228] Time spent = 34.94 s\n",
      "228:grad_norm[1000]: avg:   2.9955, min:   1.7226[ 547], max:   6.4949[ 490]\n",
      "228:loss     [1000]: avg:   7.1448, min:   5.4596[ 635], max:   9.5855[ 753]\n",
      "228:xent_pred[1000]: avg:   1.9195, min:   1.7365[ 186], max:   2.0794[ 332]\n",
      "228:xent_v0  [1000]: avg:   1.9156, min:   1.7398[ 186], max:   2.0705[  88]\n",
      "===================\n",
      "beginning of epoch:  229\n",
      "available: 2.754 GB, used: 25.914 GB, free: 2.608 GB\n",
      "EPOCH: 229\n",
      "mean score: 0.00\n",
      "Speed: train: 1858.1, buffer_add: 1016.0, buffer_size: 100049\n",
      "Total Time: 2H 13M 05S, 7985s\n",
      "Total Sample: train: 14.72M, buffer: 8.089M\n",
      "[229] Time spent = 34.73 s\n",
      "229:grad_norm[1000]: avg:   3.0056, min:   1.8713[  47], max:   5.1390[ 951]\n",
      "229:loss     [1000]: avg:   7.2352, min:   5.1154[ 156], max:   9.7138[ 723]\n",
      "229:xent_pred[1000]: avg:   1.9171, min:   1.7498[ 573], max:   2.0633[ 173]\n",
      "229:xent_v0  [1000]: avg:   1.9124, min:   1.7384[ 573], max:   2.0659[ 328]\n",
      "===================\n",
      "beginning of epoch:  230\n",
      "available: 2.749 GB, used: 25.914 GB, free: 2.645 GB\n",
      "EPOCH: 230\n",
      "mean score: 0.00\n",
      "Speed: train: 1854.8, buffer_add: 1004.3, buffer_size: 100043\n",
      "Total Time: 2H 13M 39S, 8019s\n",
      "Total Sample: train: 14.784M, buffer: 8.124M\n",
      "[230] Time spent = 34.87 s\n",
      "230:grad_norm[1000]: avg:   2.9708, min:   1.8334[ 310], max:   5.1473[ 210]\n",
      "230:loss     [1000]: avg:   7.2018, min:   5.3528[ 310], max:   9.3570[ 388]\n",
      "230:xent_pred[1000]: avg:   1.9161, min:   1.7670[ 716], max:   2.0758[ 692]\n",
      "230:xent_v0  [1000]: avg:   1.9118, min:   1.7659[ 716], max:   2.0729[ 692]\n",
      "===================\n",
      "beginning of epoch:  231\n",
      "available: 2.752 GB, used: 25.910 GB, free: 2.658 GB\n",
      "EPOCH: 231\n",
      "mean score: 0.00\n",
      "Speed: train: 1829.8, buffer_add: 1015.7, buffer_size: 100028\n",
      "Total Time: 2H 14M 14S, 8054s\n",
      "Total Sample: train: 14.848M, buffer: 8.159M\n",
      "[231] Time spent = 35.34 s\n",
      "231:grad_norm[1000]: avg:   2.9731, min:   1.8767[ 702], max:   4.6188[ 467]\n",
      "231:loss     [1000]: avg:   7.2230, min:   5.3769[ 417], max:   9.5051[ 457]\n",
      "231:xent_pred[1000]: avg:   1.9194, min:   1.7716[ 855], max:   2.0528[ 706]\n",
      "231:xent_v0  [1000]: avg:   1.9149, min:   1.7635[ 818], max:   2.0420[ 706]\n",
      "===================\n",
      "beginning of epoch:  232\n",
      "available: 2.745 GB, used: 25.917 GB, free: 2.629 GB\n",
      "EPOCH: 232\n",
      "mean score: 0.00\n",
      "Speed: train: 1862.7, buffer_add: 1016.5, buffer_size: 100030\n",
      "Total Time: 2H 14M 49S, 8089s\n",
      "Total Sample: train: 14.912M, buffer: 8.194M\n",
      "[232] Time spent = 34.76 s\n",
      "232:grad_norm[1000]: avg:   3.0044, min:   1.7999[ 343], max:   5.4037[ 161]\n",
      "232:loss     [1000]: avg:   7.1656, min:   5.3534[ 343], max:  10.5708[ 908]\n",
      "232:xent_pred[1000]: avg:   1.9172, min:   1.7454[ 448], max:   2.0891[ 842]\n",
      "232:xent_v0  [1000]: avg:   1.9127, min:   1.7445[ 529], max:   2.0852[ 842]\n",
      "===================\n",
      "beginning of epoch:  233\n",
      "available: 2.754 GB, used: 25.907 GB, free: 2.683 GB\n",
      "EPOCH: 233\n",
      "mean score: 0.00\n",
      "Speed: train: 1827.0, buffer_add: 1008.6, buffer_size: 100024\n",
      "Total Time: 2H 15M 24S, 8124s\n",
      "Total Sample: train: 14.976M, buffer: 8.229M\n",
      "[233] Time spent = 35.53 s\n",
      "233:grad_norm[1000]: avg:   2.9737, min:   1.7439[  95], max:   5.3356[ 262]\n",
      "233:loss     [1000]: avg:   7.2200, min:   5.3291[  20], max:   9.1504[ 367]\n",
      "233:xent_pred[1000]: avg:   1.9157, min:   1.7432[ 668], max:   2.0716[ 546]\n",
      "233:xent_v0  [1000]: avg:   1.9110, min:   1.7393[ 668], max:   2.0500[ 546]\n",
      "===================\n",
      "beginning of epoch:  234\n",
      "available: 2.751 GB, used: 25.909 GB, free: 2.695 GB\n",
      "EPOCH: 234\n",
      "mean score: 0.00\n",
      "Speed: train: 1851.1, buffer_add: 1020.8, buffer_size: 100067\n",
      "Total Time: 2H 15M 58S, 8158s\n",
      "Total Sample: train: 15.04M, buffer: 8.265M\n",
      "[234] Time spent = 35.12 s\n",
      "234:grad_norm[1000]: avg:   2.9793, min:   1.7070[ 189], max:   5.5208[ 927]\n",
      "234:loss     [1000]: avg:   7.2093, min:   5.3036[ 468], max:   9.4323[ 711]\n",
      "234:xent_pred[1000]: avg:   1.9166, min:   1.7410[ 313], max:   2.0916[ 155]\n",
      "234:xent_v0  [1000]: avg:   1.9125, min:   1.7513[ 313], max:   2.0840[ 155]\n",
      "===================\n",
      "beginning of epoch:  235\n",
      "available: 2.755 GB, used: 25.907 GB, free: 2.684 GB\n",
      "EPOCH: 235\n",
      "mean score: 0.00\n",
      "Speed: train: 1840.9, buffer_add: 1030.5, buffer_size: 100077\n",
      "Total Time: 2H 16M 33S, 8193s\n",
      "Total Sample: train: 15.104M, buffer: 8.3M\n",
      "[235] Time spent = 35.21 s\n",
      "235:grad_norm[1000]: avg:   2.9750, min:   1.8039[ 354], max:   5.0862[ 779]\n",
      "235:loss     [1000]: avg:   7.1931, min:   4.9189[ 354], max:   9.3080[ 850]\n",
      "235:xent_pred[1000]: avg:   1.9135, min:   1.7595[ 397], max:   2.0586[ 728]\n",
      "235:xent_v0  [1000]: avg:   1.9091, min:   1.7573[ 397], max:   2.0560[ 552]\n",
      "===================\n",
      "beginning of epoch:  236\n",
      "available: 2.753 GB, used: 25.910 GB, free: 2.660 GB\n",
      "EPOCH: 236\n",
      "mean score: 0.00\n",
      "Speed: train: 1862.3, buffer_add: 1014.7, buffer_size: 100030\n",
      "Total Time: 2H 17M 07S, 8227s\n",
      "Total Sample: train: 15.168M, buffer: 8.335M\n",
      "[236] Time spent = 34.66 s\n",
      "236:grad_norm[1000]: avg:   2.9530, min:   1.5537[ 190], max:   5.9781[ 240]\n",
      "236:loss     [1000]: avg:   7.1618, min:   5.2552[ 799], max:   9.7492[  62]\n",
      "236:xent_pred[1000]: avg:   1.9196, min:   1.7741[ 613], max:   2.0773[ 428]\n",
      "236:xent_v0  [1000]: avg:   1.9150, min:   1.7686[ 452], max:   2.0822[ 428]\n",
      "===================\n",
      "beginning of epoch:  237\n",
      "available: 2.752 GB, used: 25.906 GB, free: 2.696 GB\n",
      "EPOCH: 237\n",
      "mean score: 0.00\n",
      "Speed: train: 1869.3, buffer_add: 1010.3, buffer_size: 100030\n",
      "Total Time: 2H 17M 42S, 8262s\n",
      "Total Sample: train: 15.232M, buffer: 8.37M\n",
      "[237] Time spent = 34.60 s\n",
      "237:grad_norm[1000]: avg:   2.9647, min:   1.7385[ 110], max:   5.4616[ 445]\n",
      "237:loss     [1000]: avg:   7.1768, min:   5.2562[  43], max:   9.6727[ 741]\n",
      "237:xent_pred[1000]: avg:   1.9162, min:   1.7710[ 741], max:   2.0908[ 884]\n",
      "237:xent_v0  [1000]: avg:   1.9120, min:   1.7639[ 723], max:   2.0892[ 884]\n",
      "===================\n",
      "beginning of epoch:  238\n",
      "available: 2.740 GB, used: 25.912 GB, free: 2.699 GB\n",
      "EPOCH: 238\n",
      "mean score: 0.00\n",
      "Speed: train: 1857.6, buffer_add: 1011.4, buffer_size: 100012\n",
      "Total Time: 2H 18M 16S, 8296s\n",
      "Total Sample: train: 15.296M, buffer: 8.405M\n",
      "[238] Time spent = 34.83 s\n",
      "238:grad_norm[1000]: avg:   2.9809, min:   1.7171[ 821], max:   4.8580[ 196]\n",
      "238:loss     [1000]: avg:   7.2124, min:   5.1955[ 770], max:   9.8154[  82]\n",
      "238:xent_pred[1000]: avg:   1.9170, min:   1.7737[ 232], max:   2.1096[ 417]\n",
      "238:xent_v0  [1000]: avg:   1.9128, min:   1.7603[ 232], max:   2.0907[ 417]\n",
      "===================\n",
      "beginning of epoch:  239\n",
      "available: 2.751 GB, used: 25.913 GB, free: 2.645 GB\n",
      "EPOCH: 239\n",
      "mean score: 0.00\n",
      "Speed: train: 1843.5, buffer_add: 1017.4, buffer_size: 100028\n",
      "Total Time: 2H 18M 51S, 8331s\n",
      "Total Sample: train: 15.36M, buffer: 8.44M\n",
      "[239] Time spent = 35.17 s\n",
      "239:grad_norm[1000]: avg:   2.9462, min:   1.8130[ 797], max:   5.2046[ 699]\n",
      "239:loss     [1000]: avg:   7.1899, min:   4.8861[ 351], max:   9.8469[ 855]\n",
      "239:xent_pred[1000]: avg:   1.9170, min:   1.7503[ 116], max:   2.0913[ 701]\n",
      "239:xent_v0  [1000]: avg:   1.9125, min:   1.7392[ 116], max:   2.0918[ 701]\n",
      "===================\n",
      "beginning of epoch:  240\n",
      "available: 2.749 GB, used: 25.919 GB, free: 2.619 GB\n",
      "EPOCH: 240\n",
      "mean score: 0.00\n",
      "Speed: train: 1881.1, buffer_add: 1012.2, buffer_size: 100043\n",
      "Total Time: 2H 19M 25S, 8365s\n",
      "Total Sample: train: 15.424M, buffer: 8.475M\n",
      "[240] Time spent = 34.34 s\n",
      "240:grad_norm[1000]: avg:   2.9403, min:   1.6738[ 457], max:   5.3721[ 501]\n",
      "240:loss     [1000]: avg:   7.1573, min:   4.8724[ 457], max:   9.3181[ 199]\n",
      "240:xent_pred[1000]: avg:   1.9178, min:   1.7838[ 232], max:   2.0745[ 860]\n",
      "240:xent_v0  [1000]: avg:   1.9134, min:   1.7845[ 232], max:   2.0652[ 860]\n",
      "===================\n",
      "beginning of epoch:  241\n",
      "available: 2.753 GB, used: 25.915 GB, free: 2.549 GB\n",
      "EPOCH: 241\n",
      "mean score: 0.01\n",
      "Speed: train: 1860.9, buffer_add: 1003.2, buffer_size: 100015\n",
      "Total Time: 2H 19M 59S, 8399s\n",
      "Total Sample: train: 15.488M, buffer: 8.509M\n",
      "[241] Time spent = 34.74 s\n",
      "241:grad_norm[1000]: avg:   2.9142, min:   1.5670[ 725], max:   4.9845[  58]\n",
      "241:loss     [1000]: avg:   7.1528, min:   5.1651[ 832], max:   9.8303[ 856]\n",
      "241:xent_pred[1000]: avg:   1.9190, min:   1.7441[ 368], max:   2.0430[ 567]\n",
      "241:xent_v0  [1000]: avg:   1.9151, min:   1.7398[ 368], max:   2.0457[ 567]\n",
      "===================\n",
      "beginning of epoch:  242\n",
      "available: 2.760 GB, used: 25.905 GB, free: 2.635 GB\n",
      "EPOCH: 242\n",
      "mean score: 0.00\n",
      "Speed: train: 1868.6, buffer_add: 1012.8, buffer_size: 100065\n",
      "Total Time: 2H 20M 33S, 8433s\n",
      "Total Sample: train: 15.552M, buffer: 8.544M\n",
      "[242] Time spent = 34.60 s\n",
      "242:grad_norm[1000]: avg:   2.9331, min:   1.7036[ 182], max:   7.1343[ 323]\n",
      "242:loss     [1000]: avg:   7.1467, min:   5.1564[ 998], max:   9.7009[ 791]\n",
      "242:xent_pred[1000]: avg:   1.9185, min:   1.7740[ 314], max:   2.0702[ 134]\n",
      "242:xent_v0  [1000]: avg:   1.9145, min:   1.7698[ 498], max:   2.0627[  89]\n",
      "===================\n",
      "beginning of epoch:  243\n",
      "available: 2.751 GB, used: 25.903 GB, free: 2.707 GB\n",
      "EPOCH: 243\n",
      "mean score: 0.00\n",
      "Speed: train: 1812.4, buffer_add: 1014.2, buffer_size: 100021\n",
      "Total Time: 2H 21M 09S, 8469s\n",
      "Total Sample: train: 15.616M, buffer: 8.58M\n",
      "[243] Time spent = 35.70 s\n",
      "243:grad_norm[1000]: avg:   2.9352, min:   1.5805[ 243], max:   5.5627[  39]\n",
      "243:loss     [1000]: avg:   7.1776, min:   5.0055[ 243], max:   9.7889[  39]\n",
      "243:xent_pred[1000]: avg:   1.9174, min:   1.7377[ 614], max:   2.0602[ 692]\n",
      "243:xent_v0  [1000]: avg:   1.9132, min:   1.7271[ 614], max:   2.0596[ 692]\n",
      "===================\n",
      "beginning of epoch:  244\n",
      "available: 2.753 GB, used: 25.903 GB, free: 2.679 GB\n",
      "EPOCH: 244\n",
      "mean score: 0.00\n",
      "Speed: train: 1884.6, buffer_add: 1019.6, buffer_size: 100040\n",
      "Total Time: 2H 21M 43S, 8503s\n",
      "Total Sample: train: 15.68M, buffer: 8.614M\n",
      "[244] Time spent = 34.30 s\n",
      "244:grad_norm[1000]: avg:   2.9578, min:   1.6541[ 596], max:   8.0732[ 369]\n",
      "244:loss     [1000]: avg:   7.1989, min:   5.0880[ 339], max:   9.3833[ 566]\n",
      "244:xent_pred[1000]: avg:   1.9142, min:   1.7638[ 890], max:   2.0879[ 479]\n",
      "244:xent_v0  [1000]: avg:   1.9100, min:   1.7591[ 890], max:   2.0766[ 479]\n",
      "===================\n",
      "beginning of epoch:  245\n",
      "available: 2.734 GB, used: 25.923 GB, free: 2.631 GB\n",
      "EPOCH: 245\n",
      "mean score: 0.00\n",
      "Speed: train: 1863.9, buffer_add: 1018.3, buffer_size: 100021\n",
      "Total Time: 2H 22M 17S, 8537s\n",
      "Total Sample: train: 15.744M, buffer: 8.649M\n",
      "[245] Time spent = 34.69 s\n",
      "245:grad_norm[1000]: avg:   2.9298, min:   1.6616[ 134], max:   5.7139[ 306]\n",
      "245:loss     [1000]: avg:   7.2291, min:   4.9693[ 134], max:   9.7669[ 495]\n",
      "245:xent_pred[1000]: avg:   1.9170, min:   1.7553[ 828], max:   2.0757[ 676]\n",
      "245:xent_v0  [1000]: avg:   1.9129, min:   1.7525[ 828], max:   2.0720[ 676]\n",
      "===================\n",
      "beginning of epoch:  246\n",
      "available: 2.754 GB, used: 25.912 GB, free: 2.613 GB\n",
      "EPOCH: 246\n",
      "mean score: 0.00\n",
      "Speed: train: 1879.9, buffer_add: 1010.5, buffer_size: 100022\n",
      "Total Time: 2H 22M 51S, 8571s\n",
      "Total Sample: train: 15.808M, buffer: 8.684M\n",
      "[246] Time spent = 34.35 s\n",
      "246:grad_norm[1000]: avg:   2.9406, min:   1.7366[ 904], max:   5.9487[ 271]\n",
      "246:loss     [1000]: avg:   7.2348, min:   5.3824[ 122], max:   9.5779[ 937]\n",
      "246:xent_pred[1000]: avg:   1.9155, min:   1.7689[ 160], max:   2.0350[ 610]\n",
      "246:xent_v0  [1000]: avg:   1.9117, min:   1.7697[ 160], max:   2.0398[ 893]\n",
      "===================\n",
      "beginning of epoch:  247\n",
      "available: 2.752 GB, used: 25.910 GB, free: 2.652 GB\n",
      "EPOCH: 247\n",
      "mean score: 0.00\n",
      "Speed: train: 1906.1, buffer_add: 1006.5, buffer_size: 100019\n",
      "Total Time: 2H 23M 25S, 8605s\n",
      "Total Sample: train: 15.872M, buffer: 8.717M\n",
      "[247] Time spent = 34.14 s\n",
      "247:grad_norm[1000]: avg:   2.9295, min:   1.7882[ 989], max:   5.0770[ 468]\n",
      "247:loss     [1000]: avg:   7.2113, min:   5.2530[  59], max:   9.7398[ 941]\n",
      "247:xent_pred[1000]: avg:   1.9156, min:   1.7617[ 256], max:   2.0595[ 792]\n",
      "247:xent_v0  [1000]: avg:   1.9119, min:   1.7698[ 256], max:   2.0558[ 187]\n",
      "===================\n",
      "beginning of epoch:  248\n",
      "available: 2.747 GB, used: 25.911 GB, free: 2.677 GB\n",
      "EPOCH: 248\n",
      "mean score: 0.00\n",
      "Speed: train: 1900.8, buffer_add: 1021.2, buffer_size: 100007\n",
      "Total Time: 2H 23M 58S, 8638s\n",
      "Total Sample: train: 15.936M, buffer: 8.752M\n",
      "[248] Time spent = 33.93 s\n",
      "248:grad_norm[1000]: avg:   2.9213, min:   1.6401[ 812], max:   5.0141[ 675]\n",
      "248:loss     [1000]: avg:   7.1685, min:   5.5381[  55], max:   9.3429[ 861]\n",
      "248:xent_pred[1000]: avg:   1.9163, min:   1.7475[ 953], max:   2.0958[ 439]\n",
      "248:xent_v0  [1000]: avg:   1.9120, min:   1.7396[ 953], max:   2.0890[ 439]\n",
      "===================\n",
      "beginning of epoch:  249\n",
      "available: 2.760 GB, used: 25.896 GB, free: 2.712 GB\n",
      "EPOCH: 249\n",
      "mean score: 0.00\n",
      "Speed: train: 1886.3, buffer_add: 1006.1, buffer_size: 100031\n",
      "Total Time: 2H 24M 32S, 8672s\n",
      "Total Sample: train: 16M, buffer: 8.786M\n",
      "[249] Time spent = 34.17 s\n",
      "249:grad_norm[1000]: avg:   2.9121, min:   1.7683[ 214], max:   4.6435[ 462]\n",
      "249:loss     [1000]: avg:   7.2259, min:   5.3833[  51], max:   9.4640[ 155]\n",
      "249:xent_pred[1000]: avg:   1.9138, min:   1.7637[  62], max:   2.0761[ 285]\n",
      "249:xent_v0  [1000]: avg:   1.9098, min:   1.7635[ 631], max:   2.0809[ 285]\n",
      "===================\n",
      "beginning of epoch:  250\n",
      "available: 2.750 GB, used: 25.906 GB, free: 2.728 GB\n",
      "EPOCH: 250\n",
      "mean score: 0.00\n",
      "Speed: train: 1890.9, buffer_add: 1008.6, buffer_size: 100019\n",
      "Total Time: 2H 25M 06S, 8706s\n",
      "Total Sample: train: 16.064M, buffer: 8.82M\n",
      "[250] Time spent = 34.23 s\n",
      "250:grad_norm[1000]: avg:   2.9465, min:   1.7157[ 335], max:   5.0711[ 619]\n",
      "250:loss     [1000]: avg:   7.1685, min:   5.2820[ 814], max:   9.3917[ 663]\n",
      "250:xent_pred[1000]: avg:   1.9154, min:   1.7559[ 456], max:   2.0580[  42]\n",
      "250:xent_v0  [1000]: avg:   1.9117, min:   1.7583[ 429], max:   2.0547[ 302]\n",
      "===================\n",
      "beginning of epoch:  251\n",
      "available: 2.751 GB, used: 25.908 GB, free: 2.674 GB\n",
      "EPOCH: 251\n",
      "mean score: 0.00\n",
      "Speed: train: 1887.5, buffer_add: 1017.3, buffer_size: 100023\n",
      "Total Time: 2H 25M 40S, 8740s\n",
      "Total Sample: train: 16.128M, buffer: 8.854M\n",
      "[251] Time spent = 34.36 s\n",
      "251:grad_norm[1000]: avg:   2.9604, min:   1.7407[  52], max:   6.6904[ 697]\n",
      "251:loss     [1000]: avg:   7.1896, min:   5.1814[  52], max:   9.7407[ 291]\n",
      "251:xent_pred[1000]: avg:   1.9147, min:   1.7756[ 405], max:   2.0720[ 227]\n",
      "251:xent_v0  [1000]: avg:   1.9108, min:   1.7648[ 405], max:   2.0649[ 227]\n",
      "===================\n",
      "beginning of epoch:  252\n",
      "available: 2.747 GB, used: 25.908 GB, free: 2.688 GB\n",
      "EPOCH: 252\n",
      "mean score: 0.00\n",
      "Speed: train: 1900.3, buffer_add: 1015.7, buffer_size: 100014\n",
      "Total Time: 2H 26M 14S, 8774s\n",
      "Total Sample: train: 16.192M, buffer: 8.889M\n",
      "[252] Time spent = 34.13 s\n",
      "252:grad_norm[1000]: avg:   2.9145, min:   1.6115[ 872], max:   4.9588[ 489]\n",
      "252:loss     [1000]: avg:   7.1944, min:   5.1110[ 488], max:   9.4848[ 618]\n",
      "252:xent_pred[1000]: avg:   1.9145, min:   1.7779[ 259], max:   2.0843[ 774]\n",
      "252:xent_v0  [1000]: avg:   1.9107, min:   1.7670[ 259], max:   2.0844[ 774]\n",
      "===================\n",
      "beginning of epoch:  253\n",
      "available: 2.747 GB, used: 25.909 GB, free: 2.705 GB\n",
      "EPOCH: 253\n",
      "mean score: 0.00\n",
      "Speed: train: 1812.0, buffer_add: 1015.5, buffer_size: 100095\n",
      "Total Time: 2H 26M 49S, 8809s\n",
      "Total Sample: train: 16.256M, buffer: 8.925M\n",
      "[253] Time spent = 35.80 s\n",
      "253:grad_norm[1000]: avg:   2.8626, min:   1.6511[ 460], max:   4.8368[ 281]\n",
      "253:loss     [1000]: avg:   7.1309, min:   5.1372[ 298], max:   9.4135[ 728]\n",
      "253:xent_pred[1000]: avg:   1.9197, min:   1.7662[ 369], max:   2.0634[ 318]\n",
      "253:xent_v0  [1000]: avg:   1.9154, min:   1.7591[ 369], max:   2.0653[ 359]\n",
      "===================\n",
      "beginning of epoch:  254\n",
      "available: 2.743 GB, used: 25.908 GB, free: 2.698 GB\n",
      "EPOCH: 254\n",
      "mean score: 0.00\n",
      "Speed: train: 1843.5, buffer_add: 1018.0, buffer_size: 100011\n",
      "Total Time: 2H 27M 24S, 8844s\n",
      "Total Sample: train: 16.32M, buffer: 8.96M\n",
      "[254] Time spent = 35.11 s\n",
      "254:grad_norm[1000]: avg:   2.9039, min:   1.7291[ 263], max:   4.4737[ 793]\n",
      "254:loss     [1000]: avg:   7.2126, min:   5.2487[ 930], max:  10.7651[ 492]\n",
      "254:xent_pred[1000]: avg:   1.9173, min:   1.7694[ 433], max:   2.0840[ 840]\n",
      "254:xent_v0  [1000]: avg:   1.9131, min:   1.7669[ 433], max:   2.0767[ 840]\n",
      "===================\n",
      "beginning of epoch:  255\n",
      "available: 2.733 GB, used: 25.924 GB, free: 2.677 GB\n",
      "EPOCH: 255\n",
      "mean score: 0.00\n",
      "Speed: train: 1849.0, buffer_add: 1013.4, buffer_size: 100043\n",
      "Total Time: 2H 27M 58S, 8878s\n",
      "Total Sample: train: 16.384M, buffer: 8.995M\n",
      "[255] Time spent = 34.99 s\n",
      "255:grad_norm[1000]: avg:   2.9335, min:   1.8319[ 457], max:   5.3858[ 738]\n",
      "255:loss     [1000]: avg:   7.2198, min:   5.4971[ 500], max:   9.6916[ 189]\n",
      "255:xent_pred[1000]: avg:   1.9203, min:   1.7623[ 817], max:   2.0656[ 638]\n",
      "255:xent_v0  [1000]: avg:   1.9165, min:   1.7543[ 817], max:   2.0637[ 638]\n",
      "===================\n",
      "beginning of epoch:  256\n",
      "available: 2.738 GB, used: 25.922 GB, free: 2.642 GB\n",
      "EPOCH: 256\n",
      "mean score: 0.00\n",
      "Speed: train: 1858.4, buffer_add: 1027.3, buffer_size: 100004\n",
      "Total Time: 2H 28M 33S, 8913s\n",
      "Total Sample: train: 16.448M, buffer: 9.03M\n",
      "[256] Time spent = 34.73 s\n",
      "256:grad_norm[1000]: avg:   2.9140, min:   1.7484[ 517], max:   5.0641[ 547]\n",
      "256:loss     [1000]: avg:   7.2097, min:   5.2153[ 953], max:   9.5190[ 980]\n",
      "256:xent_pred[1000]: avg:   1.9208, min:   1.7753[ 753], max:   2.0500[ 837]\n",
      "256:xent_v0  [1000]: avg:   1.9168, min:   1.7741[ 847], max:   2.0460[ 197]\n",
      "===================\n",
      "beginning of epoch:  257\n",
      "available: 2.745 GB, used: 25.911 GB, free: 2.648 GB\n",
      "EPOCH: 257\n",
      "mean score: 0.00\n",
      "Speed: train: 1861.0, buffer_add: 1010.8, buffer_size: 100020\n",
      "Total Time: 2H 29M 07S, 8947s\n",
      "Total Sample: train: 16.512M, buffer: 9.065M\n",
      "[257] Time spent = 34.74 s\n",
      "257:grad_norm[1000]: avg:   2.8960, min:   1.7815[ 111], max:   6.4536[ 654]\n",
      "257:loss     [1000]: avg:   7.1955, min:   5.1917[ 882], max:   9.5728[ 918]\n",
      "257:xent_pred[1000]: avg:   1.9177, min:   1.7584[ 974], max:   2.0768[ 126]\n",
      "257:xent_v0  [1000]: avg:   1.9138, min:   1.7561[ 905], max:   2.0717[ 126]\n",
      "===================\n",
      "beginning of epoch:  258\n",
      "available: 2.753 GB, used: 25.907 GB, free: 2.675 GB\n",
      "EPOCH: 258\n",
      "mean score: 0.00\n",
      "Speed: train: 1865.9, buffer_add: 1009.5, buffer_size: 100021\n",
      "Total Time: 2H 29M 41S, 8981s\n",
      "Total Sample: train: 16.576M, buffer: 9.1M\n",
      "[258] Time spent = 34.80 s\n",
      "258:grad_norm[1000]: avg:   2.9299, min:   1.7356[ 963], max:   6.0259[ 413]\n",
      "258:loss     [1000]: avg:   7.1965, min:   5.5766[ 118], max:   9.3264[ 751]\n",
      "258:xent_pred[1000]: avg:   1.9178, min:   1.7682[ 991], max:   2.0672[ 801]\n",
      "258:xent_v0  [1000]: avg:   1.9142, min:   1.7508[ 991], max:   2.0645[ 801]\n",
      "===================\n",
      "beginning of epoch:  259\n",
      "available: 2.750 GB, used: 25.914 GB, free: 2.673 GB\n",
      "EPOCH: 259\n",
      "mean score: 0.00\n",
      "Speed: train: 1835.9, buffer_add: 1017.4, buffer_size: 100028\n",
      "Total Time: 2H 30M 16S, 9016s\n",
      "Total Sample: train: 16.64M, buffer: 9.135M\n",
      "[259] Time spent = 35.27 s\n",
      "259:grad_norm[1000]: avg:   2.8799, min:   1.7246[ 606], max:   5.4616[ 572]\n",
      "259:loss     [1000]: avg:   7.1619, min:   5.3182[ 666], max:   9.6978[ 889]\n",
      "259:xent_pred[1000]: avg:   1.9162, min:   1.7548[  13], max:   2.0954[ 793]\n",
      "259:xent_v0  [1000]: avg:   1.9123, min:   1.7579[  13], max:   2.0929[ 793]\n",
      "===================\n",
      "beginning of epoch:  260\n",
      "available: 2.744 GB, used: 25.915 GB, free: 2.653 GB\n",
      "EPOCH: 260\n",
      "mean score: 0.00\n",
      "Speed: train: 1858.0, buffer_add: 1017.7, buffer_size: 100017\n",
      "Total Time: 2H 30M 51S, 9051s\n",
      "Total Sample: train: 16.704M, buffer: 9.17M\n",
      "[260] Time spent = 35.08 s\n",
      "260:grad_norm[1000]: avg:   2.8271, min:   1.6718[ 448], max:   4.4683[ 106]\n",
      "260:loss     [1000]: avg:   7.0936, min:   5.2498[ 517], max:   9.4203[ 927]\n",
      "260:xent_pred[1000]: avg:   1.9235, min:   1.7698[  24], max:   2.0664[ 297]\n",
      "260:xent_v0  [1000]: avg:   1.9199, min:   1.7786[  24], max:   2.0659[ 297]\n",
      "===================\n",
      "beginning of epoch:  261\n",
      "available: 2.751 GB, used: 25.914 GB, free: 2.633 GB\n",
      "EPOCH: 261\n",
      "mean score: 0.00\n",
      "Speed: train: 1873.1, buffer_add: 1012.5, buffer_size: 100014\n",
      "Total Time: 2H 31M 25S, 9085s\n",
      "Total Sample: train: 16.768M, buffer: 9.205M\n",
      "[261] Time spent = 34.56 s\n",
      "261:grad_norm[1000]: avg:   2.8703, min:   1.7514[ 368], max:   6.3057[ 925]\n",
      "261:loss     [1000]: avg:   7.1291, min:   5.2453[ 735], max:  10.2302[ 804]\n",
      "261:xent_pred[1000]: avg:   1.9217, min:   1.7811[ 370], max:   2.0707[ 993]\n",
      "261:xent_v0  [1000]: avg:   1.9182, min:   1.7672[ 370], max:   2.0565[ 513]\n",
      "===================\n",
      "beginning of epoch:  262\n",
      "available: 2.744 GB, used: 25.913 GB, free: 2.686 GB\n",
      "EPOCH: 262\n",
      "mean score: 0.00\n",
      "Speed: train: 1867.7, buffer_add: 1005.0, buffer_size: 100017\n",
      "Total Time: 2H 31M 59S, 9119s\n",
      "Total Sample: train: 16.832M, buffer: 9.239M\n",
      "[262] Time spent = 34.66 s\n",
      "262:grad_norm[1000]: avg:   2.8838, min:   1.7371[ 805], max:   4.5333[ 804]\n",
      "262:loss     [1000]: avg:   7.1645, min:   5.2440[ 843], max:   9.9081[ 505]\n",
      "262:xent_pred[1000]: avg:   1.9226, min:   1.7668[ 727], max:   2.0912[ 756]\n",
      "262:xent_v0  [1000]: avg:   1.9187, min:   1.7533[ 589], max:   2.0787[ 756]\n",
      "===================\n",
      "beginning of epoch:  263\n",
      "available: 2.743 GB, used: 25.917 GB, free: 2.668 GB\n",
      "EPOCH: 263\n",
      "mean score: 0.00\n",
      "Speed: train: 1868.0, buffer_add: 1014.8, buffer_size: 100011\n",
      "Total Time: 2H 32M 33S, 9153s\n",
      "Total Sample: train: 16.896M, buffer: 9.274M\n",
      "[263] Time spent = 34.64 s\n",
      "263:grad_norm[1000]: avg:   2.9166, min:   1.7053[ 284], max:   5.6840[ 443]\n",
      "263:loss     [1000]: avg:   7.2136, min:   5.2441[ 108], max:   9.4220[ 834]\n",
      "263:xent_pred[1000]: avg:   1.9146, min:   1.7643[ 188], max:   2.0946[ 850]\n",
      "263:xent_v0  [1000]: avg:   1.9105, min:   1.7660[ 188], max:   2.0706[ 850]\n",
      "===================\n",
      "beginning of epoch:  264\n",
      "available: 2.748 GB, used: 25.913 GB, free: 2.703 GB\n",
      "EPOCH: 264\n",
      "mean score: 0.00\n",
      "Speed: train: 1870.1, buffer_add: 1005.7, buffer_size: 100071\n",
      "Total Time: 2H 33M 08S, 9188s\n",
      "Total Sample: train: 16.96M, buffer: 9.308M\n",
      "[264] Time spent = 34.69 s\n",
      "264:grad_norm[1000]: avg:   2.8969, min:   1.4836[ 965], max:   5.2531[ 730]\n",
      "264:loss     [1000]: avg:   7.1805, min:   5.4067[  40], max:   9.4165[ 177]\n",
      "264:xent_pred[1000]: avg:   1.9186, min:   1.7525[ 831], max:   2.0791[ 419]\n",
      "264:xent_v0  [1000]: avg:   1.9151, min:   1.7586[ 831], max:   2.0719[ 419]\n",
      "===================\n",
      "beginning of epoch:  265\n",
      "available: 2.743 GB, used: 25.910 GB, free: 2.716 GB\n",
      "EPOCH: 265\n",
      "mean score: 0.00\n",
      "Speed: train: 1867.2, buffer_add: 1005.6, buffer_size: 100058\n",
      "Total Time: 2H 33M 42S, 9222s\n",
      "Total Sample: train: 17.024M, buffer: 9.343M\n",
      "[265] Time spent = 34.48 s\n",
      "265:grad_norm[1000]: avg:   2.9312, min:   1.7908[ 955], max:   7.3628[ 417]\n",
      "265:loss     [1000]: avg:   7.2350, min:   5.0305[  73], max:   9.4650[ 636]\n",
      "265:xent_pred[1000]: avg:   1.9144, min:   1.7751[ 290], max:   2.0980[ 962]\n",
      "265:xent_v0  [1000]: avg:   1.9100, min:   1.7706[ 290], max:   2.0973[ 139]\n",
      "===================\n",
      "beginning of epoch:  266\n",
      "available: 2.749 GB, used: 25.908 GB, free: 2.677 GB\n",
      "EPOCH: 266\n",
      "mean score: 0.00\n",
      "Speed: train: 1882.9, buffer_add: 1014.9, buffer_size: 100028\n",
      "Total Time: 2H 34M 16S, 9256s\n",
      "Total Sample: train: 17.088M, buffer: 9.377M\n",
      "[266] Time spent = 34.45 s\n",
      "266:grad_norm[1000]: avg:   2.8932, min:   1.7746[  87], max:   5.8500[ 438]\n",
      "266:loss     [1000]: avg:   7.1879, min:   5.2104[ 270], max:   9.9521[ 388]\n",
      "266:xent_pred[1000]: avg:   1.9176, min:   1.7526[ 642], max:   2.0705[  83]\n",
      "266:xent_v0  [1000]: avg:   1.9135, min:   1.7443[ 642], max:   2.0624[  83]\n",
      "===================\n",
      "beginning of epoch:  267\n",
      "available: 2.748 GB, used: 25.909 GB, free: 2.674 GB\n",
      "EPOCH: 267\n",
      "mean score: 0.00\n",
      "Speed: train: 1884.6, buffer_add: 1012.1, buffer_size: 100026\n",
      "Total Time: 2H 34M 50S, 9290s\n",
      "Total Sample: train: 17.152M, buffer: 9.412M\n",
      "[267] Time spent = 34.47 s\n",
      "267:grad_norm[1000]: avg:   2.8647, min:   1.6314[ 926], max:   5.4428[ 429]\n",
      "267:loss     [1000]: avg:   7.1607, min:   4.9934[ 327], max:   9.6152[ 447]\n",
      "267:xent_pred[1000]: avg:   1.9198, min:   1.7529[ 874], max:   2.0956[ 470]\n",
      "267:xent_v0  [1000]: avg:   1.9158, min:   1.7636[ 797], max:   2.0896[ 470]\n",
      "===================\n",
      "beginning of epoch:  268\n",
      "available: 2.746 GB, used: 25.914 GB, free: 2.663 GB\n",
      "EPOCH: 268\n",
      "mean score: 0.00\n",
      "Speed: train: 1865.7, buffer_add: 1014.7, buffer_size: 100012\n",
      "Total Time: 2H 35M 24S, 9324s\n",
      "Total Sample: train: 17.216M, buffer: 9.447M\n",
      "[268] Time spent = 34.72 s\n",
      "268:grad_norm[1000]: avg:   2.8521, min:   1.5408[  92], max:   4.9927[ 166]\n",
      "268:loss     [1000]: avg:   7.1530, min:   5.1596[  92], max:   9.9368[   8]\n",
      "268:xent_pred[1000]: avg:   1.9195, min:   1.7813[ 820], max:   2.0694[ 675]\n",
      "268:xent_v0  [1000]: avg:   1.9156, min:   1.7833[ 820], max:   2.0627[ 675]\n",
      "===================\n",
      "beginning of epoch:  269\n",
      "available: 2.742 GB, used: 25.913 GB, free: 2.691 GB\n",
      "EPOCH: 269\n",
      "mean score: 0.00\n",
      "Speed: train: 1860.9, buffer_add: 1005.4, buffer_size: 100011\n",
      "Total Time: 2H 35M 59S, 9359s\n",
      "Total Sample: train: 17.28M, buffer: 9.481M\n",
      "[269] Time spent = 34.82 s\n",
      "269:grad_norm[1000]: avg:   2.8582, min:   1.6601[   3], max:   4.5188[   4]\n",
      "269:loss     [1000]: avg:   7.1964, min:   5.2222[ 834], max:   9.5528[ 861]\n",
      "269:xent_pred[1000]: avg:   1.9184, min:   1.7762[ 359], max:   2.0732[ 843]\n",
      "269:xent_v0  [1000]: avg:   1.9146, min:   1.7744[ 809], max:   2.0665[ 392]\n",
      "===================\n",
      "beginning of epoch:  270\n",
      "available: 2.749 GB, used: 25.906 GB, free: 2.686 GB\n",
      "EPOCH: 270\n",
      "mean score: 0.00\n",
      "Speed: train: 1869.4, buffer_add: 1013.7, buffer_size: 100025\n",
      "Total Time: 2H 36M 33S, 9393s\n",
      "Total Sample: train: 17.344M, buffer: 9.516M\n",
      "[270] Time spent = 34.71 s\n",
      "270:grad_norm[1000]: avg:   2.8535, min:   1.5508[ 955], max:   4.8973[ 759]\n",
      "270:loss     [1000]: avg:   7.1852, min:   5.3046[ 997], max:   9.7618[ 650]\n",
      "270:xent_pred[1000]: avg:   1.9193, min:   1.7787[ 152], max:   2.0758[ 627]\n",
      "270:xent_v0  [1000]: avg:   1.9161, min:   1.7782[ 152], max:   2.0761[ 627]\n",
      "===================\n",
      "beginning of epoch:  271\n",
      "available: 2.739 GB, used: 25.917 GB, free: 2.678 GB\n",
      "EPOCH: 271\n",
      "mean score: 0.00\n",
      "Speed: train: 1829.0, buffer_add: 1018.9, buffer_size: 100024\n",
      "Total Time: 2H 37M 08S, 9428s\n",
      "Total Sample: train: 17.408M, buffer: 9.552M\n",
      "[271] Time spent = 35.41 s\n",
      "271:grad_norm[1000]: avg:   2.8506, min:   1.7360[ 936], max:   6.5242[ 757]\n",
      "271:loss     [1000]: avg:   7.1874, min:   5.4506[ 214], max:  10.1117[ 444]\n",
      "271:xent_pred[1000]: avg:   1.9186, min:   1.7712[ 579], max:   2.0855[ 159]\n",
      "271:xent_v0  [1000]: avg:   1.9151, min:   1.7691[ 579], max:   2.0665[ 159]\n",
      "===================\n",
      "beginning of epoch:  272\n",
      "available: 2.749 GB, used: 25.911 GB, free: 2.656 GB\n",
      "EPOCH: 272\n",
      "mean score: 0.00\n",
      "Speed: train: 1848.3, buffer_add: 1007.0, buffer_size: 100004\n",
      "Total Time: 2H 37M 42S, 9462s\n",
      "Total Sample: train: 17.472M, buffer: 9.586M\n",
      "[272] Time spent = 35.09 s\n",
      "272:grad_norm[1000]: avg:   2.8440, min:   1.6667[ 716], max:   5.6567[ 331]\n",
      "272:loss     [1000]: avg:   7.1619, min:   4.8720[  13], max:   9.5308[ 210]\n",
      "272:xent_pred[1000]: avg:   1.9186, min:   1.7777[ 439], max:   2.0741[  31]\n",
      "272:xent_v0  [1000]: avg:   1.9156, min:   1.7678[ 439], max:   2.0694[  31]\n",
      "===================\n",
      "beginning of epoch:  273\n",
      "available: 2.746 GB, used: 25.909 GB, free: 2.699 GB\n",
      "EPOCH: 273\n",
      "mean score: 0.00\n",
      "Speed: train: 1869.8, buffer_add: 1019.3, buffer_size: 100014\n",
      "Total Time: 2H 38M 17S, 9497s\n",
      "Total Sample: train: 17.536M, buffer: 9.621M\n",
      "[273] Time spent = 34.74 s\n",
      "273:grad_norm[1000]: avg:   2.8396, min:   1.5674[ 602], max:   8.8159[ 749]\n",
      "273:loss     [1000]: avg:   7.1336, min:   5.3236[ 139], max:   9.8226[ 719]\n",
      "273:xent_pred[1000]: avg:   1.9205, min:   1.7913[ 842], max:   2.0695[ 827]\n",
      "273:xent_v0  [1000]: avg:   1.9176, min:   1.7851[ 665], max:   2.0632[ 827]\n",
      "===================\n",
      "beginning of epoch:  274\n",
      "available: 2.742 GB, used: 25.916 GB, free: 2.666 GB\n",
      "EPOCH: 274\n",
      "mean score: 0.00\n",
      "Speed: train: 1889.3, buffer_add: 1022.9, buffer_size: 100017\n",
      "Total Time: 2H 38M 51S, 9531s\n",
      "Total Sample: train: 17.6M, buffer: 9.656M\n",
      "[274] Time spent = 34.26 s\n",
      "274:grad_norm[1000]: avg:   2.8711, min:   1.6584[ 590], max:   4.7634[ 732]\n",
      "274:loss     [1000]: avg:   7.1880, min:   5.1248[ 692], max:   9.7314[ 296]\n",
      "274:xent_pred[1000]: avg:   1.9184, min:   1.7887[ 296], max:   2.0502[ 369]\n",
      "274:xent_v0  [1000]: avg:   1.9153, min:   1.7789[ 296], max:   2.0551[ 521]\n",
      "===================\n",
      "beginning of epoch:  275\n",
      "available: 2.749 GB, used: 25.906 GB, free: 2.704 GB\n",
      "EPOCH: 275\n",
      "mean score: 0.00\n",
      "Speed: train: 1857.3, buffer_add: 1020.7, buffer_size: 100039\n",
      "Total Time: 2H 39M 25S, 9565s\n",
      "Total Sample: train: 17.664M, buffer: 9.691M\n",
      "[275] Time spent = 34.83 s\n",
      "275:grad_norm[1000]: avg:   2.8505, min:   1.6047[ 217], max:   4.7849[ 108]\n",
      "275:loss     [1000]: avg:   7.2143, min:   5.2470[ 766], max:  10.1506[ 486]\n",
      "275:xent_pred[1000]: avg:   1.9195, min:   1.7345[  46], max:   2.1035[  14]\n",
      "275:xent_v0  [1000]: avg:   1.9158, min:   1.7314[  46], max:   2.0831[ 509]\n",
      "===================\n",
      "beginning of epoch:  276\n",
      "available: 2.728 GB, used: 25.926 GB, free: 2.703 GB\n",
      "EPOCH: 276\n",
      "mean score: 0.00\n",
      "Speed: train: 1846.6, buffer_add: 1013.0, buffer_size: 100035\n",
      "Total Time: 2H 40M 00S, 9600s\n",
      "Total Sample: train: 17.728M, buffer: 9.726M\n",
      "[276] Time spent = 35.06 s\n",
      "276:grad_norm[1000]: avg:   2.8411, min:   1.7549[ 289], max:   4.3672[ 671]\n",
      "276:loss     [1000]: avg:   7.2256, min:   4.9905[ 504], max:   9.4260[ 602]\n",
      "276:xent_pred[1000]: avg:   1.9163, min:   1.7669[ 631], max:   2.0546[ 369]\n",
      "276:xent_v0  [1000]: avg:   1.9129, min:   1.7649[ 631], max:   2.0442[ 809]\n",
      "===================\n",
      "beginning of epoch:  277\n",
      "available: 2.747 GB, used: 25.913 GB, free: 2.636 GB\n",
      "EPOCH: 277\n",
      "mean score: 0.00\n",
      "Speed: train: 1840.8, buffer_add: 1020.4, buffer_size: 100041\n",
      "Total Time: 2H 40M 34S, 9634s\n",
      "Total Sample: train: 17.792M, buffer: 9.762M\n",
      "[277] Time spent = 35.20 s\n",
      "277:grad_norm[1000]: avg:   2.8210, min:   1.6216[ 948], max:   5.0433[ 531]\n",
      "277:loss     [1000]: avg:   7.1652, min:   5.2224[ 807], max:  10.0865[ 989]\n",
      "277:xent_pred[1000]: avg:   1.9158, min:   1.7652[ 626], max:   2.0736[ 275]\n",
      "277:xent_v0  [1000]: avg:   1.9123, min:   1.7579[ 626], max:   2.0564[ 660]\n",
      "===================\n",
      "beginning of epoch:  278\n",
      "available: 2.747 GB, used: 25.918 GB, free: 2.642 GB\n",
      "EPOCH: 278\n",
      "mean score: 0.00\n",
      "Speed: train: 1877.0, buffer_add: 1017.6, buffer_size: 100006\n",
      "Total Time: 2H 41M 09S, 9669s\n",
      "Total Sample: train: 17.856M, buffer: 9.796M\n",
      "[278] Time spent = 34.37 s\n",
      "278:grad_norm[1000]: avg:   2.8012, min:   1.4561[ 451], max:   4.5532[ 406]\n",
      "278:loss     [1000]: avg:   7.1534, min:   5.0195[ 442], max:   9.2465[ 968]\n",
      "278:xent_pred[1000]: avg:   1.9190, min:   1.7602[ 674], max:   2.0796[ 624]\n",
      "278:xent_v0  [1000]: avg:   1.9156, min:   1.7558[ 674], max:   2.0598[ 624]\n",
      "===================\n",
      "beginning of epoch:  279\n",
      "available: 2.746 GB, used: 25.908 GB, free: 2.725 GB\n",
      "EPOCH: 279\n",
      "mean score: 0.00\n",
      "Speed: train: 1895.5, buffer_add: 1011.8, buffer_size: 100025\n",
      "Total Time: 2H 41M 42S, 9702s\n",
      "Total Sample: train: 17.92M, buffer: 9.831M\n",
      "[279] Time spent = 34.15 s\n",
      "279:grad_norm[1000]: avg:   2.8125, min:   1.6361[ 827], max:   6.9964[ 796]\n",
      "279:loss     [1000]: avg:   7.1437, min:   5.3398[ 646], max:   9.5404[ 589]\n",
      "279:xent_pred[1000]: avg:   1.9168, min:   1.7391[ 591], max:   2.0989[ 973]\n",
      "279:xent_v0  [1000]: avg:   1.9137, min:   1.7291[ 591], max:   2.0893[ 973]\n",
      "===================\n",
      "beginning of epoch:  280\n",
      "available: 2.743 GB, used: 25.908 GB, free: 2.684 GB\n",
      "EPOCH: 280\n",
      "mean score: 0.00\n",
      "Speed: train: 1885.6, buffer_add: 1005.4, buffer_size: 100045\n",
      "Total Time: 2H 42M 16S, 9736s\n",
      "Total Sample: train: 17.984M, buffer: 9.865M\n",
      "[280] Time spent = 34.34 s\n",
      "280:grad_norm[1000]: avg:   2.8293, min:   1.7413[ 601], max:   6.6779[ 981]\n",
      "280:loss     [1000]: avg:   7.1744, min:   5.4156[ 175], max:   9.6122[ 752]\n",
      "280:xent_pred[1000]: avg:   1.9169, min:   1.7452[ 643], max:   2.0500[ 141]\n",
      "280:xent_v0  [1000]: avg:   1.9134, min:   1.7502[ 643], max:   2.0547[ 141]\n",
      "===================\n",
      "beginning of epoch:  281\n",
      "available: 2.746 GB, used: 25.906 GB, free: 2.704 GB\n",
      "EPOCH: 281\n",
      "mean score: 0.00\n",
      "Speed: train: 1885.5, buffer_add: 1006.6, buffer_size: 100009\n",
      "Total Time: 2H 42M 50S, 9770s\n",
      "Total Sample: train: 18.048M, buffer: 9.899M\n",
      "[281] Time spent = 34.31 s\n",
      "281:grad_norm[1000]: avg:   2.8001, min:   1.6692[ 695], max:   4.7184[ 876]\n",
      "281:loss     [1000]: avg:   7.1752, min:   5.2509[ 534], max:   9.7250[ 172]\n",
      "281:xent_pred[1000]: avg:   1.9149, min:   1.7579[ 547], max:   2.0853[ 780]\n",
      "281:xent_v0  [1000]: avg:   1.9107, min:   1.7453[ 547], max:   2.0770[ 780]\n",
      "===================\n",
      "beginning of epoch:  282\n",
      "available: 2.742 GB, used: 25.912 GB, free: 2.690 GB\n",
      "EPOCH: 282\n",
      "mean score: 0.00\n",
      "Speed: train: 1862.5, buffer_add: 1006.6, buffer_size: 100022\n",
      "Total Time: 2H 43M 25S, 9805s\n",
      "Total Sample: train: 18.112M, buffer: 9.933M\n",
      "[282] Time spent = 34.99 s\n",
      "282:grad_norm[1000]: avg:   2.8000, min:   1.6876[ 144], max:   5.3536[ 736]\n",
      "282:loss     [1000]: avg:   7.1418, min:   4.8965[ 178], max:   9.6197[ 122]\n",
      "282:xent_pred[1000]: avg:   1.9188, min:   1.7844[  13], max:   2.0626[ 682]\n",
      "282:xent_v0  [1000]: avg:   1.9151, min:   1.7830[  13], max:   2.0625[ 128]\n",
      "===================\n",
      "beginning of epoch:  283\n",
      "available: 2.750 GB, used: 25.908 GB, free: 2.693 GB\n",
      "EPOCH: 283\n",
      "mean score: 0.00\n",
      "Speed: train: 1874.7, buffer_add: 1020.8, buffer_size: 100045\n",
      "Total Time: 2H 43M 59S, 9839s\n",
      "Total Sample: train: 18.176M, buffer: 9.968M\n",
      "[283] Time spent = 34.49 s\n",
      "283:grad_norm[1000]: avg:   2.8000, min:   1.7445[ 523], max:   4.8823[  87]\n",
      "283:loss     [1000]: avg:   7.1639, min:   5.1857[ 682], max:   9.3396[ 920]\n",
      "283:xent_pred[1000]: avg:   1.9185, min:   1.7456[ 732], max:   2.0676[ 990]\n",
      "283:xent_v0  [1000]: avg:   1.9154, min:   1.7527[ 732], max:   2.0711[ 990]\n",
      "===================\n",
      "beginning of epoch:  284\n",
      "available: 2.747 GB, used: 25.912 GB, free: 2.666 GB\n",
      "EPOCH: 284\n",
      "mean score: 0.00\n",
      "Speed: train: 1872.7, buffer_add: 1014.0, buffer_size: 100043\n",
      "Total Time: 2H 44M 33S, 9873s\n",
      "Total Sample: train: 18.24M, buffer: 10.003M\n",
      "[284] Time spent = 34.46 s\n",
      "284:grad_norm[1000]: avg:   2.7731, min:   1.7695[ 202], max:   4.9320[ 365]\n",
      "284:loss     [1000]: avg:   7.1560, min:   5.1449[  61], max:   9.5989[  14]\n",
      "284:xent_pred[1000]: avg:   1.9195, min:   1.7555[ 654], max:   2.0520[ 658]\n",
      "284:xent_v0  [1000]: avg:   1.9163, min:   1.7617[ 654], max:   2.0507[ 149]\n",
      "===================\n",
      "beginning of epoch:  285\n",
      "available: 2.746 GB, used: 25.915 GB, free: 2.676 GB\n",
      "EPOCH: 285\n",
      "mean score: 0.00\n",
      "Speed: train: 1852.2, buffer_add: 1018.9, buffer_size: 100010\n",
      "Total Time: 2H 45M 07S, 9907s\n",
      "Total Sample: train: 18.304M, buffer: 10.038M\n",
      "[285] Time spent = 34.96 s\n",
      "285:grad_norm[1000]: avg:   2.7831, min:   1.4717[ 171], max:   4.8203[  56]\n",
      "285:loss     [1000]: avg:   7.1556, min:   5.1632[ 260], max:  10.4220[ 537]\n",
      "285:xent_pred[1000]: avg:   1.9183, min:   1.7417[  24], max:   2.0675[   7]\n",
      "285:xent_v0  [1000]: avg:   1.9151, min:   1.7461[  24], max:   2.0730[   7]\n",
      "===================\n",
      "beginning of epoch:  286\n",
      "available: 2.749 GB, used: 25.910 GB, free: 2.679 GB\n",
      "EPOCH: 286\n",
      "mean score: 0.00\n",
      "Speed: train: 1861.7, buffer_add: 1014.2, buffer_size: 100023\n",
      "Total Time: 2H 45M 42S, 9942s\n",
      "Total Sample: train: 18.368M, buffer: 10.073M\n",
      "[286] Time spent = 34.85 s\n",
      "286:grad_norm[1000]: avg:   2.7896, min:   1.7306[ 513], max:   8.0175[ 517]\n",
      "286:loss     [1000]: avg:   7.1648, min:   5.3081[ 200], max:   9.4556[   9]\n",
      "286:xent_pred[1000]: avg:   1.9196, min:   1.7255[ 743], max:   2.0606[ 294]\n",
      "286:xent_v0  [1000]: avg:   1.9162, min:   1.7255[ 743], max:   2.0555[ 815]\n",
      "===================\n",
      "beginning of epoch:  287\n",
      "available: 2.741 GB, used: 25.921 GB, free: 2.677 GB\n",
      "EPOCH: 287\n",
      "mean score: 0.00\n",
      "Speed: train: 1841.8, buffer_add: 1024.9, buffer_size: 100032\n",
      "Total Time: 2H 46M 17S, 9977s\n",
      "Total Sample: train: 18.432M, buffer: 10.109M\n",
      "[287] Time spent = 35.18 s\n",
      "287:grad_norm[1000]: avg:   2.7790, min:   1.6249[ 434], max:   5.1302[  13]\n",
      "287:loss     [1000]: avg:   7.1314, min:   5.1808[ 999], max:   9.1942[ 838]\n",
      "287:xent_pred[1000]: avg:   1.9169, min:   1.7656[ 825], max:   2.0767[ 335]\n",
      "287:xent_v0  [1000]: avg:   1.9132, min:   1.7649[ 825], max:   2.0775[ 335]\n",
      "===================\n",
      "beginning of epoch:  288\n",
      "available: 2.739 GB, used: 25.917 GB, free: 2.714 GB\n",
      "EPOCH: 288\n",
      "mean score: 0.00\n",
      "Speed: train: 1847.2, buffer_add: 1021.3, buffer_size: 100024\n",
      "Total Time: 2H 46M 51S, 10011s\n",
      "Total Sample: train: 18.496M, buffer: 10.144M\n",
      "[288] Time spent = 35.07 s\n",
      "288:grad_norm[1000]: avg:   2.7557, min:   1.5160[ 948], max:   5.2237[ 475]\n",
      "288:loss     [1000]: avg:   7.1459, min:   5.2713[ 948], max:   9.8498[ 678]\n",
      "288:xent_pred[1000]: avg:   1.9194, min:   1.7758[ 240], max:   2.0727[ 839]\n",
      "288:xent_v0  [1000]: avg:   1.9157, min:   1.7791[ 379], max:   2.0697[ 242]\n",
      "===================\n",
      "beginning of epoch:  289\n",
      "available: 2.750 GB, used: 25.911 GB, free: 2.692 GB\n",
      "EPOCH: 289\n",
      "mean score: 0.00\n",
      "Speed: train: 1860.8, buffer_add: 1013.3, buffer_size: 100023\n",
      "Total Time: 2H 47M 26S, 10046s\n",
      "Total Sample: train: 18.56M, buffer: 10.179M\n",
      "[289] Time spent = 34.70 s\n",
      "289:grad_norm[1000]: avg:   2.7587, min:   1.6592[ 556], max:   7.8953[ 345]\n",
      "289:loss     [1000]: avg:   7.1421, min:   5.2014[ 865], max:   9.6033[  69]\n",
      "289:xent_pred[1000]: avg:   1.9209, min:   1.7679[  47], max:   2.0744[ 389]\n",
      "289:xent_v0  [1000]: avg:   1.9174, min:   1.7612[  47], max:   2.0615[ 389]\n",
      "===================\n",
      "beginning of epoch:  290\n",
      "available: 2.751 GB, used: 25.906 GB, free: 2.699 GB\n",
      "EPOCH: 290\n",
      "mean score: 0.00\n",
      "Speed: train: 1883.7, buffer_add: 1003.0, buffer_size: 100039\n",
      "Total Time: 2H 48M 00S, 10080s\n",
      "Total Sample: train: 18.624M, buffer: 10.213M\n",
      "[290] Time spent = 34.27 s\n",
      "290:grad_norm[1000]: avg:   2.7742, min:   1.6544[ 874], max:   6.0524[ 395]\n",
      "290:loss     [1000]: avg:   7.1639, min:   4.7772[ 874], max:   9.4671[ 403]\n",
      "290:xent_pred[1000]: avg:   1.9174, min:   1.7699[ 820], max:   2.0705[ 126]\n",
      "290:xent_v0  [1000]: avg:   1.9140, min:   1.7698[ 820], max:   2.0677[ 874]\n",
      "===================\n",
      "beginning of epoch:  291\n",
      "available: 2.752 GB, used: 25.904 GB, free: 2.685 GB\n",
      "EPOCH: 291\n",
      "mean score: 0.00\n",
      "Speed: train: 1879.1, buffer_add: 1014.6, buffer_size: 100041\n",
      "Total Time: 2H 48M 34S, 10114s\n",
      "Total Sample: train: 18.688M, buffer: 10.247M\n",
      "[291] Time spent = 34.56 s\n",
      "291:grad_norm[1000]: avg:   2.7945, min:   1.5967[  80], max:   5.1232[ 794]\n",
      "291:loss     [1000]: avg:   7.2018, min:   5.4849[  80], max:   9.4294[ 398]\n",
      "291:xent_pred[1000]: avg:   1.9174, min:   1.7484[ 905], max:   2.0558[ 562]\n",
      "291:xent_v0  [1000]: avg:   1.9135, min:   1.7504[ 905], max:   2.0510[ 562]\n",
      "===================\n",
      "beginning of epoch:  292\n",
      "available: 2.737 GB, used: 25.929 GB, free: 2.640 GB\n",
      "EPOCH: 292\n",
      "mean score: 0.00\n",
      "Speed: train: 1921.4, buffer_add: 1013.0, buffer_size: 100023\n",
      "Total Time: 2H 49M 07S, 10147s\n",
      "Total Sample: train: 18.752M, buffer: 10.281M\n",
      "[292] Time spent = 33.67 s\n",
      "292:grad_norm[1000]: avg:   2.7569, min:   1.5570[ 458], max:   4.7746[ 271]\n",
      "292:loss     [1000]: avg:   7.1664, min:   5.2325[ 854], max:   9.4269[ 987]\n",
      "292:xent_pred[1000]: avg:   1.9173, min:   1.7519[ 250], max:   2.1295[ 762]\n",
      "292:xent_v0  [1000]: avg:   1.9139, min:   1.7408[ 250], max:   2.1305[ 762]\n",
      "===================\n",
      "beginning of epoch:  293\n",
      "available: 2.748 GB, used: 25.915 GB, free: 2.661 GB\n",
      "EPOCH: 293\n",
      "mean score: 0.00\n",
      "Speed: train: 1895.8, buffer_add: 1008.5, buffer_size: 100112\n",
      "Total Time: 2H 49M 41S, 10181s\n",
      "Total Sample: train: 18.816M, buffer: 10.315M\n",
      "[293] Time spent = 34.15 s\n",
      "293:grad_norm[1000]: avg:   2.7672, min:   1.6696[ 324], max:   4.8805[ 745]\n",
      "293:loss     [1000]: avg:   7.1389, min:   5.2245[  32], max:   9.1658[ 206]\n",
      "293:xent_pred[1000]: avg:   1.9162, min:   1.7700[ 228], max:   2.0952[ 272]\n",
      "293:xent_v0  [1000]: avg:   1.9128, min:   1.7760[ 228], max:   2.0961[ 272]\n",
      "===================\n",
      "beginning of epoch:  294\n",
      "available: 2.751 GB, used: 25.907 GB, free: 2.695 GB\n",
      "EPOCH: 294\n",
      "mean score: 0.00\n",
      "Speed: train: 1865.7, buffer_add: 1001.3, buffer_size: 100015\n",
      "Total Time: 2H 50M 15S, 10215s\n",
      "Total Sample: train: 18.88M, buffer: 10.35M\n",
      "[294] Time spent = 34.83 s\n",
      "294:grad_norm[1000]: avg:   2.7686, min:   1.4629[ 802], max:   4.6141[ 517]\n",
      "294:loss     [1000]: avg:   7.1676, min:   5.2883[ 356], max:   9.4216[ 482]\n",
      "294:xent_pred[1000]: avg:   1.9159, min:   1.7439[ 947], max:   2.1032[ 356]\n",
      "294:xent_v0  [1000]: avg:   1.9126, min:   1.7408[ 947], max:   2.0837[ 356]\n",
      "===================\n",
      "beginning of epoch:  295\n",
      "available: 2.749 GB, used: 25.909 GB, free: 2.680 GB\n",
      "EPOCH: 295\n",
      "mean score: 0.00\n",
      "Speed: train: 1878.0, buffer_add: 1010.2, buffer_size: 100051\n",
      "Total Time: 2H 50M 49S, 10249s\n",
      "Total Sample: train: 18.944M, buffer: 10.384M\n",
      "[295] Time spent = 34.61 s\n",
      "295:grad_norm[1000]: avg:   2.7691, min:   1.5918[  75], max:   4.6737[  93]\n",
      "295:loss     [1000]: avg:   7.1831, min:   5.3379[ 726], max:   9.7157[ 179]\n",
      "295:xent_pred[1000]: avg:   1.9162, min:   1.7493[ 179], max:   2.0803[ 982]\n",
      "295:xent_v0  [1000]: avg:   1.9129, min:   1.7547[ 599], max:   2.0684[ 982]\n",
      "===================\n",
      "beginning of epoch:  296\n",
      "available: 2.746 GB, used: 25.913 GB, free: 2.648 GB\n",
      "EPOCH: 296\n",
      "mean score: 0.00\n",
      "Speed: train: 1857.0, buffer_add: 1012.8, buffer_size: 100058\n",
      "Total Time: 2H 51M 24S, 10284s\n",
      "Total Sample: train: 19.008M, buffer: 10.419M\n",
      "[296] Time spent = 34.78 s\n",
      "296:grad_norm[1000]: avg:   2.7999, min:   1.6914[ 348], max:   5.0884[ 935]\n",
      "296:loss     [1000]: avg:   7.2084, min:   5.2202[  30], max:   9.7090[ 336]\n",
      "296:xent_pred[1000]: avg:   1.9141, min:   1.7586[ 511], max:   2.0840[ 913]\n",
      "296:xent_v0  [1000]: avg:   1.9106, min:   1.7526[ 935], max:   2.0782[ 913]\n",
      "===================\n",
      "beginning of epoch:  297\n",
      "available: 2.749 GB, used: 25.914 GB, free: 2.668 GB\n",
      "EPOCH: 297\n",
      "mean score: 0.00\n",
      "Speed: train: 1830.8, buffer_add: 990.0, buffer_size: 100036\n",
      "Total Time: 2H 51M 59S, 10319s\n",
      "Total Sample: train: 19.072M, buffer: 10.454M\n",
      "[297] Time spent = 35.30 s\n",
      "297:grad_norm[1000]: avg:   2.8032, min:   1.6002[ 162], max:   5.9515[ 554]\n",
      "297:loss     [1000]: avg:   7.1687, min:   5.4603[ 614], max:   9.2318[ 385]\n",
      "297:xent_pred[1000]: avg:   1.9175, min:   1.7616[ 979], max:   2.1031[ 848]\n",
      "297:xent_v0  [1000]: avg:   1.9136, min:   1.7592[ 979], max:   2.0872[ 848]\n",
      "===================\n",
      "beginning of epoch:  298\n",
      "available: 2.742 GB, used: 25.914 GB, free: 2.699 GB\n",
      "EPOCH: 298\n",
      "mean score: 0.00\n",
      "Speed: train: 1850.7, buffer_add: 1016.2, buffer_size: 100017\n",
      "Total Time: 2H 52M 33S, 10353s\n",
      "Total Sample: train: 19.136M, buffer: 10.489M\n",
      "[298] Time spent = 34.98 s\n",
      "298:grad_norm[1000]: avg:   2.7936, min:   1.7598[ 172], max:   7.2018[ 659]\n",
      "298:loss     [1000]: avg:   7.1875, min:   5.4717[ 271], max:   9.6058[ 515]\n",
      "298:xent_pred[1000]: avg:   1.9169, min:   1.7739[ 815], max:   2.0644[ 263]\n",
      "298:xent_v0  [1000]: avg:   1.9133, min:   1.7711[ 815], max:   2.0590[ 263]\n",
      "===================\n",
      "beginning of epoch:  299\n",
      "available: 2.743 GB, used: 25.916 GB, free: 2.668 GB\n",
      "EPOCH: 299\n",
      "mean score: 0.00\n",
      "Speed: train: 1852.5, buffer_add: 1008.8, buffer_size: 100022\n",
      "Total Time: 2H 53M 08S, 10388s\n",
      "Total Sample: train: 19.2M, buffer: 10.524M\n",
      "[299] Time spent = 35.03 s\n",
      "299:grad_norm[1000]: avg:   2.7974, min:   1.5566[ 519], max:   6.3982[ 715]\n",
      "299:loss     [1000]: avg:   7.1773, min:   5.1835[ 307], max:   9.6087[ 133]\n",
      "299:xent_pred[1000]: avg:   1.9172, min:   1.7605[ 918], max:   2.0487[ 329]\n",
      "299:xent_v0  [1000]: avg:   1.9136, min:   1.7610[ 918], max:   2.0493[ 883]\n",
      "===================\n",
      "beginning of epoch:  300\n",
      "available: 2.743 GB, used: 25.918 GB, free: 2.647 GB\n",
      "EPOCH: 300\n",
      "mean score: 0.00\n",
      "Speed: train: 1868.4, buffer_add: 1017.1, buffer_size: 100004\n",
      "Total Time: 2H 53M 42S, 10422s\n",
      "Total Sample: train: 19.264M, buffer: 10.558M\n",
      "[300] Time spent = 34.67 s\n",
      "300:grad_norm[1000]: avg:   2.7663, min:   1.6571[ 773], max:   4.9458[  77]\n",
      "300:loss     [1000]: avg:   7.1539, min:   5.3606[ 642], max:  10.0498[ 224]\n",
      "300:xent_pred[1000]: avg:   1.9149, min:   1.6953[ 224], max:   2.1042[ 507]\n",
      "300:xent_v0  [1000]: avg:   1.9114, min:   1.6915[ 224], max:   2.0867[ 507]\n",
      "===================\n",
      "beginning of epoch:  301\n",
      "available: 2.746 GB, used: 25.913 GB, free: 2.626 GB\n",
      "EPOCH: 301\n",
      "mean score: 0.00\n",
      "Speed: train: 1856.0, buffer_add: 1012.7, buffer_size: 100030\n",
      "Total Time: 2H 54M 16S, 10456s\n",
      "Total Sample: train: 19.328M, buffer: 10.593M\n",
      "[301] Time spent = 34.97 s\n",
      "301:grad_norm[1000]: avg:   2.7559, min:   1.5552[ 876], max:   4.7016[ 791]\n",
      "301:loss     [1000]: avg:   7.1484, min:   5.1130[ 498], max:   9.4951[ 471]\n",
      "301:xent_pred[1000]: avg:   1.9168, min:   1.7315[ 986], max:   2.0677[ 928]\n",
      "301:xent_v0  [1000]: avg:   1.9135, min:   1.7297[ 986], max:   2.0645[ 928]\n",
      "===================\n",
      "beginning of epoch:  302\n",
      "available: 2.753 GB, used: 25.902 GB, free: 2.703 GB\n",
      "EPOCH: 302\n",
      "mean score: 0.00\n",
      "Speed: train: 1919.6, buffer_add: 1010.1, buffer_size: 100015\n",
      "Total Time: 2H 54M 50S, 10490s\n",
      "Total Sample: train: 19.392M, buffer: 10.627M\n",
      "[302] Time spent = 33.72 s\n",
      "302:grad_norm[1000]: avg:   2.7221, min:   1.6276[ 962], max:   4.8084[ 476]\n",
      "302:loss     [1000]: avg:   7.1436, min:   5.1312[ 120], max:   9.6701[ 384]\n",
      "302:xent_pred[1000]: avg:   1.9185, min:   1.7545[  37], max:   2.0945[ 526]\n",
      "302:xent_v0  [1000]: avg:   1.9153, min:   1.7489[  72], max:   2.0872[ 526]\n",
      "===================\n",
      "beginning of epoch:  303\n",
      "available: 2.749 GB, used: 25.910 GB, free: 2.707 GB\n",
      "EPOCH: 303\n",
      "mean score: 0.00\n",
      "Speed: train: 1842.5, buffer_add: 1015.2, buffer_size: 100023\n",
      "Total Time: 2H 55M 24S, 10524s\n",
      "Total Sample: train: 19.456M, buffer: 10.662M\n",
      "[303] Time spent = 34.98 s\n",
      "303:grad_norm[1000]: avg:   2.7772, min:   1.6373[ 729], max:   4.9832[ 806]\n",
      "303:loss     [1000]: avg:   7.1711, min:   5.0694[ 649], max:   9.3274[ 726]\n",
      "303:xent_pred[1000]: avg:   1.9178, min:   1.7416[ 214], max:   2.0683[ 815]\n",
      "303:xent_v0  [1000]: avg:   1.9146, min:   1.7514[ 214], max:   2.0692[ 815]\n",
      "===================\n",
      "beginning of epoch:  304\n",
      "available: 2.750 GB, used: 25.910 GB, free: 2.694 GB\n",
      "EPOCH: 304\n",
      "mean score: 0.00\n",
      "Speed: train: 1859.0, buffer_add: 1017.2, buffer_size: 100036\n",
      "Total Time: 2H 55M 59S, 10559s\n",
      "Total Sample: train: 19.52M, buffer: 10.697M\n",
      "[304] Time spent = 34.91 s\n",
      "304:grad_norm[1000]: avg:   2.7656, min:   1.5406[ 415], max:   5.7932[ 467]\n",
      "304:loss     [1000]: avg:   7.1714, min:   5.2409[  13], max:   9.7568[ 497]\n",
      "304:xent_pred[1000]: avg:   1.9164, min:   1.7719[ 389], max:   2.1133[ 209]\n",
      "304:xent_v0  [1000]: avg:   1.9132, min:   1.7680[ 389], max:   2.1223[ 209]\n",
      "===================\n",
      "beginning of epoch:  305\n",
      "available: 2.744 GB, used: 25.918 GB, free: 2.632 GB\n",
      "EPOCH: 305\n",
      "mean score: 0.00\n",
      "Speed: train: 1846.8, buffer_add: 1009.8, buffer_size: 100020\n",
      "Total Time: 2H 56M 34S, 10594s\n",
      "Total Sample: train: 19.584M, buffer: 10.732M\n",
      "[305] Time spent = 35.08 s\n",
      "305:grad_norm[1000]: avg:   2.7393, min:   1.6448[ 730], max:   5.1271[ 483]\n",
      "305:loss     [1000]: avg:   7.1273, min:   5.1958[ 153], max:   9.2855[ 430]\n",
      "305:xent_pred[1000]: avg:   1.9164, min:   1.7687[ 689], max:   2.0627[ 657]\n",
      "305:xent_v0  [1000]: avg:   1.9133, min:   1.7615[ 689], max:   2.0638[ 657]\n",
      "===================\n",
      "beginning of epoch:  306\n",
      "available: 2.749 GB, used: 25.908 GB, free: 2.670 GB\n",
      "EPOCH: 306\n",
      "mean score: 0.00\n",
      "Speed: train: 1861.7, buffer_add: 1003.4, buffer_size: 100041\n",
      "Total Time: 2H 57M 08S, 10628s\n",
      "Total Sample: train: 19.648M, buffer: 10.767M\n",
      "[306] Time spent = 34.92 s\n",
      "306:grad_norm[1000]: avg:   2.7439, min:   1.5841[ 294], max:   4.7033[ 799]\n",
      "306:loss     [1000]: avg:   7.1712, min:   5.0609[ 986], max:   9.2800[ 906]\n",
      "306:xent_pred[1000]: avg:   1.9190, min:   1.7649[ 527], max:   2.0885[ 986]\n",
      "306:xent_v0  [1000]: avg:   1.9154, min:   1.7555[ 527], max:   2.0848[ 986]\n",
      "===================\n",
      "beginning of epoch:  307\n",
      "available: 2.733 GB, used: 25.919 GB, free: 2.708 GB\n",
      "EPOCH: 307\n",
      "mean score: 0.00\n",
      "Speed: train: 1853.2, buffer_add: 1022.6, buffer_size: 100030\n",
      "Total Time: 2H 57M 42S, 10662s\n",
      "Total Sample: train: 19.712M, buffer: 10.802M\n",
      "[307] Time spent = 34.99 s\n",
      "307:grad_norm[1000]: avg:   2.7708, min:   1.5127[ 127], max:   4.8061[ 413]\n",
      "307:loss     [1000]: avg:   7.1643, min:   5.2660[ 265], max:   9.3806[ 747]\n",
      "307:xent_pred[1000]: avg:   1.9194, min:   1.7550[ 938], max:   2.0627[ 587]\n",
      "307:xent_v0  [1000]: avg:   1.9164, min:   1.7591[ 938], max:   2.0648[  68]\n",
      "===================\n",
      "beginning of epoch:  308\n",
      "available: 2.750 GB, used: 25.915 GB, free: 2.646 GB\n",
      "EPOCH: 308\n",
      "mean score: 0.00\n",
      "Speed: train: 1837.3, buffer_add: 1008.9, buffer_size: 100047\n",
      "Total Time: 2H 58M 17S, 10697s\n",
      "Total Sample: train: 19.776M, buffer: 10.837M\n",
      "[308] Time spent = 35.12 s\n",
      "308:grad_norm[1000]: avg:   2.7340, min:   1.6442[ 690], max:   5.4664[ 665]\n",
      "308:loss     [1000]: avg:   7.1631, min:   5.3719[  97], max:   9.6423[ 569]\n",
      "308:xent_pred[1000]: avg:   1.9181, min:   1.7625[ 805], max:   2.0665[  19]\n",
      "308:xent_v0  [1000]: avg:   1.9149, min:   1.7609[ 805], max:   2.0635[ 724]\n",
      "===================\n",
      "beginning of epoch:  309\n",
      "available: 2.746 GB, used: 25.908 GB, free: 2.645 GB\n",
      "EPOCH: 309\n",
      "mean score: 0.00\n",
      "Speed: train: 1879.6, buffer_add: 1006.5, buffer_size: 100012\n",
      "Total Time: 2H 58M 51S, 10731s\n",
      "Total Sample: train: 19.84M, buffer: 10.872M\n",
      "[309] Time spent = 34.48 s\n",
      "309:grad_norm[1000]: avg:   2.7333, min:   1.2974[  58], max:   4.6677[ 454]\n",
      "309:loss     [1000]: avg:   7.1617, min:   5.3290[ 695], max:   9.4073[ 779]\n",
      "309:xent_pred[1000]: avg:   1.9168, min:   1.7839[ 994], max:   2.0634[  58]\n",
      "309:xent_v0  [1000]: avg:   1.9140, min:   1.7725[ 994], max:   2.0561[ 233]\n",
      "===================\n",
      "beginning of epoch:  310\n",
      "available: 2.752 GB, used: 25.915 GB, free: 2.665 GB\n",
      "EPOCH: 310\n",
      "mean score: 0.00\n",
      "Speed: train: 1888.9, buffer_add: 1009.2, buffer_size: 100103\n",
      "Total Time: 2H 59M 25S, 10765s\n",
      "Total Sample: train: 19.904M, buffer: 10.906M\n",
      "[310] Time spent = 34.23 s\n",
      "310:grad_norm[1000]: avg:   2.7302, min:   1.5412[ 388], max:   4.9298[ 834]\n",
      "310:loss     [1000]: avg:   7.1888, min:   5.5201[  91], max:   9.6441[ 242]\n",
      "310:xent_pred[1000]: avg:   1.9160, min:   1.7771[ 358], max:   2.0646[ 997]\n",
      "310:xent_v0  [1000]: avg:   1.9133, min:   1.7791[ 358], max:   2.0736[ 997]\n",
      "===================\n",
      "beginning of epoch:  311\n",
      "available: 2.744 GB, used: 25.906 GB, free: 2.706 GB\n",
      "EPOCH: 311\n",
      "mean score: 0.00\n",
      "Speed: train: 1843.7, buffer_add: 1015.0, buffer_size: 100021\n",
      "Total Time: 3H 00M 00S, 10800s\n",
      "Total Sample: train: 19.968M, buffer: 10.941M\n",
      "[311] Time spent = 35.15 s\n",
      "311:grad_norm[1000]: avg:   2.7049, min:   1.5357[ 603], max:   5.2869[ 443]\n",
      "311:loss     [1000]: avg:   7.1349, min:   5.2439[ 529], max:   9.3446[ 441]\n",
      "311:xent_pred[1000]: avg:   1.9180, min:   1.7429[ 311], max:   2.0721[ 529]\n",
      "311:xent_v0  [1000]: avg:   1.9150, min:   1.7397[ 311], max:   2.0624[ 529]\n",
      "===================\n",
      "beginning of epoch:  312\n",
      "available: 2.746 GB, used: 25.913 GB, free: 2.679 GB\n",
      "EPOCH: 312\n",
      "mean score: 0.00\n",
      "Speed: train: 1856.6, buffer_add: 1010.6, buffer_size: 100092\n",
      "Total Time: 3H 00M 34S, 10834s\n",
      "Total Sample: train: 20.032M, buffer: 10.976M\n",
      "[312] Time spent = 34.80 s\n",
      "312:grad_norm[1000]: avg:   2.7610, min:   1.4682[ 651], max:   5.4401[ 746]\n",
      "312:loss     [1000]: avg:   7.2022, min:   5.3750[ 553], max:   9.6448[  12]\n",
      "312:xent_pred[1000]: avg:   1.9169, min:   1.7897[ 373], max:   2.0840[   2]\n",
      "312:xent_v0  [1000]: avg:   1.9132, min:   1.7899[ 373], max:   2.0842[   2]\n",
      "===================\n",
      "beginning of epoch:  313\n",
      "available: 2.739 GB, used: 25.918 GB, free: 2.716 GB\n",
      "EPOCH: 313\n",
      "mean score: 0.00\n",
      "Speed: train: 1870.4, buffer_add: 1001.2, buffer_size: 100018\n",
      "Total Time: 3H 01M 09S, 10869s\n",
      "Total Sample: train: 20.096M, buffer: 11.01M\n",
      "[313] Time spent = 34.77 s\n",
      "313:grad_norm[1000]: avg:   2.7540, min:   1.5526[ 939], max:   5.1285[ 519]\n",
      "313:loss     [1000]: avg:   7.1795, min:   4.8918[ 939], max:   9.3754[ 919]\n",
      "313:xent_pred[1000]: avg:   1.9168, min:   1.7392[ 142], max:   2.0471[ 751]\n",
      "313:xent_v0  [1000]: avg:   1.9134, min:   1.7392[ 142], max:   2.0455[ 751]\n",
      "===================\n",
      "beginning of epoch:  314\n",
      "available: 2.736 GB, used: 25.921 GB, free: 2.675 GB\n",
      "EPOCH: 314\n",
      "mean score: 0.00\n",
      "Speed: train: 1869.0, buffer_add: 1021.7, buffer_size: 100014\n",
      "Total Time: 3H 01M 43S, 10903s\n",
      "Total Sample: train: 20.16M, buffer: 11.045M\n",
      "[314] Time spent = 34.56 s\n",
      "314:grad_norm[1000]: avg:   2.7438, min:   1.6719[ 484], max:   8.0280[ 712]\n",
      "314:loss     [1000]: avg:   7.1875, min:   5.0413[ 440], max:   9.3580[ 692]\n",
      "314:xent_pred[1000]: avg:   1.9163, min:   1.7533[ 797], max:   2.0715[ 440]\n",
      "314:xent_v0  [1000]: avg:   1.9131, min:   1.7474[ 797], max:   2.0729[ 440]\n",
      "===================\n",
      "beginning of epoch:  315\n",
      "available: 2.739 GB, used: 25.921 GB, free: 2.616 GB\n",
      "EPOCH: 315\n",
      "mean score: 0.00\n",
      "Speed: train: 1853.4, buffer_add: 1013.3, buffer_size: 100036\n",
      "Total Time: 3H 02M 17S, 10937s\n",
      "Total Sample: train: 20.224M, buffer: 11.08M\n",
      "[315] Time spent = 34.98 s\n",
      "315:grad_norm[1000]: avg:   2.7173, min:   1.6367[ 157], max:   4.6153[ 403]\n",
      "315:loss     [1000]: avg:   7.1711, min:   5.1032[  10], max:  10.0710[ 396]\n",
      "315:xent_pred[1000]: avg:   1.9175, min:   1.7574[ 385], max:   2.0892[  31]\n",
      "315:xent_v0  [1000]: avg:   1.9145, min:   1.7518[ 385], max:   2.0796[  31]\n",
      "===================\n",
      "beginning of epoch:  316\n",
      "available: 2.736 GB, used: 25.921 GB, free: 2.654 GB\n",
      "EPOCH: 316\n",
      "mean score: 0.00\n",
      "Speed: train: 1882.8, buffer_add: 1022.8, buffer_size: 100019\n",
      "Total Time: 3H 02M 51S, 10971s\n",
      "Total Sample: train: 20.288M, buffer: 11.115M\n",
      "[316] Time spent = 34.19 s\n",
      "316:grad_norm[1000]: avg:   2.7198, min:   1.6134[ 582], max:   7.3896[ 585]\n",
      "316:loss     [1000]: avg:   7.1528, min:   5.2180[  96], max:   9.7274[ 772]\n",
      "316:xent_pred[1000]: avg:   1.9157, min:   1.7867[ 136], max:   2.0757[ 750]\n",
      "316:xent_v0  [1000]: avg:   1.9124, min:   1.7758[ 936], max:   2.0731[ 442]\n",
      "===================\n",
      "beginning of epoch:  317\n",
      "available: 2.738 GB, used: 25.922 GB, free: 2.636 GB\n",
      "EPOCH: 317\n",
      "mean score: 0.00\n",
      "Speed: train: 1838.4, buffer_add: 1006.9, buffer_size: 100017\n",
      "Total Time: 3H 03M 26S, 11006s\n",
      "Total Sample: train: 20.352M, buffer: 11.15M\n",
      "[317] Time spent = 35.22 s\n",
      "317:grad_norm[1000]: avg:   2.7191, min:   1.5972[ 346], max:   6.1082[ 935]\n",
      "317:loss     [1000]: avg:   7.1432, min:   5.0697[  84], max:   9.2543[ 230]\n",
      "317:xent_pred[1000]: avg:   1.9192, min:   1.7733[ 360], max:   2.0594[ 877]\n",
      "317:xent_v0  [1000]: avg:   1.9156, min:   1.7676[ 360], max:   2.0570[ 653]\n",
      "===================\n",
      "beginning of epoch:  318\n",
      "available: 2.756 GB, used: 25.915 GB, free: 2.657 GB\n",
      "EPOCH: 318\n",
      "mean score: 0.00\n",
      "Speed: train: 1860.8, buffer_add: 1024.1, buffer_size: 100001\n",
      "Total Time: 3H 04M 01S, 11041s\n",
      "Total Sample: train: 20.416M, buffer: 11.185M\n",
      "[318] Time spent = 34.80 s\n",
      "318:grad_norm[1000]: avg:   2.7265, min:   1.5977[ 906], max:   6.0591[ 825]\n",
      "318:loss     [1000]: avg:   7.1797, min:   5.3859[ 273], max:   9.5196[ 857]\n",
      "318:xent_pred[1000]: avg:   1.9176, min:   1.7586[ 188], max:   2.0940[ 441]\n",
      "318:xent_v0  [1000]: avg:   1.9149, min:   1.7574[ 744], max:   2.0873[ 441]\n",
      "===================\n",
      "beginning of epoch:  319\n",
      "available: 2.752 GB, used: 25.911 GB, free: 2.583 GB\n",
      "EPOCH: 319\n",
      "mean score: 0.00\n",
      "Speed: train: 1881.7, buffer_add: 1016.2, buffer_size: 100058\n",
      "Total Time: 3H 04M 35S, 11075s\n",
      "Total Sample: train: 20.48M, buffer: 11.22M\n",
      "[319] Time spent = 34.40 s\n",
      "319:grad_norm[1000]: avg:   2.7289, min:   1.4019[ 269], max:   4.3329[ 145]\n",
      "319:loss     [1000]: avg:   7.1426, min:   5.3110[ 247], max:   9.6100[ 191]\n",
      "319:xent_pred[1000]: avg:   1.9171, min:   1.7437[ 218], max:   2.1039[ 920]\n",
      "319:xent_v0  [1000]: avg:   1.9141, min:   1.7399[ 218], max:   2.0983[ 920]\n",
      "===================\n",
      "beginning of epoch:  320\n",
      "available: 2.754 GB, used: 25.909 GB, free: 2.628 GB\n",
      "EPOCH: 320\n",
      "mean score: 0.00\n",
      "Speed: train: 1873.6, buffer_add: 1022.5, buffer_size: 100004\n",
      "Total Time: 3H 05M 09S, 11109s\n",
      "Total Sample: train: 20.544M, buffer: 11.255M\n",
      "[320] Time spent = 34.49 s\n",
      "320:grad_norm[1000]: avg:   2.7374, min:   1.6571[ 382], max:   4.9025[  79]\n",
      "320:loss     [1000]: avg:   7.2146, min:   5.3310[ 876], max:   9.2681[ 363]\n",
      "320:xent_pred[1000]: avg:   1.9163, min:   1.7839[  69], max:   2.0861[ 800]\n",
      "320:xent_v0  [1000]: avg:   1.9127, min:   1.7774[ 183], max:   2.0839[ 800]\n",
      "===================\n",
      "beginning of epoch:  321\n",
      "available: 2.750 GB, used: 25.909 GB, free: 2.661 GB\n",
      "EPOCH: 321\n",
      "mean score: 0.00\n",
      "Speed: train: 1861.1, buffer_add: 1004.2, buffer_size: 100024\n",
      "Total Time: 3H 05M 43S, 11143s\n",
      "Total Sample: train: 20.608M, buffer: 11.289M\n",
      "[321] Time spent = 34.80 s\n",
      "321:grad_norm[1000]: avg:   2.7112, min:   1.6053[ 786], max:   5.1592[ 251]\n",
      "321:loss     [1000]: avg:   7.1861, min:   5.2595[ 848], max:   9.6163[ 973]\n",
      "321:xent_pred[1000]: avg:   1.9191, min:   1.7819[ 220], max:   2.0691[ 971]\n",
      "321:xent_v0  [1000]: avg:   1.9157, min:   1.7818[ 663], max:   2.0633[ 971]\n",
      "===================\n",
      "beginning of epoch:  322\n",
      "available: 2.751 GB, used: 25.910 GB, free: 2.675 GB\n",
      "EPOCH: 322\n",
      "mean score: 0.00\n",
      "Speed: train: 1852.9, buffer_add: 1015.7, buffer_size: 100026\n",
      "Total Time: 3H 06M 18S, 11178s\n",
      "Total Sample: train: 20.672M, buffer: 11.324M\n",
      "[322] Time spent = 35.41 s\n",
      "322:grad_norm[1000]: avg:   2.6917, min:   1.4230[ 157], max:   6.0874[ 747]\n",
      "322:loss     [1000]: avg:   7.1087, min:   5.1670[ 297], max:   9.4922[ 210]\n",
      "322:xent_pred[1000]: avg:   1.9235, min:   1.7873[ 161], max:   2.0941[  53]\n",
      "322:xent_v0  [1000]: avg:   1.9207, min:   1.7861[ 796], max:   2.0877[  53]\n",
      "===================\n",
      "beginning of epoch:  323\n",
      "available: 2.755 GB, used: 25.905 GB, free: 2.702 GB\n",
      "EPOCH: 323\n",
      "mean score: 0.00\n",
      "Speed: train: 1855.0, buffer_add: 1036.0, buffer_size: 100006\n",
      "Total Time: 3H 06M 52S, 11212s\n",
      "Total Sample: train: 20.736M, buffer: 11.36M\n",
      "[323] Time spent = 34.80 s\n",
      "323:grad_norm[1000]: avg:   2.7141, min:   1.5264[  79], max:   6.0405[  52]\n",
      "323:loss     [1000]: avg:   7.1907, min:   5.3190[ 514], max:   9.6181[ 566]\n",
      "323:xent_pred[1000]: avg:   1.9181, min:   1.7030[ 748], max:   2.1018[ 168]\n",
      "323:xent_v0  [1000]: avg:   1.9149, min:   1.7046[ 748], max:   2.1051[ 168]\n",
      "===================\n",
      "beginning of epoch:  324\n",
      "available: 2.749 GB, used: 25.909 GB, free: 2.675 GB\n",
      "EPOCH: 324\n",
      "mean score: 0.00\n",
      "Speed: train: 1863.9, buffer_add: 1008.1, buffer_size: 100012\n",
      "Total Time: 3H 07M 27S, 11247s\n",
      "Total Sample: train: 20.8M, buffer: 11.395M\n",
      "[324] Time spent = 34.55 s\n",
      "324:grad_norm[1000]: avg:   2.6951, min:   1.4357[ 645], max:   4.6897[ 344]\n",
      "324:loss     [1000]: avg:   7.1789, min:   5.2794[ 542], max:   9.2186[ 779]\n",
      "324:xent_pred[1000]: avg:   1.9171, min:   1.7827[ 386], max:   2.0704[ 139]\n",
      "324:xent_v0  [1000]: avg:   1.9136, min:   1.7717[ 386], max:   2.0759[ 139]\n",
      "===================\n",
      "beginning of epoch:  325\n",
      "available: 2.754 GB, used: 25.902 GB, free: 2.687 GB\n",
      "EPOCH: 325\n",
      "mean score: 0.00\n",
      "Speed: train: 1869.4, buffer_add: 997.3, buffer_size: 100011\n",
      "Total Time: 3H 08M 01S, 11281s\n",
      "Total Sample: train: 20.864M, buffer: 11.429M\n",
      "[325] Time spent = 34.68 s\n",
      "325:grad_norm[1000]: avg:   2.6832, min:   1.6794[ 786], max:   4.4099[ 439]\n",
      "325:loss     [1000]: avg:   7.2026, min:   5.1421[ 390], max:   9.4037[ 939]\n",
      "325:xent_pred[1000]: avg:   1.9180, min:   1.7637[ 904], max:   2.0763[ 150]\n",
      "325:xent_v0  [1000]: avg:   1.9146, min:   1.7587[ 393], max:   2.0667[ 150]\n",
      "===================\n",
      "beginning of epoch:  326\n",
      "available: 2.749 GB, used: 25.904 GB, free: 2.707 GB\n",
      "EPOCH: 326\n",
      "mean score: 0.00\n",
      "Speed: train: 1854.4, buffer_add: 1009.5, buffer_size: 100032\n",
      "Total Time: 3H 08M 35S, 11315s\n",
      "Total Sample: train: 20.928M, buffer: 11.463M\n",
      "[326] Time spent = 34.91 s\n",
      "326:grad_norm[1000]: avg:   2.7019, min:   1.6009[ 724], max:   4.9661[ 429]\n",
      "326:loss     [1000]: avg:   7.1774, min:   5.3797[ 307], max:   9.5150[  13]\n",
      "326:xent_pred[1000]: avg:   1.9187, min:   1.7348[  13], max:   2.0654[ 136]\n",
      "326:xent_v0  [1000]: avg:   1.9157, min:   1.7333[  13], max:   2.0584[ 136]\n",
      "===================\n",
      "beginning of epoch:  327\n",
      "available: 2.759 GB, used: 25.905 GB, free: 2.691 GB\n",
      "EPOCH: 327\n",
      "mean score: 0.00\n",
      "Speed: train: 1834.9, buffer_add: 1015.0, buffer_size: 100021\n",
      "Total Time: 3H 09M 10S, 11350s\n",
      "Total Sample: train: 20.992M, buffer: 11.499M\n",
      "[327] Time spent = 35.28 s\n",
      "327:grad_norm[1000]: avg:   2.7159, min:   1.6454[ 666], max:   4.7335[ 229]\n",
      "327:loss     [1000]: avg:   7.2240, min:   5.3423[ 174], max:   9.5810[ 396]\n",
      "327:xent_pred[1000]: avg:   1.9161, min:   1.7494[ 397], max:   2.0533[ 652]\n",
      "327:xent_v0  [1000]: avg:   1.9130, min:   1.7499[ 397], max:   2.0491[ 652]\n",
      "===================\n",
      "beginning of epoch:  328\n",
      "available: 2.752 GB, used: 25.908 GB, free: 2.676 GB\n",
      "EPOCH: 328\n",
      "mean score: 0.00\n",
      "Speed: train: 1871.1, buffer_add: 1013.5, buffer_size: 100031\n",
      "Total Time: 3H 09M 44S, 11384s\n",
      "Total Sample: train: 21.056M, buffer: 11.534M\n",
      "[328] Time spent = 34.60 s\n",
      "328:grad_norm[1000]: avg:   2.7013, min:   1.5570[ 532], max:   4.7042[ 183]\n",
      "328:loss     [1000]: avg:   7.2035, min:   5.2852[ 794], max:   9.4899[ 755]\n",
      "328:xent_pred[1000]: avg:   1.9161, min:   1.7442[ 595], max:   2.0732[ 785]\n",
      "328:xent_v0  [1000]: avg:   1.9127, min:   1.7394[ 595], max:   2.0655[ 785]\n",
      "===================\n",
      "beginning of epoch:  329\n",
      "available: 2.757 GB, used: 25.908 GB, free: 2.648 GB\n",
      "EPOCH: 329\n",
      "mean score: 0.00\n",
      "Speed: train: 1870.8, buffer_add: 1014.5, buffer_size: 100034\n",
      "Total Time: 3H 10M 19S, 11419s\n",
      "Total Sample: train: 21.12M, buffer: 11.568M\n",
      "[329] Time spent = 34.37 s\n",
      "329:grad_norm[1000]: avg:   2.7011, min:   1.5300[  66], max:   5.2084[ 830]\n",
      "329:loss     [1000]: avg:   7.1431, min:   5.2804[  66], max:   9.4209[  32]\n",
      "329:xent_pred[1000]: avg:   1.9182, min:   1.7377[ 128], max:   2.0885[ 605]\n",
      "329:xent_v0  [1000]: avg:   1.9154, min:   1.7238[ 128], max:   2.0746[ 605]\n",
      "===================\n",
      "beginning of epoch:  330\n",
      "available: 2.747 GB, used: 25.910 GB, free: 2.684 GB\n",
      "EPOCH: 330\n",
      "mean score: 0.00\n",
      "Speed: train: 1864.6, buffer_add: 1001.1, buffer_size: 100112\n",
      "Total Time: 3H 10M 53S, 11453s\n",
      "Total Sample: train: 21.184M, buffer: 11.603M\n",
      "[330] Time spent = 34.70 s\n",
      "330:grad_norm[1000]: avg:   2.7298, min:   1.5217[ 630], max:   4.9129[ 312]\n",
      "330:loss     [1000]: avg:   7.1623, min:   5.3912[ 506], max:   9.5259[ 450]\n",
      "330:xent_pred[1000]: avg:   1.9198, min:   1.7593[ 608], max:   2.0882[ 671]\n",
      "330:xent_v0  [1000]: avg:   1.9166, min:   1.7559[ 667], max:   2.0936[ 671]\n",
      "===================\n",
      "beginning of epoch:  331\n",
      "available: 2.733 GB, used: 25.924 GB, free: 2.701 GB\n",
      "EPOCH: 331\n",
      "mean score: 0.00\n",
      "Speed: train: 1854.8, buffer_add: 1011.8, buffer_size: 100053\n",
      "Total Time: 3H 11M 27S, 11487s\n",
      "Total Sample: train: 21.248M, buffer: 11.638M\n",
      "[331] Time spent = 34.98 s\n",
      "331:grad_norm[1000]: avg:   2.6964, min:   1.4761[ 811], max:   5.8686[ 219]\n",
      "331:loss     [1000]: avg:   7.1554, min:   5.1271[   6], max:   9.7219[ 649]\n",
      "331:xent_pred[1000]: avg:   1.9173, min:   1.7637[ 776], max:   2.0773[ 725]\n",
      "331:xent_v0  [1000]: avg:   1.9149, min:   1.7549[ 776], max:   2.0803[ 725]\n",
      "===================\n",
      "beginning of epoch:  332\n",
      "available: 2.741 GB, used: 25.922 GB, free: 2.645 GB\n",
      "EPOCH: 332\n",
      "mean score: 0.00\n",
      "Speed: train: 1806.0, buffer_add: 1018.0, buffer_size: 100023\n",
      "Total Time: 3H 12M 03S, 11523s\n",
      "Total Sample: train: 21.312M, buffer: 11.674M\n",
      "[332] Time spent = 35.85 s\n",
      "332:grad_norm[1000]: avg:   2.6900, min:   1.6008[ 976], max:   4.4967[  82]\n",
      "332:loss     [1000]: avg:   7.1531, min:   5.3365[ 744], max:   9.1647[ 622]\n",
      "332:xent_pred[1000]: avg:   1.9180, min:   1.7425[ 415], max:   2.0545[ 609]\n",
      "332:xent_v0  [1000]: avg:   1.9151, min:   1.7388[ 469], max:   2.0474[ 570]\n",
      "===================\n",
      "beginning of epoch:  333\n",
      "available: 2.754 GB, used: 25.909 GB, free: 2.617 GB\n",
      "EPOCH: 333\n",
      "mean score: 0.00\n",
      "Speed: train: 1872.6, buffer_add: 1018.2, buffer_size: 100029\n",
      "Total Time: 3H 12M 37S, 11557s\n",
      "Total Sample: train: 21.376M, buffer: 11.708M\n",
      "[333] Time spent = 34.61 s\n",
      "333:grad_norm[1000]: avg:   2.6651, min:   1.5636[ 371], max:   7.2460[ 249]\n",
      "333:loss     [1000]: avg:   7.1250, min:   5.0882[ 495], max:   9.9075[ 380]\n",
      "333:xent_pred[1000]: avg:   1.9174, min:   1.7648[ 826], max:   2.0613[ 323]\n",
      "333:xent_v0  [1000]: avg:   1.9146, min:   1.7599[ 826], max:   2.0466[ 749]\n",
      "===================\n",
      "beginning of epoch:  334\n",
      "available: 2.744 GB, used: 25.910 GB, free: 2.726 GB\n",
      "EPOCH: 334\n",
      "mean score: 0.00\n",
      "Speed: train: 1831.0, buffer_add: 1006.5, buffer_size: 100067\n",
      "Total Time: 3H 13M 12S, 11592s\n",
      "Total Sample: train: 21.44M, buffer: 11.744M\n",
      "[334] Time spent = 35.41 s\n",
      "334:grad_norm[1000]: avg:   2.7056, min:   1.5918[ 224], max:   4.1169[ 980]\n",
      "334:loss     [1000]: avg:   7.1805, min:   5.3396[ 363], max:   9.5810[ 899]\n",
      "334:xent_pred[1000]: avg:   1.9158, min:   1.7586[ 285], max:   2.0632[ 701]\n",
      "334:xent_v0  [1000]: avg:   1.9130, min:   1.7634[ 285], max:   2.0642[ 284]\n",
      "===================\n",
      "beginning of epoch:  335\n",
      "available: 2.748 GB, used: 25.906 GB, free: 2.722 GB\n",
      "EPOCH: 335\n",
      "mean score: 0.00\n",
      "Speed: train: 1859.0, buffer_add: 1009.4, buffer_size: 100038\n",
      "Total Time: 3H 13M 46S, 11626s\n",
      "Total Sample: train: 21.504M, buffer: 11.778M\n",
      "[335] Time spent = 34.83 s\n",
      "335:grad_norm[1000]: avg:   2.6840, min:   1.3573[ 229], max:   5.4411[ 898]\n",
      "335:loss     [1000]: avg:   7.1758, min:   5.2683[ 514], max:   9.6579[ 160]\n",
      "335:xent_pred[1000]: avg:   1.9151, min:   1.7410[ 488], max:   2.0655[ 810]\n",
      "335:xent_v0  [1000]: avg:   1.9122, min:   1.7387[ 488], max:   2.0603[ 376]\n",
      "===================\n",
      "beginning of epoch:  336\n",
      "available: 2.746 GB, used: 25.908 GB, free: 2.652 GB\n",
      "EPOCH: 336\n",
      "mean score: 0.00\n",
      "Speed: train: 1880.3, buffer_add: 1020.8, buffer_size: 100036\n",
      "Total Time: 3H 14M 20S, 11660s\n",
      "Total Sample: train: 21.568M, buffer: 11.813M\n",
      "[336] Time spent = 34.42 s\n",
      "336:grad_norm[1000]: avg:   2.6866, min:   1.5570[ 311], max:   5.2137[ 526]\n",
      "336:loss     [1000]: avg:   7.1699, min:   5.3944[ 125], max:   9.3798[   2]\n",
      "336:xent_pred[1000]: avg:   1.9160, min:   1.7096[ 565], max:   2.0560[ 438]\n",
      "336:xent_v0  [1000]: avg:   1.9128, min:   1.7237[ 565], max:   2.0563[ 438]\n",
      "===================\n",
      "beginning of epoch:  337\n",
      "available: 2.738 GB, used: 25.916 GB, free: 2.670 GB\n",
      "EPOCH: 337\n",
      "mean score: 0.00\n",
      "Speed: train: 1852.1, buffer_add: 1016.3, buffer_size: 100042\n",
      "Total Time: 3H 14M 55S, 11695s\n",
      "Total Sample: train: 21.632M, buffer: 11.848M\n",
      "[337] Time spent = 34.88 s\n",
      "337:grad_norm[1000]: avg:   2.6919, min:   1.5898[ 478], max:   4.5437[ 470]\n",
      "337:loss     [1000]: avg:   7.1670, min:   5.2490[ 478], max:   9.7895[ 321]\n",
      "337:xent_pred[1000]: avg:   1.9164, min:   1.7601[ 708], max:   2.0778[ 776]\n",
      "337:xent_v0  [1000]: avg:   1.9132, min:   1.7606[ 708], max:   2.0686[ 604]\n",
      "===================\n",
      "beginning of epoch:  338\n",
      "available: 2.739 GB, used: 25.923 GB, free: 2.627 GB\n",
      "EPOCH: 338\n",
      "mean score: 0.00\n",
      "Speed: train: 1870.6, buffer_add: 1007.5, buffer_size: 100007\n",
      "Total Time: 3H 15M 29S, 11729s\n",
      "Total Sample: train: 21.696M, buffer: 11.883M\n",
      "[338] Time spent = 34.74 s\n",
      "338:grad_norm[1000]: avg:   2.7104, min:   1.4874[ 348], max:   5.6544[ 527]\n",
      "338:loss     [1000]: avg:   7.1746, min:   4.9499[ 348], max:   9.1891[  32]\n",
      "338:xent_pred[1000]: avg:   1.9161, min:   1.7694[ 236], max:   2.0577[ 109]\n",
      "338:xent_v0  [1000]: avg:   1.9133, min:   1.7646[ 236], max:   2.0494[ 355]\n",
      "===================\n",
      "beginning of epoch:  339\n",
      "available: 2.748 GB, used: 25.915 GB, free: 2.601 GB\n",
      "EPOCH: 339\n",
      "mean score: 0.00\n",
      "Speed: train: 1834.0, buffer_add: 1027.1, buffer_size: 100041\n",
      "Total Time: 3H 16M 04S, 11764s\n",
      "Total Sample: train: 21.76M, buffer: 11.919M\n",
      "[339] Time spent = 35.28 s\n",
      "339:grad_norm[1000]: avg:   2.6619, min:   1.5331[ 410], max:   4.3433[ 833]\n",
      "339:loss     [1000]: avg:   7.1619, min:   4.6089[ 732], max:   9.3486[ 404]\n",
      "339:xent_pred[1000]: avg:   1.9172, min:   1.7800[ 499], max:   2.0425[ 387]\n",
      "339:xent_v0  [1000]: avg:   1.9143, min:   1.7725[ 280], max:   2.0330[   9]\n",
      "===================\n",
      "beginning of epoch:  340\n",
      "available: 2.732 GB, used: 25.933 GB, free: 2.576 GB\n",
      "EPOCH: 340\n",
      "mean score: 0.00\n",
      "Speed: train: 1850.4, buffer_add: 1018.0, buffer_size: 100052\n",
      "Total Time: 3H 16M 39S, 11799s\n",
      "Total Sample: train: 21.824M, buffer: 11.954M\n",
      "[340] Time spent = 35.02 s\n",
      "340:grad_norm[1000]: avg:   2.7036, min:   1.5594[ 325], max:   5.0076[ 494]\n",
      "340:loss     [1000]: avg:   7.1924, min:   5.0063[ 176], max:   9.7356[ 806]\n",
      "340:xent_pred[1000]: avg:   1.9134, min:   1.7685[ 135], max:   2.0998[ 739]\n",
      "340:xent_v0  [1000]: avg:   1.9101, min:   1.7592[ 135], max:   2.0967[ 739]\n",
      "===================\n",
      "beginning of epoch:  341\n",
      "available: 2.733 GB, used: 25.924 GB, free: 2.637 GB\n",
      "EPOCH: 341\n",
      "mean score: 0.00\n",
      "Speed: train: 1877.4, buffer_add: 1015.3, buffer_size: 100031\n",
      "Total Time: 3H 17M 13S, 11833s\n",
      "Total Sample: train: 21.888M, buffer: 11.988M\n",
      "[341] Time spent = 34.50 s\n",
      "341:grad_norm[1000]: avg:   2.6517, min:   1.5181[ 766], max:   7.4052[ 999]\n",
      "341:loss     [1000]: avg:   7.1234, min:   5.4951[ 851], max:   9.5865[ 719]\n",
      "341:xent_pred[1000]: avg:   1.9166, min:   1.7629[ 800], max:   2.0734[ 300]\n",
      "341:xent_v0  [1000]: avg:   1.9138, min:   1.7628[ 800], max:   2.0596[ 312]\n",
      "===================\n",
      "beginning of epoch:  342\n",
      "available: 2.751 GB, used: 25.913 GB, free: 2.687 GB\n",
      "EPOCH: 342\n",
      "mean score: 0.00\n",
      "Speed: train: 1850.4, buffer_add: 1024.2, buffer_size: 100048\n",
      "Total Time: 3H 17M 47S, 11867s\n",
      "Total Sample: train: 21.952M, buffer: 12.024M\n",
      "[342] Time spent = 35.03 s\n",
      "342:grad_norm[1000]: avg:   2.6370, min:   1.3653[ 793], max:   4.4667[ 767]\n",
      "342:loss     [1000]: avg:   7.1442, min:   5.3557[ 542], max:   9.2283[ 688]\n",
      "342:xent_pred[1000]: avg:   1.9158, min:   1.7231[ 797], max:   2.0688[   0]\n",
      "342:xent_v0  [1000]: avg:   1.9131, min:   1.7234[ 797], max:   2.0565[   0]\n",
      "===================\n",
      "beginning of epoch:  343\n",
      "available: 2.752 GB, used: 25.913 GB, free: 2.669 GB\n",
      "EPOCH: 343\n",
      "mean score: 0.00\n",
      "Speed: train: 1824.3, buffer_add: 1011.5, buffer_size: 100021\n",
      "Total Time: 3H 18M 22S, 11902s\n",
      "Total Sample: train: 22.016M, buffer: 12.059M\n",
      "[343] Time spent = 35.47 s\n",
      "343:grad_norm[1000]: avg:   2.6627, min:   1.5450[ 782], max:   5.1045[ 186]\n",
      "343:loss     [1000]: avg:   7.1794, min:   5.2776[ 657], max:   9.7565[ 269]\n",
      "343:xent_pred[1000]: avg:   1.9156, min:   1.7643[  31], max:   2.0879[ 473]\n",
      "343:xent_v0  [1000]: avg:   1.9128, min:   1.7672[  31], max:   2.0829[ 473]\n",
      "===================\n",
      "beginning of epoch:  344\n",
      "available: 2.743 GB, used: 25.920 GB, free: 2.646 GB\n",
      "EPOCH: 344\n",
      "mean score: 0.00\n",
      "Speed: train: 1885.9, buffer_add: 988.7, buffer_size: 100040\n",
      "Total Time: 3H 18M 56S, 11936s\n",
      "Total Sample: train: 22.08M, buffer: 12.093M\n",
      "[344] Time spent = 34.36 s\n",
      "344:grad_norm[1000]: avg:   2.6512, min:   1.6170[ 486], max:   4.6850[ 576]\n",
      "344:loss     [1000]: avg:   7.1930, min:   5.1956[ 877], max:   9.5480[ 555]\n",
      "344:xent_pred[1000]: avg:   1.9174, min:   1.7675[ 788], max:   2.0824[ 681]\n",
      "344:xent_v0  [1000]: avg:   1.9143, min:   1.7597[ 788], max:   2.0681[ 681]\n",
      "===================\n",
      "beginning of epoch:  345\n",
      "available: 2.739 GB, used: 25.916 GB, free: 2.601 GB\n",
      "EPOCH: 345\n",
      "mean score: 0.00\n",
      "Speed: train: 1851.5, buffer_add: 1001.6, buffer_size: 100044\n",
      "Total Time: 3H 19M 31S, 11971s\n",
      "Total Sample: train: 22.144M, buffer: 12.127M\n",
      "[345] Time spent = 34.98 s\n",
      "345:grad_norm[1000]: avg:   2.6738, min:   1.4893[ 560], max:   6.3366[ 510]\n",
      "345:loss     [1000]: avg:   7.2286, min:   5.4315[ 560], max:  10.0221[ 567]\n",
      "345:xent_pred[1000]: avg:   1.9135, min:   1.7346[ 667], max:   2.0739[ 729]\n",
      "345:xent_v0  [1000]: avg:   1.9106, min:   1.7362[ 667], max:   2.0653[ 729]\n",
      "===================\n",
      "beginning of epoch:  346\n",
      "available: 2.745 GB, used: 25.903 GB, free: 2.598 GB\n",
      "EPOCH: 346\n",
      "mean score: 0.00\n",
      "Speed: train: 1850.2, buffer_add: 1011.8, buffer_size: 100017\n",
      "Total Time: 3H 20M 06S, 12006s\n",
      "Total Sample: train: 22.208M, buffer: 12.162M\n",
      "[346] Time spent = 34.99 s\n",
      "346:grad_norm[1000]: avg:   2.6522, min:   1.4281[ 570], max:   4.1944[ 968]\n",
      "346:loss     [1000]: avg:   7.2127, min:   5.2196[ 389], max:   9.9996[ 391]\n",
      "346:xent_pred[1000]: avg:   1.9132, min:   1.6843[ 630], max:   2.0733[ 756]\n",
      "346:xent_v0  [1000]: avg:   1.9099, min:   1.6904[ 630], max:   2.0601[ 756]\n",
      "===================\n",
      "beginning of epoch:  347\n",
      "available: 2.752 GB, used: 25.903 GB, free: 2.512 GB\n",
      "EPOCH: 347\n",
      "mean score: 0.00\n",
      "Speed: train: 1868.7, buffer_add: 1012.8, buffer_size: 100011\n",
      "Total Time: 3H 20M 40S, 12040s\n",
      "Total Sample: train: 22.272M, buffer: 12.197M\n",
      "[347] Time spent = 34.64 s\n",
      "347:grad_norm[1000]: avg:   2.6606, min:   1.6236[ 396], max:   7.4165[ 985]\n",
      "347:loss     [1000]: avg:   7.1451, min:   5.4562[ 466], max:   9.5059[ 174]\n",
      "347:xent_pred[1000]: avg:   1.9130, min:   1.7714[ 966], max:   2.0467[ 549]\n",
      "347:xent_v0  [1000]: avg:   1.9097, min:   1.7757[ 966], max:   2.0441[  56]\n",
      "===================\n",
      "beginning of epoch:  348\n",
      "available: 2.745 GB, used: 25.908 GB, free: 2.553 GB\n",
      "EPOCH: 348\n",
      "mean score: 0.00\n",
      "Speed: train: 1829.6, buffer_add: 1015.0, buffer_size: 100023\n",
      "Total Time: 3H 21M 15S, 12075s\n",
      "Total Sample: train: 22.336M, buffer: 12.233M\n",
      "[348] Time spent = 35.36 s\n",
      "348:grad_norm[1000]: avg:   2.6556, min:   1.4768[ 684], max:   5.9938[ 420]\n",
      "348:loss     [1000]: avg:   7.1906, min:   5.1998[ 273], max:   9.3702[ 609]\n",
      "348:xent_pred[1000]: avg:   1.9142, min:   1.7492[ 742], max:   2.0487[ 504]\n",
      "348:xent_v0  [1000]: avg:   1.9114, min:   1.7518[ 742], max:   2.0498[ 504]\n",
      "===================\n",
      "beginning of epoch:  349\n",
      "available: 2.751 GB, used: 25.905 GB, free: 2.575 GB\n",
      "EPOCH: 349\n",
      "mean score: 0.00\n",
      "Speed: train: 1847.2, buffer_add: 1017.3, buffer_size: 100022\n",
      "Total Time: 3H 21M 49S, 12109s\n",
      "Total Sample: train: 22.4M, buffer: 12.268M\n",
      "[349] Time spent = 34.90 s\n",
      "349:grad_norm[1000]: avg:   2.6572, min:   1.5993[ 202], max:   5.1838[ 393]\n",
      "349:loss     [1000]: avg:   7.2190, min:   5.5469[ 408], max:   9.4659[ 699]\n",
      "349:xent_pred[1000]: avg:   1.9134, min:   1.7713[ 871], max:   2.0848[ 612]\n",
      "349:xent_v0  [1000]: avg:   1.9102, min:   1.7754[ 871], max:   2.0760[ 612]\n",
      "===================\n",
      "beginning of epoch:  350\n",
      "available: 2.747 GB, used: 25.910 GB, free: 2.613 GB\n",
      "EPOCH: 350\n",
      "mean score: 0.00\n",
      "Speed: train: 1832.6, buffer_add: 1003.6, buffer_size: 100035\n",
      "Total Time: 3H 22M 24S, 12144s\n",
      "Total Sample: train: 22.464M, buffer: 12.303M\n",
      "[350] Time spent = 35.33 s\n",
      "350:grad_norm[1000]: avg:   2.6711, min:   1.5985[ 341], max:   8.3936[ 402]\n",
      "350:loss     [1000]: avg:   7.1818, min:   5.3412[ 165], max:   9.6935[ 952]\n",
      "350:xent_pred[1000]: avg:   1.9158, min:   1.7283[ 109], max:   2.0701[ 878]\n",
      "350:xent_v0  [1000]: avg:   1.9130, min:   1.7317[ 239], max:   2.0649[ 878]\n",
      "===================\n",
      "beginning of epoch:  351\n",
      "available: 2.748 GB, used: 25.914 GB, free: 2.622 GB\n",
      "EPOCH: 351\n",
      "mean score: 0.00\n",
      "Speed: train: 1846.8, buffer_add: 1018.2, buffer_size: 100008\n",
      "Total Time: 3H 22M 59S, 12179s\n",
      "Total Sample: train: 22.528M, buffer: 12.338M\n",
      "[351] Time spent = 35.01 s\n",
      "351:grad_norm[1000]: avg:   2.6492, min:   1.5084[  95], max:   4.8303[ 438]\n",
      "351:loss     [1000]: avg:   7.1518, min:   5.0705[ 160], max:   9.1065[ 397]\n",
      "351:xent_pred[1000]: avg:   1.9184, min:   1.7538[ 211], max:   2.0741[ 460]\n",
      "351:xent_v0  [1000]: avg:   1.9151, min:   1.7531[ 211], max:   2.0700[ 460]\n",
      "===================\n",
      "beginning of epoch:  352\n",
      "available: 2.754 GB, used: 25.904 GB, free: 2.648 GB\n",
      "EPOCH: 352\n",
      "mean score: 0.00\n",
      "Speed: train: 1844.4, buffer_add: 1013.7, buffer_size: 100001\n",
      "Total Time: 3H 23M 34S, 12214s\n",
      "Total Sample: train: 22.592M, buffer: 12.373M\n",
      "[352] Time spent = 35.14 s\n",
      "352:grad_norm[1000]: avg:   2.6686, min:   1.4033[  88], max:   4.4358[ 776]\n",
      "352:loss     [1000]: avg:   7.1873, min:   5.0656[ 215], max:   9.3688[ 798]\n",
      "352:xent_pred[1000]: avg:   1.9171, min:   1.7746[  34], max:   2.0738[  93]\n",
      "352:xent_v0  [1000]: avg:   1.9141, min:   1.7813[  34], max:   2.0589[  93]\n",
      "===================\n",
      "beginning of epoch:  353\n",
      "available: 2.756 GB, used: 25.900 GB, free: 2.662 GB\n",
      "EPOCH: 353\n",
      "mean score: 0.00\n",
      "Speed: train: 1875.8, buffer_add: 1002.3, buffer_size: 100030\n",
      "Total Time: 3H 24M 08S, 12248s\n",
      "Total Sample: train: 22.656M, buffer: 12.408M\n",
      "[353] Time spent = 34.42 s\n",
      "353:grad_norm[1000]: avg:   2.6555, min:   1.6345[ 884], max:   4.8699[ 952]\n",
      "353:loss     [1000]: avg:   7.1827, min:   5.2301[ 497], max:   9.5934[ 804]\n",
      "353:xent_pred[1000]: avg:   1.9212, min:   1.7630[ 966], max:   2.0729[ 455]\n",
      "353:xent_v0  [1000]: avg:   1.9187, min:   1.7657[ 966], max:   2.0736[ 985]\n",
      "===================\n",
      "beginning of epoch:  354\n",
      "available: 2.751 GB, used: 25.904 GB, free: 2.732 GB\n",
      "EPOCH: 354\n",
      "mean score: 0.00\n",
      "Speed: train: 1820.6, buffer_add: 1008.0, buffer_size: 100023\n",
      "Total Time: 3H 24M 43S, 12283s\n",
      "Total Sample: train: 22.72M, buffer: 12.443M\n",
      "[354] Time spent = 35.43 s\n",
      "354:grad_norm[1000]: avg:   2.6308, min:   1.5097[ 342], max:   5.1676[ 694]\n",
      "354:loss     [1000]: avg:   7.2239, min:   4.8264[ 714], max:   9.9561[ 470]\n",
      "354:xent_pred[1000]: avg:   1.9173, min:   1.7652[ 467], max:   2.0668[ 754]\n",
      "354:xent_v0  [1000]: avg:   1.9150, min:   1.7594[ 467], max:   2.0724[ 754]\n",
      "===================\n",
      "beginning of epoch:  355\n",
      "available: 2.741 GB, used: 25.909 GB, free: 2.719 GB\n",
      "EPOCH: 355\n",
      "mean score: 0.00\n",
      "Speed: train: 1827.5, buffer_add: 1004.2, buffer_size: 100022\n",
      "Total Time: 3H 25M 18S, 12318s\n",
      "Total Sample: train: 22.784M, buffer: 12.478M\n",
      "[355] Time spent = 35.52 s\n",
      "355:grad_norm[1000]: avg:   2.6574, min:   1.5113[ 509], max:  15.1952[ 279]\n",
      "355:loss     [1000]: avg:   7.2190, min:   5.4343[ 549], max:   9.9148[ 935]\n",
      "355:xent_pred[1000]: avg:   1.9159, min:   1.7638[ 364], max:   2.0780[ 947]\n",
      "355:xent_v0  [1000]: avg:   1.9134, min:   1.7683[ 646], max:   2.0710[ 546]\n",
      "===================\n",
      "beginning of epoch:  356\n",
      "available: 2.738 GB, used: 25.921 GB, free: 2.685 GB\n",
      "EPOCH: 356\n",
      "mean score: 0.00\n",
      "Speed: train: 1839.1, buffer_add: 1016.9, buffer_size: 100011\n",
      "Total Time: 3H 25M 53S, 12353s\n",
      "Total Sample: train: 22.848M, buffer: 12.514M\n",
      "[356] Time spent = 35.17 s\n",
      "356:grad_norm[1000]: avg:   2.6950, min:   1.5323[ 682], max:   5.3174[ 856]\n",
      "356:loss     [1000]: avg:   7.2423, min:   5.2697[ 826], max:   9.8990[ 452]\n",
      "356:xent_pred[1000]: avg:   1.9114, min:   1.7590[ 129], max:   2.1352[ 730]\n",
      "356:xent_v0  [1000]: avg:   1.9090, min:   1.7560[ 129], max:   2.1163[ 730]\n",
      "===================\n",
      "beginning of epoch:  357\n",
      "available: 2.748 GB, used: 25.910 GB, free: 2.657 GB\n",
      "EPOCH: 357\n",
      "mean score: 0.00\n",
      "Speed: train: 1861.3, buffer_add: 1024.5, buffer_size: 100032\n",
      "Total Time: 3H 26M 27S, 12387s\n",
      "Total Sample: train: 22.912M, buffer: 12.549M\n",
      "[357] Time spent = 34.83 s\n",
      "357:grad_norm[1000]: avg:   2.6520, min:   1.5636[ 111], max:   4.9867[ 804]\n",
      "357:loss     [1000]: avg:   7.2171, min:   5.3698[ 589], max:   9.7435[ 447]\n",
      "357:xent_pred[1000]: avg:   1.9123, min:   1.7771[ 447], max:   2.0843[ 207]\n",
      "357:xent_v0  [1000]: avg:   1.9090, min:   1.7755[ 447], max:   2.0810[ 207]\n",
      "===================\n",
      "beginning of epoch:  358\n",
      "available: 2.746 GB, used: 25.909 GB, free: 2.710 GB\n",
      "EPOCH: 358\n",
      "mean score: 0.00\n",
      "Speed: train: 1883.9, buffer_add: 1021.2, buffer_size: 100038\n",
      "Total Time: 3H 27M 01S, 12421s\n",
      "Total Sample: train: 22.976M, buffer: 12.583M\n",
      "[358] Time spent = 34.47 s\n",
      "358:grad_norm[1000]: avg:   2.6728, min:   1.5174[ 629], max:   6.0044[ 124]\n",
      "358:loss     [1000]: avg:   7.1962, min:   5.3948[ 615], max:   9.4616[ 815]\n",
      "358:xent_pred[1000]: avg:   1.9166, min:   1.7208[ 136], max:   2.0793[ 542]\n",
      "358:xent_v0  [1000]: avg:   1.9138, min:   1.7154[ 136], max:   2.0668[ 542]\n",
      "===================\n",
      "beginning of epoch:  359\n",
      "available: 2.747 GB, used: 25.908 GB, free: 2.705 GB\n",
      "EPOCH: 359\n",
      "mean score: 0.00\n",
      "Speed: train: 1863.6, buffer_add: 1024.7, buffer_size: 100073\n",
      "Total Time: 3H 27M 35S, 12455s\n",
      "Total Sample: train: 23.04M, buffer: 12.619M\n",
      "[359] Time spent = 34.79 s\n",
      "359:grad_norm[1000]: avg:   2.6748, min:   1.5785[  88], max:   5.2524[ 377]\n",
      "359:loss     [1000]: avg:   7.2134, min:   5.3637[ 854], max:   9.9106[ 494]\n",
      "359:xent_pred[1000]: avg:   1.9147, min:   1.7283[ 317], max:   2.0579[ 463]\n",
      "359:xent_v0  [1000]: avg:   1.9119, min:   1.7447[ 317], max:   2.0477[ 135]\n",
      "===================\n",
      "beginning of epoch:  360\n",
      "available: 2.744 GB, used: 25.910 GB, free: 2.658 GB\n",
      "EPOCH: 360\n",
      "mean score: 0.00\n",
      "Speed: train: 1838.2, buffer_add: 1014.8, buffer_size: 100056\n",
      "Total Time: 3H 28M 10S, 12490s\n",
      "Total Sample: train: 23.104M, buffer: 12.654M\n",
      "[360] Time spent = 35.31 s\n",
      "360:grad_norm[1000]: avg:   2.6603, min:   1.5975[ 176], max:   4.4502[ 532]\n",
      "360:loss     [1000]: avg:   7.1843, min:   5.4337[  82], max:   9.9318[ 823]\n",
      "360:xent_pred[1000]: avg:   1.9167, min:   1.7327[  31], max:   2.0483[ 147]\n",
      "360:xent_v0  [1000]: avg:   1.9143, min:   1.7376[  31], max:   2.0575[ 679]\n",
      "===================\n",
      "beginning of epoch:  361\n",
      "available: 2.749 GB, used: 25.908 GB, free: 2.667 GB\n",
      "EPOCH: 361\n",
      "mean score: 0.00\n",
      "Speed: train: 1866.3, buffer_add: 1016.7, buffer_size: 100035\n",
      "Total Time: 3H 28M 45S, 12525s\n",
      "Total Sample: train: 23.168M, buffer: 12.689M\n",
      "[361] Time spent = 34.67 s\n",
      "361:grad_norm[1000]: avg:   2.6716, min:   1.6043[ 248], max:   5.5839[ 700]\n",
      "361:loss     [1000]: avg:   7.1957, min:   5.2893[  59], max:   9.9409[ 948]\n",
      "361:xent_pred[1000]: avg:   1.9133, min:   1.7877[ 663], max:   2.0862[ 955]\n",
      "361:xent_v0  [1000]: avg:   1.9105, min:   1.7843[ 663], max:   2.0748[ 955]\n",
      "===================\n",
      "beginning of epoch:  362\n",
      "available: 2.737 GB, used: 25.919 GB, free: 2.657 GB\n",
      "EPOCH: 362\n",
      "mean score: 0.00\n",
      "Speed: train: 1862.0, buffer_add: 1005.5, buffer_size: 99997\n",
      "Total Time: 3H 29M 19S, 12559s\n",
      "Total Sample: train: 23.232M, buffer: 12.723M\n",
      "[362] Time spent = 34.75 s\n",
      "362:grad_norm[1000]: avg:   2.6385, min:   1.5092[ 309], max:   6.3052[ 527]\n",
      "362:loss     [1000]: avg:   7.1953, min:   5.3024[ 611], max:   9.5405[ 552]\n",
      "362:xent_pred[1000]: avg:   1.9139, min:   1.7710[ 155], max:   2.0747[ 937]\n",
      "362:xent_v0  [1000]: avg:   1.9108, min:   1.7672[ 906], max:   2.0654[ 937]\n",
      "===================\n",
      "beginning of epoch:  363\n",
      "available: 2.754 GB, used: 25.907 GB, free: 2.686 GB\n",
      "EPOCH: 363\n",
      "mean score: 0.00\n",
      "Speed: train: 1869.0, buffer_add: 1007.2, buffer_size: 100016\n",
      "Total Time: 3H 29M 53S, 12593s\n",
      "Total Sample: train: 23.296M, buffer: 12.758M\n",
      "[363] Time spent = 34.65 s\n",
      "363:grad_norm[1000]: avg:   2.6212, min:   1.5188[ 144], max:   4.2813[ 683]\n",
      "363:loss     [1000]: avg:   7.1092, min:   5.0518[ 981], max:   9.2554[ 295]\n",
      "363:xent_pred[1000]: avg:   1.9155, min:   1.7511[ 836], max:   2.0475[ 518]\n",
      "363:xent_v0  [1000]: avg:   1.9130, min:   1.7382[ 836], max:   2.0386[ 518]\n",
      "===================\n",
      "beginning of epoch:  364\n",
      "available: 2.742 GB, used: 25.915 GB, free: 2.661 GB\n",
      "EPOCH: 364\n",
      "mean score: 0.00\n",
      "Speed: train: 1821.9, buffer_add: 1010.7, buffer_size: 100008\n",
      "Total Time: 3H 30M 28S, 12628s\n",
      "Total Sample: train: 23.36M, buffer: 12.793M\n",
      "[364] Time spent = 35.60 s\n",
      "364:grad_norm[1000]: avg:   2.5844, min:   1.6387[ 994], max:   4.7767[ 226]\n",
      "364:loss     [1000]: avg:   7.1530, min:   5.2903[ 294], max:   9.0071[ 621]\n",
      "364:xent_pred[1000]: avg:   1.9151, min:   1.7663[ 772], max:   2.0949[ 190]\n",
      "364:xent_v0  [1000]: avg:   1.9120, min:   1.7619[ 818], max:   2.0996[ 190]\n",
      "===================\n",
      "beginning of epoch:  365\n",
      "available: 2.746 GB, used: 25.910 GB, free: 2.691 GB\n",
      "EPOCH: 365\n",
      "mean score: 0.00\n",
      "Speed: train: 1832.1, buffer_add: 1015.4, buffer_size: 100028\n",
      "Total Time: 3H 31M 03S, 12663s\n",
      "Total Sample: train: 23.424M, buffer: 12.829M\n",
      "[365] Time spent = 35.30 s\n",
      "365:grad_norm[1000]: avg:   2.6176, min:   1.4706[ 747], max:   4.8056[ 516]\n",
      "365:loss     [1000]: avg:   7.2209, min:   5.0391[ 747], max:   9.1594[ 141]\n",
      "365:xent_pred[1000]: avg:   1.9129, min:   1.7375[ 801], max:   2.0435[ 194]\n",
      "365:xent_v0  [1000]: avg:   1.9103, min:   1.7258[ 801], max:   2.0374[ 268]\n",
      "===================\n",
      "beginning of epoch:  366\n",
      "available: 2.742 GB, used: 25.913 GB, free: 2.674 GB\n",
      "EPOCH: 366\n",
      "mean score: 0.00\n",
      "Speed: train: 1860.4, buffer_add: 1010.8, buffer_size: 100015\n",
      "Total Time: 3H 31M 38S, 12698s\n",
      "Total Sample: train: 23.488M, buffer: 12.864M\n",
      "[366] Time spent = 34.73 s\n",
      "366:grad_norm[1000]: avg:   2.6085, min:   1.4985[ 763], max:   4.4035[ 262]\n",
      "366:loss     [1000]: avg:   7.2137, min:   5.2536[ 238], max:   9.7968[ 262]\n",
      "366:xent_pred[1000]: avg:   1.9120, min:   1.7389[ 133], max:   2.0500[ 816]\n",
      "366:xent_v0  [1000]: avg:   1.9097, min:   1.7355[ 106], max:   2.0538[ 816]\n",
      "===================\n",
      "beginning of epoch:  367\n",
      "available: 2.741 GB, used: 25.917 GB, free: 2.677 GB\n",
      "EPOCH: 367\n",
      "mean score: 0.00\n",
      "Speed: train: 1888.9, buffer_add: 1007.0, buffer_size: 100013\n",
      "Total Time: 3H 32M 12S, 12732s\n",
      "Total Sample: train: 23.552M, buffer: 12.898M\n",
      "[367] Time spent = 34.20 s\n",
      "367:grad_norm[1000]: avg:   2.6142, min:   1.4171[ 850], max:   7.5488[ 580]\n",
      "367:loss     [1000]: avg:   7.2005, min:   5.1134[ 769], max:   9.4688[ 248]\n",
      "367:xent_pred[1000]: avg:   1.9128, min:   1.7651[ 714], max:   2.0702[ 408]\n",
      "367:xent_v0  [1000]: avg:   1.9107, min:   1.7624[ 714], max:   2.0590[ 402]\n",
      "===================\n",
      "beginning of epoch:  368\n",
      "available: 2.737 GB, used: 25.914 GB, free: 2.701 GB\n",
      "EPOCH: 368\n",
      "mean score: 0.00\n",
      "Speed: train: 1859.9, buffer_add: 1013.8, buffer_size: 100055\n",
      "Total Time: 3H 32M 46S, 12766s\n",
      "Total Sample: train: 23.616M, buffer: 12.933M\n",
      "[368] Time spent = 34.81 s\n",
      "368:grad_norm[1000]: avg:   2.6349, min:   1.5754[ 578], max:   6.0312[  38]\n",
      "368:loss     [1000]: avg:   7.2300, min:   5.5174[ 481], max:   9.9426[ 342]\n",
      "368:xent_pred[1000]: avg:   1.9132, min:   1.7587[ 185], max:   2.0877[ 250]\n",
      "368:xent_v0  [1000]: avg:   1.9106, min:   1.7584[ 185], max:   2.0948[ 250]\n",
      "===================\n",
      "beginning of epoch:  369\n",
      "available: 2.747 GB, used: 25.915 GB, free: 2.655 GB\n",
      "EPOCH: 369\n",
      "mean score: 0.00\n",
      "Speed: train: 1856.5, buffer_add: 1013.6, buffer_size: 100029\n",
      "Total Time: 3H 33M 20S, 12800s\n",
      "Total Sample: train: 23.68M, buffer: 12.968M\n",
      "[369] Time spent = 34.68 s\n",
      "369:grad_norm[1000]: avg:   2.6256, min:   1.5724[ 533], max:   4.2262[  88]\n",
      "369:loss     [1000]: avg:   7.2006, min:   5.3247[ 533], max:   9.2586[ 306]\n",
      "369:xent_pred[1000]: avg:   1.9135, min:   1.7626[ 734], max:   2.0667[  40]\n",
      "369:xent_v0  [1000]: avg:   1.9114, min:   1.7582[ 512], max:   2.0636[  40]\n",
      "===================\n",
      "beginning of epoch:  370\n",
      "available: 2.750 GB, used: 25.904 GB, free: 2.713 GB\n",
      "EPOCH: 370\n",
      "mean score: 0.00\n",
      "Speed: train: 1872.8, buffer_add: 1015.0, buffer_size: 100035\n",
      "Total Time: 3H 33M 55S, 12835s\n",
      "Total Sample: train: 23.744M, buffer: 13.002M\n",
      "[370] Time spent = 34.54 s\n",
      "370:grad_norm[1000]: avg:   2.6077, min:   1.4045[ 358], max:   4.4462[ 109]\n",
      "370:loss     [1000]: avg:   7.1677, min:   5.2440[ 260], max:   9.4080[ 877]\n",
      "370:xent_pred[1000]: avg:   1.9166, min:   1.7510[ 720], max:   2.0768[ 198]\n",
      "370:xent_v0  [1000]: avg:   1.9139, min:   1.7389[ 720], max:   2.0745[ 198]\n",
      "===================\n",
      "beginning of epoch:  371\n",
      "available: 2.739 GB, used: 25.916 GB, free: 2.675 GB\n",
      "EPOCH: 371\n",
      "mean score: 0.00\n",
      "Speed: train: 1833.6, buffer_add: 1022.6, buffer_size: 100046\n",
      "Total Time: 3H 34M 30S, 12870s\n",
      "Total Sample: train: 23.808M, buffer: 13.038M\n",
      "[371] Time spent = 35.14 s\n",
      "371:grad_norm[1000]: avg:   2.6251, min:   1.4831[ 777], max:   5.5367[ 128]\n",
      "371:loss     [1000]: avg:   7.1487, min:   5.1538[ 361], max:   9.4612[ 752]\n",
      "371:xent_pred[1000]: avg:   1.9166, min:   1.7723[ 475], max:   2.0937[  17]\n",
      "371:xent_v0  [1000]: avg:   1.9142, min:   1.7683[ 475], max:   2.0955[  17]\n",
      "===================\n",
      "beginning of epoch:  372\n",
      "available: 2.738 GB, used: 25.919 GB, free: 2.649 GB\n",
      "EPOCH: 372\n",
      "mean score: 0.00\n",
      "Speed: train: 1851.7, buffer_add: 1000.6, buffer_size: 100018\n",
      "Total Time: 3H 35M 04S, 12904s\n",
      "Total Sample: train: 23.872M, buffer: 13.073M\n",
      "[372] Time spent = 35.10 s\n",
      "372:grad_norm[1000]: avg:   2.6038, min:   1.5702[ 508], max:   4.3330[ 770]\n",
      "372:loss     [1000]: avg:   7.1693, min:   4.9984[ 106], max:   9.4073[ 897]\n",
      "372:xent_pred[1000]: avg:   1.9179, min:   1.7704[  27], max:   2.0563[  87]\n",
      "372:xent_v0  [1000]: avg:   1.9153, min:   1.7744[  27], max:   2.0561[ 508]\n",
      "===================\n",
      "beginning of epoch:  373\n",
      "available: 2.742 GB, used: 25.922 GB, free: 2.640 GB\n",
      "EPOCH: 373\n",
      "mean score: 0.00\n",
      "Speed: train: 1853.5, buffer_add: 1018.5, buffer_size: 100043\n",
      "Total Time: 3H 35M 39S, 12939s\n",
      "Total Sample: train: 23.936M, buffer: 13.108M\n",
      "[373] Time spent = 34.98 s\n",
      "373:grad_norm[1000]: avg:   2.5776, min:   1.5666[ 500], max:   5.6442[  49]\n",
      "373:loss     [1000]: avg:   7.1401, min:   4.8352[ 188], max:   9.8259[ 271]\n",
      "373:xent_pred[1000]: avg:   1.9181, min:   1.7383[ 671], max:   2.0694[ 554]\n",
      "373:xent_v0  [1000]: avg:   1.9161, min:   1.7399[ 671], max:   2.0614[ 554]\n",
      "===================\n",
      "beginning of epoch:  374\n",
      "available: 2.742 GB, used: 25.919 GB, free: 2.633 GB\n",
      "EPOCH: 374\n",
      "mean score: 0.00\n",
      "Speed: train: 1838.2, buffer_add: 1008.6, buffer_size: 100039\n",
      "Total Time: 3H 36M 13S, 12973s\n",
      "Total Sample: train: 24M, buffer: 13.143M\n",
      "[374] Time spent = 35.20 s\n",
      "374:grad_norm[1000]: avg:   2.5879, min:   1.4678[ 993], max:   4.8567[ 442]\n",
      "374:loss     [1000]: avg:   7.1687, min:   5.1123[ 196], max:   9.3697[ 913]\n",
      "374:xent_pred[1000]: avg:   1.9168, min:   1.7320[ 920], max:   2.0676[  24]\n",
      "374:xent_v0  [1000]: avg:   1.9141, min:   1.7390[ 920], max:   2.0620[  24]\n",
      "===================\n",
      "beginning of epoch:  375\n",
      "available: 2.739 GB, used: 25.921 GB, free: 2.640 GB\n",
      "EPOCH: 375\n",
      "mean score: 0.00\n",
      "Speed: train: 1821.4, buffer_add: 1018.7, buffer_size: 100042\n",
      "Total Time: 3H 36M 49S, 13009s\n",
      "Total Sample: train: 24.064M, buffer: 13.179M\n",
      "[375] Time spent = 35.84 s\n",
      "375:grad_norm[1000]: avg:   2.5725, min:   1.4564[ 923], max:   4.5738[ 425]\n",
      "375:loss     [1000]: avg:   7.1801, min:   5.2209[ 982], max:   9.4200[ 149]\n",
      "375:xent_pred[1000]: avg:   1.9163, min:   1.7830[ 971], max:   2.0761[  79]\n",
      "375:xent_v0  [1000]: avg:   1.9134, min:   1.7682[ 163], max:   2.0725[  79]\n",
      "===================\n",
      "beginning of epoch:  376\n",
      "available: 2.737 GB, used: 25.925 GB, free: 2.665 GB\n",
      "EPOCH: 376\n",
      "mean score: 0.00\n",
      "Speed: train: 1886.0, buffer_add: 1025.7, buffer_size: 100037\n",
      "Total Time: 3H 37M 22S, 13042s\n",
      "Total Sample: train: 24.128M, buffer: 13.213M\n",
      "[376] Time spent = 34.36 s\n",
      "376:grad_norm[1000]: avg:   2.5807, min:   1.4843[ 791], max:   5.0458[ 422]\n",
      "376:loss     [1000]: avg:   7.1565, min:   5.3587[ 716], max:   9.6433[ 153]\n",
      "376:xent_pred[1000]: avg:   1.9160, min:   1.7685[ 764], max:   2.0674[ 717]\n",
      "376:xent_v0  [1000]: avg:   1.9133, min:   1.7689[ 414], max:   2.0525[ 717]\n",
      "===================\n",
      "beginning of epoch:  377\n",
      "available: 2.740 GB, used: 25.921 GB, free: 2.704 GB\n",
      "EPOCH: 377\n",
      "mean score: 0.00\n",
      "Speed: train: 1887.2, buffer_add: 1015.8, buffer_size: 100045\n",
      "Total Time: 3H 37M 56S, 13076s\n",
      "Total Sample: train: 24.192M, buffer: 13.248M\n",
      "[377] Time spent = 34.50 s\n",
      "377:grad_norm[1000]: avg:   2.5838, min:   1.3842[ 657], max:   4.3058[ 398]\n",
      "377:loss     [1000]: avg:   7.1727, min:   5.0255[ 412], max:   9.3383[ 787]\n",
      "377:xent_pred[1000]: avg:   1.9157, min:   1.6973[ 711], max:   2.0495[ 689]\n",
      "377:xent_v0  [1000]: avg:   1.9133, min:   1.7035[ 711], max:   2.0476[ 689]\n",
      "===================\n",
      "beginning of epoch:  378\n",
      "available: 2.745 GB, used: 25.912 GB, free: 2.692 GB\n",
      "EPOCH: 378\n",
      "mean score: 0.00\n",
      "Speed: train: 1859.7, buffer_add: 1018.4, buffer_size: 100031\n",
      "Total Time: 3H 38M 31S, 13111s\n",
      "Total Sample: train: 24.256M, buffer: 13.283M\n",
      "[378] Time spent = 34.75 s\n",
      "378:grad_norm[1000]: avg:   2.6165, min:   1.5592[ 279], max:   5.5025[  29]\n",
      "378:loss     [1000]: avg:   7.1709, min:   5.4290[ 723], max:   9.8634[ 898]\n",
      "378:xent_pred[1000]: avg:   1.9145, min:   1.7839[ 947], max:   2.0951[ 613]\n",
      "378:xent_v0  [1000]: avg:   1.9119, min:   1.7691[ 947], max:   2.0827[ 613]\n",
      "===================\n",
      "beginning of epoch:  379\n",
      "available: 2.731 GB, used: 25.922 GB, free: 2.674 GB\n",
      "EPOCH: 379\n",
      "mean score: 0.00\n",
      "Speed: train: 1850.0, buffer_add: 1018.7, buffer_size: 100030\n",
      "Total Time: 3H 39M 05S, 13145s\n",
      "Total Sample: train: 24.32M, buffer: 13.318M\n",
      "[379] Time spent = 34.85 s\n",
      "379:grad_norm[1000]: avg:   2.6117, min:   1.5128[ 914], max:   5.2164[ 504]\n",
      "379:loss     [1000]: avg:   7.1768, min:   5.2920[  74], max:   9.5375[ 226]\n",
      "379:xent_pred[1000]: avg:   1.9150, min:   1.7515[ 857], max:   2.0480[ 993]\n",
      "379:xent_v0  [1000]: avg:   1.9123, min:   1.7505[ 857], max:   2.0507[ 577]\n",
      "===================\n",
      "beginning of epoch:  380\n",
      "available: 2.735 GB, used: 25.922 GB, free: 2.640 GB\n",
      "EPOCH: 380\n",
      "mean score: 0.00\n",
      "Speed: train: 1862.8, buffer_add: 1007.7, buffer_size: 100014\n",
      "Total Time: 3H 39M 40S, 13180s\n",
      "Total Sample: train: 24.384M, buffer: 13.353M\n",
      "[380] Time spent = 34.80 s\n",
      "380:grad_norm[1000]: avg:   2.5623, min:   1.1694[ 750], max:   5.2438[ 673]\n",
      "380:loss     [1000]: avg:   7.1471, min:   4.9656[ 750], max:   9.3688[ 469]\n",
      "380:xent_pred[1000]: avg:   1.9184, min:   1.7600[ 649], max:   2.0566[ 329]\n",
      "380:xent_v0  [1000]: avg:   1.9162, min:   1.7551[ 649], max:   2.0592[ 320]\n",
      "===================\n",
      "beginning of epoch:  381\n",
      "available: 2.738 GB, used: 25.927 GB, free: 2.598 GB\n",
      "EPOCH: 381\n",
      "mean score: 0.00\n",
      "Speed: train: 1828.9, buffer_add: 1015.7, buffer_size: 100021\n",
      "Total Time: 3H 40M 15S, 13215s\n",
      "Total Sample: train: 24.448M, buffer: 13.388M\n",
      "[381] Time spent = 35.40 s\n",
      "381:grad_norm[1000]: avg:   2.5661, min:   1.5160[ 795], max:   6.9080[ 558]\n",
      "381:loss     [1000]: avg:   7.1850, min:   5.1832[ 299], max:   9.2928[ 798]\n",
      "381:xent_pred[1000]: avg:   1.9200, min:   1.6802[ 810], max:   2.0684[  15]\n",
      "381:xent_v0  [1000]: avg:   1.9175, min:   1.6848[ 810], max:   2.0768[  15]\n",
      "===================\n",
      "beginning of epoch:  382\n",
      "available: 2.734 GB, used: 25.926 GB, free: 2.654 GB\n",
      "EPOCH: 382\n",
      "mean score: 0.00\n",
      "Speed: train: 1865.7, buffer_add: 1010.2, buffer_size: 100029\n",
      "Total Time: 3H 40M 49S, 13249s\n",
      "Total Sample: train: 24.512M, buffer: 13.423M\n",
      "[382] Time spent = 34.61 s\n",
      "382:grad_norm[1000]: avg:   2.5646, min:   1.6128[ 788], max:   4.6359[ 193]\n",
      "382:loss     [1000]: avg:   7.2058, min:   5.1094[ 673], max:  10.0535[ 968]\n",
      "382:xent_pred[1000]: avg:   1.9198, min:   1.7715[ 352], max:   2.0486[ 958]\n",
      "382:xent_v0  [1000]: avg:   1.9171, min:   1.7747[ 352], max:   2.0381[ 958]\n",
      "===================\n",
      "beginning of epoch:  383\n",
      "available: 2.732 GB, used: 25.925 GB, free: 2.698 GB\n",
      "EPOCH: 383\n",
      "mean score: 0.00\n",
      "Speed: train: 1875.6, buffer_add: 1011.9, buffer_size: 100049\n",
      "Total Time: 3H 41M 23S, 13283s\n",
      "Total Sample: train: 24.576M, buffer: 13.458M\n",
      "[383] Time spent = 34.52 s\n",
      "383:grad_norm[1000]: avg:   2.5698, min:   1.5348[ 822], max:   5.3133[ 217]\n",
      "383:loss     [1000]: avg:   7.2119, min:   5.1339[ 911], max:   9.2093[ 931]\n",
      "383:xent_pred[1000]: avg:   1.9169, min:   1.7648[ 735], max:   2.0871[ 608]\n",
      "383:xent_v0  [1000]: avg:   1.9143, min:   1.7561[ 735], max:   2.0838[ 608]\n",
      "===================\n",
      "beginning of epoch:  384\n",
      "available: 2.733 GB, used: 25.922 GB, free: 2.692 GB\n",
      "EPOCH: 384\n",
      "mean score: 0.00\n",
      "Speed: train: 1842.7, buffer_add: 1014.4, buffer_size: 100017\n",
      "Total Time: 3H 41M 58S, 13318s\n",
      "Total Sample: train: 24.64M, buffer: 13.493M\n",
      "[384] Time spent = 35.18 s\n",
      "384:grad_norm[1000]: avg:   2.5480, min:   1.4521[ 920], max:   4.5409[ 805]\n",
      "384:loss     [1000]: avg:   7.2011, min:   5.2605[ 609], max:   9.5201[ 463]\n",
      "384:xent_pred[1000]: avg:   1.9176, min:   1.7131[ 359], max:   2.0424[ 864]\n",
      "384:xent_v0  [1000]: avg:   1.9151, min:   1.6993[ 359], max:   2.0404[ 864]\n",
      "===================\n",
      "beginning of epoch:  385\n",
      "available: 2.735 GB, used: 25.926 GB, free: 2.674 GB\n",
      "EPOCH: 385\n",
      "mean score: 0.00\n",
      "Speed: train: 1868.0, buffer_add: 1015.0, buffer_size: 100033\n",
      "Total Time: 3H 42M 32S, 13352s\n",
      "Total Sample: train: 24.704M, buffer: 13.528M\n",
      "[385] Time spent = 34.64 s\n",
      "385:grad_norm[1000]: avg:   2.5710, min:   1.4145[ 397], max:  10.2487[ 113]\n",
      "385:loss     [1000]: avg:   7.1731, min:   5.1178[  30], max:   9.2627[ 606]\n",
      "385:xent_pred[1000]: avg:   1.9168, min:   1.7602[ 867], max:   2.0881[ 225]\n",
      "385:xent_v0  [1000]: avg:   1.9141, min:   1.7629[ 867], max:   2.0801[ 619]\n",
      "===================\n",
      "beginning of epoch:  386\n",
      "available: 2.732 GB, used: 25.924 GB, free: 2.685 GB\n",
      "EPOCH: 386\n",
      "mean score: 0.00\n",
      "Speed: train: 1846.7, buffer_add: 1016.6, buffer_size: 100034\n",
      "Total Time: 3H 43M 07S, 13387s\n",
      "Total Sample: train: 24.768M, buffer: 13.563M\n",
      "[386] Time spent = 35.00 s\n",
      "386:grad_norm[1000]: avg:   2.5536, min:   1.4195[ 132], max:   4.4668[  19]\n",
      "386:loss     [1000]: avg:   7.1669, min:   5.0905[ 113], max:   9.1962[ 750]\n",
      "386:xent_pred[1000]: avg:   1.9180, min:   1.7493[ 993], max:   2.0707[ 546]\n",
      "386:xent_v0  [1000]: avg:   1.9154, min:   1.7413[ 993], max:   2.0795[ 968]\n",
      "===================\n",
      "beginning of epoch:  387\n",
      "available: 2.742 GB, used: 25.915 GB, free: 2.717 GB\n",
      "EPOCH: 387\n",
      "mean score: 0.00\n",
      "Speed: train: 1855.8, buffer_add: 1016.1, buffer_size: 100045\n",
      "Total Time: 3H 43M 41S, 13421s\n",
      "Total Sample: train: 24.832M, buffer: 13.598M\n",
      "[387] Time spent = 35.00 s\n",
      "387:grad_norm[1000]: avg:   2.5495, min:   1.5022[ 314], max:   7.1071[ 712]\n",
      "387:loss     [1000]: avg:   7.1468, min:   5.1391[ 169], max:   9.8797[ 619]\n",
      "387:xent_pred[1000]: avg:   1.9131, min:   1.7452[ 706], max:   2.0699[ 948]\n",
      "387:xent_v0  [1000]: avg:   1.9112, min:   1.7509[ 706], max:   2.0745[ 948]\n",
      "===================\n",
      "beginning of epoch:  388\n",
      "available: 2.735 GB, used: 25.918 GB, free: 2.699 GB\n",
      "EPOCH: 388\n",
      "mean score: 0.00\n",
      "Speed: train: 1853.3, buffer_add: 1006.4, buffer_size: 100054\n",
      "Total Time: 3H 44M 16S, 13456s\n",
      "Total Sample: train: 24.896M, buffer: 13.633M\n",
      "[388] Time spent = 34.91 s\n",
      "388:grad_norm[1000]: avg:   2.5571, min:   1.5567[ 915], max:   4.4231[  72]\n",
      "388:loss     [1000]: avg:   7.1433, min:   5.2194[ 672], max:   9.0214[ 457]\n",
      "388:xent_pred[1000]: avg:   1.9181, min:   1.7498[ 604], max:   2.0746[ 762]\n",
      "388:xent_v0  [1000]: avg:   1.9156, min:   1.7465[ 604], max:   2.0754[ 762]\n",
      "===================\n",
      "beginning of epoch:  389\n",
      "available: 2.734 GB, used: 25.917 GB, free: 2.706 GB\n",
      "EPOCH: 389\n",
      "mean score: 0.00\n",
      "Speed: train: 1833.4, buffer_add: 987.4, buffer_size: 100029\n",
      "Total Time: 3H 44M 51S, 13491s\n",
      "Total Sample: train: 24.96M, buffer: 13.667M\n",
      "[389] Time spent = 35.23 s\n",
      "389:grad_norm[1000]: avg:   2.5869, min:   1.3896[ 242], max:   8.1536[ 531]\n",
      "389:loss     [1000]: avg:   7.1644, min:   4.7741[  48], max:  10.2162[ 410]\n",
      "389:xent_pred[1000]: avg:   1.9168, min:   1.7517[ 207], max:   2.0611[ 514]\n",
      "389:xent_v0  [1000]: avg:   1.9144, min:   1.7571[ 207], max:   2.0692[  48]\n",
      "===================\n",
      "beginning of epoch:  390\n",
      "available: 2.741 GB, used: 25.920 GB, free: 2.640 GB\n",
      "EPOCH: 390\n",
      "mean score: 0.00\n",
      "Speed: train: 1852.5, buffer_add: 999.3, buffer_size: 100020\n",
      "Total Time: 3H 45M 25S, 13525s\n",
      "Total Sample: train: 25.024M, buffer: 13.702M\n",
      "[390] Time spent = 34.95 s\n",
      "390:grad_norm[1000]: avg:   2.5515, min:   1.4677[ 469], max:   4.9462[ 341]\n",
      "390:loss     [1000]: avg:   7.1644, min:   5.2607[  16], max:   9.4326[ 408]\n",
      "390:xent_pred[1000]: avg:   1.9167, min:   1.7643[ 803], max:   2.0656[ 371]\n",
      "390:xent_v0  [1000]: avg:   1.9143, min:   1.7634[ 803], max:   2.0647[ 371]\n",
      "===================\n",
      "beginning of epoch:  391\n",
      "available: 2.736 GB, used: 25.918 GB, free: 2.667 GB\n",
      "EPOCH: 391\n",
      "mean score: 0.00\n",
      "Speed: train: 1850.2, buffer_add: 984.2, buffer_size: 100040\n",
      "Total Time: 3H 46M 00S, 13560s\n",
      "Total Sample: train: 25.088M, buffer: 13.736M\n",
      "[391] Time spent = 35.05 s\n",
      "391:grad_norm[1000]: avg:   2.5501, min:   1.4808[ 531], max:   4.0005[ 491]\n",
      "391:loss     [1000]: avg:   7.2022, min:   5.0208[ 246], max:   9.2025[ 611]\n",
      "391:xent_pred[1000]: avg:   1.9159, min:   1.7782[  48], max:   2.0771[ 836]\n",
      "391:xent_v0  [1000]: avg:   1.9138, min:   1.7816[  48], max:   2.0667[  51]\n",
      "===================\n",
      "beginning of epoch:  392\n",
      "available: 2.735 GB, used: 25.917 GB, free: 2.706 GB\n",
      "EPOCH: 392\n",
      "mean score: 0.01\n",
      "Speed: train: 1834.0, buffer_add: 977.6, buffer_size: 100085\n",
      "Total Time: 3H 46M 35S, 13595s\n",
      "Total Sample: train: 25.152M, buffer: 13.77M\n",
      "[392] Time spent = 35.47 s\n",
      "392:grad_norm[1000]: avg:   2.5618, min:   1.5739[  84], max:   4.9789[ 904]\n",
      "392:loss     [1000]: avg:   7.2005, min:   5.1921[ 795], max:   9.1926[ 215]\n",
      "392:xent_pred[1000]: avg:   1.9135, min:   1.7502[ 192], max:   2.0532[ 237]\n",
      "392:xent_v0  [1000]: avg:   1.9110, min:   1.7548[ 641], max:   2.0508[ 164]\n",
      "===================\n",
      "beginning of epoch:  393\n",
      "available: 2.726 GB, used: 25.924 GB, free: 2.682 GB\n",
      "EPOCH: 393\n",
      "mean score: 0.00\n",
      "Speed: train: 1896.1, buffer_add: 985.9, buffer_size: 100045\n",
      "Total Time: 3H 47M 09S, 13629s\n",
      "Total Sample: train: 25.216M, buffer: 13.803M\n",
      "[393] Time spent = 34.37 s\n",
      "393:grad_norm[1000]: avg:   2.6008, min:   1.6281[ 372], max:   9.8063[  18]\n",
      "393:loss     [1000]: avg:   7.1979, min:   5.1049[ 362], max:   9.1668[ 600]\n",
      "393:xent_pred[1000]: avg:   1.9155, min:   1.7457[ 449], max:   2.0646[ 550]\n",
      "393:xent_v0  [1000]: avg:   1.9129, min:   1.7499[ 449], max:   2.0596[ 723]\n",
      "===================\n",
      "beginning of epoch:  394\n",
      "available: 2.723 GB, used: 25.933 GB, free: 2.744 GB\n",
      "EPOCH: 394\n",
      "mean score: 0.00\n",
      "Speed: train: 1731.2, buffer_add: 901.0, buffer_size: 100062\n",
      "Total Time: 3H 47M 46S, 13666s\n",
      "Total Sample: train: 25.28M, buffer: 13.836M\n",
      "[394] Time spent = 37.37 s\n",
      "394:grad_norm[1000]: avg:   2.5589, min:   1.5322[  87], max:   4.2754[ 919]\n",
      "394:loss     [1000]: avg:   7.1886, min:   5.2653[ 305], max:   9.6084[ 331]\n",
      "394:xent_pred[1000]: avg:   1.9162, min:   1.7302[ 412], max:   2.0945[ 902]\n",
      "394:xent_v0  [1000]: avg:   1.9137, min:   1.7226[ 412], max:   2.0992[ 902]\n",
      "===================\n",
      "beginning of epoch:  395\n",
      "available: 2.711 GB, used: 25.943 GB, free: 2.676 GB\n",
      "EPOCH: 395\n",
      "mean score: 0.00\n",
      "Speed: train: 1672.9, buffer_add: 879.6, buffer_size: 100036\n",
      "Total Time: 3H 48M 24S, 13704s\n",
      "Total Sample: train: 25.344M, buffer: 13.87M\n",
      "[395] Time spent = 38.73 s\n",
      "395:grad_norm[1000]: avg:   2.5599, min:   1.5139[ 886], max:   4.7693[ 564]\n",
      "395:loss     [1000]: avg:   7.1960, min:   5.0838[ 256], max:   9.7508[ 564]\n",
      "395:xent_pred[1000]: avg:   1.9159, min:   1.7537[ 680], max:   2.0715[  84]\n",
      "395:xent_v0  [1000]: avg:   1.9128, min:   1.7538[ 680], max:   2.0676[  84]\n",
      "===================\n",
      "beginning of epoch:  396\n",
      "available: 2.714 GB, used: 25.940 GB, free: 2.647 GB\n",
      "EPOCH: 396\n",
      "mean score: 0.00\n",
      "Speed: train: 1667.5, buffer_add: 881.2, buffer_size: 100035\n",
      "Total Time: 3H 49M 02S, 13742s\n",
      "Total Sample: train: 25.408M, buffer: 13.904M\n",
      "[396] Time spent = 38.88 s\n",
      "396:grad_norm[1000]: avg:   2.5471, min:   1.3696[ 881], max:   4.8059[ 216]\n",
      "396:loss     [1000]: avg:   7.1094, min:   5.0887[ 618], max:   9.7620[ 216]\n",
      "396:xent_pred[1000]: avg:   1.9168, min:   1.7329[ 262], max:   2.0495[ 933]\n",
      "396:xent_v0  [1000]: avg:   1.9145, min:   1.7207[ 262], max:   2.0480[  66]\n",
      "===================\n",
      "beginning of epoch:  397\n",
      "available: 2.703 GB, used: 25.949 GB, free: 2.636 GB\n",
      "EPOCH: 397\n",
      "mean score: 0.00\n",
      "Speed: train: 1682.8, buffer_add: 881.5, buffer_size: 100048\n",
      "Total Time: 3H 49M 40S, 13780s\n",
      "Total Sample: train: 25.472M, buffer: 13.937M\n",
      "[397] Time spent = 38.88 s\n",
      "397:grad_norm[1000]: avg:   2.5188, min:   1.4215[ 300], max:   5.5067[ 179]\n",
      "397:loss     [1000]: avg:   7.0877, min:   4.6411[ 168], max:   9.3619[  37]\n",
      "397:xent_pred[1000]: avg:   1.9183, min:   1.7627[ 294], max:   2.0679[ 168]\n",
      "397:xent_v0  [1000]: avg:   1.9158, min:   1.7612[ 533], max:   2.0732[ 168]\n",
      "===================\n",
      "beginning of epoch:  398\n",
      "available: 2.701 GB, used: 25.946 GB, free: 2.691 GB\n",
      "EPOCH: 398\n",
      "mean score: 0.00\n",
      "Speed: train: 1663.8, buffer_add: 888.3, buffer_size: 100100\n",
      "Total Time: 3H 50M 19S, 13819s\n",
      "Total Sample: train: 25.536M, buffer: 13.971M\n",
      "[398] Time spent = 39.29 s\n",
      "398:grad_norm[1000]: avg:   2.5245, min:   1.5434[ 803], max:   4.8682[ 594]\n",
      "398:loss     [1000]: avg:   7.0777, min:   4.9268[ 496], max:   9.0672[ 574]\n",
      "398:xent_pred[1000]: avg:   1.9198, min:   1.7885[ 228], max:   2.0529[  56]\n",
      "398:xent_v0  [1000]: avg:   1.9173, min:   1.7825[ 884], max:   2.0574[ 913]\n",
      "===================\n",
      "beginning of epoch:  399\n",
      "available: 2.699 GB, used: 25.948 GB, free: 2.687 GB\n",
      "EPOCH: 399\n",
      "mean score: 0.00\n",
      "Speed: train: 1638.0, buffer_add: 864.8, buffer_size: 100030\n",
      "Total Time: 3H 50M 58S, 13858s\n",
      "Total Sample: train: 25.6M, buffer: 14.005M\n",
      "[399] Time spent = 39.61 s\n",
      "399:grad_norm[1000]: avg:   2.5152, min:   1.4677[ 655], max:   4.2350[ 455]\n",
      "399:loss     [1000]: avg:   7.0968, min:   4.9485[ 327], max:   9.2042[ 613]\n",
      "399:xent_pred[1000]: avg:   1.9182, min:   1.7316[  48], max:   2.0644[ 835]\n",
      "399:xent_v0  [1000]: avg:   1.9159, min:   1.7375[  48], max:   2.0655[ 835]\n",
      "===================\n",
      "beginning of epoch:  400\n",
      "available: 2.702 GB, used: 25.951 GB, free: 2.631 GB\n",
      "EPOCH: 400\n",
      "mean score: 0.00\n",
      "Speed: train: 1651.1, buffer_add: 873.7, buffer_size: 100033\n",
      "Total Time: 3H 51M 36S, 13896s\n",
      "Total Sample: train: 25.664M, buffer: 14.039M\n",
      "[400] Time spent = 39.28 s\n",
      "400:grad_norm[1000]: avg:   2.5236, min:   1.4316[ 855], max:   8.4483[ 706]\n",
      "400:loss     [1000]: avg:   7.1145, min:   5.1584[ 968], max:   9.3196[ 712]\n",
      "400:xent_pred[1000]: avg:   1.9196, min:   1.7599[ 708], max:   2.0740[ 755]\n",
      "400:xent_v0  [1000]: avg:   1.9174, min:   1.7507[ 708], max:   2.0734[ 755]\n",
      "===================\n",
      "beginning of epoch:  401\n",
      "available: 2.691 GB, used: 25.960 GB, free: 2.623 GB\n",
      "EPOCH: 401\n",
      "mean score: 0.00\n",
      "Speed: train: 1659.9, buffer_add: 859.1, buffer_size: 100047\n",
      "Total Time: 3H 52M 15S, 13935s\n",
      "Total Sample: train: 25.728M, buffer: 14.072M\n",
      "[401] Time spent = 39.04 s\n",
      "401:grad_norm[1000]: avg:   2.5547, min:   1.5817[ 352], max:   5.4112[ 809]\n",
      "401:loss     [1000]: avg:   7.1250, min:   5.0361[  15], max:   9.2973[ 471]\n",
      "401:xent_pred[1000]: avg:   1.9165, min:   1.7586[ 618], max:   2.0609[  71]\n",
      "401:xent_v0  [1000]: avg:   1.9143, min:   1.7562[ 618], max:   2.0578[  71]\n",
      "===================\n",
      "beginning of epoch:  402\n",
      "available: 2.703 GB, used: 25.946 GB, free: 2.667 GB\n",
      "EPOCH: 402\n",
      "mean score: 0.00\n",
      "Speed: train: 1639.9, buffer_add: 854.5, buffer_size: 100016\n",
      "Total Time: 3H 52M 54S, 13974s\n",
      "Total Sample: train: 25.792M, buffer: 14.106M\n",
      "[402] Time spent = 39.36 s\n",
      "402:grad_norm[1000]: avg:   2.5815, min:   1.5477[ 302], max:   4.4783[ 893]\n",
      "402:loss     [1000]: avg:   7.1515, min:   5.3085[ 942], max:   9.2991[ 236]\n",
      "402:xent_pred[1000]: avg:   1.9161, min:   1.7403[ 378], max:   2.0881[ 549]\n",
      "402:xent_v0  [1000]: avg:   1.9136, min:   1.7478[ 378], max:   2.0777[ 549]\n",
      "===================\n",
      "beginning of epoch:  403\n",
      "available: 2.706 GB, used: 25.950 GB, free: 2.616 GB\n",
      "EPOCH: 403\n",
      "mean score: 0.00\n",
      "Speed: train: 1695.3, buffer_add: 890.5, buffer_size: 100010\n",
      "Total Time: 3H 53M 32S, 14012s\n",
      "Total Sample: train: 25.856M, buffer: 14.139M\n",
      "[403] Time spent = 38.13 s\n",
      "403:grad_norm[1000]: avg:   2.5317, min:   1.5460[ 633], max:   4.0824[ 999]\n",
      "403:loss     [1000]: avg:   7.1171, min:   5.3559[  34], max:   9.3772[  94]\n",
      "403:xent_pred[1000]: avg:   1.9128, min:   1.7455[ 367], max:   2.0815[ 699]\n",
      "403:xent_v0  [1000]: avg:   1.9104, min:   1.7388[ 367], max:   2.0749[ 699]\n",
      "===================\n",
      "beginning of epoch:  404\n",
      "available: 2.714 GB, used: 25.946 GB, free: 2.614 GB\n",
      "EPOCH: 404\n",
      "mean score: 0.00\n",
      "Speed: train: 1749.8, buffer_add: 926.9, buffer_size: 100045\n",
      "Total Time: 3H 54M 08S, 14048s\n",
      "Total Sample: train: 25.92M, buffer: 14.173M\n",
      "[404] Time spent = 37.11 s\n",
      "404:grad_norm[1000]: avg:   2.5903, min:   1.3775[ 625], max:   4.9018[ 611]\n",
      "404:loss     [1000]: avg:   7.2165, min:   5.4165[  87], max:   9.7450[ 439]\n",
      "404:xent_pred[1000]: avg:   1.9143, min:   1.7526[ 854], max:   2.0571[ 915]\n",
      "404:xent_v0  [1000]: avg:   1.9122, min:   1.7577[ 854], max:   2.0632[ 915]\n",
      "===================\n",
      "beginning of epoch:  405\n",
      "available: 2.707 GB, used: 25.945 GB, free: 2.632 GB\n",
      "EPOCH: 405\n",
      "mean score: 0.00\n",
      "Speed: train: 1537.4, buffer_add: 778.8, buffer_size: 100022\n",
      "Total Time: 3H 54M 50S, 14090s\n",
      "Total Sample: train: 25.984M, buffer: 14.206M\n",
      "[405] Time spent = 42.18 s\n",
      "405:grad_norm[1000]: avg:   2.5220, min:   1.4683[ 906], max:   4.3429[ 401]\n",
      "405:loss     [1000]: avg:   7.1471, min:   5.1755[ 348], max:   9.8709[ 143]\n",
      "405:xent_pred[1000]: avg:   1.9159, min:   1.7620[ 603], max:   2.0589[ 235]\n",
      "405:xent_v0  [1000]: avg:   1.9139, min:   1.7567[ 489], max:   2.0560[ 235]\n",
      "===================\n",
      "beginning of epoch:  406\n",
      "available: 2.718 GB, used: 25.950 GB, free: 2.668 GB\n",
      "EPOCH: 406\n",
      "mean score: 0.00\n",
      "Speed: train: 1786.0, buffer_add: 963.4, buffer_size: 100015\n",
      "Total Time: 3H 55M 26S, 14126s\n",
      "Total Sample: train: 26.048M, buffer: 14.24M\n",
      "[406] Time spent = 36.27 s\n",
      "406:grad_norm[1000]: avg:   2.5786, min:   1.5131[ 989], max:   4.2967[ 472]\n",
      "406:loss     [1000]: avg:   7.2206, min:   5.0860[ 209], max:   9.8462[ 265]\n",
      "406:xent_pred[1000]: avg:   1.9144, min:   1.7515[ 966], max:   2.0825[ 277]\n",
      "406:xent_v0  [1000]: avg:   1.9119, min:   1.7398[ 966], max:   2.0771[ 277]\n",
      "===================\n",
      "beginning of epoch:  407\n",
      "available: 2.714 GB, used: 25.948 GB, free: 2.606 GB\n",
      "EPOCH: 407\n",
      "mean score: 0.00\n",
      "Speed: train: 1826.6, buffer_add: 998.1, buffer_size: 100052\n",
      "Total Time: 3H 56M 01S, 14161s\n",
      "Total Sample: train: 26.112M, buffer: 14.275M\n",
      "[407] Time spent = 35.57 s\n",
      "407:grad_norm[1000]: avg:   2.5701, min:   1.4367[ 766], max:   8.1322[ 700]\n",
      "407:loss     [1000]: avg:   7.2525, min:   5.0979[ 766], max:   9.5502[ 309]\n",
      "407:xent_pred[1000]: avg:   1.9140, min:   1.7732[ 198], max:   2.0517[ 681]\n",
      "407:xent_v0  [1000]: avg:   1.9114, min:   1.7759[ 302], max:   2.0561[ 681]\n",
      "===================\n",
      "beginning of epoch:  408\n",
      "available: 2.719 GB, used: 25.938 GB, free: 2.689 GB\n",
      "EPOCH: 408\n",
      "mean score: 0.00\n",
      "Speed: train: 1815.6, buffer_add: 970.9, buffer_size: 100077\n",
      "Total Time: 3H 56M 36S, 14196s\n",
      "Total Sample: train: 26.176M, buffer: 14.309M\n",
      "[408] Time spent = 35.74 s\n",
      "408:grad_norm[1000]: avg:   2.5558, min:   1.4202[ 855], max:   4.8295[ 261]\n",
      "408:loss     [1000]: avg:   7.2484, min:   5.0985[ 367], max:   9.4309[ 608]\n",
      "408:xent_pred[1000]: avg:   1.9168, min:   1.7615[ 283], max:   2.0744[ 870]\n",
      "408:xent_v0  [1000]: avg:   1.9143, min:   1.7626[ 406], max:   2.0742[ 870]\n",
      "===================\n",
      "beginning of epoch:  409\n",
      "available: 2.712 GB, used: 25.943 GB, free: 2.658 GB\n",
      "EPOCH: 409\n",
      "mean score: 0.00\n",
      "Speed: train: 1643.7, buffer_add: 872.5, buffer_size: 100028\n",
      "Total Time: 3H 57M 15S, 14235s\n",
      "Total Sample: train: 26.24M, buffer: 14.343M\n",
      "[409] Time spent = 39.36 s\n",
      "409:grad_norm[1000]: avg:   2.5523, min:   1.4441[ 710], max:   4.9880[ 738]\n",
      "409:loss     [1000]: avg:   7.1913, min:   5.2154[ 973], max:  10.7934[ 863]\n",
      "409:xent_pred[1000]: avg:   1.9186, min:   1.7526[ 855], max:   2.0702[ 377]\n",
      "409:xent_v0  [1000]: avg:   1.9159, min:   1.7554[ 855], max:   2.0607[  97]\n",
      "===================\n",
      "beginning of epoch:  410\n",
      "available: 2.713 GB, used: 25.938 GB, free: 2.607 GB\n",
      "EPOCH: 410\n",
      "mean score: 0.00\n",
      "Speed: train: 1685.6, buffer_add: 877.8, buffer_size: 100025\n",
      "Total Time: 3H 57M 53S, 14273s\n",
      "Total Sample: train: 26.304M, buffer: 14.377M\n",
      "[410] Time spent = 38.26 s\n",
      "410:grad_norm[1000]: avg:   2.5473, min:   1.4026[ 424], max:   5.2463[ 115]\n",
      "410:loss     [1000]: avg:   7.1704, min:   5.3049[ 136], max:   9.3929[ 638]\n",
      "410:xent_pred[1000]: avg:   1.9161, min:   1.7630[ 821], max:   2.0720[ 670]\n",
      "410:xent_v0  [1000]: avg:   1.9140, min:   1.7538[ 821], max:   2.0644[ 670]\n",
      "===================\n",
      "beginning of epoch:  411\n",
      "available: 2.720 GB, used: 25.938 GB, free: 2.595 GB\n",
      "EPOCH: 411\n",
      "mean score: 0.00\n",
      "Speed: train: 1691.5, buffer_add: 867.7, buffer_size: 100047\n",
      "Total Time: 3H 58M 31S, 14311s\n",
      "Total Sample: train: 26.368M, buffer: 14.409M\n",
      "[411] Time spent = 38.24 s\n",
      "411:grad_norm[1000]: avg:   2.5547, min:   1.5327[ 447], max:   5.2993[ 641]\n",
      "411:loss     [1000]: avg:   7.1513, min:   5.5369[ 921], max:   9.3479[ 364]\n",
      "411:xent_pred[1000]: avg:   1.9157, min:   1.7584[ 402], max:   2.0723[ 101]\n",
      "411:xent_v0  [1000]: avg:   1.9139, min:   1.7632[ 402], max:   2.0619[ 101]\n",
      "===================\n",
      "beginning of epoch:  412\n",
      "available: 2.721 GB, used: 25.935 GB, free: 2.618 GB\n",
      "EPOCH: 412\n",
      "mean score: 0.00\n",
      "Speed: train: 1700.8, buffer_add: 867.1, buffer_size: 100030\n",
      "Total Time: 3H 59M 09S, 14349s\n",
      "Total Sample: train: 26.432M, buffer: 14.442M\n",
      "[412] Time spent = 38.02 s\n",
      "412:grad_norm[1000]: avg:   2.5107, min:   1.3433[ 512], max:   4.8940[ 153]\n",
      "412:loss     [1000]: avg:   7.1214, min:   4.9979[ 797], max:   9.2432[ 465]\n",
      "412:xent_pred[1000]: avg:   1.9199, min:   1.7791[ 326], max:   2.0793[  86]\n",
      "412:xent_v0  [1000]: avg:   1.9178, min:   1.7802[ 326], max:   2.0853[  86]\n",
      "===================\n",
      "beginning of epoch:  413\n",
      "available: 2.727 GB, used: 25.935 GB, free: 2.659 GB\n",
      "EPOCH: 413\n",
      "mean score: 0.00\n",
      "Speed: train: 1663.1, buffer_add: 867.9, buffer_size: 100048\n",
      "Total Time: 3H 59M 47S, 14387s\n",
      "Total Sample: train: 26.496M, buffer: 14.475M\n",
      "[413] Time spent = 38.83 s\n",
      "413:grad_norm[1000]: avg:   2.5266, min:   1.5856[ 748], max:   4.6870[ 342]\n",
      "413:loss     [1000]: avg:   7.1078, min:   5.3765[ 113], max:   9.2115[ 536]\n",
      "413:xent_pred[1000]: avg:   1.9154, min:   1.7790[ 840], max:   2.0722[ 666]\n",
      "413:xent_v0  [1000]: avg:   1.9138, min:   1.7778[ 205], max:   2.0751[ 666]\n",
      "===================\n",
      "beginning of epoch:  414\n",
      "available: 2.721 GB, used: 25.935 GB, free: 2.656 GB\n",
      "EPOCH: 414\n",
      "mean score: 0.00\n",
      "Speed: train: 1622.8, buffer_add: 860.5, buffer_size: 100020\n",
      "Total Time: 4H 00M 26S, 14426s\n",
      "Total Sample: train: 26.56M, buffer: 14.509M\n",
      "[414] Time spent = 39.87 s\n",
      "414:grad_norm[1000]: avg:   2.5228, min:   1.3247[  34], max:   4.4363[ 345]\n",
      "414:loss     [1000]: avg:   7.1483, min:   5.2896[ 255], max:   9.8305[ 261]\n",
      "414:xent_pred[1000]: avg:   1.9173, min:   1.7746[ 330], max:   2.0764[ 151]\n",
      "414:xent_v0  [1000]: avg:   1.9153, min:   1.7790[ 466], max:   2.0679[ 182]\n",
      "===================\n",
      "beginning of epoch:  415\n",
      "available: 2.716 GB, used: 25.939 GB, free: 2.657 GB\n",
      "EPOCH: 415\n",
      "mean score: 0.00\n",
      "Speed: train: 1675.5, buffer_add: 879.1, buffer_size: 100032\n",
      "Total Time: 4H 01M 05S, 14465s\n",
      "Total Sample: train: 26.624M, buffer: 14.543M\n",
      "[415] Time spent = 38.58 s\n",
      "415:grad_norm[1000]: avg:   2.5174, min:   1.4081[  72], max:   5.7714[ 589]\n",
      "415:loss     [1000]: avg:   7.1595, min:   5.4701[  83], max:   9.3873[ 445]\n",
      "415:xent_pred[1000]: avg:   1.9141, min:   1.7323[ 479], max:   2.0571[ 213]\n",
      "415:xent_v0  [1000]: avg:   1.9117, min:   1.7335[ 479], max:   2.0517[ 465]\n",
      "===================\n",
      "beginning of epoch:  416\n",
      "available: 2.725 GB, used: 25.934 GB, free: 2.647 GB\n",
      "EPOCH: 416\n",
      "mean score: 0.00\n",
      "Speed: train: 1646.4, buffer_add: 877.1, buffer_size: 100014\n",
      "Total Time: 4H 01M 44S, 14504s\n",
      "Total Sample: train: 26.688M, buffer: 14.577M\n",
      "[416] Time spent = 39.18 s\n",
      "416:grad_norm[1000]: avg:   2.5310, min:   1.2947[ 680], max:   4.2876[ 362]\n",
      "416:loss     [1000]: avg:   7.2119, min:   5.0863[ 167], max:   9.5075[ 216]\n",
      "416:xent_pred[1000]: avg:   1.9133, min:   1.7568[  64], max:   2.0984[ 796]\n",
      "416:xent_v0  [1000]: avg:   1.9111, min:   1.7496[  64], max:   2.0985[ 796]\n",
      "===================\n",
      "beginning of epoch:  417\n",
      "available: 2.719 GB, used: 25.940 GB, free: 2.602 GB\n",
      "EPOCH: 417\n",
      "mean score: 0.00\n",
      "Speed: train: 1643.4, buffer_add: 873.2, buffer_size: 100013\n",
      "Total Time: 4H 02M 22S, 14542s\n",
      "Total Sample: train: 26.752M, buffer: 14.611M\n",
      "[417] Time spent = 39.36 s\n",
      "417:grad_norm[1000]: avg:   2.5076, min:   1.6408[ 671], max:   4.2228[ 409]\n",
      "417:loss     [1000]: avg:   7.1688, min:   5.4029[ 220], max:  10.3178[ 409]\n",
      "417:xent_pred[1000]: avg:   1.9181, min:   1.7688[ 531], max:   2.0787[ 324]\n",
      "417:xent_v0  [1000]: avg:   1.9160, min:   1.7608[ 531], max:   2.0781[ 684]\n",
      "===================\n",
      "beginning of epoch:  418\n",
      "available: 2.719 GB, used: 25.939 GB, free: 2.626 GB\n",
      "EPOCH: 418\n",
      "mean score: 0.00\n",
      "Speed: train: 1731.7, buffer_add: 928.6, buffer_size: 100026\n",
      "Total Time: 4H 02M 59S, 14579s\n",
      "Total Sample: train: 26.816M, buffer: 14.645M\n",
      "[418] Time spent = 37.36 s\n",
      "418:grad_norm[1000]: avg:   2.5240, min:   1.6152[ 464], max:   7.7767[ 610]\n",
      "418:loss     [1000]: avg:   7.1350, min:   5.4631[ 112], max:   9.7227[ 732]\n",
      "418:xent_pred[1000]: avg:   1.9215, min:   1.7815[ 687], max:   2.0673[ 448]\n",
      "418:xent_v0  [1000]: avg:   1.9193, min:   1.7873[  67], max:   2.0621[ 285]\n",
      "===================\n",
      "beginning of epoch:  419\n",
      "available: 2.729 GB, used: 25.935 GB, free: 2.620 GB\n",
      "EPOCH: 419\n",
      "mean score: 0.00\n",
      "Speed: train: 1645.2, buffer_add: 881.3, buffer_size: 100029\n",
      "Total Time: 4H 03M 38S, 14618s\n",
      "Total Sample: train: 26.88M, buffer: 14.68M\n",
      "[419] Time spent = 39.34 s\n",
      "419:grad_norm[1000]: avg:   2.5093, min:   1.3780[ 122], max:   7.0458[ 955]\n",
      "419:loss     [1000]: avg:   7.1736, min:   5.2197[ 154], max:   9.5634[ 706]\n",
      "419:xent_pred[1000]: avg:   1.9176, min:   1.7376[  39], max:   2.0707[ 881]\n",
      "419:xent_v0  [1000]: avg:   1.9156, min:   1.7406[  39], max:   2.0680[ 881]\n",
      "===================\n",
      "beginning of epoch:  420\n",
      "available: 2.728 GB, used: 25.937 GB, free: 2.529 GB\n",
      "EPOCH: 420\n",
      "mean score: 0.00\n",
      "Speed: train: 1543.3, buffer_add: 787.2, buffer_size: 100022\n",
      "Total Time: 4H 04M 20S, 14660s\n",
      "Total Sample: train: 26.944M, buffer: 14.712M\n",
      "[420] Time spent = 41.86 s\n",
      "420:grad_norm[1000]: avg:   2.5102, min:   1.4533[ 395], max:   4.5332[  68]\n",
      "420:loss     [1000]: avg:   7.1771, min:   5.1820[ 200], max:   9.6958[ 154]\n",
      "420:xent_pred[1000]: avg:   1.9154, min:   1.7709[ 817], max:   2.0737[  49]\n",
      "420:xent_v0  [1000]: avg:   1.9133, min:   1.7746[ 817], max:   2.0706[  49]\n",
      "===================\n",
      "beginning of epoch:  421\n",
      "available: 2.726 GB, used: 25.938 GB, free: 2.563 GB\n",
      "EPOCH: 421\n",
      "mean score: 0.00\n",
      "Speed: train: 1664.0, buffer_add: 878.6, buffer_size: 100031\n",
      "Total Time: 4H 04M 58S, 14698s\n",
      "Total Sample: train: 27.008M, buffer: 14.746M\n",
      "[421] Time spent = 38.78 s\n",
      "421:grad_norm[1000]: avg:   2.5280, min:   1.5455[ 716], max:   5.0651[ 960]\n",
      "421:loss     [1000]: avg:   7.1983, min:   5.3519[ 903], max:   9.6719[  14]\n",
      "421:xent_pred[1000]: avg:   1.9155, min:   1.7685[ 804], max:   2.0768[ 606]\n",
      "421:xent_v0  [1000]: avg:   1.9132, min:   1.7579[ 804], max:   2.0789[ 903]\n",
      "===================\n",
      "beginning of epoch:  422\n",
      "available: 2.723 GB, used: 25.937 GB, free: 2.631 GB\n",
      "EPOCH: 422\n",
      "mean score: 0.00\n",
      "Speed: train: 1643.5, buffer_add: 858.1, buffer_size: 100017\n",
      "Total Time: 4H 05M 37S, 14737s\n",
      "Total Sample: train: 27.072M, buffer: 14.78M\n",
      "[422] Time spent = 39.34 s\n",
      "422:grad_norm[1000]: avg:   2.5048, min:   1.5663[ 267], max:   4.4959[ 943]\n",
      "422:loss     [1000]: avg:   7.1361, min:   5.2128[ 267], max:   9.7738[ 639]\n",
      "422:xent_pred[1000]: avg:   1.9188, min:   1.6948[ 263], max:   2.0656[ 392]\n",
      "422:xent_v0  [1000]: avg:   1.9169, min:   1.7042[ 263], max:   2.0568[ 392]\n",
      "===================\n",
      "beginning of epoch:  423\n",
      "available: 2.725 GB, used: 25.932 GB, free: 2.662 GB\n",
      "EPOCH: 423\n",
      "mean score: 0.00\n",
      "Speed: train: 1663.9, buffer_add: 875.0, buffer_size: 100053\n",
      "Total Time: 4H 06M 16S, 14776s\n",
      "Total Sample: train: 27.136M, buffer: 14.813M\n",
      "[423] Time spent = 38.78 s\n",
      "423:grad_norm[1000]: avg:   2.4612, min:   1.5245[ 467], max:   5.7591[ 727]\n",
      "423:loss     [1000]: avg:   7.0943, min:   5.3085[ 208], max:   9.7693[ 201]\n",
      "423:xent_pred[1000]: avg:   1.9204, min:   1.7939[ 578], max:   2.0882[ 559]\n",
      "423:xent_v0  [1000]: avg:   1.9184, min:   1.7974[ 122], max:   2.0799[ 559]\n",
      "===================\n",
      "beginning of epoch:  424\n",
      "available: 2.721 GB, used: 25.932 GB, free: 2.688 GB\n",
      "EPOCH: 424\n",
      "mean score: 0.00\n",
      "Speed: train: 1671.3, buffer_add: 854.1, buffer_size: 100044\n",
      "Total Time: 4H 06M 54S, 14814s\n",
      "Total Sample: train: 27.2M, buffer: 14.846M\n",
      "[424] Time spent = 38.67 s\n",
      "424:grad_norm[1000]: avg:   2.4970, min:   1.5096[ 684], max:   4.4530[ 235]\n",
      "424:loss     [1000]: avg:   7.1175, min:   5.4450[ 822], max:   9.3828[ 471]\n",
      "424:xent_pred[1000]: avg:   1.9165, min:   1.7702[ 540], max:   2.0760[ 395]\n",
      "424:xent_v0  [1000]: avg:   1.9138, min:   1.7646[ 540], max:   2.0868[ 395]\n",
      "===================\n",
      "beginning of epoch:  425\n",
      "available: 2.720 GB, used: 25.933 GB, free: 2.682 GB\n",
      "EPOCH: 425\n",
      "mean score: 0.00\n",
      "Speed: train: 1686.1, buffer_add: 884.2, buffer_size: 100021\n",
      "Total Time: 4H 07M 32S, 14852s\n",
      "Total Sample: train: 27.264M, buffer: 14.879M\n",
      "[425] Time spent = 38.30 s\n",
      "425:grad_norm[1000]: avg:   2.5141, min:   1.4139[  23], max:   8.2519[ 572]\n",
      "425:loss     [1000]: avg:   7.1562, min:   5.0741[ 285], max:   9.6511[ 887]\n",
      "425:xent_pred[1000]: avg:   1.9163, min:   1.7771[ 465], max:   2.0624[ 696]\n",
      "425:xent_v0  [1000]: avg:   1.9144, min:   1.7713[ 465], max:   2.0506[ 993]\n",
      "===================\n",
      "beginning of epoch:  426\n",
      "available: 2.724 GB, used: 25.934 GB, free: 2.633 GB\n",
      "EPOCH: 426\n",
      "mean score: 0.00\n",
      "Speed: train: 1679.3, buffer_add: 860.9, buffer_size: 100029\n",
      "Total Time: 4H 08M 10S, 14890s\n",
      "Total Sample: train: 27.328M, buffer: 14.912M\n",
      "[426] Time spent = 38.60 s\n",
      "426:grad_norm[1000]: avg:   2.5098, min:   1.2693[   1], max:   4.3761[  62]\n",
      "426:loss     [1000]: avg:   7.1308, min:   5.2246[   1], max:   9.3527[ 926]\n",
      "426:xent_pred[1000]: avg:   1.9183, min:   1.7578[ 926], max:   2.0517[ 783]\n",
      "426:xent_v0  [1000]: avg:   1.9166, min:   1.7551[   4], max:   2.0556[ 857]\n",
      "===================\n",
      "beginning of epoch:  427\n",
      "available: 2.721 GB, used: 25.931 GB, free: 2.697 GB\n",
      "EPOCH: 427\n",
      "mean score: 0.00\n",
      "Speed: train: 1651.8, buffer_add: 872.0, buffer_size: 100038\n",
      "Total Time: 4H 08M 49S, 14929s\n",
      "Total Sample: train: 27.392M, buffer: 14.946M\n",
      "[427] Time spent = 39.22 s\n",
      "427:grad_norm[1000]: avg:   2.5139, min:   1.4715[ 803], max:   4.9215[ 613]\n",
      "427:loss     [1000]: avg:   7.1448, min:   5.3830[ 140], max:   9.5820[ 783]\n",
      "427:xent_pred[1000]: avg:   1.9172, min:   1.7662[ 346], max:   2.0676[ 513]\n",
      "427:xent_v0  [1000]: avg:   1.9151, min:   1.7594[ 346], max:   2.0749[ 513]\n",
      "===================\n",
      "beginning of epoch:  428\n",
      "available: 2.724 GB, used: 25.935 GB, free: 2.617 GB\n",
      "EPOCH: 428\n",
      "mean score: 0.00\n",
      "Speed: train: 1617.0, buffer_add: 855.2, buffer_size: 100035\n",
      "Total Time: 4H 09M 28S, 14968s\n",
      "Total Sample: train: 27.456M, buffer: 14.98M\n",
      "[428] Time spent = 39.98 s\n",
      "428:grad_norm[1000]: avg:   2.5300, min:   1.5204[  85], max:   6.5857[ 391]\n",
      "428:loss     [1000]: avg:   7.1947, min:   5.2892[  79], max:   9.5638[ 371]\n",
      "428:xent_pred[1000]: avg:   1.9160, min:   1.7615[ 731], max:   2.0529[ 604]\n",
      "428:xent_v0  [1000]: avg:   1.9147, min:   1.7662[ 731], max:   2.0457[ 604]\n",
      "===================\n",
      "beginning of epoch:  429\n",
      "available: 2.720 GB, used: 25.938 GB, free: 2.625 GB\n",
      "EPOCH: 429\n",
      "mean score: 0.00\n",
      "Speed: train: 1660.1, buffer_add: 871.6, buffer_size: 100054\n",
      "Total Time: 4H 10M 07S, 15007s\n",
      "Total Sample: train: 27.52M, buffer: 15.013M\n",
      "[429] Time spent = 38.90 s\n",
      "429:grad_norm[1000]: avg:   2.4954, min:   1.4932[ 533], max:   3.9564[  94]\n",
      "429:loss     [1000]: avg:   7.2005, min:   5.3252[ 240], max:   9.5323[ 829]\n",
      "429:xent_pred[1000]: avg:   1.9148, min:   1.7230[ 508], max:   2.0599[ 995]\n",
      "429:xent_v0  [1000]: avg:   1.9133, min:   1.7169[ 508], max:   2.0614[ 995]\n",
      "===================\n",
      "beginning of epoch:  430\n",
      "available: 2.720 GB, used: 25.937 GB, free: 2.688 GB\n",
      "EPOCH: 430\n",
      "mean score: 0.00\n",
      "Speed: train: 1696.3, buffer_add: 886.5, buffer_size: 100161\n",
      "Total Time: 4H 10M 45S, 15045s\n",
      "Total Sample: train: 27.584M, buffer: 15.047M\n",
      "[430] Time spent = 38.03 s\n",
      "430:grad_norm[1000]: avg:   2.4874, min:   1.3619[ 635], max:   4.3406[ 502]\n",
      "430:loss     [1000]: avg:   7.1747, min:   5.4294[  43], max:   9.2041[ 712]\n",
      "430:xent_pred[1000]: avg:   1.9161, min:   1.7883[ 688], max:   2.0624[ 864]\n",
      "430:xent_v0  [1000]: avg:   1.9138, min:   1.7874[ 688], max:   2.0573[ 864]\n",
      "===================\n",
      "beginning of epoch:  431\n",
      "available: 2.713 GB, used: 25.937 GB, free: 2.678 GB\n",
      "EPOCH: 431\n",
      "mean score: 0.00\n",
      "Speed: train: 1754.4, buffer_add: 918.2, buffer_size: 100033\n",
      "Total Time: 4H 11M 21S, 15081s\n",
      "Total Sample: train: 27.648M, buffer: 15.08M\n",
      "[431] Time spent = 36.90 s\n",
      "431:grad_norm[1000]: avg:   2.4580, min:   1.2981[ 297], max:   3.8430[ 622]\n",
      "431:loss     [1000]: avg:   7.1079, min:   5.1540[ 312], max:   9.5748[ 960]\n",
      "431:xent_pred[1000]: avg:   1.9166, min:   1.7823[ 218], max:   2.0659[ 198]\n",
      "431:xent_v0  [1000]: avg:   1.9150, min:   1.7788[ 413], max:   2.0623[ 198]\n",
      "===================\n",
      "beginning of epoch:  432\n",
      "available: 2.723 GB, used: 25.936 GB, free: 2.615 GB\n",
      "EPOCH: 432\n",
      "mean score: 0.00\n",
      "Speed: train: 1506.7, buffer_add: 792.4, buffer_size: 100036\n",
      "Total Time: 4H 12M 04S, 15124s\n",
      "Total Sample: train: 27.712M, buffer: 15.114M\n",
      "[432] Time spent = 42.99 s\n",
      "432:grad_norm[1000]: avg:   2.5352, min:   1.3535[ 362], max:   5.2751[ 458]\n",
      "432:loss     [1000]: avg:   7.1557, min:   5.4082[ 316], max:   9.3137[ 124]\n",
      "432:xent_pred[1000]: avg:   1.9157, min:   1.7749[ 951], max:   2.0508[  32]\n",
      "432:xent_v0  [1000]: avg:   1.9140, min:   1.7750[ 280], max:   2.0489[  32]\n",
      "===================\n",
      "beginning of epoch:  433\n",
      "available: 2.717 GB, used: 25.938 GB, free: 2.627 GB\n",
      "EPOCH: 433\n",
      "mean score: 0.00\n",
      "Speed: train: 1796.6, buffer_add: 949.1, buffer_size: 100040\n",
      "Total Time: 4H 12M 39S, 15159s\n",
      "Total Sample: train: 27.776M, buffer: 15.148M\n",
      "[433] Time spent = 35.93 s\n",
      "433:grad_norm[1000]: avg:   2.5548, min:   1.5202[ 509], max:   4.7714[ 141]\n",
      "433:loss     [1000]: avg:   7.1810, min:   5.2554[ 705], max:   9.1448[ 588]\n",
      "433:xent_pred[1000]: avg:   1.9109, min:   1.7618[ 306], max:   2.0841[ 346]\n",
      "433:xent_v0  [1000]: avg:   1.9088, min:   1.7662[ 306], max:   2.0811[ 346]\n",
      "===================\n",
      "beginning of epoch:  434\n",
      "available: 2.712 GB, used: 25.941 GB, free: 2.635 GB\n",
      "EPOCH: 434\n",
      "mean score: 0.00\n",
      "Speed: train: 1839.4, buffer_add: 991.9, buffer_size: 100033\n",
      "Total Time: 4H 13M 14S, 15194s\n",
      "Total Sample: train: 27.84M, buffer: 15.182M\n",
      "[434] Time spent = 35.14 s\n",
      "434:grad_norm[1000]: avg:   2.5194, min:   1.2305[ 342], max:   7.6136[ 638]\n",
      "434:loss     [1000]: avg:   7.2148, min:   5.0142[ 161], max:   9.6909[ 212]\n",
      "434:xent_pred[1000]: avg:   1.9116, min:   1.7763[ 984], max:   2.0739[ 782]\n",
      "434:xent_v0  [1000]: avg:   1.9098, min:   1.7750[ 984], max:   2.0752[ 435]\n",
      "===================\n",
      "beginning of epoch:  435\n",
      "available: 2.719 GB, used: 25.941 GB, free: 2.646 GB\n",
      "EPOCH: 435\n",
      "mean score: 0.00\n",
      "Speed: train: 1775.3, buffer_add: 941.5, buffer_size: 100035\n",
      "Total Time: 4H 13M 50S, 15230s\n",
      "Total Sample: train: 27.904M, buffer: 15.216M\n",
      "[435] Time spent = 36.32 s\n",
      "435:grad_norm[1000]: avg:   2.4864, min:   1.4327[ 424], max:   4.3235[  32]\n",
      "435:loss     [1000]: avg:   7.1905, min:   5.2406[ 706], max:   9.6156[ 641]\n",
      "435:xent_pred[1000]: avg:   1.9155, min:   1.7205[ 870], max:   2.0608[ 859]\n",
      "435:xent_v0  [1000]: avg:   1.9132, min:   1.7158[ 870], max:   2.0565[ 706]\n",
      "===================\n",
      "beginning of epoch:  436\n",
      "available: 2.720 GB, used: 25.931 GB, free: 2.646 GB\n",
      "EPOCH: 436\n",
      "mean score: 0.00\n",
      "Speed: train: 1658.0, buffer_add: 864.5, buffer_size: 100026\n",
      "Total Time: 4H 14M 29S, 15269s\n",
      "Total Sample: train: 27.968M, buffer: 15.25M\n",
      "[436] Time spent = 38.98 s\n",
      "436:grad_norm[1000]: avg:   2.4934, min:   1.2818[ 768], max:   4.1069[ 447]\n",
      "436:loss     [1000]: avg:   7.1612, min:   4.9844[ 768], max:   9.1782[ 122]\n",
      "436:xent_pred[1000]: avg:   1.9169, min:   1.7342[ 978], max:   2.0681[ 608]\n",
      "436:xent_v0  [1000]: avg:   1.9152, min:   1.7345[ 978], max:   2.0675[ 608]\n",
      "===================\n",
      "beginning of epoch:  437\n",
      "available: 2.719 GB, used: 25.935 GB, free: 2.663 GB\n",
      "EPOCH: 437\n",
      "mean score: 0.00\n",
      "Speed: train: 1642.8, buffer_add: 863.9, buffer_size: 100069\n",
      "Total Time: 4H 15M 08S, 15308s\n",
      "Total Sample: train: 28.032M, buffer: 15.283M\n",
      "[437] Time spent = 39.22 s\n",
      "437:grad_norm[1000]: avg:   2.4986, min:   1.5132[ 199], max:   4.1952[ 960]\n",
      "437:loss     [1000]: avg:   7.1763, min:   5.1424[ 635], max:   9.3063[ 155]\n",
      "437:xent_pred[1000]: avg:   1.9141, min:   1.7240[  98], max:   2.0808[ 677]\n",
      "437:xent_v0  [1000]: avg:   1.9122, min:   1.7318[ 734], max:   2.0761[ 677]\n",
      "===================\n",
      "beginning of epoch:  438\n",
      "available: 2.717 GB, used: 25.936 GB, free: 2.673 GB\n",
      "EPOCH: 438\n",
      "mean score: 0.01\n",
      "Speed: train: 1680.4, buffer_add: 857.2, buffer_size: 100022\n",
      "Total Time: 4H 15M 46S, 15346s\n",
      "Total Sample: train: 28.096M, buffer: 15.316M\n",
      "[438] Time spent = 38.38 s\n",
      "438:grad_norm[1000]: avg:   2.5017, min:   1.4202[ 109], max:   4.9033[ 697]\n",
      "438:loss     [1000]: avg:   7.1640, min:   4.9961[ 901], max:   9.4279[ 334]\n",
      "438:xent_pred[1000]: avg:   1.9156, min:   1.7354[ 670], max:   2.0679[ 822]\n",
      "438:xent_v0  [1000]: avg:   1.9138, min:   1.7371[ 670], max:   2.0572[ 822]\n",
      "===================\n",
      "beginning of epoch:  439\n",
      "available: 2.723 GB, used: 25.936 GB, free: 2.627 GB\n",
      "EPOCH: 439\n",
      "mean score: 0.00\n",
      "Speed: train: 1671.5, buffer_add: 869.1, buffer_size: 100022\n",
      "Total Time: 4H 16M 24S, 15384s\n",
      "Total Sample: train: 28.16M, buffer: 15.349M\n",
      "[439] Time spent = 38.70 s\n",
      "439:grad_norm[1000]: avg:   2.4975, min:   1.4277[ 426], max:   4.2561[ 432]\n",
      "439:loss     [1000]: avg:   7.1513, min:   4.8907[ 426], max:   9.1059[ 432]\n",
      "439:xent_pred[1000]: avg:   1.9174, min:   1.7735[ 515], max:   2.0511[  60]\n",
      "439:xent_v0  [1000]: avg:   1.9158, min:   1.7846[ 515], max:   2.0453[  60]\n",
      "===================\n",
      "beginning of epoch:  440\n",
      "available: 2.719 GB, used: 25.936 GB, free: 2.658 GB\n",
      "EPOCH: 440\n",
      "mean score: 0.00\n",
      "Speed: train: 1655.4, buffer_add: 864.8, buffer_size: 100037\n",
      "Total Time: 4H 17M 03S, 15423s\n",
      "Total Sample: train: 28.224M, buffer: 15.383M\n",
      "[440] Time spent = 39.14 s\n",
      "440:grad_norm[1000]: avg:   2.4806, min:   1.4713[ 671], max:   4.2054[ 174]\n",
      "440:loss     [1000]: avg:   7.1376, min:   5.2283[ 444], max:   9.4102[ 349]\n",
      "440:xent_pred[1000]: avg:   1.9175, min:   1.7430[ 290], max:   2.0496[ 386]\n",
      "440:xent_v0  [1000]: avg:   1.9155, min:   1.7481[  19], max:   2.0485[ 386]\n",
      "===================\n",
      "beginning of epoch:  441\n",
      "available: 2.713 GB, used: 25.941 GB, free: 2.658 GB\n",
      "EPOCH: 441\n",
      "mean score: 0.00\n",
      "Speed: train: 1619.7, buffer_add: 866.5, buffer_size: 100166\n",
      "Total Time: 4H 17M 42S, 15462s\n",
      "Total Sample: train: 28.288M, buffer: 15.417M\n",
      "[441] Time spent = 40.06 s\n",
      "441:grad_norm[1000]: avg:   2.5059, min:   1.4232[ 245], max:   4.0889[ 576]\n",
      "441:loss     [1000]: avg:   7.1711, min:   5.1052[ 495], max:  10.0261[ 340]\n",
      "441:xent_pred[1000]: avg:   1.9149, min:   1.7579[ 480], max:   2.0966[ 278]\n",
      "441:xent_v0  [1000]: avg:   1.9132, min:   1.7652[ 480], max:   2.0940[ 278]\n",
      "===================\n",
      "beginning of epoch:  442\n",
      "available: 2.718 GB, used: 25.933 GB, free: 2.697 GB\n",
      "EPOCH: 442\n",
      "mean score: 0.00\n",
      "Speed: train: 1637.2, buffer_add: 852.8, buffer_size: 100020\n",
      "Total Time: 4H 18M 21S, 15501s\n",
      "Total Sample: train: 28.352M, buffer: 15.45M\n",
      "[442] Time spent = 39.60 s\n",
      "442:grad_norm[1000]: avg:   2.4752, min:   1.3841[ 533], max:   5.0962[  97]\n",
      "442:loss     [1000]: avg:   7.1397, min:   5.2565[ 533], max:   9.4962[  96]\n",
      "442:xent_pred[1000]: avg:   1.9119, min:   1.7422[ 670], max:   2.0634[ 486]\n",
      "442:xent_v0  [1000]: avg:   1.9101, min:   1.7306[ 670], max:   2.0625[ 743]\n",
      "===================\n",
      "beginning of epoch:  443\n",
      "available: 2.717 GB, used: 25.935 GB, free: 2.589 GB\n",
      "EPOCH: 443\n",
      "mean score: 0.00\n",
      "Speed: train: 1651.8, buffer_add: 870.1, buffer_size: 100011\n",
      "Total Time: 4H 19M 00S, 15540s\n",
      "Total Sample: train: 28.416M, buffer: 15.484M\n",
      "[443] Time spent = 39.13 s\n",
      "443:grad_norm[1000]: avg:   2.5077, min:   1.4922[ 755], max:   4.4592[ 520]\n",
      "443:loss     [1000]: avg:   7.1856, min:   5.4243[ 443], max:   9.2828[ 213]\n",
      "443:xent_pred[1000]: avg:   1.9137, min:   1.7689[ 761], max:   2.0680[ 681]\n",
      "443:xent_v0  [1000]: avg:   1.9120, min:   1.7640[ 761], max:   2.0700[ 681]\n",
      "===================\n",
      "beginning of epoch:  444\n",
      "available: 2.716 GB, used: 25.943 GB, free: 2.569 GB\n",
      "EPOCH: 444\n",
      "mean score: 0.00\n",
      "Speed: train: 1675.1, buffer_add: 875.3, buffer_size: 100045\n",
      "Total Time: 4H 19M 38S, 15578s\n",
      "Total Sample: train: 28.48M, buffer: 15.517M\n",
      "[444] Time spent = 38.83 s\n",
      "444:grad_norm[1000]: avg:   2.4813, min:   1.4288[ 106], max:   5.6751[  76]\n",
      "444:loss     [1000]: avg:   7.1408, min:   5.2299[ 106], max:   9.1855[  62]\n",
      "444:xent_pred[1000]: avg:   1.9139, min:   1.7620[ 257], max:   2.0770[ 657]\n",
      "444:xent_v0  [1000]: avg:   1.9121, min:   1.7559[ 257], max:   2.0824[ 657]\n",
      "===================\n",
      "beginning of epoch:  445\n",
      "available: 2.711 GB, used: 25.945 GB, free: 2.582 GB\n",
      "EPOCH: 445\n",
      "mean score: 0.00\n",
      "Speed: train: 1781.3, buffer_add: 973.7, buffer_size: 100009\n",
      "Total Time: 4H 20M 14S, 15614s\n",
      "Total Sample: train: 28.544M, buffer: 15.552M\n",
      "[445] Time spent = 36.44 s\n",
      "445:grad_norm[1000]: avg:   2.4428, min:   1.4716[ 957], max:   8.5659[ 106]\n",
      "445:loss     [1000]: avg:   7.1203, min:   5.3671[ 164], max:   9.5663[ 697]\n",
      "445:xent_pred[1000]: avg:   1.9143, min:   1.7248[ 189], max:   2.0649[ 643]\n",
      "445:xent_v0  [1000]: avg:   1.9125, min:   1.7370[ 189], max:   2.0649[ 643]\n",
      "===================\n",
      "beginning of epoch:  446\n",
      "available: 2.715 GB, used: 25.942 GB, free: 2.652 GB\n",
      "EPOCH: 446\n",
      "mean score: 0.00\n",
      "Speed: train: 1565.3, buffer_add: 793.8, buffer_size: 100017\n",
      "Total Time: 4H 20M 55S, 15655s\n",
      "Total Sample: train: 28.608M, buffer: 15.585M\n",
      "[446] Time spent = 41.31 s\n",
      "446:grad_norm[1000]: avg:   2.4650, min:   1.3790[ 204], max:   4.3822[ 111]\n",
      "446:loss     [1000]: avg:   7.1216, min:   4.9115[ 381], max:   9.5812[  42]\n",
      "446:xent_pred[1000]: avg:   1.9143, min:   1.7686[ 356], max:   2.0649[  99]\n",
      "446:xent_v0  [1000]: avg:   1.9123, min:   1.7670[ 356], max:   2.0626[  99]\n",
      "===================\n",
      "beginning of epoch:  447\n",
      "available: 2.714 GB, used: 25.944 GB, free: 2.672 GB\n",
      "EPOCH: 447\n",
      "mean score: 0.00\n",
      "Speed: train: 1668.8, buffer_add: 869.4, buffer_size: 100075\n",
      "Total Time: 4H 21M 33S, 15693s\n",
      "Total Sample: train: 28.672M, buffer: 15.618M\n",
      "[447] Time spent = 38.86 s\n",
      "447:grad_norm[1000]: avg:   2.4723, min:   1.4612[ 256], max:   4.0687[ 257]\n",
      "447:loss     [1000]: avg:   7.1495, min:   5.4182[ 141], max:   9.5839[ 629]\n",
      "447:xent_pred[1000]: avg:   1.9162, min:   1.7706[ 272], max:   2.0578[ 322]\n",
      "447:xent_v0  [1000]: avg:   1.9143, min:   1.7751[ 461], max:   2.0614[ 842]\n",
      "===================\n",
      "beginning of epoch:  448\n",
      "available: 2.706 GB, used: 25.940 GB, free: 2.682 GB\n",
      "EPOCH: 448\n",
      "mean score: 0.00\n",
      "Speed: train: 1805.2, buffer_add: 1001.5, buffer_size: 100021\n",
      "Total Time: 4H 22M 09S, 15729s\n",
      "Total Sample: train: 28.736M, buffer: 15.654M\n",
      "[448] Time spent = 35.74 s\n",
      "448:grad_norm[1000]: avg:   2.5078, min:   1.6220[ 419], max:   5.3906[ 929]\n",
      "448:loss     [1000]: avg:   7.1823, min:   5.3040[ 248], max:   9.4167[ 316]\n",
      "448:xent_pred[1000]: avg:   1.9145, min:   1.7671[ 943], max:   2.0823[  17]\n",
      "448:xent_v0  [1000]: avg:   1.9126, min:   1.7561[ 943], max:   2.0845[  17]\n",
      "===================\n",
      "beginning of epoch:  449\n",
      "available: 2.708 GB, used: 25.949 GB, free: 2.635 GB\n",
      "EPOCH: 449\n",
      "mean score: 0.00\n",
      "Speed: train: 1798.0, buffer_add: 976.4, buffer_size: 100021\n",
      "Total Time: 4H 22M 44S, 15764s\n",
      "Total Sample: train: 28.8M, buffer: 15.688M\n",
      "[449] Time spent = 36.01 s\n",
      "449:grad_norm[1000]: avg:   2.4980, min:   1.4250[  13], max:   3.9856[ 500]\n",
      "449:loss     [1000]: avg:   7.1925, min:   5.2765[ 379], max:   9.2634[ 460]\n",
      "449:xent_pred[1000]: avg:   1.9150, min:   1.7795[ 450], max:   2.0959[ 439]\n",
      "449:xent_v0  [1000]: avg:   1.9130, min:   1.7721[ 450], max:   2.0824[ 439]\n",
      "===================\n",
      "beginning of epoch:  450\n",
      "available: 2.719 GB, used: 25.941 GB, free: 2.617 GB\n",
      "EPOCH: 450\n",
      "mean score: 0.00\n",
      "Speed: train: 1760.0, buffer_add: 923.4, buffer_size: 100029\n",
      "Total Time: 4H 23M 21S, 15801s\n",
      "Total Sample: train: 28.864M, buffer: 15.722M\n",
      "[450] Time spent = 36.51 s\n",
      "450:grad_norm[1000]: avg:   2.4477, min:   1.4452[ 378], max:   4.1814[   4]\n",
      "450:loss     [1000]: avg:   7.1248, min:   5.2041[ 572], max:   9.3295[ 362]\n",
      "450:xent_pred[1000]: avg:   1.9173, min:   1.7401[ 673], max:   2.0774[ 607]\n",
      "450:xent_v0  [1000]: avg:   1.9154, min:   1.7425[ 387], max:   2.0731[ 318]\n",
      "===================\n",
      "beginning of epoch:  451\n",
      "available: 2.718 GB, used: 25.936 GB, free: 2.687 GB\n",
      "EPOCH: 451\n",
      "mean score: 0.00\n",
      "Speed: train: 1736.9, buffer_add: 920.2, buffer_size: 100023\n",
      "Total Time: 4H 23M 58S, 15838s\n",
      "Total Sample: train: 28.928M, buffer: 15.756M\n",
      "[451] Time spent = 37.26 s\n",
      "451:grad_norm[1000]: avg:   2.4200, min:   1.4700[ 784], max:   4.4970[ 231]\n",
      "451:loss     [1000]: avg:   7.1151, min:   5.2514[ 551], max:   9.7401[ 939]\n",
      "451:xent_pred[1000]: avg:   1.9156, min:   1.7832[ 841], max:   2.0514[ 519]\n",
      "451:xent_v0  [1000]: avg:   1.9142, min:   1.7799[ 830], max:   2.0536[ 519]\n",
      "===================\n",
      "beginning of epoch:  452\n",
      "available: 2.717 GB, used: 25.934 GB, free: 2.677 GB\n",
      "EPOCH: 452\n",
      "mean score: 0.00\n",
      "Speed: train: 1753.8, buffer_add: 925.8, buffer_size: 100044\n",
      "Total Time: 4H 24M 34S, 15874s\n",
      "Total Sample: train: 28.992M, buffer: 15.79M\n",
      "[452] Time spent = 36.82 s\n",
      "452:grad_norm[1000]: avg:   2.4417, min:   1.3848[ 813], max:   4.3373[ 135]\n",
      "452:loss     [1000]: avg:   7.1730, min:   5.3490[ 920], max:   9.2755[ 542]\n",
      "452:xent_pred[1000]: avg:   1.9130, min:   1.7477[ 229], max:   2.0696[ 385]\n",
      "452:xent_v0  [1000]: avg:   1.9104, min:   1.7494[ 229], max:   2.0715[ 959]\n",
      "===================\n",
      "beginning of epoch:  453\n",
      "available: 2.719 GB, used: 25.935 GB, free: 2.648 GB\n",
      "EPOCH: 453\n",
      "mean score: 0.00\n",
      "Speed: train: 1733.3, buffer_add: 926.9, buffer_size: 100040\n",
      "Total Time: 4H 25M 11S, 15911s\n",
      "Total Sample: train: 29.056M, buffer: 15.824M\n",
      "[453] Time spent = 37.30 s\n",
      "453:grad_norm[1000]: avg:   2.4426, min:   1.5538[ 225], max:   4.0649[ 411]\n",
      "453:loss     [1000]: avg:   7.1520, min:   5.2806[ 571], max:   9.2599[ 651]\n",
      "453:xent_pred[1000]: avg:   1.9194, min:   1.7586[ 495], max:   2.0893[ 926]\n",
      "453:xent_v0  [1000]: avg:   1.9182, min:   1.7651[ 495], max:   2.0874[ 926]\n",
      "===================\n",
      "beginning of epoch:  454\n",
      "available: 2.709 GB, used: 25.941 GB, free: 2.655 GB\n",
      "EPOCH: 454\n",
      "mean score: 0.00\n",
      "Speed: train: 1761.3, buffer_add: 913.2, buffer_size: 100082\n",
      "Total Time: 4H 25M 47S, 15947s\n",
      "Total Sample: train: 29.12M, buffer: 15.857M\n",
      "[454] Time spent = 36.78 s\n",
      "454:grad_norm[1000]: avg:   2.4908, min:   1.4785[ 914], max:   7.3438[ 482]\n",
      "454:loss     [1000]: avg:   7.2221, min:   5.1300[ 210], max:   9.5996[ 104]\n",
      "454:xent_pred[1000]: avg:   1.9148, min:   1.7725[ 448], max:   2.0654[ 473]\n",
      "454:xent_v0  [1000]: avg:   1.9128, min:   1.7618[ 448], max:   2.0609[ 473]\n",
      "===================\n",
      "beginning of epoch:  455\n",
      "available: 2.718 GB, used: 25.939 GB, free: 2.689 GB\n",
      "EPOCH: 455\n",
      "mean score: 0.00\n",
      "Speed: train: 1753.4, buffer_add: 919.9, buffer_size: 100040\n",
      "Total Time: 4H 26M 24S, 15984s\n",
      "Total Sample: train: 29.184M, buffer: 15.891M\n",
      "[455] Time spent = 36.90 s\n",
      "455:grad_norm[1000]: avg:   2.4696, min:   1.3317[  47], max:   3.9154[ 336]\n",
      "455:loss     [1000]: avg:   7.1928, min:   5.1644[  48], max:   9.1982[ 858]\n",
      "455:xent_pred[1000]: avg:   1.9157, min:   1.7708[ 397], max:   2.0660[  48]\n",
      "455:xent_v0  [1000]: avg:   1.9136, min:   1.7621[ 397], max:   2.0659[  48]\n",
      "===================\n",
      "beginning of epoch:  456\n",
      "available: 2.704 GB, used: 25.941 GB, free: 2.712 GB\n",
      "EPOCH: 456\n",
      "mean score: 0.00\n",
      "Speed: train: 1761.1, buffer_add: 914.4, buffer_size: 100073\n",
      "Total Time: 4H 27M 00S, 16020s\n",
      "Total Sample: train: 29.248M, buffer: 15.924M\n",
      "[456] Time spent = 36.63 s\n",
      "456:grad_norm[1000]: avg:   2.4679, min:   1.4167[ 664], max:   4.5057[ 956]\n",
      "456:loss     [1000]: avg:   7.1710, min:   5.1595[ 600], max:   9.5914[ 510]\n",
      "456:xent_pred[1000]: avg:   1.9168, min:   1.7510[ 834], max:   2.0524[ 684]\n",
      "456:xent_v0  [1000]: avg:   1.9148, min:   1.7486[ 834], max:   2.0451[ 819]\n",
      "===================\n",
      "beginning of epoch:  457\n",
      "available: 2.690 GB, used: 25.954 GB, free: 2.648 GB\n",
      "EPOCH: 457\n",
      "mean score: 0.00\n",
      "Speed: train: 1757.3, buffer_add: 923.1, buffer_size: 100060\n",
      "Total Time: 4H 27M 37S, 16057s\n",
      "Total Sample: train: 29.312M, buffer: 15.958M\n",
      "[457] Time spent = 36.91 s\n",
      "457:grad_norm[1000]: avg:   2.4553, min:   1.4254[ 626], max:   4.4467[ 526]\n",
      "457:loss     [1000]: avg:   7.1724, min:   5.0567[ 895], max:   9.5305[ 526]\n",
      "457:xent_pred[1000]: avg:   1.9153, min:   1.7605[ 637], max:   2.0534[ 311]\n",
      "457:xent_v0  [1000]: avg:   1.9137, min:   1.7744[ 637], max:   2.0484[ 311]\n",
      "===================\n",
      "beginning of epoch:  458\n",
      "available: 2.689 GB, used: 25.957 GB, free: 2.647 GB\n",
      "EPOCH: 458\n",
      "mean score: 0.00\n",
      "Speed: train: 1727.6, buffer_add: 920.8, buffer_size: 100004\n",
      "Total Time: 4H 28M 14S, 16094s\n",
      "Total Sample: train: 29.376M, buffer: 15.992M\n",
      "[458] Time spent = 37.39 s\n",
      "458:grad_norm[1000]: avg:   2.4331, min:   1.4165[ 426], max:   5.1229[ 703]\n",
      "458:loss     [1000]: avg:   7.1242, min:   5.1646[ 603], max:   9.7416[ 680]\n",
      "458:xent_pred[1000]: avg:   1.9160, min:   1.7582[ 301], max:   2.0634[ 855]\n",
      "458:xent_v0  [1000]: avg:   1.9141, min:   1.7539[ 301], max:   2.0603[  68]\n",
      "===================\n",
      "beginning of epoch:  459\n",
      "available: 2.702 GB, used: 25.952 GB, free: 2.623 GB\n",
      "EPOCH: 459\n",
      "mean score: 0.00\n",
      "Speed: train: 1750.1, buffer_add: 922.6, buffer_size: 100029\n",
      "Total Time: 4H 28M 50S, 16130s\n",
      "Total Sample: train: 29.44M, buffer: 16.025M\n",
      "[459] Time spent = 36.96 s\n",
      "459:grad_norm[1000]: avg:   2.4599, min:   1.4882[ 979], max:   7.6783[  47]\n",
      "459:loss     [1000]: avg:   7.1491, min:   4.6757[  56], max:   9.2118[ 840]\n",
      "459:xent_pred[1000]: avg:   1.9162, min:   1.7714[ 390], max:   2.0434[ 588]\n",
      "459:xent_v0  [1000]: avg:   1.9146, min:   1.7671[ 390], max:   2.0513[ 588]\n",
      "===================\n",
      "beginning of epoch:  460\n",
      "available: 2.699 GB, used: 25.956 GB, free: 2.611 GB\n",
      "EPOCH: 460\n",
      "mean score: 0.00\n",
      "Speed: train: 1732.4, buffer_add: 931.2, buffer_size: 100009\n",
      "Total Time: 4H 29M 27S, 16167s\n",
      "Total Sample: train: 29.504M, buffer: 16.06M\n",
      "[460] Time spent = 37.35 s\n",
      "460:grad_norm[1000]: avg:   2.4635, min:   1.2878[ 389], max:   4.1503[ 177]\n",
      "460:loss     [1000]: avg:   7.1705, min:   5.3030[ 612], max:   9.2076[ 937]\n",
      "460:xent_pred[1000]: avg:   1.9115, min:   1.7742[ 721], max:   2.0680[ 869]\n",
      "460:xent_v0  [1000]: avg:   1.9096, min:   1.7751[ 721], max:   2.0660[ 869]\n",
      "===================\n",
      "beginning of epoch:  461\n",
      "available: 2.700 GB, used: 25.958 GB, free: 2.592 GB\n",
      "EPOCH: 461\n",
      "mean score: 0.00\n",
      "Speed: train: 1555.5, buffer_add: 777.2, buffer_size: 100019\n",
      "Total Time: 4H 30M 08S, 16208s\n",
      "Total Sample: train: 29.568M, buffer: 16.092M\n",
      "[461] Time spent = 41.45 s\n",
      "461:grad_norm[1000]: avg:   2.4629, min:   1.2665[ 462], max:   4.5327[ 529]\n",
      "461:loss     [1000]: avg:   7.1553, min:   4.7835[ 240], max:   9.1703[ 629]\n",
      "461:xent_pred[1000]: avg:   1.9128, min:   1.7710[ 926], max:   2.0735[ 240]\n",
      "461:xent_v0  [1000]: avg:   1.9107, min:   1.7736[ 926], max:   2.0696[ 240]\n",
      "===================\n",
      "beginning of epoch:  462\n",
      "available: 2.691 GB, used: 25.959 GB, free: 2.632 GB\n",
      "EPOCH: 462\n",
      "mean score: 0.00\n",
      "Speed: train: 1747.1, buffer_add: 933.3, buffer_size: 100027\n",
      "Total Time: 4H 30M 45S, 16245s\n",
      "Total Sample: train: 29.632M, buffer: 16.126M\n",
      "[462] Time spent = 37.12 s\n",
      "462:grad_norm[1000]: avg:   2.4440, min:   1.4509[ 462], max:   7.6707[ 469]\n",
      "462:loss     [1000]: avg:   7.1170, min:   5.2893[ 648], max:   9.5365[ 148]\n",
      "462:xent_pred[1000]: avg:   1.9185, min:   1.7752[  76], max:   2.0595[ 994]\n",
      "462:xent_v0  [1000]: avg:   1.9170, min:   1.7752[  76], max:   2.0493[ 994]\n",
      "===================\n",
      "beginning of epoch:  463\n",
      "available: 2.708 GB, used: 25.947 GB, free: 2.672 GB\n",
      "EPOCH: 463\n",
      "mean score: 0.00\n",
      "Speed: train: 1853.8, buffer_add: 989.7, buffer_size: 100131\n",
      "Total Time: 4H 31M 19S, 16279s\n",
      "Total Sample: train: 29.696M, buffer: 16.16M\n",
      "[463] Time spent = 34.99 s\n",
      "463:grad_norm[1000]: avg:   2.4548, min:   1.4142[ 282], max:   4.0661[ 697]\n",
      "463:loss     [1000]: avg:   7.1554, min:   5.1816[ 199], max:   9.5616[ 588]\n",
      "463:xent_pred[1000]: avg:   1.9149, min:   1.7675[ 325], max:   2.0820[ 397]\n",
      "463:xent_v0  [1000]: avg:   1.9129, min:   1.7665[ 164], max:   2.0741[ 397]\n",
      "===================\n",
      "beginning of epoch:  464\n",
      "available: 2.711 GB, used: 25.940 GB, free: 2.659 GB\n",
      "EPOCH: 464\n",
      "mean score: 0.00\n",
      "Speed: train: 1839.4, buffer_add: 939.1, buffer_size: 100022\n",
      "Total Time: 4H 31M 54S, 16314s\n",
      "Total Sample: train: 29.76M, buffer: 16.193M\n",
      "[464] Time spent = 35.21 s\n",
      "464:grad_norm[1000]: avg:   2.4824, min:   1.3263[ 497], max:   4.5061[ 192]\n",
      "464:loss     [1000]: avg:   7.2022, min:   5.3726[ 982], max:   9.5884[ 750]\n",
      "464:xent_pred[1000]: avg:   1.9142, min:   1.7792[ 880], max:   2.0855[ 982]\n",
      "464:xent_v0  [1000]: avg:   1.9129, min:   1.7756[ 880], max:   2.0826[ 982]\n",
      "===================\n",
      "beginning of epoch:  465\n",
      "available: 2.711 GB, used: 25.941 GB, free: 2.666 GB\n",
      "EPOCH: 465\n",
      "mean score: 0.01\n",
      "Speed: train: 1738.4, buffer_add: 923.8, buffer_size: 100054\n",
      "Total Time: 4H 32M 31S, 16351s\n",
      "Total Sample: train: 29.824M, buffer: 16.227M\n",
      "[465] Time spent = 37.23 s\n",
      "465:grad_norm[1000]: avg:   2.4476, min:   1.4597[ 775], max:   5.6900[ 162]\n",
      "465:loss     [1000]: avg:   7.1789, min:   5.3456[ 828], max:   9.6876[ 373]\n",
      "465:xent_pred[1000]: avg:   1.9156, min:   1.7625[ 149], max:   2.0999[ 838]\n",
      "465:xent_v0  [1000]: avg:   1.9138, min:   1.7615[ 149], max:   2.0960[ 838]\n",
      "===================\n",
      "beginning of epoch:  466\n",
      "available: 2.718 GB, used: 25.938 GB, free: 2.617 GB\n",
      "EPOCH: 466\n",
      "mean score: 0.00\n",
      "Speed: train: 1750.7, buffer_add: 917.6, buffer_size: 100013\n",
      "Total Time: 4H 33M 08S, 16388s\n",
      "Total Sample: train: 29.888M, buffer: 16.26M\n",
      "[466] Time spent = 36.95 s\n",
      "466:grad_norm[1000]: avg:   2.4520, min:   1.4033[  36], max:   3.9348[   7]\n",
      "466:loss     [1000]: avg:   7.1422, min:   5.1253[ 532], max:   9.8958[ 334]\n",
      "466:xent_pred[1000]: avg:   1.9157, min:   1.7674[ 706], max:   2.0661[ 305]\n",
      "466:xent_v0  [1000]: avg:   1.9145, min:   1.7644[ 706], max:   2.0606[ 305]\n",
      "===================\n",
      "beginning of epoch:  467\n",
      "available: 2.707 GB, used: 25.943 GB, free: 2.636 GB\n",
      "EPOCH: 467\n",
      "mean score: 0.00\n",
      "Speed: train: 1724.8, buffer_add: 919.0, buffer_size: 100035\n",
      "Total Time: 4H 33M 45S, 16425s\n",
      "Total Sample: train: 29.952M, buffer: 16.295M\n",
      "[467] Time spent = 37.57 s\n",
      "467:grad_norm[1000]: avg:   2.4291, min:   1.4981[ 321], max:   4.2235[ 406]\n",
      "467:loss     [1000]: avg:   7.1597, min:   4.9576[ 800], max:   9.5207[ 608]\n",
      "467:xent_pred[1000]: avg:   1.9168, min:   1.7397[ 703], max:   2.0968[  16]\n",
      "467:xent_v0  [1000]: avg:   1.9149, min:   1.7390[ 703], max:   2.0981[  16]\n",
      "===================\n",
      "beginning of epoch:  468\n",
      "available: 2.702 GB, used: 25.948 GB, free: 2.674 GB\n",
      "EPOCH: 468\n",
      "mean score: 0.00\n",
      "Speed: train: 1731.3, buffer_add: 915.4, buffer_size: 100022\n",
      "Total Time: 4H 34M 22S, 16462s\n",
      "Total Sample: train: 30.016M, buffer: 16.328M\n",
      "[468] Time spent = 37.41 s\n",
      "468:grad_norm[1000]: avg:   2.4625, min:   1.4443[ 701], max:   6.6793[ 579]\n",
      "468:loss     [1000]: avg:   7.1915, min:   5.0881[ 502], max:   9.6558[ 734]\n",
      "468:xent_pred[1000]: avg:   1.9158, min:   1.7734[ 639], max:   2.0587[ 698]\n",
      "468:xent_v0  [1000]: avg:   1.9141, min:   1.7760[ 349], max:   2.0583[ 211]\n",
      "===================\n",
      "beginning of epoch:  469\n",
      "available: 2.708 GB, used: 25.941 GB, free: 2.656 GB\n",
      "EPOCH: 469\n",
      "mean score: 0.00\n",
      "Speed: train: 1753.5, buffer_add: 918.8, buffer_size: 100000\n",
      "Total Time: 4H 34M 58S, 16498s\n",
      "Total Sample: train: 30.08M, buffer: 16.362M\n",
      "[469] Time spent = 36.91 s\n",
      "469:grad_norm[1000]: avg:   2.4735, min:   1.4419[ 334], max:   5.7117[ 921]\n",
      "469:loss     [1000]: avg:   7.2025, min:   5.3014[ 972], max:   9.5031[ 386]\n",
      "469:xent_pred[1000]: avg:   1.9154, min:   1.7585[ 711], max:   2.0513[ 367]\n",
      "469:xent_v0  [1000]: avg:   1.9136, min:   1.7613[ 338], max:   2.0470[ 367]\n",
      "===================\n",
      "beginning of epoch:  470\n",
      "available: 2.714 GB, used: 25.945 GB, free: 2.646 GB\n",
      "EPOCH: 470\n",
      "mean score: 0.02\n",
      "Speed: train: 1776.3, buffer_add: 913.8, buffer_size: 100018\n",
      "Total Time: 4H 35M 34S, 16534s\n",
      "Total Sample: train: 30.144M, buffer: 16.395M\n",
      "[470] Time spent = 36.44 s\n",
      "470:grad_norm[1000]: avg:   2.4925, min:   1.4396[ 686], max:   6.7937[ 596]\n",
      "470:loss     [1000]: avg:   7.2353, min:   5.3767[ 686], max:   9.5333[ 560]\n",
      "470:xent_pred[1000]: avg:   1.9118, min:   1.7774[ 560], max:   2.0562[ 537]\n",
      "470:xent_v0  [1000]: avg:   1.9102, min:   1.7728[ 308], max:   2.0548[ 537]\n",
      "===================\n",
      "beginning of epoch:  471\n",
      "available: 2.712 GB, used: 25.942 GB, free: 2.649 GB\n",
      "EPOCH: 471\n",
      "mean score: 0.00\n",
      "Speed: train: 1720.2, buffer_add: 919.2, buffer_size: 100084\n",
      "Total Time: 4H 36M 11S, 16571s\n",
      "Total Sample: train: 30.208M, buffer: 16.429M\n",
      "[471] Time spent = 37.57 s\n",
      "471:grad_norm[1000]: avg:   2.4713, min:   1.5183[ 669], max:   5.4521[ 975]\n",
      "471:loss     [1000]: avg:   7.1695, min:   5.5584[ 747], max:   9.9733[ 660]\n",
      "471:xent_pred[1000]: avg:   1.9149, min:   1.7582[ 564], max:   2.0801[ 176]\n",
      "471:xent_v0  [1000]: avg:   1.9136, min:   1.7592[ 564], max:   2.0810[ 176]\n",
      "===================\n",
      "beginning of epoch:  472\n",
      "available: 2.715 GB, used: 25.943 GB, free: 2.643 GB\n",
      "EPOCH: 472\n",
      "mean score: 0.00\n",
      "Speed: train: 1733.5, buffer_add: 911.0, buffer_size: 99999\n",
      "Total Time: 4H 36M 48S, 16608s\n",
      "Total Sample: train: 30.272M, buffer: 16.463M\n",
      "[472] Time spent = 37.20 s\n",
      "472:grad_norm[1000]: avg:   2.4290, min:   1.4970[ 952], max:   3.9943[ 150]\n",
      "472:loss     [1000]: avg:   7.1602, min:   5.2708[ 564], max:   9.4048[ 858]\n",
      "472:xent_pred[1000]: avg:   1.9136, min:   1.7275[ 298], max:   2.0699[ 249]\n",
      "472:xent_v0  [1000]: avg:   1.9120, min:   1.7190[ 912], max:   2.0718[ 249]\n",
      "===================\n",
      "beginning of epoch:  473\n",
      "available: 2.712 GB, used: 25.946 GB, free: 2.660 GB\n",
      "EPOCH: 473\n",
      "mean score: 0.00\n",
      "Speed: train: 1713.5, buffer_add: 907.9, buffer_size: 100046\n",
      "Total Time: 4H 37M 26S, 16646s\n",
      "Total Sample: train: 30.336M, buffer: 16.497M\n",
      "[473] Time spent = 37.76 s\n",
      "473:grad_norm[1000]: avg:   2.4477, min:   1.4080[ 650], max:   9.0848[ 443]\n",
      "473:loss     [1000]: avg:   7.2094, min:   5.0994[ 706], max:   9.2677[ 451]\n",
      "473:xent_pred[1000]: avg:   1.9121, min:   1.7662[  71], max:   2.0789[ 959]\n",
      "473:xent_v0  [1000]: avg:   1.9106, min:   1.7710[ 839], max:   2.0803[ 959]\n",
      "===================\n",
      "beginning of epoch:  474\n",
      "available: 2.718 GB, used: 25.939 GB, free: 2.639 GB\n",
      "EPOCH: 474\n",
      "mean score: 0.00\n",
      "Speed: train: 1818.0, buffer_add: 969.7, buffer_size: 100003\n",
      "Total Time: 4H 38M 01S, 16681s\n",
      "Total Sample: train: 30.4M, buffer: 16.531M\n",
      "[474] Time spent = 35.57 s\n",
      "474:grad_norm[1000]: avg:   2.4356, min:   1.4840[  84], max:   4.2412[ 324]\n",
      "474:loss     [1000]: avg:   7.1749, min:   5.2438[  10], max:   9.2877[ 209]\n",
      "474:xent_pred[1000]: avg:   1.9136, min:   1.7528[  95], max:   2.0818[ 493]\n",
      "474:xent_v0  [1000]: avg:   1.9116, min:   1.7553[ 360], max:   2.0827[ 493]\n",
      "===================\n",
      "beginning of epoch:  475\n",
      "available: 2.713 GB, used: 25.945 GB, free: 2.645 GB\n",
      "EPOCH: 475\n",
      "mean score: 0.00\n",
      "Speed: train: 1867.4, buffer_add: 1008.7, buffer_size: 100010\n",
      "Total Time: 4H 38M 35S, 16715s\n",
      "Total Sample: train: 30.464M, buffer: 16.565M\n",
      "[475] Time spent = 34.62 s\n",
      "475:grad_norm[1000]: avg:   2.4443, min:   1.4489[ 328], max:   5.4356[ 634]\n",
      "475:loss     [1000]: avg:   7.1721, min:   5.4701[  59], max:   9.2242[ 913]\n",
      "475:xent_pred[1000]: avg:   1.9120, min:   1.7833[ 207], max:   2.0661[ 426]\n",
      "475:xent_v0  [1000]: avg:   1.9100, min:   1.7665[ 207], max:   2.0619[ 404]\n",
      "===================\n",
      "beginning of epoch:  476\n",
      "available: 2.716 GB, used: 25.944 GB, free: 2.604 GB\n",
      "EPOCH: 476\n",
      "mean score: 0.00\n",
      "Speed: train: 1858.1, buffer_add: 1000.9, buffer_size: 100034\n",
      "Total Time: 4H 39M 10S, 16750s\n",
      "Total Sample: train: 30.528M, buffer: 16.6M\n",
      "[476] Time spent = 35.13 s\n",
      "476:grad_norm[1000]: avg:   2.4295, min:   1.4063[ 160], max:   4.8281[ 916]\n",
      "476:loss     [1000]: avg:   7.1488, min:   5.0323[ 731], max:   9.3742[ 431]\n",
      "476:xent_pred[1000]: avg:   1.9135, min:   1.6824[ 317], max:   2.0606[ 422]\n",
      "476:xent_v0  [1000]: avg:   1.9118, min:   1.6657[ 317], max:   2.0589[ 422]\n",
      "===================\n",
      "beginning of epoch:  477\n",
      "available: 2.714 GB, used: 25.942 GB, free: 2.630 GB\n",
      "EPOCH: 477\n",
      "mean score: 0.00\n",
      "Speed: train: 1844.8, buffer_add: 1021.0, buffer_size: 100027\n",
      "Total Time: 4H 39M 44S, 16784s\n",
      "Total Sample: train: 30.592M, buffer: 16.635M\n",
      "[477] Time spent = 35.08 s\n",
      "477:grad_norm[1000]: avg:   2.4382, min:   1.4539[ 886], max:   3.8841[ 851]\n",
      "477:loss     [1000]: avg:   7.1431, min:   5.4808[ 378], max:   9.2026[ 619]\n",
      "477:xent_pred[1000]: avg:   1.9139, min:   1.7296[  76], max:   2.1026[ 810]\n",
      "477:xent_v0  [1000]: avg:   1.9126, min:   1.7288[  76], max:   2.1080[ 810]\n",
      "===================\n",
      "beginning of epoch:  478\n",
      "available: 2.712 GB, used: 25.941 GB, free: 2.646 GB\n",
      "EPOCH: 478\n",
      "mean score: 0.00\n",
      "Speed: train: 1817.0, buffer_add: 1005.8, buffer_size: 100012\n",
      "Total Time: 4H 40M 20S, 16820s\n",
      "Total Sample: train: 30.656M, buffer: 16.671M\n",
      "[478] Time spent = 35.64 s\n",
      "478:grad_norm[1000]: avg:   2.4674, min:   1.5226[ 219], max:   5.4230[ 851]\n",
      "478:loss     [1000]: avg:   7.2043, min:   5.3239[ 714], max:   9.1823[ 343]\n",
      "478:xent_pred[1000]: avg:   1.9132, min:   1.7587[ 130], max:   2.0488[ 762]\n",
      "478:xent_v0  [1000]: avg:   1.9112, min:   1.7571[ 130], max:   2.0474[ 762]\n",
      "===================\n",
      "beginning of epoch:  479\n",
      "available: 2.709 GB, used: 25.946 GB, free: 2.664 GB\n",
      "EPOCH: 479\n",
      "mean score: 0.00\n",
      "Speed: train: 1827.8, buffer_add: 1016.1, buffer_size: 100020\n",
      "Total Time: 4H 40M 55S, 16855s\n",
      "Total Sample: train: 30.72M, buffer: 16.706M\n",
      "[479] Time spent = 35.43 s\n",
      "479:grad_norm[1000]: avg:   2.4321, min:   1.5043[ 305], max:   7.6191[ 196]\n",
      "479:loss     [1000]: avg:   7.1491, min:   5.2706[ 307], max:   9.5948[ 319]\n",
      "479:xent_pred[1000]: avg:   1.9174, min:   1.7665[ 944], max:   2.0709[  35]\n",
      "479:xent_v0  [1000]: avg:   1.9161, min:   1.7667[ 944], max:   2.0744[  35]\n",
      "===================\n",
      "beginning of epoch:  480\n",
      "available: 2.708 GB, used: 25.948 GB, free: 2.637 GB\n",
      "EPOCH: 480\n",
      "mean score: 0.00\n",
      "Speed: train: 1842.4, buffer_add: 1009.1, buffer_size: 100054\n",
      "Total Time: 4H 41M 29S, 16889s\n",
      "Total Sample: train: 30.784M, buffer: 16.741M\n",
      "[480] Time spent = 35.20 s\n",
      "480:grad_norm[1000]: avg:   2.4547, min:   1.2846[ 416], max:   6.8306[ 498]\n",
      "480:loss     [1000]: avg:   7.1634, min:   5.2744[ 459], max:   9.3554[ 169]\n",
      "480:xent_pred[1000]: avg:   1.9162, min:   1.7816[  59], max:   2.0619[   8]\n",
      "480:xent_v0  [1000]: avg:   1.9146, min:   1.7836[  59], max:   2.0632[   8]\n",
      "===================\n",
      "beginning of epoch:  481\n",
      "available: 2.694 GB, used: 25.958 GB, free: 2.651 GB\n",
      "EPOCH: 481\n",
      "mean score: 0.00\n",
      "Speed: train: 1876.0, buffer_add: 1009.0, buffer_size: 100015\n",
      "Total Time: 4H 42M 03S, 16923s\n",
      "Total Sample: train: 30.848M, buffer: 16.776M\n",
      "[481] Time spent = 34.54 s\n",
      "481:grad_norm[1000]: avg:   2.4485, min:   1.3421[ 537], max:   5.4351[ 100]\n",
      "481:loss     [1000]: avg:   7.1543, min:   5.3924[ 398], max:   9.2411[ 583]\n",
      "481:xent_pred[1000]: avg:   1.9128, min:   1.7328[ 884], max:   2.0464[ 358]\n",
      "481:xent_v0  [1000]: avg:   1.9116, min:   1.7315[ 884], max:   2.0522[ 358]\n",
      "===================\n",
      "beginning of epoch:  482\n",
      "available: 2.709 GB, used: 25.945 GB, free: 2.677 GB\n",
      "EPOCH: 482\n",
      "mean score: 0.00\n",
      "Speed: train: 1845.4, buffer_add: 999.6, buffer_size: 100042\n",
      "Total Time: 4H 42M 38S, 16958s\n",
      "Total Sample: train: 30.912M, buffer: 16.81M\n",
      "[482] Time spent = 35.10 s\n",
      "482:grad_norm[1000]: avg:   2.4536, min:   1.4153[ 726], max:   4.6940[  19]\n",
      "482:loss     [1000]: avg:   7.1730, min:   5.4417[ 142], max:   9.1497[ 454]\n",
      "482:xent_pred[1000]: avg:   1.9141, min:   1.7448[ 935], max:   2.0550[  50]\n",
      "482:xent_v0  [1000]: avg:   1.9125, min:   1.7444[ 935], max:   2.0523[  50]\n",
      "===================\n",
      "beginning of epoch:  483\n",
      "available: 2.710 GB, used: 25.943 GB, free: 2.671 GB\n",
      "EPOCH: 483\n",
      "mean score: 0.00\n",
      "Speed: train: 1871.0, buffer_add: 1002.8, buffer_size: 100017\n",
      "Total Time: 4H 43M 12S, 16992s\n",
      "Total Sample: train: 30.976M, buffer: 16.845M\n",
      "[483] Time spent = 34.66 s\n",
      "483:grad_norm[1000]: avg:   2.4603, min:   1.5126[ 925], max:   3.8945[ 514]\n",
      "483:loss     [1000]: avg:   7.1720, min:   5.4120[ 622], max:   9.0704[  39]\n",
      "483:xent_pred[1000]: avg:   1.9113, min:   1.7683[ 574], max:   2.0545[ 470]\n",
      "483:xent_v0  [1000]: avg:   1.9098, min:   1.7599[ 574], max:   2.0464[ 969]\n",
      "===================\n",
      "beginning of epoch:  484\n",
      "available: 2.703 GB, used: 25.949 GB, free: 2.622 GB\n",
      "EPOCH: 484\n",
      "mean score: 0.00\n",
      "Speed: train: 1869.7, buffer_add: 1004.9, buffer_size: 100088\n",
      "Total Time: 4H 43M 47S, 17027s\n",
      "Total Sample: train: 31.04M, buffer: 16.879M\n",
      "[484] Time spent = 34.42 s\n",
      "484:grad_norm[1000]: avg:   2.4636, min:   1.4360[ 885], max:   4.2518[ 776]\n",
      "484:loss     [1000]: avg:   7.1974, min:   5.3561[ 457], max:   9.2659[   7]\n",
      "484:xent_pred[1000]: avg:   1.9147, min:   1.7628[ 208], max:   2.0827[ 246]\n",
      "484:xent_v0  [1000]: avg:   1.9128, min:   1.7592[ 208], max:   2.0807[ 246]\n",
      "===================\n",
      "beginning of epoch:  485\n",
      "available: 2.707 GB, used: 25.944 GB, free: 2.721 GB\n",
      "EPOCH: 485\n",
      "mean score: 0.00\n",
      "Speed: train: 1861.0, buffer_add: 989.2, buffer_size: 100016\n",
      "Total Time: 4H 44M 21S, 17061s\n",
      "Total Sample: train: 31.104M, buffer: 16.913M\n",
      "[485] Time spent = 34.65 s\n",
      "485:grad_norm[1000]: avg:   2.4448, min:   1.4577[ 247], max:   4.7617[  86]\n",
      "485:loss     [1000]: avg:   7.1583, min:   5.6426[ 353], max:   9.4669[ 173]\n",
      "485:xent_pred[1000]: avg:   1.9130, min:   1.7292[ 301], max:   2.0828[ 407]\n",
      "485:xent_v0  [1000]: avg:   1.9110, min:   1.7352[ 301], max:   2.0698[ 407]\n",
      "===================\n",
      "beginning of epoch:  486\n",
      "available: 2.706 GB, used: 25.941 GB, free: 2.683 GB\n",
      "EPOCH: 486\n",
      "mean score: 0.00\n",
      "Speed: train: 1869.6, buffer_add: 991.5, buffer_size: 100103\n",
      "Total Time: 4H 44M 55S, 17095s\n",
      "Total Sample: train: 31.168M, buffer: 16.947M\n",
      "[486] Time spent = 34.67 s\n",
      "486:grad_norm[1000]: avg:   2.4469, min:   1.5110[ 795], max:   4.5533[ 160]\n",
      "486:loss     [1000]: avg:   7.1630, min:   5.2130[ 757], max:   9.3095[ 738]\n",
      "486:xent_pred[1000]: avg:   1.9160, min:   1.7451[ 264], max:   2.0848[ 809]\n",
      "486:xent_v0  [1000]: avg:   1.9145, min:   1.7510[ 264], max:   2.0806[ 809]\n",
      "===================\n",
      "beginning of epoch:  487\n",
      "available: 2.693 GB, used: 25.953 GB, free: 2.653 GB\n",
      "EPOCH: 487\n",
      "mean score: 0.00\n",
      "Speed: train: 1832.8, buffer_add: 1001.4, buffer_size: 100043\n",
      "Total Time: 4H 45M 30S, 17130s\n",
      "Total Sample: train: 31.232M, buffer: 16.982M\n",
      "[487] Time spent = 35.32 s\n",
      "487:grad_norm[1000]: avg:   2.4245, min:   1.3748[ 407], max:   4.1084[ 820]\n",
      "487:loss     [1000]: avg:   7.1152, min:   5.2522[ 869], max:   9.2138[ 954]\n",
      "487:xent_pred[1000]: avg:   1.9156, min:   1.7644[ 888], max:   2.0852[ 681]\n",
      "487:xent_v0  [1000]: avg:   1.9138, min:   1.7688[ 888], max:   2.0771[ 681]\n",
      "===================\n",
      "beginning of epoch:  488\n",
      "available: 2.703 GB, used: 25.957 GB, free: 2.608 GB\n",
      "EPOCH: 488\n",
      "mean score: 0.00\n",
      "Speed: train: 1885.2, buffer_add: 1006.1, buffer_size: 100021\n",
      "Total Time: 4H 46M 04S, 17164s\n",
      "Total Sample: train: 31.296M, buffer: 17.016M\n",
      "[488] Time spent = 34.27 s\n",
      "488:grad_norm[1000]: avg:   2.4325, min:   1.4579[ 726], max:   4.5909[ 943]\n",
      "488:loss     [1000]: avg:   7.1556, min:   5.2163[ 940], max:   9.6556[  91]\n",
      "488:xent_pred[1000]: avg:   1.9155, min:   1.7620[  15], max:   2.0675[   6]\n",
      "488:xent_v0  [1000]: avg:   1.9132, min:   1.7627[  15], max:   2.0633[ 377]\n",
      "===================\n",
      "beginning of epoch:  489\n",
      "available: 2.695 GB, used: 25.956 GB, free: 2.651 GB\n",
      "EPOCH: 489\n",
      "mean score: 0.00\n",
      "Speed: train: 1822.5, buffer_add: 1004.5, buffer_size: 100038\n",
      "Total Time: 4H 46M 39S, 17199s\n",
      "Total Sample: train: 31.36M, buffer: 17.051M\n",
      "[489] Time spent = 35.40 s\n",
      "489:grad_norm[1000]: avg:   2.4323, min:   1.4793[ 834], max:   4.3234[ 713]\n",
      "489:loss     [1000]: avg:   7.2026, min:   5.3389[ 649], max:  10.2536[ 773]\n",
      "489:xent_pred[1000]: avg:   1.9127, min:   1.7446[ 247], max:   2.0798[ 974]\n",
      "489:xent_v0  [1000]: avg:   1.9106, min:   1.7337[ 247], max:   2.0774[ 974]\n",
      "===================\n",
      "beginning of epoch:  490\n",
      "available: 2.698 GB, used: 25.961 GB, free: 2.623 GB\n",
      "EPOCH: 490\n",
      "mean score: 0.00\n",
      "Speed: train: 1855.4, buffer_add: 1004.9, buffer_size: 100074\n",
      "Total Time: 4H 47M 14S, 17234s\n",
      "Total Sample: train: 31.424M, buffer: 17.086M\n",
      "[490] Time spent = 34.97 s\n",
      "490:grad_norm[1000]: avg:   2.4179, min:   1.3538[ 974], max:   6.1671[ 460]\n",
      "490:loss     [1000]: avg:   7.1726, min:   5.1458[ 951], max:   9.9916[ 950]\n",
      "490:xent_pred[1000]: avg:   1.9162, min:   1.7696[ 301], max:   2.0627[  42]\n",
      "490:xent_v0  [1000]: avg:   1.9140, min:   1.7598[ 301], max:   2.0656[ 968]\n",
      "===================\n",
      "beginning of epoch:  491\n",
      "available: 2.702 GB, used: 25.950 GB, free: 2.673 GB\n",
      "EPOCH: 491\n",
      "mean score: 0.00\n",
      "Speed: train: 1864.9, buffer_add: 1004.2, buffer_size: 100040\n",
      "Total Time: 4H 47M 48S, 17268s\n",
      "Total Sample: train: 31.488M, buffer: 17.12M\n",
      "[491] Time spent = 34.69 s\n",
      "491:grad_norm[1000]: avg:   2.4243, min:   1.4322[ 200], max:   5.5319[ 433]\n",
      "491:loss     [1000]: avg:   7.1868, min:   5.1163[ 357], max:   9.6858[ 927]\n",
      "491:xent_pred[1000]: avg:   1.9143, min:   1.7390[ 470], max:   2.0956[  33]\n",
      "491:xent_v0  [1000]: avg:   1.9123, min:   1.7367[ 470], max:   2.0853[  33]\n",
      "===================\n",
      "beginning of epoch:  492\n",
      "available: 2.702 GB, used: 25.949 GB, free: 2.685 GB\n",
      "EPOCH: 492\n",
      "mean score: 0.00\n",
      "Speed: train: 1877.3, buffer_add: 1012.2, buffer_size: 100102\n",
      "Total Time: 4H 48M 22S, 17302s\n",
      "Total Sample: train: 31.552M, buffer: 17.155M\n",
      "[492] Time spent = 34.46 s\n",
      "492:grad_norm[1000]: avg:   2.4450, min:   1.4655[ 561], max:   4.5873[ 453]\n",
      "492:loss     [1000]: avg:   7.2094, min:   5.2510[ 300], max:   9.4157[ 958]\n",
      "492:xent_pred[1000]: avg:   1.9122, min:   1.7078[ 923], max:   2.0654[ 576]\n",
      "492:xent_v0  [1000]: avg:   1.9103, min:   1.7016[ 923], max:   2.0665[ 681]\n",
      "===================\n",
      "beginning of epoch:  493\n",
      "available: 2.700 GB, used: 25.951 GB, free: 2.655 GB\n",
      "EPOCH: 493\n",
      "mean score: 0.00\n",
      "Speed: train: 1849.9, buffer_add: 1013.4, buffer_size: 100031\n",
      "Total Time: 4H 48M 57S, 17337s\n",
      "Total Sample: train: 31.616M, buffer: 17.19M\n",
      "[493] Time spent = 34.97 s\n",
      "493:grad_norm[1000]: avg:   2.4202, min:   1.3684[ 766], max:   4.9432[  89]\n",
      "493:loss     [1000]: avg:   7.1482, min:   5.0513[ 304], max:   9.4138[ 921]\n",
      "493:xent_pred[1000]: avg:   1.9151, min:   1.7758[ 517], max:   2.0735[ 115]\n",
      "493:xent_v0  [1000]: avg:   1.9133, min:   1.7885[ 517], max:   2.0772[ 115]\n",
      "===================\n",
      "beginning of epoch:  494\n",
      "available: 2.699 GB, used: 25.951 GB, free: 2.638 GB\n",
      "EPOCH: 494\n",
      "mean score: 0.00\n",
      "Speed: train: 1827.1, buffer_add: 966.7, buffer_size: 100044\n",
      "Total Time: 4H 49M 32S, 17372s\n",
      "Total Sample: train: 31.68M, buffer: 17.224M\n",
      "[494] Time spent = 35.40 s\n",
      "494:grad_norm[1000]: avg:   2.4297, min:   1.4324[ 239], max:   4.0986[ 413]\n",
      "494:loss     [1000]: avg:   7.1700, min:   5.3877[ 221], max:  10.0721[ 593]\n",
      "494:xent_pred[1000]: avg:   1.9131, min:   1.7847[ 523], max:   2.0726[  93]\n",
      "494:xent_v0  [1000]: avg:   1.9116, min:   1.7892[ 486], max:   2.0764[ 606]\n",
      "===================\n",
      "beginning of epoch:  495\n",
      "available: 2.698 GB, used: 25.962 GB, free: 2.662 GB\n",
      "EPOCH: 495\n",
      "mean score: 0.00\n",
      "Speed: train: 1804.6, buffer_add: 963.6, buffer_size: 100016\n",
      "Total Time: 4H 50M 07S, 17407s\n",
      "Total Sample: train: 31.744M, buffer: 17.258M\n",
      "[495] Time spent = 36.00 s\n",
      "495:grad_norm[1000]: avg:   2.4326, min:   1.4413[ 427], max:   5.4469[ 124]\n",
      "495:loss     [1000]: avg:   7.1787, min:   5.3260[ 119], max:   9.7171[ 879]\n",
      "495:xent_pred[1000]: avg:   1.9153, min:   1.7595[ 891], max:   2.0448[ 927]\n",
      "495:xent_v0  [1000]: avg:   1.9138, min:   1.7595[ 891], max:   2.0471[ 927]\n",
      "===================\n",
      "beginning of epoch:  496\n",
      "available: 2.699 GB, used: 25.955 GB, free: 2.643 GB\n",
      "EPOCH: 496\n",
      "mean score: 0.00\n",
      "Speed: train: 1867.9, buffer_add: 1005.4, buffer_size: 100019\n",
      "Total Time: 4H 50M 41S, 17441s\n",
      "Total Sample: train: 31.808M, buffer: 17.293M\n",
      "[496] Time spent = 34.71 s\n",
      "496:grad_norm[1000]: avg:   2.4589, min:   1.5210[ 367], max:   7.1323[ 113]\n",
      "496:loss     [1000]: avg:   7.1644, min:   5.3155[ 938], max:   9.7862[ 510]\n",
      "496:xent_pred[1000]: avg:   1.9139, min:   1.7624[ 729], max:   2.0500[ 299]\n",
      "496:xent_v0  [1000]: avg:   1.9129, min:   1.7605[ 729], max:   2.0456[   3]\n",
      "===================\n",
      "beginning of epoch:  497\n",
      "available: 2.699 GB, used: 25.953 GB, free: 2.640 GB\n",
      "EPOCH: 497\n",
      "mean score: 0.00\n",
      "Speed: train: 1844.6, buffer_add: 1011.4, buffer_size: 100028\n",
      "Total Time: 4H 51M 16S, 17476s\n",
      "Total Sample: train: 31.872M, buffer: 17.328M\n",
      "[497] Time spent = 35.04 s\n",
      "497:grad_norm[1000]: avg:   2.4389, min:   1.2605[ 379], max:   5.1922[ 321]\n",
      "497:loss     [1000]: avg:   7.1951, min:   4.9985[ 379], max:   9.7358[ 104]\n",
      "497:xent_pred[1000]: avg:   1.9121, min:   1.7819[ 627], max:   2.0488[ 962]\n",
      "497:xent_v0  [1000]: avg:   1.9105, min:   1.7773[ 442], max:   2.0447[ 962]\n",
      "===================\n",
      "beginning of epoch:  498\n",
      "available: 2.695 GB, used: 25.959 GB, free: 2.642 GB\n",
      "EPOCH: 498\n",
      "mean score: 0.00\n",
      "Speed: train: 1826.8, buffer_add: 1004.9, buffer_size: 100019\n",
      "Total Time: 4H 51M 51S, 17511s\n",
      "Total Sample: train: 31.936M, buffer: 17.363M\n",
      "[498] Time spent = 35.31 s\n",
      "498:grad_norm[1000]: avg:   2.4274, min:   1.4066[ 505], max:   5.1166[ 710]\n",
      "498:loss     [1000]: avg:   7.2028, min:   5.3047[ 801], max:   9.4197[  91]\n",
      "498:xent_pred[1000]: avg:   1.9123, min:   1.7729[  20], max:   2.0513[ 400]\n",
      "498:xent_v0  [1000]: avg:   1.9104, min:   1.7687[  20], max:   2.0543[ 400]\n",
      "===================\n",
      "beginning of epoch:  499\n",
      "available: 2.705 GB, used: 25.946 GB, free: 2.656 GB\n",
      "EPOCH: 499\n",
      "mean score: 0.00\n",
      "Speed: train: 1825.0, buffer_add: 1007.5, buffer_size: 100002\n",
      "Total Time: 4H 52M 26S, 17546s\n",
      "Total Sample: train: 32M, buffer: 17.398M\n",
      "[499] Time spent = 35.30 s\n",
      "499:grad_norm[1000]: avg:   2.4353, min:   1.4113[ 385], max:   4.2440[ 894]\n",
      "499:loss     [1000]: avg:   7.2211, min:   5.1549[ 119], max:   9.6269[ 900]\n",
      "499:xent_pred[1000]: avg:   1.9140, min:   1.7538[ 910], max:   2.0479[ 495]\n",
      "499:xent_v0  [1000]: avg:   1.9118, min:   1.7520[ 910], max:   2.0468[ 587]\n",
      "===================\n"
     ]
    }
   ],
   "source": [
    "!sh scripts/belief_obl0.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T02:12:55.822085Z",
     "iopub.status.busy": "2022-05-10T02:12:55.821754Z",
     "iopub.status.idle": "2022-05-10T02:12:57.644633Z",
     "shell.execute_reply": "2022-05-10T02:12:57.643519Z",
     "shell.execute_reply.started": "2022-05-10T02:12:55.822040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright (c) Facebook, Inc. and its affiliates.\n",
      "# All rights reserved.\n",
      "#\n",
      "# This source code is licensed under the license found in the\n",
      "# LICENSE file in the root directory of this source tree.\n",
      "#\n",
      "#!/bin/bash\n",
      "python selfplay.py \\\n",
      "       --save_dir /notebooks/obl1 \\\n",
      "       --num_thread 8 \\\n",
      "       --num_game_per_thread 120 \\\n",
      "       --sad 0 \\\n",
      "       --act_base_eps 0.1 \\\n",
      "       --act_eps_alpha 7 \\\n",
      "       --lr 6.25e-05 \\\n",
      "       --eps 1.5e-05 \\\n",
      "       --grad_clip 5 \\\n",
      "       --gamma 0.999 \\\n",
      "       --seed 2254257 \\\n",
      "       --batchsize 64 \\\n",
      "       --burn_in_frames 10000 \\\n",
      "       --replay_buffer_size 100000 \\\n",
      "       --epoch_len 1000 \\\n",
      "       --num_epoch 1500 \\\n",
      "       --num_player 2 \\\n",
      "       --rnn_hid_dim 256 \\\n",
      "       --multi_step 1 \\\n",
      "       --train_device cuda:0 \\\n",
      "       --act_device cuda:0 \\\n",
      "       --num_lstm_layer 2 \\\n",
      "       --boltzmann_act 0 \\\n",
      "       --min_t 0.01 \\\n",
      "       --max_t 0.1 \\\n",
      "       --off_belief 1 \\\n",
      "       --num_fict_sample 10 \\\n",
      "       --belief_device cuda:0 \\\n",
      "       --belief_model exps/belief_obl0/model0.pthw \\\n",
      "       --load_model None \\\n",
      "       --net publ-lstm \\\n"
     ]
    }
   ],
   "source": [
    "!cp -n scripts/obl1.sh scripts/obl1.sh.old\n",
    "!sed -r -e \"s/(--save_dir)[^\\\\]*/\\\\1 \\\\/notebooks\\\\/obl1 /g\" \\\\\n",
    "        -e \"s/(--num_thread)[^\\\\]*/\\\\1 8 /g\" \\\\\n",
    "        -e \"s/(--num_game_per_thread)[^\\\\]*/\\\\1 120 /g\" \\\\\n",
    "        -e \"s/(--batchsize)[^\\\\]*/\\\\1 64 /g\" \\\\\n",
    "        -e \"s/(--rnn_hid_dim)[^\\\\]*/\\\\1 256 /g\" \\\\\n",
    "        -e \"s/(--act_device)[^\\\\]*/\\\\1 cuda:0 /g\" \\\\\n",
    "        -e \"s/(--belief_device)[^\\\\]*/\\\\1 cuda:0 /g\" \\\\\n",
    "        scripts/obl1.sh.old > scripts/obl1.sh\n",
    "!cat scripts/obl1.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "732f3eb9-9723-4265-a6ea-bfc4fcf94349",
     "kernelId": "4a4998a0-bb69-4701-b83a-04273713494c",
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'act_base_eps': 0.1,\n",
      " 'act_device': 'cuda:0',\n",
      " 'act_eps_alpha': 7.0,\n",
      " 'actor_sync_freq': 10,\n",
      " 'aux_weight': 0,\n",
      " 'batchsize': 64,\n",
      " 'belief_device': 'cuda:0',\n",
      " 'belief_model': 'exps/belief_obl0/model0.pthw',\n",
      " 'boltzmann_act': 0,\n",
      " 'burn_in_frames': 10000,\n",
      " 'clone_bot': '',\n",
      " 'clone_t': 0.02,\n",
      " 'clone_weight': 0.0,\n",
      " 'epoch_len': 1000,\n",
      " 'eps': 1.5e-05,\n",
      " 'eta': 0.9,\n",
      " 'eval_bomb': 0,\n",
      " 'gamma': 0.999,\n",
      " 'grad_clip': 5.0,\n",
      " 'hide_action': 0,\n",
      " 'load_model': 'None',\n",
      " 'lr': 6.25e-05,\n",
      " 'max_len': 80,\n",
      " 'max_t': 0.1,\n",
      " 'method': 'iql',\n",
      " 'min_t': 0.01,\n",
      " 'multi_step': 1,\n",
      " 'net': 'publ-lstm',\n",
      " 'num_epoch': 1500,\n",
      " 'num_fict_sample': 10,\n",
      " 'num_game_per_thread': 120,\n",
      " 'num_lstm_layer': 2,\n",
      " 'num_player': 2,\n",
      " 'num_t': 80,\n",
      " 'num_thread': 8,\n",
      " 'num_update_between_sync': 2500,\n",
      " 'off_belief': 1,\n",
      " 'prefetch': 3,\n",
      " 'priority_exponent': 0.9,\n",
      " 'priority_weight': 0.6,\n",
      " 'replay_buffer_size': 100000,\n",
      " 'rnn_hid_dim': 256,\n",
      " 'sad': 0,\n",
      " 'save_dir': '/notebooks/obl1',\n",
      " 'seed': 2254257,\n",
      " 'shuffle_color': 0,\n",
      " 'train_bomb': 0,\n",
      " 'train_device': 'cuda:0'}\n",
      "explore eps: [0.1, 0.08154407395185162, 0.06649435996665046, 0.05422221006501587, 0.04421499907374487, 0.03605471154250502, 0.02940048064334708, 0.023974349678010775, 0.019549661430912607, 0.01594159037455999, 0.012999422244132457, 0.010600258488068826, 0.008643882620598262, 0.007048574036451904, 0.005747694424835353, 0.004686904192314193, 0.0038218926206331195, 0.003116526944929431, 0.0025413430367026368, 0.0020723146452190297, 0.0016898497868124572, 0.0013779723598335584, 0.0011236548001387517, 0.0009162739011886733, 0.0007471670675868075, 0.0006092704661368676, 0.0004968239594734388, 0.0004051304969235383, 0.00033035991201283403, 0.0002693889309590173, 0.00021967070907932357, 0.00017912844546220044, 0.00014606863203649891, 0.0001191103133283007, 9.712740198471169e-05, 7.920164050192559e-05, 6.45842443019698e-05, 5.266462393484282e-05, 4.294487988789273e-05, 3.5019004614317064e-05, 2.8555923019901068e-05, 2.3285662984981972e-05, 1.8988078244652658e-05, 1.5483652565854994e-05, 1.2626001098748582e-05, 1.029575567312513e-05, 8.395578619995106e-06, 6.8460968385746595e-06, 5.582586268862691e-06, 4.552268275507311e-06, 3.712105009066358e-06, 3.0270016537634625e-06, 2.4683404670686517e-06, 2.012785375849939e-06, 1.6413071953751306e-06, 1.3383887531737569e-06, 1.0913767146512742e-06, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "avg explore eps: 0.006772832055818007\n",
      "no boltzmann\n",
      "feature_size: (191, 171, 151)\n",
      "R2D2Agent(\n",
      "  (online_net): PublicLSTMNet(\n",
      "    (priv_net): RecursiveScriptModule(\n",
      "      original_name=Sequential\n",
      "      (0): RecursiveScriptModule(original_name=Linear)\n",
      "      (1): RecursiveScriptModule(original_name=ReLU)\n",
      "      (2): RecursiveScriptModule(original_name=Linear)\n",
      "      (3): RecursiveScriptModule(original_name=ReLU)\n",
      "      (4): RecursiveScriptModule(original_name=Linear)\n",
      "      (5): RecursiveScriptModule(original_name=ReLU)\n",
      "    )\n",
      "    (publ_net): RecursiveScriptModule(\n",
      "      original_name=Sequential\n",
      "      (0): RecursiveScriptModule(original_name=Linear)\n",
      "      (1): RecursiveScriptModule(original_name=ReLU)\n",
      "    )\n",
      "    (lstm): RecursiveScriptModule(original_name=LSTM)\n",
      "    (fc_v): RecursiveScriptModule(original_name=Linear)\n",
      "    (fc_a): RecursiveScriptModule(original_name=Linear)\n",
      "    (pred_1st): RecursiveScriptModule(original_name=Linear)\n",
      "  )\n",
      "  (target_net): PublicLSTMNet(\n",
      "    (priv_net): RecursiveScriptModule(\n",
      "      original_name=Sequential\n",
      "      (0): RecursiveScriptModule(original_name=Linear)\n",
      "      (1): RecursiveScriptModule(original_name=ReLU)\n",
      "      (2): RecursiveScriptModule(original_name=Linear)\n",
      "      (3): RecursiveScriptModule(original_name=ReLU)\n",
      "      (4): RecursiveScriptModule(original_name=Linear)\n",
      "      (5): RecursiveScriptModule(original_name=ReLU)\n",
      "    )\n",
      "    (publ_net): RecursiveScriptModule(\n",
      "      original_name=Sequential\n",
      "      (0): RecursiveScriptModule(original_name=Linear)\n",
      "      (1): RecursiveScriptModule(original_name=ReLU)\n",
      "    )\n",
      "    (lstm): RecursiveScriptModule(original_name=LSTM)\n",
      "    (fc_v): RecursiveScriptModule(original_name=Linear)\n",
      "    (fc_a): RecursiveScriptModule(original_name=Linear)\n",
      "    (pred_1st): RecursiveScriptModule(original_name=Linear)\n",
      "  )\n",
      ")\n",
      "load belief model from exps/belief_obl0/model0.pthw\n",
      "add belief model to:  cuda:0\n",
      "ActGroup created\n",
      "Finished creating 8 threads with 960 games and 8 actors\n",
      "warming up replay buffer: 0\n",
      "warming up replay buffer: 4\n",
      "warming up replay buffer: 879\n",
      "warming up replay buffer: 2005\n",
      "warming up replay buffer: 3083\n",
      "warming up replay buffer: 4099\n",
      "warming up replay buffer: 5210\n",
      "warming up replay buffer: 6218\n",
      "warming up replay buffer: 7232\n",
      "warming up replay buffer: 8283\n",
      "warming up replay buffer: 9342\n",
      "Success, Done\n",
      "=======================\n",
      "beginning of epoch:  0\n",
      "available: 23.907 GB, used: 5.125 GB, free: 19.631 GB\n",
      "EPOCH: 0\n",
      "Speed: train: 1047.6, buffer_add: 829.3, buffer_size: 50665\n",
      "Total Time: 0H 01M 01S, 61s\n",
      "Total Sample: train: 64K, buffer: 50.665K\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.22%\n",
      "\tsample data       : 0 MS, 1.56%\n",
      "\tforward & backward: 40 MS, 65.59%\n",
      "\tupdate model      : 17 MS, 28.56%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 61.02 ms\n",
      "[0] Time spent = 61.10 s\n",
      "0:boltzmann_t  [1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "0:grad_norm    [1000]: avg:   0.0712, min:   0.0075[  81], max:   0.4075[ 966]\n",
      "0:loss         [1000]: avg:   0.1022, min:   0.0266[ 694], max:   0.9447[ 189]\n",
      "0:rl_loss      [1000]: avg:   0.2679, min:   0.1166[ 968], max:   0.5030[ 271]\n",
      "epoch 0, eval score: 0.3030, perfect: 0.00, model saved: True\n",
      "epoch 0, success rate for sampling ficticious state: 99.92%\n",
      "==========\n",
      "beginning of epoch:  1\n",
      "available: 18.992 GB, used: 10.040 GB, free: 14.714 GB\n",
      "EPOCH: 1\n",
      "Speed: train: 1052.2, buffer_add: 527.5, buffer_size: 82749\n",
      "Total Time: 0H 02M 01S, 121s\n",
      "Total Sample: train: 128K, buffer: 82.749K\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.84%\n",
      "\tsample data       : 1 MS, 1.65%\n",
      "\tforward & backward: 39 MS, 65.21%\n",
      "\tupdate model      : 17 MS, 29.20%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 60.75 ms\n",
      "[1] Time spent = 60.83 s\n",
      "1:boltzmann_t  [1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1:grad_norm    [1000]: avg:   0.1157, min:   0.0231[  87], max:   0.7398[ 122]\n",
      "1:loss         [1000]: avg:   0.0752, min:   0.0215[ 933], max:   0.3380[ 156]\n",
      "1:rl_loss      [1000]: avg:   0.1313, min:   0.0762[ 774], max:   0.2245[  29]\n",
      "epoch 1, eval score: 0.4350, perfect: 0.00, model saved: True\n",
      "epoch 1, success rate for sampling ficticious state: 99.86%\n",
      "==========\n",
      "beginning of epoch:  2\n",
      "available: 15.138 GB, used: 13.894 GB, free: 10.860 GB\n",
      "EPOCH: 2\n",
      "Speed: train: 1066.7, buffer_add: 495.0, buffer_size: 100026\n",
      "Total Time: 0H 03M 01S, 181s\n",
      "Total Sample: train: 192K, buffer: 112.45K\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.71%\n",
      "\tsample data       : 0 MS, 1.65%\n",
      "\tforward & backward: 39 MS, 65.62%\n",
      "\tupdate model      : 17 MS, 28.93%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 59.92 ms\n",
      "[2] Time spent = 60.00 s\n",
      "2:boltzmann_t  [1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "2:grad_norm    [1000]: avg:   0.1066, min:   0.0102[ 796], max:   0.5052[ 271]\n",
      "2:loss         [1000]: avg:   0.0552, min:   0.0059[ 796], max:   0.1849[ 174]\n",
      "2:rl_loss      [1000]: avg:   0.1064, min:   0.0569[ 821], max:   0.1760[ 414]\n",
      "epoch 2, eval score: 0.3220, perfect: 0.00, model saved: True\n",
      "epoch 2, success rate for sampling ficticious state: 99.87%\n",
      "==========\n",
      "beginning of epoch:  3\n",
      "available: 11.604 GB, used: 17.427 GB, free: 7.326 GB\n",
      "EPOCH: 3\n",
      "Speed: train: 1047.9, buffer_add: 505.3, buffer_size: 100035\n",
      "Total Time: 0H 04M 02S, 242s\n",
      "Total Sample: train: 256K, buffer: 143.312K\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.88%\n",
      "\tsample data       : 0 MS, 1.52%\n",
      "\tforward & backward: 40 MS, 65.59%\n",
      "\tupdate model      : 17 MS, 28.91%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 61.00 ms\n",
      "[3] Time spent = 61.08 s\n",
      "3:boltzmann_t  [1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "3:grad_norm    [1000]: avg:   0.0832, min:   0.0088[ 123], max:   0.3422[  18]\n",
      "3:loss         [1000]: avg:   0.0396, min:   0.0043[ 123], max:   0.1148[  45]\n",
      "3:rl_loss      [1000]: avg:   0.0778, min:   0.0396[ 400], max:   0.1451[  86]\n",
      "epoch 3, eval score: 0.3380, perfect: 0.00, model saved: True\n",
      "epoch 3, success rate for sampling ficticious state: 99.86%\n",
      "==========\n",
      "beginning of epoch:  4\n",
      "available: 9.604 GB, used: 19.427 GB, free: 5.326 GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 4\n",
      "Speed: train: 1077.5, buffer_add: 502.0, buffer_size: 100039\n",
      "Total Time: 0H 05M 02S, 302s\n",
      "Total Sample: train: 320K, buffer: 173.129K\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.90%\n",
      "\tsample data       : 0 MS, 1.59%\n",
      "\tforward & backward: 38 MS, 65.11%\n",
      "\tupdate model      : 17 MS, 29.31%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 59.33 ms\n",
      "[4] Time spent = 59.40 s\n",
      "4:boltzmann_t  [1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "4:grad_norm    [1000]: avg:   0.0835, min:   0.0100[ 559], max:   0.3433[ 323]\n",
      "4:loss         [1000]: avg:   0.0381, min:   0.0036[ 514], max:   0.1203[ 900]\n",
      "4:rl_loss      [1000]: avg:   0.0723, min:   0.0427[ 509], max:   0.1158[ 390]\n",
      "epoch 4, eval score: 0.3350, perfect: 0.00, model saved: True\n",
      "epoch 4, success rate for sampling ficticious state: 99.87%\n",
      "==========\n",
      "beginning of epoch:  5\n",
      "available: 8.679 GB, used: 20.353 GB, free: 4.401 GB\n",
      "EPOCH: 5\n",
      "Speed: train: 1070.3, buffer_add: 529.8, buffer_size: 100026\n",
      "Total Time: 0H 06M 02S, 362s\n",
      "Total Sample: train: 384K, buffer: 204.809K\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.35%\n",
      "\tsample data       : 1 MS, 2.05%\n",
      "\tforward & backward: 38 MS, 64.64%\n",
      "\tupdate model      : 17 MS, 28.84%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 59.73 ms\n",
      "[5] Time spent = 59.80 s\n",
      "5:boltzmann_t  [1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "5:grad_norm    [1000]: avg:   0.1044, min:   0.0122[ 360], max:   0.5011[ 899]\n",
      "5:loss         [1000]: avg:   0.0509, min:   0.0082[ 417], max:   0.1656[ 899]\n",
      "5:rl_loss      [1000]: avg:   0.0730, min:   0.0416[ 137], max:   0.1125[ 899]\n",
      "epoch 5, eval score: 0.3860, perfect: 0.00, model saved: True\n",
      "epoch 5, success rate for sampling ficticious state: 99.89%\n",
      "==========\n",
      "beginning of epoch:  6\n",
      "available: 7.902 GB, used: 21.129 GB, free: 3.620 GB\n",
      "EPOCH: 6\n",
      "Speed: train: 1061.8, buffer_add: 533.3, buffer_size: 100019\n",
      "Total Time: 0H 07M 02S, 422s\n",
      "Total Sample: train: 448K, buffer: 236.952K\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.84%\n",
      "\tsample data       : 1 MS, 1.75%\n",
      "\tforward & backward: 38 MS, 64.60%\n",
      "\tupdate model      : 17 MS, 29.74%\n",
      "\tupdating priority : 0 MS, 0.08%\n",
      "@@@total time per iter: 60.21 ms\n",
      "[6] Time spent = 60.28 s\n",
      "6:boltzmann_t  [1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "6:grad_norm    [1000]: avg:   0.1717, min:   0.0169[ 134], max:   0.6724[ 824]\n",
      "6:loss         [1000]: avg:   0.0644, min:   0.0067[ 134], max:   0.1867[ 611]\n",
      "6:rl_loss      [1000]: avg:   0.0711, min:   0.0355[ 932], max:   0.1123[ 682]\n",
      "epoch 6, eval score: 0.5670, perfect: 0.00, model saved: True\n",
      "epoch 6, success rate for sampling ficticious state: 99.90%\n",
      "==========\n",
      "beginning of epoch:  7\n",
      "available: 7.207 GB, used: 21.824 GB, free: 2.919 GB\n",
      "EPOCH: 7\n",
      "Speed: train: 1095.8, buffer_add: 477.3, buffer_size: 100018\n",
      "Total Time: 0H 08M 00S, 480s\n",
      "Total Sample: train: 512K, buffer: 264.829K\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.79%\n",
      "\tsample data       : 0 MS, 1.67%\n",
      "\tforward & backward: 38 MS, 65.26%\n",
      "\tupdate model      : 17 MS, 29.18%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 58.32 ms\n",
      "[7] Time spent = 58.40 s\n",
      "7:boltzmann_t  [1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "7:grad_norm    [1000]: avg:   0.2393, min:   0.0234[ 660], max:   1.0355[ 454]\n",
      "7:loss         [1000]: avg:   0.0782, min:   0.0064[ 660], max:   0.2048[ 658]\n",
      "7:rl_loss      [1000]: avg:   0.0682, min:   0.0415[ 984], max:   0.1032[ 219]\n",
      "epoch 7, eval score: 0.5650, perfect: 0.00, model saved: True\n",
      "epoch 7, success rate for sampling ficticious state: 99.89%\n",
      "==========\n",
      "beginning of epoch:  8\n",
      "available: 6.734 GB, used: 22.297 GB, free: 2.446 GB\n",
      "EPOCH: 8\n",
      "Speed: train: 1095.8, buffer_add: 467.9, buffer_size: 100029\n",
      "Total Time: 0H 08M 59S, 539s\n",
      "Total Sample: train: 576K, buffer: 292.156K\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.80%\n",
      "\tsample data       : 0 MS, 1.70%\n",
      "\tforward & backward: 38 MS, 65.49%\n",
      "\tupdate model      : 16 MS, 28.92%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 58.33 ms\n",
      "[8] Time spent = 58.41 s\n",
      "8:boltzmann_t  [1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "8:grad_norm    [1000]: avg:   0.2494, min:   0.0262[ 854], max:   0.8809[ 514]\n",
      "8:loss         [1000]: avg:   0.0902, min:   0.0089[ 854], max:   0.2385[ 394]\n",
      "8:rl_loss      [1000]: avg:   0.0654, min:   0.0404[ 459], max:   0.1016[  93]\n",
      "epoch 8, eval score: 0.7490, perfect: 0.00, model saved: True\n",
      "epoch 8, success rate for sampling ficticious state: 99.89%\n",
      "==========\n",
      "beginning of epoch:  9\n",
      "available: 6.613 GB, used: 22.418 GB, free: 2.320 GB\n",
      "EPOCH: 9\n",
      "Speed: train: 1115.2, buffer_add: 410.1, buffer_size: 100012\n",
      "Total Time: 0H 09M 56S, 596s\n",
      "Total Sample: train: 640K, buffer: 315.69K\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.94%\n",
      "\tsample data       : 1 MS, 1.87%\n",
      "\tforward & backward: 37 MS, 65.17%\n",
      "\tupdate model      : 16 MS, 28.93%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 57.33 ms\n",
      "[9] Time spent = 57.39 s\n",
      "9:boltzmann_t  [1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "9:grad_norm    [1000]: avg:   0.2823, min:   0.0294[  11], max:   0.9562[ 966]\n",
      "9:loss         [1000]: avg:   0.1024, min:   0.0163[  44], max:   0.2530[ 545]\n",
      "9:rl_loss      [1000]: avg:   0.0604, min:   0.0365[ 877], max:   0.0925[ 507]\n",
      "epoch 9, eval score: 1.0290, perfect: 0.00, model saved: True\n",
      "epoch 9, success rate for sampling ficticious state: 99.85%\n",
      "==========\n",
      "beginning of epoch:  10\n",
      "available: 6.407 GB, used: 22.625 GB, free: 2.112 GB\n",
      "EPOCH: 10\n",
      "Speed: train: 1117.7, buffer_add: 404.8, buffer_size: 100028\n",
      "Total Time: 0H 10M 53S, 653s\n",
      "Total Sample: train: 704K, buffer: 338.87K\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.64%\n",
      "\tsample data       : 0 MS, 1.68%\n",
      "\tforward & backward: 36 MS, 64.63%\n",
      "\tupdate model      : 17 MS, 29.95%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 57.17 ms\n",
      "[10] Time spent = 57.26 s\n",
      "10:boltzmann_t [1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "10:grad_norm   [1000]: avg:   0.3194, min:   0.0558[ 412], max:   1.2173[  90]\n",
      "10:loss        [1000]: avg:   0.1161, min:   0.0178[ 412], max:   0.2647[  90]\n",
      "10:rl_loss     [1000]: avg:   0.0572, min:   0.0325[ 928], max:   0.0896[ 142]\n",
      "epoch 10, eval score: 1.0240, perfect: 0.00, model saved: True\n",
      "epoch 10, success rate for sampling ficticious state: 99.86%\n",
      "==========\n",
      "beginning of epoch:  11\n",
      "available: 6.190 GB, used: 22.842 GB, free: 1.890 GB\n",
      "EPOCH: 11\n",
      "Speed: train: 1105.3, buffer_add: 405.9, buffer_size: 100026\n",
      "Total Time: 0H 11M 51S, 711s\n",
      "Total Sample: train: 768K, buffer: 362.374K\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.67%\n",
      "\tsample data       : 1 MS, 1.80%\n",
      "\tforward & backward: 37 MS, 64.49%\n",
      "\tupdate model      : 17 MS, 29.90%\n",
      "\tupdating priority : 0 MS, 0.14%\n",
      "@@@total time per iter: 57.84 ms\n",
      "[11] Time spent = 57.91 s\n",
      "11:boltzmann_t [1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "11:grad_norm   [1000]: avg:   0.3709, min:   0.0479[ 697], max:   1.3820[ 819]\n",
      "11:loss        [1000]: avg:   0.1241, min:   0.0220[ 862], max:   0.2235[ 389]\n",
      "11:rl_loss     [1000]: avg:   0.0563, min:   0.0320[ 324], max:   0.0881[ 244]\n",
      "epoch 11, eval score: 0.9810, perfect: 0.00, model saved: True\n",
      "epoch 11, success rate for sampling ficticious state: 99.87%\n",
      "==========\n",
      "beginning of epoch:  12\n",
      "available: 6.004 GB, used: 23.028 GB, free: 1.704 GB\n",
      "EPOCH: 12\n",
      "Speed: train: 1111.3, buffer_add: 405.8, buffer_size: 100016\n",
      "Total Time: 0H 12M 49S, 769s\n",
      "Total Sample: train: 832K, buffer: 385.742K\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.57%\n",
      "\tsample data       : 1 MS, 1.99%\n",
      "\tforward & backward: 36 MS, 64.14%\n",
      "\tupdate model      : 17 MS, 30.19%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 57.52 ms\n",
      "[12] Time spent = 57.59 s\n",
      "12:boltzmann_t [1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "12:grad_norm   [1000]: avg:   0.3919, min:   0.0758[ 287], max:   1.2016[ 582]\n",
      "12:loss        [1000]: avg:   0.1369, min:   0.0286[ 287], max:   0.2538[ 655]\n",
      "12:rl_loss     [1000]: avg:   0.0559, min:   0.0313[ 905], max:   0.0870[ 559]\n",
      "epoch 12, eval score: 1.0320, perfect: 0.00, model saved: True\n",
      "epoch 12, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  13\n",
      "available: 5.905 GB, used: 23.127 GB, free: 1.605 GB\n",
      "EPOCH: 15\n",
      "Speed: train: 1134.9, buffer_add: 394.2, buffer_size: 100027\n",
      "Total Time: 0H 15M 40S, 940s\n",
      "Total Sample: train: 1.024M, buffer: 453.884K\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.90%\n",
      "\tsample data       : 0 MS, 1.77%\n",
      "\tforward & backward: 36 MS, 64.78%\n",
      "\tupdate model      : 16 MS, 29.46%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.32 ms\n",
      "[15] Time spent = 56.39 s\n",
      "15:boltzmann_t [1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:grad_norm   [1000]: avg:   0.3661, min:   0.0375[ 821], max:   1.0459[ 438]\n",
      "15:loss        [1000]: avg:   0.1465, min:   0.0155[ 821], max:   0.2671[ 706]\n",
      "15:rl_loss     [1000]: avg:   0.0603, min:   0.0322[ 482], max:   0.0993[ 184]\n",
      "epoch 15, eval score: 0.9940, perfect: 0.00, model saved: False\n",
      "epoch 15, success rate for sampling ficticious state: 99.89%\n",
      "==========\n",
      "beginning of epoch:  16\n",
      "available: 5.797 GB, used: 23.235 GB, free: 1.497 GB\n",
      "EPOCH: 677\n",
      "Speed: train: 1167.2, buffer_add: 285.8, buffer_size: 100006\n",
      "Total Time: 10H 28M 14S, 37694s\n",
      "Total Sample: train: 43.392M, buffer: 10.854M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.92%\n",
      "\tsample data       : 1 MS, 1.94%\n",
      "\tforward & backward: 35 MS, 65.67%\n",
      "\tupdate model      : 15 MS, 28.36%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 54.76 ms\n",
      "[677] Time spent = 54.84 s\n",
      "677:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "677:grad_norm  [1000]: avg:   2.1084, min:   0.6088[ 625], max:   6.5014[ 654]\n",
      "677:loss       [1000]: avg:   0.6450, min:   0.2142[  72], max:   1.0696[ 969]\n",
      "677:rl_loss    [1000]: avg:   0.1104, min:   0.0557[ 469], max:   0.2731[ 700]\n",
      "epoch 677, eval score: 6.7730, perfect: 0.00, model saved: False\n",
      "epoch 677, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  678\n",
      "available: 4.417 GB, used: 24.616 GB, free: 307.969 MB\n",
      "EPOCH: 678\n",
      "Speed: train: 1161.7, buffer_add: 284.8, buffer_size: 100026\n",
      "Total Time: 10H 29M 09S, 37749s\n",
      "Total Sample: train: 43.456M, buffer: 10.87M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.58%\n",
      "\tsample data       : 0 MS, 1.81%\n",
      "\tforward & backward: 36 MS, 66.00%\n",
      "\tupdate model      : 15 MS, 28.50%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.02 ms\n",
      "[678] Time spent = 55.09 s\n",
      "678:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "678:grad_norm  [1000]: avg:   2.1231, min:   0.4541[ 975], max:   5.6419[ 766]\n",
      "678:loss       [1000]: avg:   0.6398, min:   0.2930[ 773], max:   1.0217[ 785]\n",
      "678:rl_loss    [1000]: avg:   0.1123, min:   0.0568[ 911], max:   0.2694[ 861]\n",
      "epoch 678, eval score: 6.8580, perfect: 0.00, model saved: False\n",
      "epoch 678, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  679\n",
      "available: 4.432 GB, used: 24.601 GB, free: 323.691 MB\n",
      "EPOCH: 679\n",
      "Speed: train: 1153.0, buffer_add: 286.9, buffer_size: 100007\n",
      "Total Time: 10H 30M 05S, 37805s\n",
      "Total Sample: train: 43.52M, buffer: 10.886M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.98%\n",
      "\tsample data       : 0 MS, 1.73%\n",
      "\tforward & backward: 36 MS, 65.24%\n",
      "\tupdate model      : 16 MS, 28.96%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.44 ms\n",
      "[679] Time spent = 55.51 s\n",
      "679:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "679:grad_norm  [1000]: avg:   2.2323, min:   0.6579[ 191], max:   6.4579[ 833]\n",
      "679:loss       [1000]: avg:   0.6402, min:   0.3542[ 995], max:   0.9096[ 983]\n",
      "679:rl_loss    [1000]: avg:   0.1117, min:   0.0536[ 559], max:   0.2908[ 614]\n",
      "epoch 679, eval score: 6.7520, perfect: 0.00, model saved: False\n",
      "epoch 679, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  680\n",
      "available: 4.439 GB, used: 24.594 GB, free: 330.875 MB\n",
      "EPOCH: 680\n",
      "Speed: train: 1135.5, buffer_add: 285.3, buffer_size: 100008\n",
      "Total Time: 10H 31M 01S, 37861s\n",
      "Total Sample: train: 43.584M, buffer: 10.902M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.67%\n",
      "\tsample data       : 1 MS, 1.92%\n",
      "\tforward & backward: 36 MS, 65.25%\n",
      "\tupdate model      : 16 MS, 29.08%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.30 ms\n",
      "[680] Time spent = 56.37 s\n",
      "680:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "680:grad_norm  [1000]: avg:   2.1934, min:   0.5647[ 477], max:   8.4153[ 410]\n",
      "680:loss       [1000]: avg:   0.6402, min:   0.1937[ 133], max:   0.9436[ 431]\n",
      "680:rl_loss    [1000]: avg:   0.1100, min:   0.0474[ 672], max:   0.3421[ 505]\n",
      "epoch 680, eval score: 6.8450, perfect: 0.10, model saved: False\n",
      "epoch 680, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  681\n",
      "available: 4.444 GB, used: 24.589 GB, free: 336.156 MB\n",
      "EPOCH: 681\n",
      "Speed: train: 1139.8, buffer_add: 286.6, buffer_size: 100002\n",
      "Total Time: 10H 31M 57S, 37917s\n",
      "Total Sample: train: 43.648M, buffer: 10.918M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.81%\n",
      "\tsample data       : 1 MS, 1.96%\n",
      "\tforward & backward: 36 MS, 64.86%\n",
      "\tupdate model      : 16 MS, 29.27%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 56.07 ms\n",
      "[681] Time spent = 56.15 s\n",
      "681:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "681:grad_norm  [1000]: avg:   2.1687, min:   0.7332[ 863], max:   6.2340[ 374]\n",
      "681:loss       [1000]: avg:   0.6435, min:   0.2154[ 134], max:   0.9568[ 101]\n",
      "681:rl_loss    [1000]: avg:   0.1104, min:   0.0628[ 750], max:   0.3109[ 300]\n",
      "epoch 681, eval score: 6.8350, perfect: 0.00, model saved: False\n",
      "epoch 681, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  682\n",
      "available: 4.435 GB, used: 24.598 GB, free: 326.328 MB\n",
      "EPOCH: 682\n",
      "Speed: train: 1157.5, buffer_add: 286.8, buffer_size: 100048\n",
      "Total Time: 10H 32M 53S, 37973s\n",
      "Total Sample: train: 43.712M, buffer: 10.934M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.63%\n",
      "\tsample data       : 1 MS, 1.81%\n",
      "\tforward & backward: 36 MS, 65.62%\n",
      "\tupdate model      : 15 MS, 28.84%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.21 ms\n",
      "[682] Time spent = 55.30 s\n",
      "682:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "682:grad_norm  [1000]: avg:   2.2177, min:   0.7803[ 859], max:   5.3620[ 615]\n",
      "682:loss       [1000]: avg:   0.6413, min:   0.2619[ 232], max:   0.9556[ 660]\n",
      "682:rl_loss    [1000]: avg:   0.1135, min:   0.0521[ 252], max:   0.3159[ 192]\n",
      "epoch 682, eval score: 6.8360, perfect: 0.00, model saved: False\n",
      "epoch 682, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  683\n",
      "available: 4.437 GB, used: 24.596 GB, free: 328.332 MB\n",
      "EPOCH: 683\n",
      "Speed: train: 1140.6, buffer_add: 287.1, buffer_size: 100000\n",
      "Total Time: 10H 33M 49S, 38029s\n",
      "Total Sample: train: 43.776M, buffer: 10.95M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.76%\n",
      "\tsample data       : 0 MS, 1.77%\n",
      "\tforward & backward: 36 MS, 64.68%\n",
      "\tupdate model      : 16 MS, 29.70%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 56.05 ms\n",
      "[683] Time spent = 56.11 s\n",
      "683:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "683:grad_norm  [1000]: avg:   2.2685, min:   0.4698[ 669], max:   5.3268[ 206]\n",
      "683:loss       [1000]: avg:   0.6444, min:   0.1999[ 669], max:   1.0425[ 891]\n",
      "683:rl_loss    [1000]: avg:   0.1126, min:   0.0594[ 486], max:   0.2852[ 768]\n",
      "epoch 683, eval score: 6.8040, perfect: 0.00, model saved: False\n",
      "epoch 683, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  684\n",
      "available: 4.441 GB, used: 24.592 GB, free: 332.664 MB\n",
      "EPOCH: 684\n",
      "Speed: train: 1148.2, buffer_add: 285.4, buffer_size: 100014\n",
      "Total Time: 10H 34M 44S, 38084s\n",
      "Total Sample: train: 43.84M, buffer: 10.966M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.70%\n",
      "\tsample data       : 1 MS, 1.89%\n",
      "\tforward & backward: 36 MS, 65.25%\n",
      "\tupdate model      : 16 MS, 29.06%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.67 ms\n",
      "[684] Time spent = 55.74 s\n",
      "684:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "684:grad_norm  [1000]: avg:   2.2299, min:   0.3134[ 141], max:   7.1028[ 181]\n",
      "684:loss       [1000]: avg:   0.6499, min:   0.1183[ 141], max:   0.9870[ 241]\n",
      "684:rl_loss    [1000]: avg:   0.1156, min:   0.0614[ 426], max:   0.2677[ 932]\n",
      "epoch 684, eval score: 6.7780, perfect: 0.00, model saved: False\n",
      "epoch 684, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  685\n",
      "available: 4.443 GB, used: 24.590 GB, free: 334.289 MB\n",
      "EPOCH: 685\n",
      "Speed: train: 1167.9, buffer_add: 288.1, buffer_size: 100014\n",
      "Total Time: 10H 35M 39S, 38139s\n",
      "Total Sample: train: 43.904M, buffer: 10.981M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.54%\n",
      "\tsample data       : 0 MS, 1.75%\n",
      "\tforward & backward: 36 MS, 66.00%\n",
      "\tupdate model      : 15 MS, 28.61%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 54.74 ms\n",
      "[685] Time spent = 54.80 s\n",
      "685:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "685:grad_norm  [1000]: avg:   2.2209, min:   0.7308[ 389], max:   6.5819[ 205]\n",
      "685:loss       [1000]: avg:   0.6485, min:   0.2882[ 843], max:   0.9633[ 693]\n",
      "685:rl_loss    [1000]: avg:   0.1152, min:   0.0569[ 589], max:   0.2721[ 402]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 685, eval score: 6.8470, perfect: 0.10, model saved: False\n",
      "epoch 685, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  686\n",
      "available: 4.442 GB, used: 24.592 GB, free: 332.988 MB\n",
      "EPOCH: 686\n",
      "Speed: train: 1147.6, buffer_add: 286.8, buffer_size: 100032\n",
      "Total Time: 10H 36M 35S, 38195s\n",
      "Total Sample: train: 43.968M, buffer: 10.997M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.61%\n",
      "\tsample data       : 1 MS, 1.98%\n",
      "\tforward & backward: 36 MS, 65.37%\n",
      "\tupdate model      : 16 MS, 28.95%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.66 ms\n",
      "[686] Time spent = 55.77 s\n",
      "686:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "686:grad_norm  [1000]: avg:   2.1641, min:   0.3782[ 260], max:   5.4040[ 378]\n",
      "686:loss       [1000]: avg:   0.6445, min:   0.2179[ 260], max:   0.9443[ 276]\n",
      "686:rl_loss    [1000]: avg:   0.1165, min:   0.0606[ 904], max:   0.2816[ 816]\n",
      "epoch 686, eval score: 6.7880, perfect: 0.00, model saved: False\n",
      "epoch 686, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  687\n",
      "available: 4.437 GB, used: 24.596 GB, free: 328.602 MB\n",
      "EPOCH: 687\n",
      "Speed: train: 1154.7, buffer_add: 287.3, buffer_size: 100022\n",
      "Total Time: 10H 37M 30S, 38250s\n",
      "Total Sample: train: 44.032M, buffer: 11.013M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.95%\n",
      "\tsample data       : 0 MS, 1.74%\n",
      "\tforward & backward: 36 MS, 65.23%\n",
      "\tupdate model      : 16 MS, 28.98%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.35 ms\n",
      "[687] Time spent = 55.43 s\n",
      "687:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "687:grad_norm  [1000]: avg:   2.2990, min:   0.6560[ 425], max:   6.3948[ 140]\n",
      "687:loss       [1000]: avg:   0.6456, min:   0.2662[ 349], max:   1.0169[ 212]\n",
      "687:rl_loss    [1000]: avg:   0.1160, min:   0.0584[ 136], max:   0.3388[ 890]\n",
      "epoch 687, eval score: 6.6850, perfect: 0.00, model saved: False\n",
      "epoch 687, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  688\n",
      "available: 4.437 GB, used: 24.596 GB, free: 327.574 MB\n",
      "EPOCH: 688\n",
      "Speed: train: 1139.2, buffer_add: 286.4, buffer_size: 100026\n",
      "Total Time: 10H 38M 27S, 38307s\n",
      "Total Sample: train: 44.096M, buffer: 11.029M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.50%\n",
      "\tsample data       : 0 MS, 1.70%\n",
      "\tforward & backward: 36 MS, 64.72%\n",
      "\tupdate model      : 16 MS, 29.96%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 56.12 ms\n",
      "[688] Time spent = 56.18 s\n",
      "688:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "688:grad_norm  [1000]: avg:   2.2156, min:   0.7403[ 140], max:   5.2346[ 243]\n",
      "688:loss       [1000]: avg:   0.6499, min:   0.2935[ 508], max:   0.9817[   8]\n",
      "688:rl_loss    [1000]: avg:   0.1170, min:   0.0534[ 646], max:   0.2694[ 317]\n",
      "epoch 688, eval score: 6.5890, perfect: 0.20, model saved: False\n",
      "epoch 688, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  689\n",
      "available: 4.430 GB, used: 24.603 GB, free: 320.809 MB\n",
      "EPOCH: 689\n",
      "Speed: train: 1163.1, buffer_add: 285.5, buffer_size: 100024\n",
      "Total Time: 10H 39M 22S, 38362s\n",
      "Total Sample: train: 44.16M, buffer: 11.045M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.97%\n",
      "\tsample data       : 1 MS, 1.92%\n",
      "\tforward & backward: 35 MS, 64.50%\n",
      "\tupdate model      : 16 MS, 29.52%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 54.93 ms\n",
      "[689] Time spent = 55.03 s\n",
      "689:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "689:grad_norm  [1000]: avg:   2.2647, min:   0.6493[ 504], max:   5.7427[ 575]\n",
      "689:loss       [1000]: avg:   0.6455, min:   0.2404[  72], max:   1.0729[ 154]\n",
      "689:rl_loss    [1000]: avg:   0.1144, min:   0.0595[ 532], max:   0.3145[ 320]\n",
      "epoch 689, eval score: 6.8770, perfect: 0.10, model saved: False\n",
      "epoch 689, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  690\n",
      "available: 4.436 GB, used: 24.597 GB, free: 326.680 MB\n",
      "EPOCH: 690\n",
      "Speed: train: 1140.9, buffer_add: 286.3, buffer_size: 100023\n",
      "Total Time: 10H 40M 18S, 38418s\n",
      "Total Sample: train: 44.224M, buffer: 11.061M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.74%\n",
      "\tsample data       : 1 MS, 1.93%\n",
      "\tforward & backward: 37 MS, 66.09%\n",
      "\tupdate model      : 15 MS, 28.15%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.03 ms\n",
      "[690] Time spent = 56.10 s\n",
      "690:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "690:grad_norm  [1000]: avg:   2.2233, min:   0.4852[ 831], max:   5.0804[ 230]\n",
      "690:loss       [1000]: avg:   0.6398, min:   0.2134[ 591], max:   0.9558[ 722]\n",
      "690:rl_loss    [1000]: avg:   0.1122, min:   0.0572[ 564], max:   0.2874[ 379]\n",
      "epoch 690, eval score: 6.8530, perfect: 0.10, model saved: False\n",
      "epoch 690, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  691\n",
      "available: 4.436 GB, used: 24.597 GB, free: 326.371 MB\n",
      "EPOCH: 691\n",
      "Speed: train: 1149.6, buffer_add: 286.0, buffer_size: 100000\n",
      "Total Time: 10H 41M 13S, 38473s\n",
      "Total Sample: train: 44.288M, buffer: 11.077M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.88%\n",
      "\tsample data       : 1 MS, 1.93%\n",
      "\tforward & backward: 35 MS, 64.69%\n",
      "\tupdate model      : 16 MS, 29.40%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.59 ms\n",
      "[691] Time spent = 55.67 s\n",
      "691:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "691:grad_norm  [1000]: avg:   2.3440, min:   0.6216[ 897], max:   7.1417[ 149]\n",
      "691:loss       [1000]: avg:   0.6363, min:   0.2372[ 897], max:   1.0111[ 241]\n",
      "691:rl_loss    [1000]: avg:   0.1140, min:   0.0590[ 188], max:   0.3188[ 759]\n",
      "epoch 691, eval score: 6.8250, perfect: 0.00, model saved: False\n",
      "epoch 691, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  692\n",
      "available: 4.434 GB, used: 24.599 GB, free: 324.578 MB\n",
      "EPOCH: 692\n",
      "Speed: train: 1147.6, buffer_add: 286.1, buffer_size: 100016\n",
      "Total Time: 10H 42M 09S, 38529s\n",
      "Total Sample: train: 44.352M, buffer: 11.093M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.93%\n",
      "\tsample data       : 1 MS, 1.88%\n",
      "\tforward & backward: 36 MS, 64.77%\n",
      "\tupdate model      : 16 MS, 29.32%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.70 ms\n",
      "[692] Time spent = 55.77 s\n",
      "692:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "692:grad_norm  [1000]: avg:   2.1697, min:   0.5022[ 543], max:   5.9296[  21]\n",
      "692:loss       [1000]: avg:   0.6317, min:   0.1326[ 543], max:   0.9516[  64]\n",
      "692:rl_loss    [1000]: avg:   0.1122, min:   0.0552[ 688], max:   0.2859[ 314]\n",
      "epoch 692, eval score: 6.7750, perfect: 0.10, model saved: False\n",
      "epoch 692, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  693\n",
      "available: 4.438 GB, used: 24.595 GB, free: 328.453 MB\n",
      "EPOCH: 693\n",
      "Speed: train: 1164.4, buffer_add: 286.9, buffer_size: 100006\n",
      "Total Time: 10H 43M 04S, 38584s\n",
      "Total Sample: train: 44.416M, buffer: 11.109M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.73%\n",
      "\tsample data       : 1 MS, 2.05%\n",
      "\tforward & backward: 35 MS, 65.15%\n",
      "\tupdate model      : 15 MS, 28.98%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 54.89 ms\n",
      "[693] Time spent = 54.97 s\n",
      "693:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "693:grad_norm  [1000]: avg:   2.2101, min:   0.3852[ 115], max:   5.9283[ 444]\n",
      "693:loss       [1000]: avg:   0.6338, min:   0.2185[ 115], max:   1.0564[ 464]\n",
      "693:rl_loss    [1000]: avg:   0.1121, min:   0.0567[ 505], max:   0.3527[ 295]\n",
      "epoch 693, eval score: 6.8160, perfect: 0.00, model saved: False\n",
      "epoch 693, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  694\n",
      "available: 4.430 GB, used: 24.603 GB, free: 320.355 MB\n",
      "EPOCH: 694\n",
      "Speed: train: 1172.5, buffer_add: 283.4, buffer_size: 100019\n",
      "Total Time: 10H 43M 59S, 38639s\n",
      "Total Sample: train: 44.48M, buffer: 11.124M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.67%\n",
      "\tsample data       : 1 MS, 2.11%\n",
      "\tforward & backward: 35 MS, 65.01%\n",
      "\tupdate model      : 15 MS, 29.13%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 54.51 ms\n",
      "[694] Time spent = 54.59 s\n",
      "694:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "694:grad_norm  [1000]: avg:   2.2208, min:   0.3051[ 904], max:   5.9375[  56]\n",
      "694:loss       [1000]: avg:   0.6316, min:   0.1639[ 904], max:   0.9608[ 605]\n",
      "694:rl_loss    [1000]: avg:   0.1137, min:   0.0605[ 166], max:   0.2992[  90]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 694, eval score: 6.7020, perfect: 0.10, model saved: False\n",
      "epoch 694, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  695\n",
      "available: 4.438 GB, used: 24.595 GB, free: 328.402 MB\n",
      "EPOCH: 695\n",
      "Speed: train: 1151.2, buffer_add: 288.3, buffer_size: 100002\n",
      "Total Time: 10H 44M 54S, 38694s\n",
      "Total Sample: train: 44.544M, buffer: 11.14M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.27%\n",
      "\tsample data       : 0 MS, 1.73%\n",
      "\tforward & backward: 35 MS, 64.69%\n",
      "\tupdate model      : 16 MS, 29.21%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.52 ms\n",
      "[695] Time spent = 55.60 s\n",
      "695:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "695:grad_norm  [1000]: avg:   2.1415, min:   0.8006[ 288], max:   5.5405[ 866]\n",
      "695:loss       [1000]: avg:   0.6325, min:   0.2671[ 583], max:   0.9724[ 429]\n",
      "695:rl_loss    [1000]: avg:   0.1132, min:   0.0541[ 860], max:   0.2549[ 494]\n",
      "epoch 695, eval score: 6.8560, perfect: 0.00, model saved: False\n",
      "epoch 695, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  696\n",
      "available: 4.437 GB, used: 24.596 GB, free: 327.406 MB\n",
      "EPOCH: 696\n",
      "Speed: train: 1158.9, buffer_add: 286.7, buffer_size: 100008\n",
      "Total Time: 10H 45M 49S, 38749s\n",
      "Total Sample: train: 44.608M, buffer: 11.156M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.11%\n",
      "\tsample data       : 1 MS, 1.98%\n",
      "\tforward & backward: 35 MS, 65.02%\n",
      "\tupdate model      : 15 MS, 28.79%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.16 ms\n",
      "[696] Time spent = 55.23 s\n",
      "696:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "696:grad_norm  [1000]: avg:   2.1574, min:   0.7719[ 608], max:   5.7034[ 310]\n",
      "696:loss       [1000]: avg:   0.6368, min:   0.2489[ 240], max:   0.9222[ 187]\n",
      "696:rl_loss    [1000]: avg:   0.1145, min:   0.0618[ 558], max:   0.2901[ 872]\n",
      "epoch 696, eval score: 6.8500, perfect: 0.00, model saved: False\n",
      "epoch 696, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  697\n",
      "available: 4.424 GB, used: 24.609 GB, free: 325.938 MB\n",
      "EPOCH: 697\n",
      "Speed: train: 1136.0, buffer_add: 285.7, buffer_size: 100022\n",
      "Total Time: 10H 46M 46S, 38806s\n",
      "Total Sample: train: 44.672M, buffer: 11.172M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.83%\n",
      "\tsample data       : 1 MS, 1.93%\n",
      "\tforward & backward: 36 MS, 65.04%\n",
      "\tupdate model      : 16 MS, 29.10%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 56.27 ms\n",
      "[697] Time spent = 56.34 s\n",
      "697:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "697:grad_norm  [1000]: avg:   2.2286, min:   0.9088[ 107], max:   6.4566[ 718]\n",
      "697:loss       [1000]: avg:   0.6333, min:   0.2226[ 957], max:   0.9584[ 741]\n",
      "697:rl_loss    [1000]: avg:   0.1127, min:   0.0582[  46], max:   0.2862[ 635]\n",
      "epoch 697, eval score: 6.8890, perfect: 0.00, model saved: False\n",
      "epoch 697, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  698\n",
      "available: 4.425 GB, used: 24.608 GB, free: 381.426 MB\n",
      "EPOCH: 698\n",
      "Speed: train: 1153.8, buffer_add: 286.0, buffer_size: 100002\n",
      "Total Time: 10H 47M 41S, 38861s\n",
      "Total Sample: train: 44.736M, buffer: 11.188M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.77%\n",
      "\tsample data       : 1 MS, 1.93%\n",
      "\tforward & backward: 36 MS, 65.07%\n",
      "\tupdate model      : 16 MS, 29.14%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.39 ms\n",
      "[698] Time spent = 55.47 s\n",
      "698:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "698:grad_norm  [1000]: avg:   2.2564, min:   0.6171[  92], max:   6.5141[ 761]\n",
      "698:loss       [1000]: avg:   0.6377, min:   0.2482[ 568], max:   0.9254[ 779]\n",
      "698:rl_loss    [1000]: avg:   0.1139, min:   0.0529[ 938], max:   0.2953[ 764]\n",
      "epoch 698, eval score: 6.7500, perfect: 0.10, model saved: False\n",
      "epoch 698, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  699\n",
      "available: 4.424 GB, used: 24.609 GB, free: 390.527 MB\n",
      "EPOCH: 699\n",
      "Speed: train: 1150.7, buffer_add: 286.6, buffer_size: 100024\n",
      "Total Time: 10H 48M 37S, 38917s\n",
      "Total Sample: train: 44.8M, buffer: 11.204M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.85%\n",
      "\tsample data       : 1 MS, 1.88%\n",
      "\tforward & backward: 36 MS, 65.56%\n",
      "\tupdate model      : 15 MS, 28.61%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.55 ms\n",
      "[699] Time spent = 55.62 s\n",
      "699:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "699:grad_norm  [1000]: avg:   2.2771, min:   0.5708[ 321], max:   6.0692[ 292]\n",
      "699:loss       [1000]: avg:   0.6337, min:   0.2604[ 321], max:   1.0229[ 805]\n",
      "699:rl_loss    [1000]: avg:   0.1121, min:   0.0574[ 817], max:   0.2733[ 682]\n",
      "epoch 699, eval score: 6.8040, perfect: 0.10, model saved: False\n",
      "epoch 699, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  700\n",
      "available: 4.442 GB, used: 24.590 GB, free: 452.094 MB\n",
      "EPOCH: 700\n",
      "Speed: train: 1147.5, buffer_add: 285.3, buffer_size: 100010\n",
      "Total Time: 10H 49M 33S, 38973s\n",
      "Total Sample: train: 44.864M, buffer: 11.22M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.40%\n",
      "\tsample data       : 0 MS, 1.67%\n",
      "\tforward & backward: 36 MS, 64.79%\n",
      "\tupdate model      : 16 MS, 30.04%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.71 ms\n",
      "[700] Time spent = 55.78 s\n",
      "700:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "700:grad_norm  [1000]: avg:   2.2698, min:   0.5054[ 588], max:   5.9674[ 466]\n",
      "700:loss       [1000]: avg:   0.6359, min:   0.1719[ 588], max:   1.0047[ 161]\n",
      "700:rl_loss    [1000]: avg:   0.1151, min:   0.0635[ 699], max:   0.2763[ 289]\n",
      "epoch 700, eval score: 6.7750, perfect: 0.00, model saved: False\n",
      "epoch 700, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  701\n",
      "available: 4.402 GB, used: 24.631 GB, free: 404.445 MB\n",
      "EPOCH: 701\n",
      "Speed: train: 1161.4, buffer_add: 286.6, buffer_size: 100024\n",
      "Total Time: 10H 50M 28S, 39028s\n",
      "Total Sample: train: 44.928M, buffer: 11.236M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.93%\n",
      "\tsample data       : 0 MS, 1.76%\n",
      "\tforward & backward: 35 MS, 65.02%\n",
      "\tupdate model      : 16 MS, 29.19%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.02 ms\n",
      "[701] Time spent = 55.11 s\n",
      "701:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "701:grad_norm  [1000]: avg:   2.2409, min:   0.5731[ 581], max:   7.7389[  51]\n",
      "701:loss       [1000]: avg:   0.6358, min:   0.2373[ 581], max:   0.9330[ 466]\n",
      "701:rl_loss    [1000]: avg:   0.1142, min:   0.0576[ 261], max:   0.3256[  43]\n",
      "epoch 701, eval score: 6.8710, perfect: 0.10, model saved: False\n",
      "epoch 701, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  702\n",
      "available: 4.393 GB, used: 24.640 GB, free: 395.359 MB\n",
      "EPOCH: 702\n",
      "Speed: train: 1147.5, buffer_add: 282.0, buffer_size: 100006\n",
      "Total Time: 10H 51M 24S, 39084s\n",
      "Total Sample: train: 44.992M, buffer: 11.252M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.61%\n",
      "\tsample data       : 1 MS, 1.83%\n",
      "\tforward & backward: 36 MS, 66.22%\n",
      "\tupdate model      : 15 MS, 28.25%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.71 ms\n",
      "[702] Time spent = 55.78 s\n",
      "702:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "702:grad_norm  [1000]: avg:   2.1864, min:   0.7889[ 393], max:   6.0407[ 986]\n",
      "702:loss       [1000]: avg:   0.6350, min:   0.2744[ 130], max:   0.9747[ 106]\n",
      "702:rl_loss    [1000]: avg:   0.1140, min:   0.0537[ 788], max:   0.3205[ 403]\n",
      "epoch 702, eval score: 6.9490, perfect: 0.10, model saved: True\n",
      "epoch 702, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  703\n",
      "available: 4.391 GB, used: 24.642 GB, free: 393.652 MB\n",
      "EPOCH: 703\n",
      "Speed: train: 1149.5, buffer_add: 291.0, buffer_size: 100006\n",
      "Total Time: 10H 52M 19S, 39139s\n",
      "Total Sample: train: 45.056M, buffer: 11.268M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.74%\n",
      "\tsample data       : 1 MS, 1.82%\n",
      "\tforward & backward: 36 MS, 64.97%\n",
      "\tupdate model      : 16 MS, 29.38%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.60 ms\n",
      "[703] Time spent = 55.68 s\n",
      "703:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "703:grad_norm  [1000]: avg:   2.1806, min:   0.6494[ 258], max:   6.7053[ 893]\n",
      "703:loss       [1000]: avg:   0.6361, min:   0.2384[ 507], max:   1.0250[ 218]\n",
      "703:rl_loss    [1000]: avg:   0.1147, min:   0.0627[ 834], max:   0.3369[ 813]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 703, eval score: 6.8970, perfect: 0.10, model saved: False\n",
      "epoch 703, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  704\n",
      "available: 4.380 GB, used: 24.653 GB, free: 381.883 MB\n",
      "EPOCH: 704\n",
      "Speed: train: 1144.8, buffer_add: 282.9, buffer_size: 100002\n",
      "Total Time: 10H 53M 15S, 39195s\n",
      "Total Sample: train: 45.12M, buffer: 11.284M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.67%\n",
      "\tsample data       : 0 MS, 1.72%\n",
      "\tforward & backward: 36 MS, 65.07%\n",
      "\tupdate model      : 16 MS, 29.44%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.84 ms\n",
      "[704] Time spent = 55.91 s\n",
      "704:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "704:grad_norm  [1000]: avg:   2.1995, min:   0.7575[ 539], max:   6.0062[ 164]\n",
      "704:loss       [1000]: avg:   0.6330, min:   0.2157[ 791], max:   1.0128[ 880]\n",
      "704:rl_loss    [1000]: avg:   0.1155, min:   0.0540[ 876], max:   0.3419[ 304]\n",
      "epoch 704, eval score: 6.9440, perfect: 0.40, model saved: True\n",
      "epoch 704, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  705\n",
      "available: 4.393 GB, used: 24.640 GB, free: 395.383 MB\n",
      "EPOCH: 705\n",
      "Speed: train: 1140.7, buffer_add: 288.8, buffer_size: 100043\n",
      "Total Time: 10H 54M 11S, 39251s\n",
      "Total Sample: train: 45.184M, buffer: 11.3M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.83%\n",
      "\tsample data       : 0 MS, 1.77%\n",
      "\tforward & backward: 36 MS, 64.96%\n",
      "\tupdate model      : 16 MS, 29.31%\n",
      "\tupdating priority : 0 MS, 0.13%\n",
      "@@@total time per iter: 56.04 ms\n",
      "[705] Time spent = 56.11 s\n",
      "705:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "705:grad_norm  [1000]: avg:   2.2306, min:   0.6649[ 611], max:   6.0333[ 937]\n",
      "705:loss       [1000]: avg:   0.6325, min:   0.2841[ 748], max:   0.9896[ 194]\n",
      "705:rl_loss    [1000]: avg:   0.1147, min:   0.0555[ 263], max:   0.3898[ 371]\n",
      "epoch 705, eval score: 6.8510, perfect: 0.10, model saved: False\n",
      "epoch 705, success rate for sampling ficticious state: 99.85%\n",
      "==========\n",
      "beginning of epoch:  706\n",
      "available: 4.394 GB, used: 24.639 GB, free: 395.836 MB\n",
      "EPOCH: 706\n",
      "Speed: train: 1140.2, buffer_add: 287.4, buffer_size: 100002\n",
      "Total Time: 10H 55M 07S, 39307s\n",
      "Total Sample: train: 45.248M, buffer: 11.316M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.85%\n",
      "\tsample data       : 1 MS, 1.85%\n",
      "\tforward & backward: 36 MS, 65.48%\n",
      "\tupdate model      : 16 MS, 28.73%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 56.06 ms\n",
      "[706] Time spent = 56.13 s\n",
      "706:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "706:grad_norm  [1000]: avg:   2.2063, min:   0.7670[ 899], max:   5.7598[ 310]\n",
      "706:loss       [1000]: avg:   0.6262, min:   0.2520[   9], max:   0.9021[ 379]\n",
      "706:rl_loss    [1000]: avg:   0.1126, min:   0.0588[ 111], max:   0.3112[ 232]\n",
      "epoch 706, eval score: 6.8510, perfect: 0.20, model saved: False\n",
      "epoch 706, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  707\n",
      "available: 4.388 GB, used: 24.644 GB, free: 390.215 MB\n",
      "EPOCH: 707\n",
      "Speed: train: 1155.2, buffer_add: 287.1, buffer_size: 100024\n",
      "Total Time: 10H 56M 03S, 39363s\n",
      "Total Sample: train: 45.312M, buffer: 11.332M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.83%\n",
      "\tsample data       : 1 MS, 1.83%\n",
      "\tforward & backward: 35 MS, 64.72%\n",
      "\tupdate model      : 16 MS, 29.49%\n",
      "\tupdating priority : 0 MS, 0.13%\n",
      "@@@total time per iter: 55.32 ms\n",
      "[707] Time spent = 55.41 s\n",
      "707:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "707:grad_norm  [1000]: avg:   2.2434, min:   0.6111[ 276], max:   5.3534[ 670]\n",
      "707:loss       [1000]: avg:   0.6268, min:   0.2983[ 176], max:   0.9429[ 442]\n",
      "707:rl_loss    [1000]: avg:   0.1108, min:   0.0534[ 401], max:   0.2981[ 472]\n",
      "epoch 707, eval score: 6.7630, perfect: 0.30, model saved: False\n",
      "epoch 707, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  708\n",
      "available: 4.378 GB, used: 24.655 GB, free: 379.688 MB\n",
      "EPOCH: 708\n",
      "Speed: train: 1152.5, buffer_add: 282.4, buffer_size: 100014\n",
      "Total Time: 10H 56M 58S, 39418s\n",
      "Total Sample: train: 45.376M, buffer: 11.347M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.69%\n",
      "\tsample data       : 0 MS, 1.72%\n",
      "\tforward & backward: 36 MS, 65.44%\n",
      "\tupdate model      : 16 MS, 29.04%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.46 ms\n",
      "[708] Time spent = 55.53 s\n",
      "708:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "708:grad_norm  [1000]: avg:   2.2344, min:   0.6170[ 213], max:   8.0861[ 181]\n",
      "708:loss       [1000]: avg:   0.6300, min:   0.2799[ 383], max:   0.9828[ 863]\n",
      "708:rl_loss    [1000]: avg:   0.1117, min:   0.0536[ 758], max:   0.3011[ 540]\n",
      "epoch 708, eval score: 6.8940, perfect: 0.00, model saved: False\n",
      "epoch 708, success rate for sampling ficticious state: 99.85%\n",
      "==========\n",
      "beginning of epoch:  709\n",
      "available: 4.381 GB, used: 24.652 GB, free: 382.348 MB\n",
      "EPOCH: 709\n",
      "Speed: train: 1157.3, buffer_add: 287.1, buffer_size: 100005\n",
      "Total Time: 10H 57M 54S, 39474s\n",
      "Total Sample: train: 45.44M, buffer: 11.363M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.84%\n",
      "\tsample data       : 1 MS, 2.01%\n",
      "\tforward & backward: 35 MS, 64.75%\n",
      "\tupdate model      : 16 MS, 29.29%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.24 ms\n",
      "[709] Time spent = 55.30 s\n",
      "709:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "709:grad_norm  [1000]: avg:   2.1695, min:   0.1879[ 760], max:   5.3163[  50]\n",
      "709:loss       [1000]: avg:   0.6282, min:   0.1221[ 760], max:   1.0410[ 434]\n",
      "709:rl_loss    [1000]: avg:   0.1114, min:   0.0508[ 167], max:   0.3084[ 458]\n",
      "epoch 709, eval score: 6.8550, perfect: 0.00, model saved: False\n",
      "epoch 709, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  710\n",
      "available: 4.379 GB, used: 24.654 GB, free: 380.352 MB\n",
      "EPOCH: 710\n",
      "Speed: train: 1155.2, buffer_add: 284.9, buffer_size: 100006\n",
      "Total Time: 10H 58M 49S, 39529s\n",
      "Total Sample: train: 45.504M, buffer: 11.379M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.52%\n",
      "\tsample data       : 1 MS, 1.89%\n",
      "\tforward & backward: 36 MS, 65.45%\n",
      "\tupdate model      : 16 MS, 29.03%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.34 ms\n",
      "[710] Time spent = 55.40 s\n",
      "710:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "710:grad_norm  [1000]: avg:   2.2165, min:   0.8237[ 855], max:   6.3626[ 493]\n",
      "710:loss       [1000]: avg:   0.6301, min:   0.2622[ 968], max:   0.9281[ 793]\n",
      "710:rl_loss    [1000]: avg:   0.1111, min:   0.0532[ 772], max:   0.2983[ 217]\n",
      "epoch 710, eval score: 6.8680, perfect: 0.00, model saved: False\n",
      "epoch 710, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  711\n",
      "available: 4.385 GB, used: 24.648 GB, free: 386.191 MB\n",
      "EPOCH: 711\n",
      "Speed: train: 1146.4, buffer_add: 285.6, buffer_size: 100012\n",
      "Total Time: 10H 59M 45S, 39585s\n",
      "Total Sample: train: 45.568M, buffer: 11.395M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.96%\n",
      "\tsample data       : 0 MS, 1.74%\n",
      "\tforward & backward: 36 MS, 64.97%\n",
      "\tupdate model      : 16 MS, 29.24%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.76 ms\n",
      "[711] Time spent = 55.83 s\n",
      "711:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "711:grad_norm  [1000]: avg:   2.1899, min:   0.4583[ 432], max:   5.6481[  79]\n",
      "711:loss       [1000]: avg:   0.6221, min:   0.3006[ 219], max:   0.9148[ 151]\n",
      "711:rl_loss    [1000]: avg:   0.1110, min:   0.0517[ 967], max:   0.3244[ 203]\n",
      "epoch 711, eval score: 6.9130, perfect: 0.00, model saved: False\n",
      "epoch 711, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  712\n",
      "available: 4.376 GB, used: 24.657 GB, free: 376.297 MB\n",
      "EPOCH: 712\n",
      "Speed: train: 1142.9, buffer_add: 286.9, buffer_size: 100000\n",
      "Total Time: 11H 00M 41S, 39641s\n",
      "Total Sample: train: 45.632M, buffer: 11.411M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.91%\n",
      "\tsample data       : 1 MS, 1.90%\n",
      "\tforward & backward: 36 MS, 64.74%\n",
      "\tupdate model      : 16 MS, 29.36%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.91 ms\n",
      "[712] Time spent = 56.00 s\n",
      "712:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "712:grad_norm  [1000]: avg:   2.1655, min:   0.6423[ 123], max:   6.1654[ 587]\n",
      "712:loss       [1000]: avg:   0.6292, min:   0.2265[ 443], max:   0.9672[ 543]\n",
      "712:rl_loss    [1000]: avg:   0.1103, min:   0.0508[  22], max:   0.2720[ 930]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 712, eval score: 6.8600, perfect: 0.00, model saved: False\n",
      "epoch 712, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  713\n",
      "available: 4.375 GB, used: 24.658 GB, free: 375.652 MB\n",
      "EPOCH: 713\n",
      "Speed: train: 1132.5, buffer_add: 287.0, buffer_size: 100004\n",
      "Total Time: 11H 01M 37S, 39697s\n",
      "Total Sample: train: 45.696M, buffer: 11.427M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.82%\n",
      "\tsample data       : 1 MS, 2.05%\n",
      "\tforward & backward: 36 MS, 64.72%\n",
      "\tupdate model      : 16 MS, 29.30%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 56.43 ms\n",
      "[713] Time spent = 56.51 s\n",
      "713:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "713:grad_norm  [1000]: avg:   2.2206, min:   0.7492[ 117], max:   5.5122[ 609]\n",
      "713:loss       [1000]: avg:   0.6245, min:   0.2300[  50], max:   0.9547[ 987]\n",
      "713:rl_loss    [1000]: avg:   0.1110, min:   0.0518[ 905], max:   0.2903[ 418]\n",
      "epoch 713, eval score: 6.6900, perfect: 0.00, model saved: False\n",
      "epoch 713, success rate for sampling ficticious state: 99.85%\n",
      "==========\n",
      "beginning of epoch:  714\n",
      "available: 4.381 GB, used: 24.652 GB, free: 382.004 MB\n",
      "EPOCH: 714\n",
      "Speed: train: 1147.7, buffer_add: 283.2, buffer_size: 100020\n",
      "Total Time: 11H 02M 33S, 39753s\n",
      "Total Sample: train: 45.76M, buffer: 11.443M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.79%\n",
      "\tsample data       : 1 MS, 1.81%\n",
      "\tforward & backward: 36 MS, 64.73%\n",
      "\tupdate model      : 16 MS, 29.58%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.67 ms\n",
      "[714] Time spent = 55.77 s\n",
      "714:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "714:grad_norm  [1000]: avg:   2.1164, min:   0.2613[ 398], max:   5.7686[ 570]\n",
      "714:loss       [1000]: avg:   0.6326, min:   0.1458[ 398], max:   0.9305[ 521]\n",
      "714:rl_loss    [1000]: avg:   0.1140, min:   0.0555[  87], max:   0.2865[  20]\n",
      "epoch 714, eval score: 6.8450, perfect: 0.20, model saved: False\n",
      "epoch 714, success rate for sampling ficticious state: 99.85%\n",
      "==========\n",
      "beginning of epoch:  715\n",
      "available: 4.392 GB, used: 24.641 GB, free: 392.578 MB\n",
      "EPOCH: 715\n",
      "Speed: train: 1127.1, buffer_add: 286.5, buffer_size: 100008\n",
      "Total Time: 11H 03M 30S, 39810s\n",
      "Total Sample: train: 45.824M, buffer: 11.459M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.75%\n",
      "\tsample data       : 1 MS, 2.04%\n",
      "\tforward & backward: 36 MS, 65.01%\n",
      "\tupdate model      : 16 MS, 29.11%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.71 ms\n",
      "[715] Time spent = 56.79 s\n",
      "715:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "715:grad_norm  [1000]: avg:   2.1702, min:   0.7524[ 628], max:   6.2959[ 855]\n",
      "715:loss       [1000]: avg:   0.6321, min:   0.2972[ 519], max:   0.9218[ 238]\n",
      "715:rl_loss    [1000]: avg:   0.1132, min:   0.0511[ 168], max:   0.2822[ 128]\n",
      "epoch 715, eval score: 6.9400, perfect: 0.00, model saved: True\n",
      "epoch 715, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  716\n",
      "available: 4.372 GB, used: 24.661 GB, free: 371.738 MB\n",
      "EPOCH: 716\n",
      "Speed: train: 1152.3, buffer_add: 289.4, buffer_size: 100008\n",
      "Total Time: 11H 04M 25S, 39865s\n",
      "Total Sample: train: 45.888M, buffer: 11.476M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.88%\n",
      "\tsample data       : 1 MS, 2.02%\n",
      "\tforward & backward: 36 MS, 65.00%\n",
      "\tupdate model      : 16 MS, 28.96%\n",
      "\tupdating priority : 0 MS, 0.15%\n",
      "@@@total time per iter: 55.47 ms\n",
      "[716] Time spent = 55.54 s\n",
      "716:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "716:grad_norm  [1000]: avg:   2.1348, min:   0.4868[ 239], max:   5.9383[ 939]\n",
      "716:loss       [1000]: avg:   0.6359, min:   0.1846[ 911], max:   0.9415[ 504]\n",
      "716:rl_loss    [1000]: avg:   0.1141, min:   0.0558[ 941], max:   0.2779[ 478]\n",
      "epoch 716, eval score: 6.8320, perfect: 0.20, model saved: False\n",
      "epoch 716, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  717\n",
      "available: 4.383 GB, used: 24.650 GB, free: 383.461 MB\n",
      "EPOCH: 717\n",
      "Speed: train: 1147.4, buffer_add: 286.8, buffer_size: 100000\n",
      "Total Time: 11H 05M 21S, 39921s\n",
      "Total Sample: train: 45.952M, buffer: 11.492M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.67%\n",
      "\tsample data       : 1 MS, 1.81%\n",
      "\tforward & backward: 36 MS, 65.23%\n",
      "\tupdate model      : 16 MS, 29.17%\n",
      "\tupdating priority : 0 MS, 0.12%\n",
      "@@@total time per iter: 55.72 ms\n",
      "[717] Time spent = 55.78 s\n",
      "717:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "717:grad_norm  [1000]: avg:   2.3132, min:   0.8871[ 295], max:   5.5436[ 290]\n",
      "717:loss       [1000]: avg:   0.6348, min:   0.3460[ 483], max:   0.9430[  21]\n",
      "717:rl_loss    [1000]: avg:   0.1127, min:   0.0524[ 864], max:   0.2736[ 633]\n",
      "epoch 717, eval score: 6.8650, perfect: 0.10, model saved: False\n",
      "epoch 717, success rate for sampling ficticious state: 99.85%\n",
      "==========\n",
      "beginning of epoch:  718\n",
      "available: 4.385 GB, used: 24.648 GB, free: 384.766 MB\n",
      "EPOCH: 718\n",
      "Speed: train: 1173.3, buffer_add: 284.6, buffer_size: 100028\n",
      "Total Time: 11H 06M 16S, 39976s\n",
      "Total Sample: train: 46.016M, buffer: 11.507M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.05%\n",
      "\tsample data       : 0 MS, 1.77%\n",
      "\tforward & backward: 35 MS, 65.25%\n",
      "\tupdate model      : 15 MS, 28.81%\n",
      "\tupdating priority : 0 MS, 0.12%\n",
      "@@@total time per iter: 54.48 ms\n",
      "[718] Time spent = 54.55 s\n",
      "718:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "718:grad_norm  [1000]: avg:   2.2850, min:   0.4110[ 946], max:   6.4544[ 428]\n",
      "718:loss       [1000]: avg:   0.6365, min:   0.2040[ 946], max:   0.9929[ 912]\n",
      "718:rl_loss    [1000]: avg:   0.1103, min:   0.0569[ 124], max:   0.3059[ 994]\n",
      "epoch 718, eval score: 6.8710, perfect: 0.00, model saved: False\n",
      "epoch 718, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  719\n",
      "available: 4.381 GB, used: 24.652 GB, free: 381.180 MB\n",
      "EPOCH: 719\n",
      "Speed: train: 1142.1, buffer_add: 286.7, buffer_size: 100002\n",
      "Total Time: 11H 07M 12S, 40032s\n",
      "Total Sample: train: 46.08M, buffer: 11.523M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.76%\n",
      "\tsample data       : 1 MS, 1.79%\n",
      "\tforward & backward: 36 MS, 65.11%\n",
      "\tupdate model      : 16 MS, 29.24%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.96 ms\n",
      "[719] Time spent = 56.03 s\n",
      "719:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "719:grad_norm  [1000]: avg:   2.1889, min:   0.7799[ 747], max:   6.4519[ 376]\n",
      "719:loss       [1000]: avg:   0.6414, min:   0.2528[ 565], max:   1.0562[ 766]\n",
      "719:rl_loss    [1000]: avg:   0.1103, min:   0.0569[ 842], max:   0.3064[ 766]\n",
      "epoch 719, eval score: 6.7990, perfect: 0.00, model saved: False\n",
      "epoch 719, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  720\n",
      "available: 4.385 GB, used: 24.648 GB, free: 384.461 MB\n",
      "EPOCH: 720\n",
      "Speed: train: 1138.0, buffer_add: 286.0, buffer_size: 100019\n",
      "Total Time: 11H 08M 08S, 40088s\n",
      "Total Sample: train: 46.144M, buffer: 11.539M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.63%\n",
      "\tsample data       : 1 MS, 2.22%\n",
      "\tforward & backward: 36 MS, 65.40%\n",
      "\tupdate model      : 16 MS, 28.64%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 56.17 ms\n",
      "[720] Time spent = 56.24 s\n",
      "720:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "720:grad_norm  [1000]: avg:   2.2482, min:   0.4553[ 226], max:   5.5495[ 902]\n",
      "720:loss       [1000]: avg:   0.6441, min:   0.1322[ 226], max:   0.9733[ 735]\n",
      "720:rl_loss    [1000]: avg:   0.1117, min:   0.0564[ 555], max:   0.3036[ 869]\n",
      "epoch 720, eval score: 6.7770, perfect: 0.00, model saved: False\n",
      "epoch 720, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  721\n",
      "available: 4.367 GB, used: 24.665 GB, free: 366.531 MB\n",
      "EPOCH: 721\n",
      "Speed: train: 1150.4, buffer_add: 284.6, buffer_size: 100002\n",
      "Total Time: 11H 09M 04S, 40144s\n",
      "Total Sample: train: 46.208M, buffer: 11.555M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.84%\n",
      "\tsample data       : 1 MS, 1.98%\n",
      "\tforward & backward: 36 MS, 65.98%\n",
      "\tupdate model      : 15 MS, 28.11%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.56 ms\n",
      "[721] Time spent = 55.65 s\n",
      "721:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "721:grad_norm  [1000]: avg:   2.0801, min:   0.5571[ 884], max:   4.5303[ 609]\n",
      "721:loss       [1000]: avg:   0.6367, min:   0.1848[ 884], max:   0.9967[ 727]\n",
      "721:rl_loss    [1000]: avg:   0.1109, min:   0.0550[ 212], max:   0.2843[  86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 721, eval score: 6.9130, perfect: 0.00, model saved: False\n",
      "epoch 721, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  722\n",
      "available: 4.385 GB, used: 24.648 GB, free: 384.625 MB\n",
      "EPOCH: 722\n",
      "Speed: train: 1156.4, buffer_add: 286.3, buffer_size: 100024\n",
      "Total Time: 11H 09M 59S, 40199s\n",
      "Total Sample: train: 46.272M, buffer: 11.571M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.00%\n",
      "\tsample data       : 1 MS, 1.81%\n",
      "\tforward & backward: 35 MS, 65.00%\n",
      "\tupdate model      : 16 MS, 29.08%\n",
      "\tupdating priority : 0 MS, 0.12%\n",
      "@@@total time per iter: 55.28 ms\n",
      "[722] Time spent = 55.35 s\n",
      "722:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "722:grad_norm  [1000]: avg:   2.2160, min:   0.4050[  23], max:   7.0332[   2]\n",
      "722:loss       [1000]: avg:   0.6405, min:   0.1535[ 438], max:   0.9772[ 295]\n",
      "722:rl_loss    [1000]: avg:   0.1117, min:   0.0603[ 267], max:   0.2906[ 365]\n",
      "epoch 722, eval score: 6.8250, perfect: 0.00, model saved: False\n",
      "epoch 722, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  723\n",
      "available: 4.379 GB, used: 24.654 GB, free: 378.184 MB\n",
      "EPOCH: 723\n",
      "Speed: train: 1148.3, buffer_add: 284.0, buffer_size: 100012\n",
      "Total Time: 11H 10M 55S, 40255s\n",
      "Total Sample: train: 46.336M, buffer: 11.587M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.01%\n",
      "\tsample data       : 1 MS, 1.97%\n",
      "\tforward & backward: 35 MS, 64.57%\n",
      "\tupdate model      : 16 MS, 29.34%\n",
      "\tupdating priority : 0 MS, 0.12%\n",
      "@@@total time per iter: 55.66 ms\n",
      "[723] Time spent = 55.74 s\n",
      "723:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "723:grad_norm  [1000]: avg:   2.1166, min:   0.4874[ 395], max:   6.3898[ 277]\n",
      "723:loss       [1000]: avg:   0.6386, min:   0.1642[ 395], max:   0.9733[ 164]\n",
      "723:rl_loss    [1000]: avg:   0.1134, min:   0.0426[ 361], max:   0.2900[ 563]\n",
      "epoch 723, eval score: 6.8760, perfect: 0.20, model saved: False\n",
      "epoch 723, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  724\n",
      "available: 4.379 GB, used: 24.654 GB, free: 377.672 MB\n",
      "EPOCH: 724\n",
      "Speed: train: 1139.9, buffer_add: 278.5, buffer_size: 100004\n",
      "Total Time: 11H 11M 51S, 40311s\n",
      "Total Sample: train: 46.4M, buffer: 11.602M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.75%\n",
      "\tsample data       : 1 MS, 2.04%\n",
      "\tforward & backward: 36 MS, 65.09%\n",
      "\tupdate model      : 16 MS, 29.03%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 56.06 ms\n",
      "[724] Time spent = 56.15 s\n",
      "724:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "724:grad_norm  [1000]: avg:   2.1334, min:   0.4273[ 394], max:   6.2812[ 232]\n",
      "724:loss       [1000]: avg:   0.6378, min:   0.1657[ 394], max:   0.9249[  11]\n",
      "724:rl_loss    [1000]: avg:   0.1132, min:   0.0581[ 595], max:   0.3915[ 563]\n",
      "epoch 724, eval score: 6.8520, perfect: 0.10, model saved: False\n",
      "epoch 724, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  725\n",
      "available: 4.364 GB, used: 24.669 GB, free: 443.602 MB\n",
      "EPOCH: 725\n",
      "Speed: train: 1147.6, buffer_add: 285.3, buffer_size: 100008\n",
      "Total Time: 11H 12M 47S, 40367s\n",
      "Total Sample: train: 46.464M, buffer: 11.618M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.03%\n",
      "\tsample data       : 0 MS, 1.76%\n",
      "\tforward & backward: 36 MS, 64.73%\n",
      "\tupdate model      : 16 MS, 29.36%\n",
      "\tupdating priority : 0 MS, 0.13%\n",
      "@@@total time per iter: 55.70 ms\n",
      "[725] Time spent = 55.77 s\n",
      "725:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "725:grad_norm  [1000]: avg:   2.1282, min:   0.6733[ 198], max:   5.9569[ 971]\n",
      "725:loss       [1000]: avg:   0.6381, min:   0.2809[ 863], max:   0.9752[ 662]\n",
      "725:rl_loss    [1000]: avg:   0.1148, min:   0.0515[ 101], max:   0.3142[ 829]\n",
      "epoch 725, eval score: 6.7620, perfect: 0.00, model saved: False\n",
      "epoch 725, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  726\n",
      "available: 4.383 GB, used: 24.650 GB, free: 483.129 MB\n",
      "EPOCH: 726\n",
      "Speed: train: 1140.6, buffer_add: 286.4, buffer_size: 100028\n",
      "Total Time: 11H 13M 43S, 40423s\n",
      "Total Sample: train: 46.528M, buffer: 11.634M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.66%\n",
      "\tsample data       : 1 MS, 1.80%\n",
      "\tforward & backward: 36 MS, 65.28%\n",
      "\tupdate model      : 16 MS, 29.17%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.05 ms\n",
      "[726] Time spent = 56.11 s\n",
      "726:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "726:grad_norm  [1000]: avg:   2.1436, min:   0.7836[ 692], max:   4.9958[ 578]\n",
      "726:loss       [1000]: avg:   0.6377, min:   0.2739[ 833], max:   0.9520[ 160]\n",
      "726:rl_loss    [1000]: avg:   0.1146, min:   0.0603[ 822], max:   0.3319[ 596]\n",
      "epoch 726, eval score: 6.9340, perfect: 0.00, model saved: False\n",
      "epoch 726, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  727\n",
      "available: 4.381 GB, used: 24.652 GB, free: 479.516 MB\n",
      "EPOCH: 727\n",
      "Speed: train: 1149.3, buffer_add: 285.2, buffer_size: 100014\n",
      "Total Time: 11H 14M 38S, 40478s\n",
      "Total Sample: train: 46.592M, buffer: 11.65M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.86%\n",
      "\tsample data       : 1 MS, 1.80%\n",
      "\tforward & backward: 36 MS, 65.51%\n",
      "\tupdate model      : 15 MS, 28.74%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.62 ms\n",
      "[727] Time spent = 55.69 s\n",
      "727:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "727:grad_norm  [1000]: avg:   2.2067, min:   0.5797[ 190], max:   5.5182[ 125]\n",
      "727:loss       [1000]: avg:   0.6422, min:   0.2413[ 190], max:   0.9788[  93]\n",
      "727:rl_loss    [1000]: avg:   0.1163, min:   0.0545[ 388], max:   0.3287[ 264]\n",
      "epoch 727, eval score: 6.8100, perfect: 0.10, model saved: False\n",
      "epoch 727, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  728\n",
      "available: 4.385 GB, used: 24.648 GB, free: 483.898 MB\n",
      "EPOCH: 728\n",
      "Speed: train: 1144.5, buffer_add: 286.3, buffer_size: 100006\n",
      "Total Time: 11H 15M 34S, 40534s\n",
      "Total Sample: train: 46.656M, buffer: 11.666M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.69%\n",
      "\tsample data       : 1 MS, 1.79%\n",
      "\tforward & backward: 36 MS, 64.85%\n",
      "\tupdate model      : 16 MS, 29.56%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.85 ms\n",
      "[728] Time spent = 55.92 s\n",
      "728:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "728:grad_norm  [1000]: avg:   2.1910, min:   0.7513[ 835], max:   5.5636[ 597]\n",
      "728:loss       [1000]: avg:   0.6403, min:   0.1772[ 418], max:   0.9285[ 175]\n",
      "728:rl_loss    [1000]: avg:   0.1185, min:   0.0558[ 892], max:   0.3698[ 756]\n",
      "epoch 728, eval score: 6.8480, perfect: 0.00, model saved: False\n",
      "epoch 728, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  729\n",
      "available: 4.381 GB, used: 24.652 GB, free: 479.500 MB\n",
      "EPOCH: 729\n",
      "Speed: train: 1158.5, buffer_add: 288.1, buffer_size: 100010\n",
      "Total Time: 11H 16M 30S, 40590s\n",
      "Total Sample: train: 46.72M, buffer: 11.682M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.88%\n",
      "\tsample data       : 1 MS, 1.89%\n",
      "\tforward & backward: 35 MS, 64.98%\n",
      "\tupdate model      : 16 MS, 29.14%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.17 ms\n",
      "[729] Time spent = 55.25 s\n",
      "729:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "729:grad_norm  [1000]: avg:   2.2077, min:   0.5826[ 424], max:   5.7385[ 833]\n",
      "729:loss       [1000]: avg:   0.6402, min:   0.2086[ 424], max:   1.0844[ 461]\n",
      "729:rl_loss    [1000]: avg:   0.1146, min:   0.0549[ 873], max:   0.4079[ 664]\n",
      "epoch 729, eval score: 6.8080, perfect: 0.00, model saved: False\n",
      "epoch 729, success rate for sampling ficticious state: 99.85%\n",
      "==========\n",
      "beginning of epoch:  730\n",
      "available: 4.383 GB, used: 24.651 GB, free: 480.918 MB\n",
      "EPOCH: 730\n",
      "Speed: train: 1167.8, buffer_add: 283.7, buffer_size: 100000\n",
      "Total Time: 11H 17M 24S, 40644s\n",
      "Total Sample: train: 46.784M, buffer: 11.698M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.44%\n",
      "\tsample data       : 1 MS, 2.05%\n",
      "\tforward & backward: 35 MS, 65.36%\n",
      "\tupdate model      : 15 MS, 29.05%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 54.74 ms\n",
      "[730] Time spent = 54.81 s\n",
      "730:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "730:grad_norm  [1000]: avg:   2.2086, min:   0.7230[ 470], max:   6.1250[  14]\n",
      "730:loss       [1000]: avg:   0.6430, min:   0.1617[ 304], max:   0.9262[ 584]\n",
      "730:rl_loss    [1000]: avg:   0.1161, min:   0.0591[ 719], max:   0.2923[  95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 730, eval score: 6.8910, perfect: 0.10, model saved: False\n",
      "epoch 730, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  731\n",
      "available: 4.384 GB, used: 24.649 GB, free: 482.102 MB\n",
      "EPOCH: 731\n",
      "Speed: train: 1136.3, buffer_add: 289.1, buffer_size: 100002\n",
      "Total Time: 11H 18M 21S, 40701s\n",
      "Total Sample: train: 46.848M, buffer: 11.714M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.82%\n",
      "\tsample data       : 0 MS, 1.66%\n",
      "\tforward & backward: 36 MS, 65.54%\n",
      "\tupdate model      : 16 MS, 28.89%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.26 ms\n",
      "[731] Time spent = 56.33 s\n",
      "731:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "731:grad_norm  [1000]: avg:   2.2224, min:   0.4153[ 911], max:   5.5639[ 737]\n",
      "731:loss       [1000]: avg:   0.6441, min:   0.1828[ 911], max:   0.9724[ 615]\n",
      "731:rl_loss    [1000]: avg:   0.1169, min:   0.0584[ 871], max:   0.2968[ 519]\n",
      "epoch 731, eval score: 6.8490, perfect: 0.00, model saved: False\n",
      "epoch 731, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  732\n",
      "available: 4.367 GB, used: 24.666 GB, free: 465.098 MB\n",
      "EPOCH: 732\n",
      "Speed: train: 1164.8, buffer_add: 284.0, buffer_size: 100004\n",
      "Total Time: 11H 19M 16S, 40756s\n",
      "Total Sample: train: 46.912M, buffer: 11.73M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.74%\n",
      "\tsample data       : 1 MS, 1.99%\n",
      "\tforward & backward: 35 MS, 65.21%\n",
      "\tupdate model      : 15 MS, 28.96%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 54.86 ms\n",
      "[732] Time spent = 54.94 s\n",
      "732:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "732:grad_norm  [1000]: avg:   2.2362, min:   0.5878[ 376], max:   7.8687[ 925]\n",
      "732:loss       [1000]: avg:   0.6460, min:   0.2063[ 376], max:   1.0154[ 795]\n",
      "732:rl_loss    [1000]: avg:   0.1124, min:   0.0601[ 250], max:   0.2765[ 520]\n",
      "epoch 732, eval score: 6.8890, perfect: 0.10, model saved: False\n",
      "epoch 732, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  733\n",
      "available: 4.382 GB, used: 24.651 GB, free: 480.270 MB\n",
      "EPOCH: 733\n",
      "Speed: train: 1156.1, buffer_add: 288.3, buffer_size: 100000\n",
      "Total Time: 11H 20M 11S, 40811s\n",
      "Total Sample: train: 46.976M, buffer: 11.746M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.79%\n",
      "\tsample data       : 1 MS, 1.93%\n",
      "\tforward & backward: 36 MS, 65.74%\n",
      "\tupdate model      : 15 MS, 28.42%\n",
      "\tupdating priority : 0 MS, 0.12%\n",
      "@@@total time per iter: 55.27 ms\n",
      "[733] Time spent = 55.36 s\n",
      "733:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "733:grad_norm  [1000]: avg:   2.2393, min:   0.6453[ 602], max:   6.0774[ 876]\n",
      "733:loss       [1000]: avg:   0.6409, min:   0.2102[ 602], max:   0.9790[ 402]\n",
      "733:rl_loss    [1000]: avg:   0.1126, min:   0.0614[ 829], max:   0.3001[ 840]\n",
      "epoch 733, eval score: 6.8600, perfect: 0.10, model saved: False\n",
      "epoch 733, success rate for sampling ficticious state: 99.85%\n",
      "==========\n",
      "beginning of epoch:  734\n",
      "available: 4.370 GB, used: 24.664 GB, free: 467.293 MB\n",
      "EPOCH: 734\n",
      "Speed: train: 1166.7, buffer_add: 286.6, buffer_size: 100008\n",
      "Total Time: 11H 21M 06S, 40866s\n",
      "Total Sample: train: 47.04M, buffer: 11.761M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.61%\n",
      "\tsample data       : 1 MS, 2.08%\n",
      "\tforward & backward: 35 MS, 65.39%\n",
      "\tupdate model      : 15 MS, 28.84%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 54.78 ms\n",
      "[734] Time spent = 54.86 s\n",
      "734:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "734:grad_norm  [1000]: avg:   2.1967, min:   0.5310[ 150], max:   5.6694[ 930]\n",
      "734:loss       [1000]: avg:   0.6358, min:   0.2946[ 150], max:   0.9506[ 236]\n",
      "734:rl_loss    [1000]: avg:   0.1131, min:   0.0556[ 745], max:   0.2598[ 473]\n",
      "epoch 734, eval score: 6.7880, perfect: 0.00, model saved: False\n",
      "epoch 734, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  735\n",
      "available: 4.376 GB, used: 24.658 GB, free: 473.434 MB\n",
      "EPOCH: 735\n",
      "Speed: train: 1142.5, buffer_add: 285.8, buffer_size: 100004\n",
      "Total Time: 11H 22M 02S, 40922s\n",
      "Total Sample: train: 47.104M, buffer: 11.777M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.79%\n",
      "\tsample data       : 1 MS, 2.07%\n",
      "\tforward & backward: 36 MS, 64.64%\n",
      "\tupdate model      : 16 MS, 29.39%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.95 ms\n",
      "[735] Time spent = 56.02 s\n",
      "735:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "735:grad_norm  [1000]: avg:   2.0932, min:   0.7559[ 484], max:   5.6428[ 432]\n",
      "735:loss       [1000]: avg:   0.6360, min:   0.2044[ 944], max:   0.9189[ 212]\n",
      "735:rl_loss    [1000]: avg:   0.1107, min:   0.0595[ 526], max:   0.2606[ 975]\n",
      "epoch 735, eval score: 6.9580, perfect: 0.00, model saved: True\n",
      "epoch 735, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  736\n",
      "available: 4.380 GB, used: 24.653 GB, free: 477.895 MB\n",
      "EPOCH: 736\n",
      "Speed: train: 1165.1, buffer_add: 285.8, buffer_size: 100014\n",
      "Total Time: 11H 22M 57S, 40977s\n",
      "Total Sample: train: 47.168M, buffer: 11.793M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.71%\n",
      "\tsample data       : 1 MS, 2.01%\n",
      "\tforward & backward: 35 MS, 65.37%\n",
      "\tupdate model      : 15 MS, 28.81%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 54.87 ms\n",
      "[736] Time spent = 54.93 s\n",
      "736:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "736:grad_norm  [1000]: avg:   2.2779, min:   0.8258[ 228], max:   5.7607[ 426]\n",
      "736:loss       [1000]: avg:   0.6379, min:   0.3407[ 223], max:   1.0033[ 764]\n",
      "736:rl_loss    [1000]: avg:   0.1104, min:   0.0599[ 658], max:   0.2881[ 956]\n",
      "epoch 736, eval score: 6.8330, perfect: 0.10, model saved: False\n",
      "epoch 736, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  737\n",
      "available: 4.381 GB, used: 24.652 GB, free: 478.895 MB\n",
      "EPOCH: 737\n",
      "Speed: train: 1171.4, buffer_add: 285.1, buffer_size: 100004\n",
      "Total Time: 11H 23M 51S, 41031s\n",
      "Total Sample: train: 47.232M, buffer: 11.809M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.87%\n",
      "\tsample data       : 1 MS, 1.94%\n",
      "\tforward & backward: 35 MS, 65.18%\n",
      "\tupdate model      : 15 MS, 28.91%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 54.57 ms\n",
      "[737] Time spent = 54.64 s\n",
      "737:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "737:grad_norm  [1000]: avg:   2.1960, min:   0.6990[ 548], max:   5.7680[ 877]\n",
      "737:loss       [1000]: avg:   0.6322, min:   0.2177[ 105], max:   0.9782[ 241]\n",
      "737:rl_loss    [1000]: avg:   0.1120, min:   0.0580[ 795], max:   0.2712[ 216]\n",
      "epoch 737, eval score: 6.8310, perfect: 0.20, model saved: False\n",
      "epoch 737, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  738\n",
      "available: 4.378 GB, used: 24.655 GB, free: 475.680 MB\n",
      "EPOCH: 738\n",
      "Speed: train: 1138.5, buffer_add: 286.8, buffer_size: 100008\n",
      "Total Time: 11H 24M 48S, 41088s\n",
      "Total Sample: train: 47.296M, buffer: 11.825M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.72%\n",
      "\tsample data       : 1 MS, 2.14%\n",
      "\tforward & backward: 36 MS, 64.77%\n",
      "\tupdate model      : 16 MS, 29.24%\n",
      "\tupdating priority : 0 MS, 0.13%\n",
      "@@@total time per iter: 56.14 ms\n",
      "[738] Time spent = 56.21 s\n",
      "738:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "738:grad_norm  [1000]: avg:   2.2551, min:   0.7671[ 225], max:   5.6092[  91]\n",
      "738:loss       [1000]: avg:   0.6300, min:   0.2222[ 254], max:   0.9402[ 543]\n",
      "738:rl_loss    [1000]: avg:   0.1115, min:   0.0555[ 724], max:   0.3085[ 473]\n",
      "epoch 738, eval score: 6.9340, perfect: 0.10, model saved: False\n",
      "epoch 738, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  739\n",
      "available: 4.380 GB, used: 24.654 GB, free: 476.988 MB\n",
      "EPOCH: 739\n",
      "Speed: train: 1157.2, buffer_add: 285.1, buffer_size: 100014\n",
      "Total Time: 11H 25M 43S, 41143s\n",
      "Total Sample: train: 47.36M, buffer: 11.84M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.72%\n",
      "\tsample data       : 0 MS, 1.79%\n",
      "\tforward & backward: 36 MS, 65.33%\n",
      "\tupdate model      : 16 MS, 29.08%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.23 ms\n",
      "[739] Time spent = 55.31 s\n",
      "739:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "739:grad_norm  [1000]: avg:   2.1626, min:   0.3833[ 261], max:   5.4431[ 680]\n",
      "739:loss       [1000]: avg:   0.6314, min:   0.1358[ 261], max:   0.9031[ 338]\n",
      "739:rl_loss    [1000]: avg:   0.1107, min:   0.0568[ 571], max:   0.2888[ 889]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 739, eval score: 6.9050, perfect: 0.10, model saved: False\n",
      "epoch 739, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  740\n",
      "available: 4.377 GB, used: 24.656 GB, free: 474.965 MB\n",
      "EPOCH: 740\n",
      "Speed: train: 1153.4, buffer_add: 285.5, buffer_size: 100020\n",
      "Total Time: 11H 26M 39S, 41199s\n",
      "Total Sample: train: 47.424M, buffer: 11.856M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.99%\n",
      "\tsample data       : 1 MS, 1.85%\n",
      "\tforward & backward: 35 MS, 64.64%\n",
      "\tupdate model      : 16 MS, 29.42%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.42 ms\n",
      "[740] Time spent = 55.49 s\n",
      "740:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "740:grad_norm  [1000]: avg:   2.2594, min:   0.7218[ 908], max:   7.5474[ 387]\n",
      "740:loss       [1000]: avg:   0.6388, min:   0.1643[ 908], max:   1.0049[ 640]\n",
      "740:rl_loss    [1000]: avg:   0.1122, min:   0.0546[ 597], max:   0.2899[ 551]\n",
      "epoch 740, eval score: 6.7030, perfect: 0.10, model saved: False\n",
      "epoch 740, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  741\n",
      "available: 4.363 GB, used: 24.670 GB, free: 460.266 MB\n",
      "EPOCH: 741\n",
      "Speed: train: 1133.3, buffer_add: 286.4, buffer_size: 100012\n",
      "Total Time: 11H 27M 35S, 41255s\n",
      "Total Sample: train: 47.488M, buffer: 11.872M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.81%\n",
      "\tsample data       : 1 MS, 1.90%\n",
      "\tforward & backward: 36 MS, 64.69%\n",
      "\tupdate model      : 16 MS, 29.50%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.39 ms\n",
      "[741] Time spent = 56.47 s\n",
      "741:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "741:grad_norm  [1000]: avg:   2.2221, min:   0.4990[ 637], max:   5.5008[ 550]\n",
      "741:loss       [1000]: avg:   0.6308, min:   0.1705[ 637], max:   0.9631[ 221]\n",
      "741:rl_loss    [1000]: avg:   0.1115, min:   0.0531[ 431], max:   0.2646[ 260]\n",
      "epoch 741, eval score: 6.8150, perfect: 0.20, model saved: False\n",
      "epoch 741, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  742\n",
      "available: 4.376 GB, used: 24.657 GB, free: 473.547 MB\n",
      "EPOCH: 742\n",
      "Speed: train: 1145.8, buffer_add: 285.9, buffer_size: 100012\n",
      "Total Time: 11H 28M 31S, 41311s\n",
      "Total Sample: train: 47.552M, buffer: 11.888M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.86%\n",
      "\tsample data       : 1 MS, 1.94%\n",
      "\tforward & backward: 36 MS, 64.95%\n",
      "\tupdate model      : 16 MS, 29.15%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.76 ms\n",
      "[742] Time spent = 55.86 s\n",
      "742:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "742:grad_norm  [1000]: avg:   2.2125, min:   0.6467[ 740], max:   7.1545[ 949]\n",
      "742:loss       [1000]: avg:   0.6444, min:   0.2635[ 740], max:   1.0170[ 554]\n",
      "742:rl_loss    [1000]: avg:   0.1147, min:   0.0555[ 500], max:   0.2888[ 697]\n",
      "epoch 742, eval score: 6.8450, perfect: 0.10, model saved: False\n",
      "epoch 742, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  743\n",
      "available: 4.380 GB, used: 24.654 GB, free: 476.723 MB\n",
      "EPOCH: 743\n",
      "Speed: train: 1154.9, buffer_add: 286.7, buffer_size: 100008\n",
      "Total Time: 11H 29M 26S, 41366s\n",
      "Total Sample: train: 47.616M, buffer: 11.904M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.76%\n",
      "\tsample data       : 0 MS, 1.74%\n",
      "\tforward & backward: 36 MS, 65.77%\n",
      "\tupdate model      : 15 MS, 28.62%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.35 ms\n",
      "[743] Time spent = 55.42 s\n",
      "743:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "743:grad_norm  [1000]: avg:   2.2417, min:   0.6309[ 726], max:   7.5461[ 825]\n",
      "743:loss       [1000]: avg:   0.6443, min:   0.2572[ 714], max:   0.9346[ 909]\n",
      "743:rl_loss    [1000]: avg:   0.1126, min:   0.0576[ 308], max:   0.3022[ 355]\n",
      "epoch 743, eval score: 6.8000, perfect: 0.00, model saved: False\n",
      "epoch 743, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  744\n",
      "available: 4.368 GB, used: 24.666 GB, free: 464.418 MB\n",
      "EPOCH: 744\n",
      "Speed: train: 1152.5, buffer_add: 287.3, buffer_size: 100000\n",
      "Total Time: 11H 30M 22S, 41422s\n",
      "Total Sample: train: 47.68M, buffer: 11.92M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.75%\n",
      "\tsample data       : 1 MS, 2.17%\n",
      "\tforward & backward: 36 MS, 65.01%\n",
      "\tupdate model      : 16 MS, 28.98%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.48 ms\n",
      "[744] Time spent = 55.54 s\n",
      "744:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "744:grad_norm  [1000]: avg:   2.1991, min:   0.6690[ 732], max:   5.9656[ 397]\n",
      "744:loss       [1000]: avg:   0.6422, min:   0.1929[ 562], max:   0.9228[ 588]\n",
      "744:rl_loss    [1000]: avg:   0.1143, min:   0.0542[ 609], max:   0.2843[ 988]\n",
      "epoch 744, eval score: 6.9790, perfect: 0.20, model saved: True\n",
      "epoch 744, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  745\n",
      "available: 4.373 GB, used: 24.660 GB, free: 469.734 MB\n",
      "EPOCH: 745\n",
      "Speed: train: 1158.5, buffer_add: 287.2, buffer_size: 100012\n",
      "Total Time: 11H 31M 17S, 41477s\n",
      "Total Sample: train: 47.744M, buffer: 11.936M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.95%\n",
      "\tsample data       : 0 MS, 1.63%\n",
      "\tforward & backward: 36 MS, 65.46%\n",
      "\tupdate model      : 15 MS, 28.87%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.17 ms\n",
      "[745] Time spent = 55.25 s\n",
      "745:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "745:grad_norm  [1000]: avg:   2.1999, min:   0.4565[ 444], max:   7.0782[ 949]\n",
      "745:loss       [1000]: avg:   0.6483, min:   0.2172[ 499], max:   1.3679[ 432]\n",
      "745:rl_loss    [1000]: avg:   0.1134, min:   0.0485[ 307], max:   0.3857[ 901]\n",
      "epoch 745, eval score: 6.8420, perfect: 0.00, model saved: False\n",
      "epoch 745, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  746\n",
      "available: 4.377 GB, used: 24.657 GB, free: 473.188 MB\n",
      "EPOCH: 746\n",
      "Speed: train: 1150.3, buffer_add: 288.4, buffer_size: 100055\n",
      "Total Time: 11H 32M 13S, 41533s\n",
      "Total Sample: train: 47.808M, buffer: 11.952M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.89%\n",
      "\tsample data       : 1 MS, 1.93%\n",
      "\tforward & backward: 36 MS, 64.92%\n",
      "\tupdate model      : 16 MS, 29.16%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.57 ms\n",
      "[746] Time spent = 55.65 s\n",
      "746:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "746:grad_norm  [1000]: avg:   2.2599, min:   0.7884[ 149], max:   5.6822[ 869]\n",
      "746:loss       [1000]: avg:   0.6479, min:   0.2615[ 188], max:   0.9580[ 813]\n",
      "746:rl_loss    [1000]: avg:   0.1145, min:   0.0582[ 399], max:   0.3530[ 120]\n",
      "epoch 746, eval score: 6.9110, perfect: 0.10, model saved: False\n",
      "epoch 746, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  747\n",
      "available: 4.381 GB, used: 24.652 GB, free: 477.707 MB\n",
      "EPOCH: 747\n",
      "Speed: train: 1154.8, buffer_add: 286.2, buffer_size: 100010\n",
      "Total Time: 11H 33M 08S, 41588s\n",
      "Total Sample: train: 47.872M, buffer: 11.968M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.49%\n",
      "\tsample data       : 1 MS, 1.93%\n",
      "\tforward & backward: 36 MS, 65.31%\n",
      "\tupdate model      : 16 MS, 29.17%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.35 ms\n",
      "[747] Time spent = 55.42 s\n",
      "747:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "747:grad_norm  [1000]: avg:   2.2200, min:   0.6780[ 169], max:   5.7327[ 681]\n",
      "747:loss       [1000]: avg:   0.6522, min:   0.3090[ 247], max:   0.9924[ 983]\n",
      "747:rl_loss    [1000]: avg:   0.1145, min:   0.0534[ 278], max:   0.3167[ 520]\n",
      "epoch 747, eval score: 6.8710, perfect: 0.20, model saved: False\n",
      "epoch 747, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  748\n",
      "available: 4.384 GB, used: 24.650 GB, free: 480.309 MB\n",
      "EPOCH: 748\n",
      "Speed: train: 1134.3, buffer_add: 286.0, buffer_size: 100004\n",
      "Total Time: 11H 34M 05S, 41645s\n",
      "Total Sample: train: 47.936M, buffer: 11.984M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.79%\n",
      "\tsample data       : 1 MS, 1.98%\n",
      "\tforward & backward: 36 MS, 65.15%\n",
      "\tupdate model      : 16 MS, 28.98%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 56.35 ms\n",
      "[748] Time spent = 56.42 s\n",
      "748:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "748:grad_norm  [1000]: avg:   2.1613, min:   0.7106[ 670], max:   5.8573[  30]\n",
      "748:loss       [1000]: avg:   0.6458, min:   0.2292[ 670], max:   0.9712[ 931]\n",
      "748:rl_loss    [1000]: avg:   0.1169, min:   0.0594[ 395], max:   0.2748[ 567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 748, eval score: 6.8980, perfect: 0.20, model saved: False\n",
      "epoch 748, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  749\n",
      "available: 4.378 GB, used: 24.656 GB, free: 474.258 MB\n",
      "EPOCH: 749\n",
      "Speed: train: 1158.9, buffer_add: 283.9, buffer_size: 100014\n",
      "Total Time: 11H 35M 00S, 41700s\n",
      "Total Sample: train: 48M, buffer: 12M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.76%\n",
      "\tsample data       : 0 MS, 1.79%\n",
      "\tforward & backward: 36 MS, 65.64%\n",
      "\tupdate model      : 15 MS, 28.71%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.16 ms\n",
      "[749] Time spent = 55.23 s\n",
      "749:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "749:grad_norm  [1000]: avg:   2.2265, min:   0.8139[ 842], max:   5.9922[   8]\n",
      "749:loss       [1000]: avg:   0.6555, min:   0.3210[ 305], max:   0.9813[ 339]\n",
      "749:rl_loss    [1000]: avg:   0.1179, min:   0.0608[ 580], max:   0.3152[ 905]\n",
      "epoch 749, eval score: 6.8870, perfect: 0.00, model saved: False\n",
      "epoch 749, success rate for sampling ficticious state: 99.85%\n",
      "==========\n",
      "beginning of epoch:  750\n",
      "available: 4.378 GB, used: 24.655 GB, free: 474.785 MB\n",
      "EPOCH: 750\n",
      "Speed: train: 1163.3, buffer_add: 283.9, buffer_size: 100014\n",
      "Total Time: 11H 35M 55S, 41755s\n",
      "Total Sample: train: 48.064M, buffer: 12.015M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.54%\n",
      "\tsample data       : 1 MS, 1.84%\n",
      "\tforward & backward: 36 MS, 65.92%\n",
      "\tupdate model      : 15 MS, 28.59%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 54.96 ms\n",
      "[750] Time spent = 55.02 s\n",
      "750:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "750:grad_norm  [1000]: avg:   2.1023, min:   0.7821[ 125], max:   5.5905[ 795]\n",
      "750:loss       [1000]: avg:   0.6448, min:   0.2704[ 946], max:   0.9453[ 990]\n",
      "750:rl_loss    [1000]: avg:   0.1170, min:   0.0582[  77], max:   0.2645[ 405]\n",
      "epoch 750, eval score: 6.8750, perfect: 0.10, model saved: False\n",
      "epoch 750, success rate for sampling ficticious state: 99.85%\n",
      "==========\n",
      "beginning of epoch:  751\n",
      "available: 4.377 GB, used: 24.656 GB, free: 473.762 MB\n",
      "EPOCH: 751\n",
      "Speed: train: 1131.6, buffer_add: 288.0, buffer_size: 100020\n",
      "Total Time: 11H 36M 51S, 41811s\n",
      "Total Sample: train: 48.128M, buffer: 12.032M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.11%\n",
      "\tsample data       : 1 MS, 1.91%\n",
      "\tforward & backward: 36 MS, 64.92%\n",
      "\tupdate model      : 16 MS, 28.97%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.48 ms\n",
      "[751] Time spent = 56.56 s\n",
      "751:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "751:grad_norm  [1000]: avg:   2.2115, min:   0.4658[ 185], max:   5.5834[ 306]\n",
      "751:loss       [1000]: avg:   0.6425, min:   0.1597[ 185], max:   1.0227[ 472]\n",
      "751:rl_loss    [1000]: avg:   0.1165, min:   0.0570[ 833], max:   0.3502[ 597]\n",
      "epoch 751, eval score: 6.9120, perfect: 0.10, model saved: False\n",
      "epoch 751, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  752\n",
      "available: 4.380 GB, used: 24.654 GB, free: 476.164 MB\n",
      "EPOCH: 752\n",
      "Speed: train: 1140.4, buffer_add: 287.6, buffer_size: 100008\n",
      "Total Time: 11H 37M 47S, 41867s\n",
      "Total Sample: train: 48.192M, buffer: 12.048M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.63%\n",
      "\tsample data       : 1 MS, 2.21%\n",
      "\tforward & backward: 36 MS, 64.25%\n",
      "\tupdate model      : 16 MS, 29.83%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.04 ms\n",
      "[752] Time spent = 56.12 s\n",
      "752:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "752:grad_norm  [1000]: avg:   2.1863, min:   0.3208[ 871], max:   5.2709[ 208]\n",
      "752:loss       [1000]: avg:   0.6477, min:   0.1477[ 871], max:   1.0267[ 836]\n",
      "752:rl_loss    [1000]: avg:   0.1154, min:   0.0572[ 106], max:   0.3126[ 514]\n",
      "epoch 752, eval score: 6.8660, perfect: 0.00, model saved: False\n",
      "epoch 752, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  753\n",
      "available: 4.377 GB, used: 24.656 GB, free: 473.125 MB\n",
      "EPOCH: 753\n",
      "Speed: train: 1153.4, buffer_add: 286.3, buffer_size: 100004\n",
      "Total Time: 11H 38M 43S, 41923s\n",
      "Total Sample: train: 48.256M, buffer: 12.064M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.86%\n",
      "\tsample data       : 1 MS, 1.82%\n",
      "\tforward & backward: 36 MS, 65.20%\n",
      "\tupdate model      : 16 MS, 29.00%\n",
      "\tupdating priority : 0 MS, 0.12%\n",
      "@@@total time per iter: 55.40 ms\n",
      "[753] Time spent = 55.49 s\n",
      "753:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "753:grad_norm  [1000]: avg:   2.2196, min:   0.5119[ 614], max:   6.4984[ 159]\n",
      "753:loss       [1000]: avg:   0.6439, min:   0.2438[ 614], max:   0.9896[ 159]\n",
      "753:rl_loss    [1000]: avg:   0.1148, min:   0.0602[ 856], max:   0.3043[ 425]\n",
      "epoch 753, eval score: 7.0180, perfect: 0.00, model saved: True\n",
      "epoch 753, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  754\n",
      "available: 4.370 GB, used: 24.664 GB, free: 465.977 MB\n",
      "EPOCH: 754\n",
      "Speed: train: 1160.9, buffer_add: 288.2, buffer_size: 100040\n",
      "Total Time: 11H 39M 38S, 41978s\n",
      "Total Sample: train: 48.32M, buffer: 12.08M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.98%\n",
      "\tsample data       : 1 MS, 1.95%\n",
      "\tforward & backward: 35 MS, 64.97%\n",
      "\tupdate model      : 15 MS, 28.99%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.05 ms\n",
      "[754] Time spent = 55.13 s\n",
      "754:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "754:grad_norm  [1000]: avg:   2.1605, min:   0.6920[ 160], max:   5.4535[ 871]\n",
      "754:loss       [1000]: avg:   0.6464, min:   0.2528[  67], max:   0.9815[ 871]\n",
      "754:rl_loss    [1000]: avg:   0.1139, min:   0.0591[ 959], max:   0.2611[ 660]\n",
      "epoch 754, eval score: 6.8710, perfect: 0.00, model saved: False\n",
      "epoch 754, success rate for sampling ficticious state: 99.85%\n",
      "==========\n",
      "beginning of epoch:  755\n",
      "available: 4.370 GB, used: 24.663 GB, free: 465.957 MB\n",
      "EPOCH: 755\n",
      "Speed: train: 1152.9, buffer_add: 284.9, buffer_size: 100000\n",
      "Total Time: 11H 40M 34S, 42034s\n",
      "Total Sample: train: 48.384M, buffer: 12.095M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.04%\n",
      "\tsample data       : 1 MS, 1.96%\n",
      "\tforward & backward: 36 MS, 65.88%\n",
      "\tupdate model      : 15 MS, 28.03%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.44 ms\n",
      "[755] Time spent = 55.51 s\n",
      "755:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "755:grad_norm  [1000]: avg:   2.2159, min:   0.7422[ 777], max:   6.6262[  12]\n",
      "755:loss       [1000]: avg:   0.6508, min:   0.2904[ 280], max:   0.9736[  94]\n",
      "755:rl_loss    [1000]: avg:   0.1124, min:   0.0593[  54], max:   0.3333[ 735]\n",
      "epoch 755, eval score: 6.9110, perfect: 0.00, model saved: False\n",
      "epoch 755, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  756\n",
      "available: 4.378 GB, used: 24.656 GB, free: 473.605 MB\n",
      "EPOCH: 756\n",
      "Speed: train: 1139.9, buffer_add: 287.8, buffer_size: 100022\n",
      "Total Time: 11H 41M 30S, 42090s\n",
      "Total Sample: train: 48.448M, buffer: 12.112M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.78%\n",
      "\tsample data       : 1 MS, 2.00%\n",
      "\tforward & backward: 36 MS, 64.65%\n",
      "\tupdate model      : 16 MS, 29.49%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.08 ms\n",
      "[756] Time spent = 56.15 s\n",
      "756:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "756:grad_norm  [1000]: avg:   2.1559, min:   0.5248[ 719], max:   5.7294[ 282]\n",
      "756:loss       [1000]: avg:   0.6430, min:   0.2037[ 931], max:   0.9293[ 747]\n",
      "756:rl_loss    [1000]: avg:   0.1126, min:   0.0582[ 395], max:   0.3619[ 861]\n",
      "epoch 756, eval score: 6.8050, perfect: 0.20, model saved: False\n",
      "epoch 756, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  757\n",
      "available: 4.380 GB, used: 24.653 GB, free: 476.000 MB\n",
      "EPOCH: 757\n",
      "Speed: train: 1146.9, buffer_add: 287.6, buffer_size: 100002\n",
      "Total Time: 11H 42M 25S, 42145s\n",
      "Total Sample: train: 48.512M, buffer: 12.128M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.97%\n",
      "\tsample data       : 1 MS, 2.01%\n",
      "\tforward & backward: 35 MS, 64.23%\n",
      "\tupdate model      : 16 MS, 29.69%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.74 ms\n",
      "[757] Time spent = 55.80 s\n",
      "757:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "757:grad_norm  [1000]: avg:   2.1274, min:   0.7140[ 443], max:   5.4751[ 254]\n",
      "757:loss       [1000]: avg:   0.6509, min:   0.2732[ 884], max:   0.9962[ 549]\n",
      "757:rl_loss    [1000]: avg:   0.1115, min:   0.0567[ 349], max:   0.2996[ 387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 757, eval score: 6.8870, perfect: 0.00, model saved: False\n",
      "epoch 757, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  758\n",
      "available: 4.371 GB, used: 24.662 GB, free: 466.699 MB\n",
      "EPOCH: 758\n",
      "Speed: train: 1153.1, buffer_add: 287.7, buffer_size: 100030\n",
      "Total Time: 11H 43M 21S, 42201s\n",
      "Total Sample: train: 48.576M, buffer: 12.144M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.64%\n",
      "\tsample data       : 0 MS, 1.74%\n",
      "\tforward & backward: 36 MS, 65.06%\n",
      "\tupdate model      : 16 MS, 29.46%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.43 ms\n",
      "[758] Time spent = 55.51 s\n",
      "758:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "758:grad_norm  [1000]: avg:   2.2138, min:   0.8059[ 608], max:   5.7807[ 271]\n",
      "758:loss       [1000]: avg:   0.6516, min:   0.3240[ 372], max:   0.9481[ 154]\n",
      "758:rl_loss    [1000]: avg:   0.1138, min:   0.0504[ 803], max:   0.3109[ 120]\n",
      "epoch 758, eval score: 6.8080, perfect: 0.30, model saved: False\n",
      "epoch 758, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  759\n",
      "available: 4.371 GB, used: 24.663 GB, free: 465.785 MB\n",
      "EPOCH: 759\n",
      "Speed: train: 1137.0, buffer_add: 286.9, buffer_size: 100032\n",
      "Total Time: 11H 44M 17S, 42257s\n",
      "Total Sample: train: 48.64M, buffer: 12.16M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.92%\n",
      "\tsample data       : 0 MS, 1.65%\n",
      "\tforward & backward: 36 MS, 65.05%\n",
      "\tupdate model      : 16 MS, 29.29%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.20 ms\n",
      "[759] Time spent = 56.29 s\n",
      "759:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "759:grad_norm  [1000]: avg:   2.1548, min:   0.7343[  50], max:   5.8412[  23]\n",
      "759:loss       [1000]: avg:   0.6452, min:   0.2580[  87], max:   0.9419[ 919]\n",
      "759:rl_loss    [1000]: avg:   0.1152, min:   0.0540[ 845], max:   0.3322[ 398]\n",
      "epoch 759, eval score: 6.8420, perfect: 0.30, model saved: False\n",
      "epoch 759, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  760\n",
      "available: 4.368 GB, used: 24.665 GB, free: 463.180 MB\n",
      "EPOCH: 760\n",
      "Speed: train: 1160.4, buffer_add: 284.3, buffer_size: 100030\n",
      "Total Time: 11H 45M 12S, 42312s\n",
      "Total Sample: train: 48.704M, buffer: 12.175M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.85%\n",
      "\tsample data       : 1 MS, 1.91%\n",
      "\tforward & backward: 35 MS, 65.08%\n",
      "\tupdate model      : 16 MS, 29.05%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.08 ms\n",
      "[760] Time spent = 55.16 s\n",
      "760:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "760:grad_norm  [1000]: avg:   2.1300, min:   0.6841[ 319], max:   5.9769[ 879]\n",
      "760:loss       [1000]: avg:   0.6501, min:   0.2316[ 939], max:   0.9918[ 277]\n",
      "760:rl_loss    [1000]: avg:   0.1143, min:   0.0535[ 358], max:   0.2800[ 342]\n",
      "epoch 760, eval score: 6.7920, perfect: 0.00, model saved: False\n",
      "epoch 760, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  761\n",
      "available: 4.368 GB, used: 24.665 GB, free: 462.996 MB\n",
      "EPOCH: 761\n",
      "Speed: train: 1164.0, buffer_add: 284.2, buffer_size: 100011\n",
      "Total Time: 11H 46M 07S, 42367s\n",
      "Total Sample: train: 48.768M, buffer: 12.191M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.69%\n",
      "\tsample data       : 1 MS, 1.94%\n",
      "\tforward & backward: 36 MS, 65.66%\n",
      "\tupdate model      : 15 MS, 28.60%\n",
      "\tupdating priority : 0 MS, 0.12%\n",
      "@@@total time per iter: 54.93 ms\n",
      "[761] Time spent = 54.99 s\n",
      "761:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "761:grad_norm  [1000]: avg:   2.1404, min:   0.1513[ 531], max:   6.2111[ 304]\n",
      "761:loss       [1000]: avg:   0.6412, min:   0.0556[ 531], max:   0.9697[ 699]\n",
      "761:rl_loss    [1000]: avg:   0.1138, min:   0.0642[ 803], max:   0.2925[ 862]\n",
      "epoch 761, eval score: 6.7750, perfect: 0.10, model saved: False\n",
      "epoch 761, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  762\n",
      "available: 4.373 GB, used: 24.660 GB, free: 467.941 MB\n",
      "EPOCH: 762\n",
      "Speed: train: 1152.6, buffer_add: 282.6, buffer_size: 100008\n",
      "Total Time: 11H 47M 03S, 42423s\n",
      "Total Sample: train: 48.832M, buffer: 12.207M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.85%\n",
      "\tsample data       : 1 MS, 1.85%\n",
      "\tforward & backward: 36 MS, 65.59%\n",
      "\tupdate model      : 15 MS, 28.61%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.46 ms\n",
      "[762] Time spent = 55.53 s\n",
      "762:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "762:grad_norm  [1000]: avg:   2.2147, min:   0.6975[ 337], max:   5.4968[ 226]\n",
      "762:loss       [1000]: avg:   0.6424, min:   0.2483[ 438], max:   1.0455[ 793]\n",
      "762:rl_loss    [1000]: avg:   0.1135, min:   0.0501[ 214], max:   0.2866[ 380]\n",
      "epoch 762, eval score: 6.8870, perfect: 0.30, model saved: False\n",
      "epoch 762, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  763\n",
      "available: 4.373 GB, used: 24.661 GB, free: 467.020 MB\n",
      "EPOCH: 763\n",
      "Speed: train: 1146.8, buffer_add: 286.6, buffer_size: 100048\n",
      "Total Time: 11H 47M 59S, 42479s\n",
      "Total Sample: train: 48.896M, buffer: 12.223M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.50%\n",
      "\tsample data       : 1 MS, 2.00%\n",
      "\tforward & backward: 36 MS, 64.88%\n",
      "\tupdate model      : 16 MS, 29.53%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.75 ms\n",
      "[763] Time spent = 55.81 s\n",
      "763:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "763:grad_norm  [1000]: avg:   2.2316, min:   0.5536[ 455], max:   6.1412[ 422]\n",
      "763:loss       [1000]: avg:   0.6518, min:   0.2424[ 455], max:   1.0046[ 394]\n",
      "763:rl_loss    [1000]: avg:   0.1161, min:   0.0567[ 698], max:   0.3168[ 825]\n",
      "epoch 763, eval score: 6.8090, perfect: 0.10, model saved: False\n",
      "epoch 763, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  764\n",
      "available: 4.368 GB, used: 24.665 GB, free: 462.113 MB\n",
      "EPOCH: 764\n",
      "Speed: train: 1136.0, buffer_add: 287.5, buffer_size: 100018\n",
      "Total Time: 11H 48M 55S, 42535s\n",
      "Total Sample: train: 48.96M, buffer: 12.239M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.54%\n",
      "\tsample data       : 1 MS, 2.24%\n",
      "\tforward & backward: 36 MS, 64.90%\n",
      "\tupdate model      : 16 MS, 29.22%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 56.27 ms\n",
      "[764] Time spent = 56.34 s\n",
      "764:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "764:grad_norm  [1000]: avg:   2.2484, min:   0.5800[ 348], max:   5.7263[ 294]\n",
      "764:loss       [1000]: avg:   0.6477, min:   0.1922[ 525], max:   0.9736[ 801]\n",
      "764:rl_loss    [1000]: avg:   0.1159, min:   0.0629[  45], max:   0.3087[ 175]\n",
      "epoch 764, eval score: 6.9220, perfect: 0.10, model saved: False\n",
      "epoch 764, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  765\n",
      "available: 4.365 GB, used: 24.669 GB, free: 458.809 MB\n",
      "EPOCH: 765\n",
      "Speed: train: 1128.4, buffer_add: 284.9, buffer_size: 100023\n",
      "Total Time: 11H 49M 52S, 42592s\n",
      "Total Sample: train: 49.024M, buffer: 12.255M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.09%\n",
      "\tsample data       : 1 MS, 1.79%\n",
      "\tforward & backward: 36 MS, 64.52%\n",
      "\tupdate model      : 16 MS, 29.51%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.63 ms\n",
      "[765] Time spent = 56.72 s\n",
      "765:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "765:grad_norm  [1000]: avg:   2.2069, min:   0.6871[ 398], max:   5.0069[ 442]\n",
      "765:loss       [1000]: avg:   0.6432, min:   0.2993[ 686], max:   1.0177[ 155]\n",
      "765:rl_loss    [1000]: avg:   0.1146, min:   0.0597[ 530], max:   0.2647[ 837]\n",
      "epoch 765, eval score: 6.8560, perfect: 0.00, model saved: False\n",
      "epoch 765, success rate for sampling ficticious state: 99.85%\n",
      "==========\n",
      "beginning of epoch:  766\n",
      "available: 4.365 GB, used: 24.668 GB, free: 459.051 MB\n",
      "EPOCH: 766\n",
      "Speed: train: 1153.3, buffer_add: 283.4, buffer_size: 100028\n",
      "Total Time: 11H 50M 47S, 42647s\n",
      "Total Sample: train: 49.088M, buffer: 12.271M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.79%\n",
      "\tsample data       : 1 MS, 2.15%\n",
      "\tforward & backward: 36 MS, 65.09%\n",
      "\tupdate model      : 15 MS, 28.88%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.39 ms\n",
      "[766] Time spent = 55.49 s\n",
      "766:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "766:grad_norm  [1000]: avg:   2.2498, min:   0.5659[ 237], max:   5.6208[ 672]\n",
      "766:loss       [1000]: avg:   0.6469, min:   0.3075[ 194], max:   0.9791[ 400]\n",
      "766:rl_loss    [1000]: avg:   0.1150, min:   0.0505[ 639], max:   0.3535[ 851]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 766, eval score: 6.8350, perfect: 0.00, model saved: False\n",
      "epoch 766, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  767\n",
      "available: 4.374 GB, used: 24.659 GB, free: 468.531 MB\n",
      "EPOCH: 767\n",
      "Speed: train: 1146.0, buffer_add: 284.3, buffer_size: 100002\n",
      "Total Time: 11H 51M 43S, 42703s\n",
      "Total Sample: train: 49.152M, buffer: 12.287M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.72%\n",
      "\tsample data       : 1 MS, 1.97%\n",
      "\tforward & backward: 36 MS, 64.81%\n",
      "\tupdate model      : 16 MS, 29.40%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.77 ms\n",
      "[767] Time spent = 55.85 s\n",
      "767:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "767:grad_norm  [1000]: avg:   2.1778, min:   0.4064[ 390], max:   6.4484[ 652]\n",
      "767:loss       [1000]: avg:   0.6445, min:   0.1882[ 391], max:   1.0057[ 979]\n",
      "767:rl_loss    [1000]: avg:   0.1145, min:   0.0494[ 596], max:   0.2899[ 967]\n",
      "epoch 767, eval score: 6.7420, perfect: 0.00, model saved: False\n",
      "epoch 767, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  768\n",
      "available: 4.371 GB, used: 24.662 GB, free: 465.258 MB\n",
      "EPOCH: 768\n",
      "Speed: train: 1155.2, buffer_add: 286.4, buffer_size: 100006\n",
      "Total Time: 11H 52M 39S, 42759s\n",
      "Total Sample: train: 49.216M, buffer: 12.303M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.58%\n",
      "\tsample data       : 1 MS, 1.85%\n",
      "\tforward & backward: 36 MS, 65.64%\n",
      "\tupdate model      : 15 MS, 28.83%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.33 ms\n",
      "[768] Time spent = 55.40 s\n",
      "768:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "768:grad_norm  [1000]: avg:   2.1706, min:   0.5864[ 817], max:   6.0678[ 278]\n",
      "768:loss       [1000]: avg:   0.6402, min:   0.2975[ 119], max:   0.9472[ 462]\n",
      "768:rl_loss    [1000]: avg:   0.1158, min:   0.0582[ 577], max:   0.3158[ 846]\n",
      "epoch 768, eval score: 6.9530, perfect: 0.00, model saved: True\n",
      "epoch 768, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  769\n",
      "available: 4.372 GB, used: 24.661 GB, free: 466.328 MB\n",
      "EPOCH: 769\n",
      "Speed: train: 1153.1, buffer_add: 287.9, buffer_size: 100000\n",
      "Total Time: 11H 53M 34S, 42814s\n",
      "Total Sample: train: 49.28M, buffer: 12.319M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.94%\n",
      "\tsample data       : 1 MS, 2.05%\n",
      "\tforward & backward: 36 MS, 65.50%\n",
      "\tupdate model      : 15 MS, 28.41%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.43 ms\n",
      "[769] Time spent = 55.51 s\n",
      "769:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "769:grad_norm  [1000]: avg:   2.2215, min:   0.7133[ 771], max:   5.7718[ 700]\n",
      "769:loss       [1000]: avg:   0.6480, min:   0.1993[ 771], max:   0.9657[ 425]\n",
      "769:rl_loss    [1000]: avg:   0.1166, min:   0.0604[ 641], max:   0.3995[ 556]\n",
      "epoch 769, eval score: 6.9100, perfect: 0.00, model saved: False\n",
      "epoch 769, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  770\n",
      "available: 4.370 GB, used: 24.663 GB, free: 463.668 MB\n",
      "EPOCH: 770\n",
      "Speed: train: 1163.3, buffer_add: 286.2, buffer_size: 100004\n",
      "Total Time: 11H 54M 29S, 42869s\n",
      "Total Sample: train: 49.344M, buffer: 12.334M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.74%\n",
      "\tsample data       : 1 MS, 1.83%\n",
      "\tforward & backward: 35 MS, 65.00%\n",
      "\tupdate model      : 16 MS, 29.32%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 54.95 ms\n",
      "[770] Time spent = 55.02 s\n",
      "770:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "770:grad_norm  [1000]: avg:   2.0972, min:   0.5964[ 541], max:   5.9780[ 790]\n",
      "770:loss       [1000]: avg:   0.6465, min:   0.2814[ 541], max:   0.9458[ 842]\n",
      "770:rl_loss    [1000]: avg:   0.1171, min:   0.0561[ 850], max:   0.3133[ 261]\n",
      "epoch 770, eval score: 6.7900, perfect: 0.10, model saved: False\n",
      "epoch 770, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  771\n",
      "available: 4.367 GB, used: 24.666 GB, free: 460.570 MB\n",
      "EPOCH: 771\n",
      "Speed: train: 1145.2, buffer_add: 285.9, buffer_size: 100028\n",
      "Total Time: 11H 55M 25S, 42925s\n",
      "Total Sample: train: 49.408M, buffer: 12.35M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.13%\n",
      "\tsample data       : 1 MS, 2.07%\n",
      "\tforward & backward: 36 MS, 65.07%\n",
      "\tupdate model      : 15 MS, 28.64%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.83 ms\n",
      "[771] Time spent = 55.89 s\n",
      "771:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "771:grad_norm  [1000]: avg:   2.2024, min:   0.7968[ 839], max:   6.1308[  45]\n",
      "771:loss       [1000]: avg:   0.6462, min:   0.2417[ 472], max:   0.9703[ 987]\n",
      "771:rl_loss    [1000]: avg:   0.1155, min:   0.0501[ 123], max:   0.2984[ 582]\n",
      "epoch 771, eval score: 6.9190, perfect: 0.00, model saved: False\n",
      "epoch 771, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  772\n",
      "available: 4.375 GB, used: 24.658 GB, free: 469.168 MB\n",
      "EPOCH: 772\n",
      "Speed: train: 1144.0, buffer_add: 286.7, buffer_size: 100002\n",
      "Total Time: 11H 56M 21S, 42981s\n",
      "Total Sample: train: 49.472M, buffer: 12.366M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.93%\n",
      "\tsample data       : 0 MS, 1.74%\n",
      "\tforward & backward: 36 MS, 64.82%\n",
      "\tupdate model      : 16 MS, 29.40%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.88 ms\n",
      "[772] Time spent = 55.95 s\n",
      "772:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "772:grad_norm  [1000]: avg:   2.2095, min:   0.4839[ 899], max:   7.0746[ 159]\n",
      "772:loss       [1000]: avg:   0.6556, min:   0.2305[ 812], max:   0.9450[ 543]\n",
      "772:rl_loss    [1000]: avg:   0.1194, min:   0.0636[ 642], max:   0.2671[ 225]\n",
      "epoch 772, eval score: 6.7780, perfect: 0.10, model saved: False\n",
      "epoch 772, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  773\n",
      "available: 4.369 GB, used: 24.664 GB, free: 462.809 MB\n",
      "EPOCH: 773\n",
      "Speed: train: 1132.2, buffer_add: 289.0, buffer_size: 100002\n",
      "Total Time: 11H 57M 17S, 43037s\n",
      "Total Sample: train: 49.536M, buffer: 12.383M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.75%\n",
      "\tsample data       : 1 MS, 2.13%\n",
      "\tforward & backward: 36 MS, 65.53%\n",
      "\tupdate model      : 16 MS, 28.49%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.43 ms\n",
      "[773] Time spent = 56.52 s\n",
      "773:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "773:grad_norm  [1000]: avg:   2.1848, min:   0.6672[ 384], max:   5.5091[  44]\n",
      "773:loss       [1000]: avg:   0.6536, min:   0.2464[ 384], max:   1.0514[ 266]\n",
      "773:rl_loss    [1000]: avg:   0.1184, min:   0.0525[  73], max:   0.3370[ 853]\n",
      "epoch 773, eval score: 6.8770, perfect: 0.00, model saved: False\n",
      "epoch 773, success rate for sampling ficticious state: 99.85%\n",
      "==========\n",
      "beginning of epoch:  774\n",
      "available: 4.352 GB, used: 24.681 GB, free: 444.625 MB\n",
      "EPOCH: 774\n",
      "Speed: train: 1139.6, buffer_add: 284.8, buffer_size: 100002\n",
      "Total Time: 11H 58M 14S, 43094s\n",
      "Total Sample: train: 49.6M, buffer: 12.399M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.52%\n",
      "\tsample data       : 1 MS, 1.93%\n",
      "\tforward & backward: 36 MS, 64.93%\n",
      "\tupdate model      : 16 MS, 29.53%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.10 ms\n",
      "[774] Time spent = 56.16 s\n",
      "774:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "774:grad_norm  [1000]: avg:   2.1704, min:   0.5198[ 577], max:   6.2472[ 989]\n",
      "774:loss       [1000]: avg:   0.6553, min:   0.2085[ 227], max:   1.0229[ 532]\n",
      "774:rl_loss    [1000]: avg:   0.1199, min:   0.0592[ 130], max:   0.3016[ 484]\n",
      "epoch 774, eval score: 6.8390, perfect: 0.10, model saved: False\n",
      "epoch 774, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  775\n",
      "available: 4.365 GB, used: 24.668 GB, free: 458.672 MB\n",
      "EPOCH: 775\n",
      "Speed: train: 1148.2, buffer_add: 285.7, buffer_size: 100042\n",
      "Total Time: 11H 59M 09S, 43149s\n",
      "Total Sample: train: 49.664M, buffer: 12.415M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.65%\n",
      "\tsample data       : 1 MS, 1.98%\n",
      "\tforward & backward: 36 MS, 64.92%\n",
      "\tupdate model      : 16 MS, 29.34%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.66 ms\n",
      "[775] Time spent = 55.74 s\n",
      "775:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "775:grad_norm  [1000]: avg:   2.1698, min:   0.5578[ 376], max:   6.6475[   3]\n",
      "775:loss       [1000]: avg:   0.6563, min:   0.2097[ 623], max:   1.0325[ 531]\n",
      "775:rl_loss    [1000]: avg:   0.1202, min:   0.0627[ 541], max:   0.3212[ 456]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 775, eval score: 6.8110, perfect: 0.00, model saved: False\n",
      "epoch 775, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  776\n",
      "available: 4.354 GB, used: 24.680 GB, free: 446.551 MB\n",
      "EPOCH: 776\n",
      "Speed: train: 1163.1, buffer_add: 288.0, buffer_size: 100034\n",
      "Total Time: 12H 00M 04S, 43204s\n",
      "Total Sample: train: 49.728M, buffer: 12.43M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.72%\n",
      "\tsample data       : 1 MS, 1.90%\n",
      "\tforward & backward: 35 MS, 64.72%\n",
      "\tupdate model      : 16 MS, 29.57%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 54.96 ms\n",
      "[776] Time spent = 55.03 s\n",
      "776:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "776:grad_norm  [1000]: avg:   2.2445, min:   0.6179[ 741], max:   5.8925[ 651]\n",
      "776:loss       [1000]: avg:   0.6515, min:   0.2111[ 741], max:   0.9978[ 580]\n",
      "776:rl_loss    [1000]: avg:   0.1203, min:   0.0619[ 347], max:   0.3718[ 791]\n",
      "epoch 776, eval score: 6.7960, perfect: 0.20, model saved: False\n",
      "epoch 776, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  777\n",
      "available: 4.366 GB, used: 24.668 GB, free: 458.648 MB\n",
      "EPOCH: 777\n",
      "Speed: train: 1155.0, buffer_add: 286.0, buffer_size: 100000\n",
      "Total Time: 12H 01M 00S, 43260s\n",
      "Total Sample: train: 49.792M, buffer: 12.446M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.78%\n",
      "\tsample data       : 0 MS, 1.67%\n",
      "\tforward & backward: 36 MS, 65.58%\n",
      "\tupdate model      : 15 MS, 28.86%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.34 ms\n",
      "[777] Time spent = 55.41 s\n",
      "777:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "777:grad_norm  [1000]: avg:   2.2079, min:   0.3799[ 902], max:   5.8768[ 594]\n",
      "777:loss       [1000]: avg:   0.6556, min:   0.1468[ 902], max:   1.0684[ 667]\n",
      "777:rl_loss    [1000]: avg:   0.1199, min:   0.0612[ 805], max:   0.3157[ 838]\n",
      "epoch 777, eval score: 6.9120, perfect: 0.10, model saved: False\n",
      "epoch 777, success rate for sampling ficticious state: 99.85%\n",
      "==========\n",
      "beginning of epoch:  778\n",
      "available: 4.367 GB, used: 24.666 GB, free: 459.469 MB\n",
      "EPOCH: 778\n",
      "Speed: train: 1147.0, buffer_add: 284.8, buffer_size: 100000\n",
      "Total Time: 12H 01M 56S, 43316s\n",
      "Total Sample: train: 49.856M, buffer: 12.462M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.76%\n",
      "\tsample data       : 0 MS, 1.79%\n",
      "\tforward & backward: 36 MS, 65.21%\n",
      "\tupdate model      : 16 MS, 29.15%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.74 ms\n",
      "[778] Time spent = 55.80 s\n",
      "778:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "778:grad_norm  [1000]: avg:   2.1649, min:   0.4918[ 469], max:   6.1381[ 671]\n",
      "778:loss       [1000]: avg:   0.6619, min:   0.2494[  35], max:   0.9605[ 690]\n",
      "778:rl_loss    [1000]: avg:   0.1188, min:   0.0569[  30], max:   0.3126[ 576]\n",
      "epoch 778, eval score: 6.8880, perfect: 0.00, model saved: False\n",
      "epoch 778, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  779\n",
      "available: 4.354 GB, used: 24.680 GB, free: 445.598 MB\n",
      "EPOCH: 779\n",
      "Speed: train: 1154.4, buffer_add: 288.2, buffer_size: 100004\n",
      "Total Time: 12H 02M 51S, 43371s\n",
      "Total Sample: train: 49.92M, buffer: 12.478M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.47%\n",
      "\tsample data       : 1 MS, 2.05%\n",
      "\tforward & backward: 35 MS, 65.01%\n",
      "\tupdate model      : 16 MS, 29.38%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.37 ms\n",
      "[779] Time spent = 55.44 s\n",
      "779:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "779:grad_norm  [1000]: avg:   2.2490, min:   0.8190[ 863], max:   5.5100[ 311]\n",
      "779:loss       [1000]: avg:   0.6677, min:   0.3428[ 144], max:   1.0083[ 982]\n",
      "779:rl_loss    [1000]: avg:   0.1192, min:   0.0552[ 251], max:   0.3121[ 413]\n",
      "epoch 779, eval score: 6.8240, perfect: 0.00, model saved: False\n",
      "epoch 779, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  780\n",
      "available: 4.361 GB, used: 24.672 GB, free: 453.320 MB\n",
      "EPOCH: 780\n",
      "Speed: train: 1146.8, buffer_add: 289.4, buffer_size: 100004\n",
      "Total Time: 12H 03M 47S, 43427s\n",
      "Total Sample: train: 49.984M, buffer: 12.494M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.58%\n",
      "\tsample data       : 1 MS, 2.02%\n",
      "\tforward & backward: 36 MS, 65.36%\n",
      "\tupdate model      : 16 MS, 28.94%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.74 ms\n",
      "[780] Time spent = 55.81 s\n",
      "780:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "780:grad_norm  [1000]: avg:   2.1978, min:   0.5591[   0], max:   5.2293[ 802]\n",
      "780:loss       [1000]: avg:   0.6637, min:   0.2314[ 713], max:   1.0423[ 284]\n",
      "780:rl_loss    [1000]: avg:   0.1229, min:   0.0588[ 879], max:   0.3112[ 965]\n",
      "epoch 780, eval score: 6.9660, perfect: 0.10, model saved: True\n",
      "epoch 780, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  781\n",
      "available: 4.362 GB, used: 24.671 GB, free: 454.082 MB\n",
      "EPOCH: 781\n",
      "Speed: train: 1155.8, buffer_add: 287.5, buffer_size: 100006\n",
      "Total Time: 12H 04M 42S, 43482s\n",
      "Total Sample: train: 50.048M, buffer: 12.51M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.78%\n",
      "\tsample data       : 1 MS, 1.84%\n",
      "\tforward & backward: 36 MS, 65.34%\n",
      "\tupdate model      : 16 MS, 28.95%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.29 ms\n",
      "[781] Time spent = 55.37 s\n",
      "781:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "781:grad_norm  [1000]: avg:   2.2528, min:   0.6805[ 682], max:   6.3911[ 906]\n",
      "781:loss       [1000]: avg:   0.6620, min:   0.2398[ 444], max:   0.9687[ 354]\n",
      "781:rl_loss    [1000]: avg:   0.1198, min:   0.0465[ 457], max:   0.3011[ 320]\n",
      "epoch 781, eval score: 6.9700, perfect: 0.00, model saved: True\n",
      "epoch 781, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  782\n",
      "available: 4.371 GB, used: 24.662 GB, free: 463.422 MB\n",
      "EPOCH: 782\n",
      "Speed: train: 1144.9, buffer_add: 286.8, buffer_size: 100005\n",
      "Total Time: 12H 05M 38S, 43538s\n",
      "Total Sample: train: 50.112M, buffer: 12.526M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.62%\n",
      "\tsample data       : 1 MS, 2.03%\n",
      "\tforward & backward: 36 MS, 65.11%\n",
      "\tupdate model      : 16 MS, 29.14%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.82 ms\n",
      "[782] Time spent = 55.90 s\n",
      "782:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "782:grad_norm  [1000]: avg:   2.2532, min:   0.7914[ 298], max:   5.6950[ 739]\n",
      "782:loss       [1000]: avg:   0.6467, min:   0.2985[ 279], max:   0.9975[ 255]\n",
      "782:rl_loss    [1000]: avg:   0.1175, min:   0.0612[ 651], max:   0.2862[ 587]\n",
      "epoch 782, eval score: 6.7920, perfect: 0.00, model saved: False\n",
      "epoch 782, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  783\n",
      "available: 4.368 GB, used: 24.665 GB, free: 459.715 MB\n",
      "EPOCH: 783\n",
      "Speed: train: 1148.3, buffer_add: 288.2, buffer_size: 100000\n",
      "Total Time: 12H 06M 34S, 43594s\n",
      "Total Sample: train: 50.176M, buffer: 12.542M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.75%\n",
      "\tsample data       : 1 MS, 1.88%\n",
      "\tforward & backward: 36 MS, 65.01%\n",
      "\tupdate model      : 16 MS, 29.26%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.67 ms\n",
      "[783] Time spent = 55.74 s\n",
      "783:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "783:grad_norm  [1000]: avg:   2.2735, min:   0.6447[ 185], max:   6.6293[ 293]\n",
      "783:loss       [1000]: avg:   0.6491, min:   0.2133[ 671], max:   0.9727[ 568]\n",
      "783:rl_loss    [1000]: avg:   0.1150, min:   0.0469[ 917], max:   0.2934[ 241]\n",
      "epoch 783, eval score: 6.8520, perfect: 0.10, model saved: False\n",
      "epoch 783, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  784\n",
      "available: 4.358 GB, used: 24.675 GB, free: 449.840 MB\n",
      "EPOCH: 784\n",
      "Speed: train: 1155.3, buffer_add: 286.2, buffer_size: 100012\n",
      "Total Time: 12H 07M 29S, 43649s\n",
      "Total Sample: train: 50.24M, buffer: 12.558M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.46%\n",
      "\tsample data       : 0 MS, 1.66%\n",
      "\tforward & backward: 36 MS, 65.43%\n",
      "\tupdate model      : 16 MS, 29.35%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.32 ms\n",
      "[784] Time spent = 55.40 s\n",
      "784:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "784:grad_norm  [1000]: avg:   2.0759, min:   0.3417[ 199], max:   5.8715[ 847]\n",
      "784:loss       [1000]: avg:   0.6456, min:   0.1229[ 199], max:   1.0606[ 437]\n",
      "784:rl_loss    [1000]: avg:   0.1153, min:   0.0535[ 517], max:   0.3993[ 838]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 784, eval score: 6.8040, perfect: 0.20, model saved: False\n",
      "epoch 784, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  785\n",
      "available: 4.359 GB, used: 24.674 GB, free: 450.801 MB\n",
      "EPOCH: 785\n",
      "Speed: train: 1155.3, buffer_add: 285.5, buffer_size: 100000\n",
      "Total Time: 12H 08M 25S, 43705s\n",
      "Total Sample: train: 50.304M, buffer: 12.574M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.99%\n",
      "\tsample data       : 1 MS, 1.92%\n",
      "\tforward & backward: 35 MS, 64.88%\n",
      "\tupdate model      : 16 MS, 29.10%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.33 ms\n",
      "[785] Time spent = 55.40 s\n",
      "785:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "785:grad_norm  [1000]: avg:   2.2088, min:   0.6259[ 224], max:   5.8737[ 616]\n",
      "785:loss       [1000]: avg:   0.6480, min:   0.2308[ 441], max:   0.9631[ 461]\n",
      "785:rl_loss    [1000]: avg:   0.1146, min:   0.0579[ 197], max:   0.2439[ 834]\n",
      "epoch 785, eval score: 6.8860, perfect: 0.10, model saved: False\n",
      "epoch 785, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  786\n",
      "available: 4.358 GB, used: 24.675 GB, free: 449.258 MB\n",
      "EPOCH: 786\n",
      "Speed: train: 1145.5, buffer_add: 286.8, buffer_size: 100006\n",
      "Total Time: 12H 09M 20S, 43760s\n",
      "Total Sample: train: 50.368M, buffer: 12.59M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.87%\n",
      "\tsample data       : 1 MS, 2.00%\n",
      "\tforward & backward: 36 MS, 64.93%\n",
      "\tupdate model      : 16 MS, 29.12%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.80 ms\n",
      "[786] Time spent = 55.87 s\n",
      "786:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "786:grad_norm  [1000]: avg:   2.1732, min:   0.6991[ 954], max:   7.6904[ 666]\n",
      "786:loss       [1000]: avg:   0.6508, min:   0.2475[ 996], max:   0.9942[ 586]\n",
      "786:rl_loss    [1000]: avg:   0.1164, min:   0.0552[ 314], max:   0.2834[ 780]\n",
      "epoch 786, eval score: 6.8190, perfect: 0.10, model saved: False\n",
      "epoch 786, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  787\n",
      "available: 4.351 GB, used: 24.682 GB, free: 442.000 MB\n",
      "EPOCH: 787\n",
      "Speed: train: 1176.3, buffer_add: 286.5, buffer_size: 100011\n",
      "Total Time: 12H 10M 15S, 43815s\n",
      "Total Sample: train: 50.432M, buffer: 12.606M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.83%\n",
      "\tsample data       : 0 MS, 1.78%\n",
      "\tforward & backward: 35 MS, 64.72%\n",
      "\tupdate model      : 16 MS, 29.55%\n",
      "\tupdating priority : 0 MS, 0.12%\n",
      "@@@total time per iter: 54.33 ms\n",
      "[787] Time spent = 54.41 s\n",
      "787:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "787:grad_norm  [1000]: avg:   2.1177, min:   0.7057[ 522], max:   7.2988[ 962]\n",
      "787:loss       [1000]: avg:   0.6473, min:   0.2806[ 522], max:   0.9926[ 457]\n",
      "787:rl_loss    [1000]: avg:   0.1163, min:   0.0556[ 566], max:   0.2914[ 153]\n",
      "epoch 787, eval score: 6.8440, perfect: 0.10, model saved: False\n",
      "epoch 787, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  788\n",
      "available: 4.365 GB, used: 24.668 GB, free: 457.039 MB\n",
      "EPOCH: 788\n",
      "Speed: train: 1145.2, buffer_add: 286.9, buffer_size: 100030\n",
      "Total Time: 12H 11M 11S, 43871s\n",
      "Total Sample: train: 50.496M, buffer: 12.622M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.98%\n",
      "\tsample data       : 1 MS, 1.94%\n",
      "\tforward & backward: 35 MS, 64.40%\n",
      "\tupdate model      : 16 MS, 29.57%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.80 ms\n",
      "[788] Time spent = 55.89 s\n",
      "788:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "788:grad_norm  [1000]: avg:   2.1254, min:   0.7162[ 638], max:   5.7550[ 475]\n",
      "788:loss       [1000]: avg:   0.6519, min:   0.2089[ 692], max:   0.9854[ 382]\n",
      "788:rl_loss    [1000]: avg:   0.1152, min:   0.0526[ 340], max:   0.3163[  36]\n",
      "epoch 788, eval score: 6.7420, perfect: 0.00, model saved: False\n",
      "epoch 788, success rate for sampling ficticious state: 99.85%\n",
      "==========\n",
      "beginning of epoch:  789\n",
      "available: 4.365 GB, used: 24.668 GB, free: 456.867 MB\n",
      "EPOCH: 789\n",
      "Speed: train: 1172.2, buffer_add: 284.5, buffer_size: 100000\n",
      "Total Time: 12H 12M 05S, 43925s\n",
      "Total Sample: train: 50.56M, buffer: 12.637M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.74%\n",
      "\tsample data       : 0 MS, 1.80%\n",
      "\tforward & backward: 35 MS, 64.92%\n",
      "\tupdate model      : 16 MS, 29.42%\n",
      "\tupdating priority : 0 MS, 0.12%\n",
      "@@@total time per iter: 54.52 ms\n",
      "[789] Time spent = 54.60 s\n",
      "789:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "789:grad_norm  [1000]: avg:   2.2325, min:   0.6430[ 484], max:   5.1837[ 732]\n",
      "789:loss       [1000]: avg:   0.6553, min:   0.3179[ 454], max:   0.9358[ 934]\n",
      "789:rl_loss    [1000]: avg:   0.1160, min:   0.0604[ 467], max:   0.2777[ 857]\n",
      "epoch 789, eval score: 6.8760, perfect: 0.00, model saved: False\n",
      "epoch 789, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  790\n",
      "available: 4.365 GB, used: 24.669 GB, free: 456.152 MB\n",
      "EPOCH: 790\n",
      "Speed: train: 1156.3, buffer_add: 283.9, buffer_size: 100036\n",
      "Total Time: 12H 13M 01S, 43981s\n",
      "Total Sample: train: 50.624M, buffer: 12.653M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.92%\n",
      "\tsample data       : 1 MS, 1.92%\n",
      "\tforward & backward: 36 MS, 65.42%\n",
      "\tupdate model      : 15 MS, 28.64%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.28 ms\n",
      "[790] Time spent = 55.35 s\n",
      "790:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "790:grad_norm  [1000]: avg:   2.1555, min:   0.6940[  15], max:   5.8610[ 394]\n",
      "790:loss       [1000]: avg:   0.6504, min:   0.2108[ 497], max:   1.0356[ 649]\n",
      "790:rl_loss    [1000]: avg:   0.1143, min:   0.0570[ 715], max:   0.2971[ 162]\n",
      "epoch 790, eval score: 6.8240, perfect: 0.00, model saved: False\n",
      "epoch 790, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  791\n",
      "available: 4.344 GB, used: 24.689 GB, free: 434.547 MB\n",
      "EPOCH: 791\n",
      "Speed: train: 1154.6, buffer_add: 285.3, buffer_size: 100032\n",
      "Total Time: 12H 13M 56S, 44036s\n",
      "Total Sample: train: 50.688M, buffer: 12.669M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.76%\n",
      "\tsample data       : 0 MS, 1.67%\n",
      "\tforward & backward: 36 MS, 65.41%\n",
      "\tupdate model      : 16 MS, 29.06%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.37 ms\n",
      "[791] Time spent = 55.43 s\n",
      "791:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "791:grad_norm  [1000]: avg:   2.2000, min:   0.5735[ 773], max:   5.5936[ 915]\n",
      "791:loss       [1000]: avg:   0.6515, min:   0.2024[ 217], max:   0.9621[ 261]\n",
      "791:rl_loss    [1000]: avg:   0.1151, min:   0.0556[ 272], max:   0.2950[ 658]\n",
      "epoch 791, eval score: 6.9080, perfect: 0.10, model saved: False\n",
      "epoch 791, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  792\n",
      "available: 4.352 GB, used: 24.681 GB, free: 442.859 MB\n",
      "EPOCH: 792\n",
      "Speed: train: 1146.6, buffer_add: 287.5, buffer_size: 100017\n",
      "Total Time: 12H 14M 52S, 44092s\n",
      "Total Sample: train: 50.752M, buffer: 12.685M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.14%\n",
      "\tsample data       : 1 MS, 2.02%\n",
      "\tforward & backward: 36 MS, 64.87%\n",
      "\tupdate model      : 16 MS, 28.88%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.72 ms\n",
      "[792] Time spent = 55.82 s\n",
      "792:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "792:grad_norm  [1000]: avg:   2.2818, min:   0.8293[ 999], max:   6.3851[  98]\n",
      "792:loss       [1000]: avg:   0.6521, min:   0.2623[ 907], max:   1.0109[  45]\n",
      "792:rl_loss    [1000]: avg:   0.1176, min:   0.0595[ 208], max:   0.2672[ 642]\n",
      "epoch 792, eval score: 6.7940, perfect: 0.00, model saved: False\n",
      "epoch 792, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  793\n",
      "available: 4.366 GB, used: 24.667 GB, free: 457.195 MB\n",
      "EPOCH: 793\n",
      "Speed: train: 1152.8, buffer_add: 285.3, buffer_size: 100000\n",
      "Total Time: 12H 15M 47S, 44147s\n",
      "Total Sample: train: 50.816M, buffer: 12.701M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.89%\n",
      "\tsample data       : 1 MS, 2.14%\n",
      "\tforward & backward: 36 MS, 65.31%\n",
      "\tupdate model      : 15 MS, 28.56%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.45 ms\n",
      "[793] Time spent = 55.52 s\n",
      "793:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "793:grad_norm  [1000]: avg:   2.1355, min:   0.3548[ 879], max:   5.8737[  22]\n",
      "793:loss       [1000]: avg:   0.6484, min:   0.1897[ 879], max:   1.0285[ 686]\n",
      "793:rl_loss    [1000]: avg:   0.1141, min:   0.0583[  66], max:   0.3054[ 476]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 793, eval score: 6.9190, perfect: 0.00, model saved: False\n",
      "epoch 793, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  794\n",
      "available: 4.366 GB, used: 24.667 GB, free: 456.625 MB\n",
      "EPOCH: 794\n",
      "Speed: train: 1164.7, buffer_add: 283.9, buffer_size: 100024\n",
      "Total Time: 12H 16M 42S, 44202s\n",
      "Total Sample: train: 50.88M, buffer: 12.716M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.80%\n",
      "\tsample data       : 1 MS, 1.84%\n",
      "\tforward & backward: 35 MS, 65.53%\n",
      "\tupdate model      : 15 MS, 28.71%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 54.88 ms\n",
      "[794] Time spent = 54.95 s\n",
      "794:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "794:grad_norm  [1000]: avg:   2.2154, min:   0.4813[ 642], max:   6.0102[ 411]\n",
      "794:loss       [1000]: avg:   0.6538, min:   0.1097[ 642], max:   0.9706[ 954]\n",
      "794:rl_loss    [1000]: avg:   0.1164, min:   0.0584[ 931], max:   0.3084[ 989]\n",
      "epoch 794, eval score: 6.8400, perfect: 0.00, model saved: False\n",
      "epoch 794, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  795\n",
      "available: 4.359 GB, used: 24.674 GB, free: 449.227 MB\n",
      "EPOCH: 795\n",
      "Speed: train: 1154.1, buffer_add: 284.4, buffer_size: 100026\n",
      "Total Time: 12H 17M 38S, 44258s\n",
      "Total Sample: train: 50.944M, buffer: 12.732M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.01%\n",
      "\tsample data       : 1 MS, 1.88%\n",
      "\tforward & backward: 35 MS, 64.74%\n",
      "\tupdate model      : 16 MS, 29.28%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.38 ms\n",
      "[795] Time spent = 55.46 s\n",
      "795:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "795:grad_norm  [1000]: avg:   2.2694, min:   0.6517[ 372], max:   8.1662[ 732]\n",
      "795:loss       [1000]: avg:   0.6421, min:   0.1106[ 372], max:   0.9882[   2]\n",
      "795:rl_loss    [1000]: avg:   0.1161, min:   0.0574[ 211], max:   0.2918[ 466]\n",
      "epoch 795, eval score: 6.7710, perfect: 0.10, model saved: False\n",
      "epoch 795, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  796\n",
      "available: 4.355 GB, used: 24.678 GB, free: 445.070 MB\n",
      "EPOCH: 796\n",
      "Speed: train: 1163.0, buffer_add: 285.8, buffer_size: 100010\n",
      "Total Time: 12H 18M 33S, 44313s\n",
      "Total Sample: train: 51.008M, buffer: 12.748M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.77%\n",
      "\tsample data       : 0 MS, 1.78%\n",
      "\tforward & backward: 35 MS, 65.47%\n",
      "\tupdate model      : 15 MS, 28.87%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 54.96 ms\n",
      "[796] Time spent = 55.03 s\n",
      "796:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "796:grad_norm  [1000]: avg:   2.2040, min:   0.7331[ 338], max:   7.8240[ 910]\n",
      "796:loss       [1000]: avg:   0.6469, min:   0.1596[ 401], max:   0.9721[  90]\n",
      "796:rl_loss    [1000]: avg:   0.1180, min:   0.0632[ 492], max:   0.2977[  82]\n",
      "epoch 796, eval score: 6.8470, perfect: 0.00, model saved: False\n",
      "epoch 796, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  797\n",
      "available: 4.365 GB, used: 24.669 GB, free: 455.039 MB\n",
      "EPOCH: 797\n",
      "Speed: train: 1153.6, buffer_add: 287.2, buffer_size: 100000\n",
      "Total Time: 12H 19M 28S, 44368s\n",
      "Total Sample: train: 51.072M, buffer: 12.764M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.76%\n",
      "\tsample data       : 1 MS, 1.96%\n",
      "\tforward & backward: 36 MS, 65.07%\n",
      "\tupdate model      : 16 MS, 29.11%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.39 ms\n",
      "[797] Time spent = 55.48 s\n",
      "797:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "797:grad_norm  [1000]: avg:   2.2192, min:   0.6629[ 382], max:   5.8723[ 553]\n",
      "797:loss       [1000]: avg:   0.6406, min:   0.2345[ 382], max:   0.9748[   6]\n",
      "797:rl_loss    [1000]: avg:   0.1197, min:   0.0598[ 705], max:   0.4284[ 880]\n",
      "epoch 797, eval score: 6.8950, perfect: 0.00, model saved: False\n",
      "epoch 797, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  798\n",
      "available: 4.353 GB, used: 24.681 GB, free: 442.785 MB\n",
      "EPOCH: 798\n",
      "Speed: train: 1143.8, buffer_add: 286.3, buffer_size: 100038\n",
      "Total Time: 12H 20M 24S, 44424s\n",
      "Total Sample: train: 51.136M, buffer: 12.78M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.79%\n",
      "\tsample data       : 0 MS, 1.76%\n",
      "\tforward & backward: 36 MS, 64.98%\n",
      "\tupdate model      : 16 MS, 29.38%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.89 ms\n",
      "[798] Time spent = 55.96 s\n",
      "798:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "798:grad_norm  [1000]: avg:   2.2153, min:   0.3313[ 608], max:   6.1415[ 120]\n",
      "798:loss       [1000]: avg:   0.6414, min:   0.0574[ 608], max:   1.0195[  88]\n",
      "798:rl_loss    [1000]: avg:   0.1150, min:   0.0547[  71], max:   0.3175[ 486]\n",
      "epoch 798, eval score: 6.8990, perfect: 0.10, model saved: False\n",
      "epoch 798, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  799\n",
      "available: 4.362 GB, used: 24.671 GB, free: 452.863 MB\n",
      "EPOCH: 799\n",
      "Speed: train: 1160.2, buffer_add: 280.5, buffer_size: 100010\n",
      "Total Time: 12H 21M 20S, 44480s\n",
      "Total Sample: train: 51.2M, buffer: 12.795M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.98%\n",
      "\tsample data       : 1 MS, 1.85%\n",
      "\tforward & backward: 36 MS, 65.64%\n",
      "\tupdate model      : 15 MS, 28.44%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.09 ms\n",
      "[799] Time spent = 55.17 s\n",
      "799:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "799:grad_norm  [1000]: avg:   2.1872, min:   0.7022[ 352], max:   6.1948[ 375]\n",
      "799:loss       [1000]: avg:   0.6381, min:   0.2330[ 987], max:   0.9814[ 347]\n",
      "799:rl_loss    [1000]: avg:   0.1152, min:   0.0635[ 672], max:   0.2799[  30]\n",
      "epoch 799, eval score: 6.8790, perfect: 0.10, model saved: False\n",
      "epoch 799, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  800\n",
      "available: 4.362 GB, used: 24.671 GB, free: 452.828 MB\n",
      "EPOCH: 800\n",
      "Speed: train: 1147.4, buffer_add: 286.7, buffer_size: 100000\n",
      "Total Time: 12H 22M 15S, 44535s\n",
      "Total Sample: train: 51.264M, buffer: 12.811M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.87%\n",
      "\tsample data       : 1 MS, 2.26%\n",
      "\tforward & backward: 36 MS, 64.85%\n",
      "\tupdate model      : 16 MS, 28.93%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.69 ms\n",
      "[800] Time spent = 55.77 s\n",
      "800:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "800:grad_norm  [1000]: avg:   2.2369, min:   0.6406[ 678], max:   7.2644[  64]\n",
      "800:loss       [1000]: avg:   0.6409, min:   0.2994[ 589], max:   1.0127[ 623]\n",
      "800:rl_loss    [1000]: avg:   0.1145, min:   0.0552[  77], max:   0.2898[ 190]\n",
      "epoch 800, eval score: 6.8520, perfect: 0.20, model saved: False\n",
      "epoch 800, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  801\n",
      "available: 4.354 GB, used: 24.680 GB, free: 438.875 MB\n",
      "EPOCH: 801\n",
      "Speed: train: 1140.6, buffer_add: 289.1, buffer_size: 100006\n",
      "Total Time: 12H 23M 11S, 44591s\n",
      "Total Sample: train: 51.328M, buffer: 12.827M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.82%\n",
      "\tsample data       : 1 MS, 1.98%\n",
      "\tforward & backward: 36 MS, 65.01%\n",
      "\tupdate model      : 16 MS, 29.08%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 56.05 ms\n",
      "[801] Time spent = 56.11 s\n",
      "801:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "801:grad_norm  [1000]: avg:   2.2152, min:   0.6071[ 328], max:   6.7804[ 688]\n",
      "801:loss       [1000]: avg:   0.6325, min:   0.2691[ 328], max:   0.9260[ 292]\n",
      "801:rl_loss    [1000]: avg:   0.1127, min:   0.0583[ 611], max:   0.3193[ 154]\n",
      "epoch 801, eval score: 6.8140, perfect: 0.00, model saved: False\n",
      "epoch 801, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  802\n",
      "available: 4.359 GB, used: 24.675 GB, free: 443.922 MB\n",
      "EPOCH: 802\n",
      "Speed: train: 1141.4, buffer_add: 285.0, buffer_size: 100014\n",
      "Total Time: 12H 24M 07S, 44647s\n",
      "Total Sample: train: 51.392M, buffer: 12.843M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.86%\n",
      "\tsample data       : 1 MS, 2.00%\n",
      "\tforward & backward: 36 MS, 65.25%\n",
      "\tupdate model      : 16 MS, 28.76%\n",
      "\tupdating priority : 0 MS, 0.12%\n",
      "@@@total time per iter: 56.01 ms\n",
      "[802] Time spent = 56.07 s\n",
      "802:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "802:grad_norm  [1000]: avg:   2.1990, min:   0.7059[ 767], max:   6.5060[ 631]\n",
      "802:loss       [1000]: avg:   0.6392, min:   0.3098[ 440], max:   0.9276[  82]\n",
      "802:rl_loss    [1000]: avg:   0.1126, min:   0.0609[ 161], max:   0.2542[ 622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 802, eval score: 6.9310, perfect: 0.00, model saved: False\n",
      "epoch 802, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  803\n",
      "available: 4.363 GB, used: 24.670 GB, free: 448.645 MB\n",
      "EPOCH: 803\n",
      "Speed: train: 1158.2, buffer_add: 287.6, buffer_size: 100013\n",
      "Total Time: 12H 25M 03S, 44703s\n",
      "Total Sample: train: 51.456M, buffer: 12.859M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.78%\n",
      "\tsample data       : 1 MS, 1.93%\n",
      "\tforward & backward: 36 MS, 65.51%\n",
      "\tupdate model      : 15 MS, 28.67%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.19 ms\n",
      "[803] Time spent = 55.26 s\n",
      "803:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "803:grad_norm  [1000]: avg:   2.1385, min:   0.5314[ 816], max:   6.1821[ 177]\n",
      "803:loss       [1000]: avg:   0.6375, min:   0.3283[ 816], max:   0.9421[ 918]\n",
      "803:rl_loss    [1000]: avg:   0.1112, min:   0.0558[ 423], max:   0.2887[ 659]\n",
      "epoch 803, eval score: 6.9140, perfect: 0.10, model saved: False\n",
      "epoch 803, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  804\n",
      "available: 4.367 GB, used: 24.666 GB, free: 452.383 MB\n",
      "EPOCH: 804\n",
      "Speed: train: 1165.5, buffer_add: 287.4, buffer_size: 100024\n",
      "Total Time: 12H 25M 58S, 44758s\n",
      "Total Sample: train: 51.52M, buffer: 12.875M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.94%\n",
      "\tsample data       : 0 MS, 1.81%\n",
      "\tforward & backward: 35 MS, 65.58%\n",
      "\tupdate model      : 15 MS, 28.58%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 54.84 ms\n",
      "[804] Time spent = 54.91 s\n",
      "804:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "804:grad_norm  [1000]: avg:   2.1615, min:   0.4344[ 700], max:   6.0006[ 434]\n",
      "804:loss       [1000]: avg:   0.6371, min:   0.1935[ 700], max:   1.0665[ 270]\n",
      "804:rl_loss    [1000]: avg:   0.1126, min:   0.0572[ 628], max:   0.2927[ 991]\n",
      "epoch 804, eval score: 6.8630, perfect: 0.10, model saved: False\n",
      "epoch 804, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  805\n",
      "available: 4.364 GB, used: 24.670 GB, free: 448.719 MB\n",
      "EPOCH: 805\n",
      "Speed: train: 1156.0, buffer_add: 283.8, buffer_size: 100002\n",
      "Total Time: 12H 26M 53S, 44813s\n",
      "Total Sample: train: 51.584M, buffer: 12.891M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.71%\n",
      "\tsample data       : 1 MS, 2.09%\n",
      "\tforward & backward: 36 MS, 65.21%\n",
      "\tupdate model      : 15 MS, 28.89%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.29 ms\n",
      "[805] Time spent = 55.37 s\n",
      "805:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "805:grad_norm  [1000]: avg:   2.1630, min:   0.6017[ 428], max:   5.9506[ 515]\n",
      "805:loss       [1000]: avg:   0.6345, min:   0.3327[ 111], max:   0.9506[ 329]\n",
      "805:rl_loss    [1000]: avg:   0.1120, min:   0.0545[  65], max:   0.2926[ 263]\n",
      "epoch 805, eval score: 6.8160, perfect: 0.10, model saved: False\n",
      "epoch 805, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  806\n",
      "available: 4.361 GB, used: 24.672 GB, free: 446.395 MB\n",
      "EPOCH: 806\n",
      "Speed: train: 1156.8, buffer_add: 287.8, buffer_size: 100022\n",
      "Total Time: 12H 27M 48S, 44868s\n",
      "Total Sample: train: 51.648M, buffer: 12.907M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.91%\n",
      "\tsample data       : 1 MS, 1.83%\n",
      "\tforward & backward: 35 MS, 64.92%\n",
      "\tupdate model      : 16 MS, 29.25%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.24 ms\n",
      "[806] Time spent = 55.32 s\n",
      "806:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "806:grad_norm  [1000]: avg:   2.1485, min:   0.7213[ 785], max:   6.0332[ 378]\n",
      "806:loss       [1000]: avg:   0.6452, min:   0.3073[ 451], max:   0.9940[ 564]\n",
      "806:rl_loss    [1000]: avg:   0.1163, min:   0.0583[ 687], max:   0.3027[ 623]\n",
      "epoch 806, eval score: 6.8960, perfect: 0.10, model saved: False\n",
      "epoch 806, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  807\n",
      "available: 4.356 GB, used: 24.677 GB, free: 441.082 MB\n",
      "EPOCH: 807\n",
      "Speed: train: 1138.2, buffer_add: 289.7, buffer_size: 100010\n",
      "Total Time: 12H 28M 45S, 44925s\n",
      "Total Sample: train: 51.712M, buffer: 12.923M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.78%\n",
      "\tsample data       : 0 MS, 1.76%\n",
      "\tforward & backward: 36 MS, 64.36%\n",
      "\tupdate model      : 16 MS, 30.00%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 56.17 ms\n",
      "[807] Time spent = 56.23 s\n",
      "807:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "807:grad_norm  [1000]: avg:   2.0886, min:   0.6847[  32], max:   5.2107[ 630]\n",
      "807:loss       [1000]: avg:   0.6416, min:   0.2683[ 419], max:   0.9195[  79]\n",
      "807:rl_loss    [1000]: avg:   0.1132, min:   0.0593[ 642], max:   0.3147[ 624]\n",
      "epoch 807, eval score: 6.8910, perfect: 0.00, model saved: False\n",
      "epoch 807, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  808\n",
      "available: 4.366 GB, used: 24.668 GB, free: 450.453 MB\n",
      "EPOCH: 808\n",
      "Speed: train: 1161.4, buffer_add: 287.2, buffer_size: 100009\n",
      "Total Time: 12H 29M 40S, 44980s\n",
      "Total Sample: train: 51.776M, buffer: 12.939M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.88%\n",
      "\tsample data       : 1 MS, 1.92%\n",
      "\tforward & backward: 35 MS, 65.06%\n",
      "\tupdate model      : 15 MS, 29.04%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.04 ms\n",
      "[808] Time spent = 55.11 s\n",
      "808:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "808:grad_norm  [1000]: avg:   2.1002, min:   0.5307[ 850], max:   5.7933[  41]\n",
      "808:loss       [1000]: avg:   0.6374, min:   0.2070[ 850], max:   1.0213[ 811]\n",
      "808:rl_loss    [1000]: avg:   0.1160, min:   0.0609[ 941], max:   0.2916[ 846]\n",
      "epoch 808, eval score: 6.9890, perfect: 0.20, model saved: True\n",
      "epoch 808, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  809\n",
      "available: 4.367 GB, used: 24.667 GB, free: 451.641 MB\n",
      "EPOCH: 809\n",
      "Speed: train: 1149.7, buffer_add: 288.3, buffer_size: 100009\n",
      "Total Time: 12H 30M 35S, 45035s\n",
      "Total Sample: train: 51.84M, buffer: 12.955M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.87%\n",
      "\tsample data       : 1 MS, 1.95%\n",
      "\tforward & backward: 35 MS, 64.48%\n",
      "\tupdate model      : 16 MS, 29.59%\n",
      "\tupdating priority : 0 MS, 0.12%\n",
      "@@@total time per iter: 55.60 ms\n",
      "[809] Time spent = 55.67 s\n",
      "809:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "809:grad_norm  [1000]: avg:   2.1756, min:   0.5690[ 275], max:   6.2142[ 817]\n",
      "809:loss       [1000]: avg:   0.6439, min:   0.2457[ 275], max:   0.9364[ 439]\n",
      "809:rl_loss    [1000]: avg:   0.1161, min:   0.0562[ 235], max:   0.2795[ 249]\n",
      "epoch 809, eval score: 6.7970, perfect: 0.10, model saved: False\n",
      "epoch 809, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  810\n",
      "available: 4.360 GB, used: 24.673 GB, free: 444.309 MB\n",
      "EPOCH: 810\n",
      "Speed: train: 1151.0, buffer_add: 288.4, buffer_size: 100004\n",
      "Total Time: 12H 31M 31S, 45091s\n",
      "Total Sample: train: 51.904M, buffer: 12.971M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.81%\n",
      "\tsample data       : 1 MS, 1.89%\n",
      "\tforward & backward: 36 MS, 65.24%\n",
      "\tupdate model      : 16 MS, 28.96%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.54 ms\n",
      "[810] Time spent = 55.61 s\n",
      "810:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "810:grad_norm  [1000]: avg:   2.1216, min:   0.3630[ 348], max:   5.1883[ 504]\n",
      "810:loss       [1000]: avg:   0.6469, min:   0.1735[ 348], max:   0.9855[ 981]\n",
      "810:rl_loss    [1000]: avg:   0.1171, min:   0.0570[ 435], max:   0.2761[ 261]\n",
      "epoch 810, eval score: 6.7570, perfect: 0.20, model saved: False\n",
      "epoch 810, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  811\n",
      "available: 4.367 GB, used: 24.667 GB, free: 451.262 MB\n",
      "EPOCH: 811\n",
      "Speed: train: 1167.0, buffer_add: 283.9, buffer_size: 100012\n",
      "Total Time: 12H 32M 26S, 45146s\n",
      "Total Sample: train: 51.968M, buffer: 12.986M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.86%\n",
      "\tsample data       : 1 MS, 1.89%\n",
      "\tforward & backward: 36 MS, 65.78%\n",
      "\tupdate model      : 15 MS, 28.38%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 54.76 ms\n",
      "[811] Time spent = 54.84 s\n",
      "811:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "811:grad_norm  [1000]: avg:   2.1306, min:   0.7128[ 209], max:   5.8383[ 176]\n",
      "811:loss       [1000]: avg:   0.6452, min:   0.2237[ 209], max:   0.9605[ 607]\n",
      "811:rl_loss    [1000]: avg:   0.1177, min:   0.0657[ 960], max:   0.3462[ 128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 811, eval score: 6.7800, perfect: 0.00, model saved: False\n",
      "epoch 811, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  812\n",
      "available: 4.361 GB, used: 24.672 GB, free: 445.719 MB\n",
      "EPOCH: 812\n",
      "Speed: train: 1160.0, buffer_add: 286.6, buffer_size: 100006\n",
      "Total Time: 12H 33M 21S, 45201s\n",
      "Total Sample: train: 52.032M, buffer: 13.002M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.05%\n",
      "\tsample data       : 1 MS, 1.92%\n",
      "\tforward & backward: 35 MS, 64.90%\n",
      "\tupdate model      : 15 MS, 29.02%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.10 ms\n",
      "[812] Time spent = 55.17 s\n",
      "812:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "812:grad_norm  [1000]: avg:   2.1974, min:   0.6271[ 146], max:   7.2613[ 580]\n",
      "812:loss       [1000]: avg:   0.6512, min:   0.2743[ 146], max:   0.9673[ 941]\n",
      "812:rl_loss    [1000]: avg:   0.1150, min:   0.0559[ 181], max:   0.3193[ 446]\n",
      "epoch 812, eval score: 6.8050, perfect: 0.10, model saved: False\n",
      "epoch 812, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  813\n",
      "available: 4.361 GB, used: 24.673 GB, free: 444.945 MB\n",
      "EPOCH: 813\n",
      "Speed: train: 1141.5, buffer_add: 286.8, buffer_size: 100034\n",
      "Total Time: 12H 34M 17S, 45257s\n",
      "Total Sample: train: 52.096M, buffer: 13.018M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.72%\n",
      "\tsample data       : 1 MS, 1.89%\n",
      "\tforward & backward: 36 MS, 65.76%\n",
      "\tupdate model      : 15 MS, 28.53%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.99 ms\n",
      "[813] Time spent = 56.07 s\n",
      "813:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "813:grad_norm  [1000]: avg:   2.2060, min:   0.8042[ 853], max:   5.2062[ 870]\n",
      "813:loss       [1000]: avg:   0.6576, min:   0.3453[ 807], max:   0.9917[ 111]\n",
      "813:rl_loss    [1000]: avg:   0.1170, min:   0.0600[ 706], max:   0.3146[ 749]\n",
      "epoch 813, eval score: 6.7360, perfect: 0.00, model saved: False\n",
      "epoch 813, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  814\n",
      "available: 4.359 GB, used: 24.674 GB, free: 443.461 MB\n",
      "EPOCH: 814\n",
      "Speed: train: 1163.9, buffer_add: 286.7, buffer_size: 100007\n",
      "Total Time: 12H 35M 12S, 45312s\n",
      "Total Sample: train: 52.16M, buffer: 13.034M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.62%\n",
      "\tsample data       : 1 MS, 1.98%\n",
      "\tforward & backward: 36 MS, 65.70%\n",
      "\tupdate model      : 15 MS, 28.61%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 54.91 ms\n",
      "[814] Time spent = 54.99 s\n",
      "814:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "814:grad_norm  [1000]: avg:   2.1614, min:   0.6740[ 663], max:   5.4350[  88]\n",
      "814:loss       [1000]: avg:   0.6515, min:   0.2204[ 909], max:   1.0563[ 930]\n",
      "814:rl_loss    [1000]: avg:   0.1155, min:   0.0469[ 158], max:   0.2810[ 554]\n",
      "epoch 814, eval score: 6.8090, perfect: 0.10, model saved: False\n",
      "epoch 814, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  815\n",
      "available: 4.346 GB, used: 24.688 GB, free: 428.734 MB\n",
      "EPOCH: 815\n",
      "Speed: train: 1173.1, buffer_add: 282.9, buffer_size: 100024\n",
      "Total Time: 12H 36M 07S, 45367s\n",
      "Total Sample: train: 52.224M, buffer: 13.049M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.71%\n",
      "\tsample data       : 0 MS, 1.81%\n",
      "\tforward & backward: 35 MS, 65.13%\n",
      "\tupdate model      : 15 MS, 29.25%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 54.49 ms\n",
      "[815] Time spent = 54.56 s\n",
      "815:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "815:grad_norm  [1000]: avg:   2.3099, min:   0.6540[ 863], max:   5.5401[ 472]\n",
      "815:loss       [1000]: avg:   0.6516, min:   0.1969[ 937], max:   1.0580[ 478]\n",
      "815:rl_loss    [1000]: avg:   0.1170, min:   0.0616[ 605], max:   0.3136[ 262]\n",
      "epoch 815, eval score: 6.8610, perfect: 0.10, model saved: False\n",
      "epoch 815, success rate for sampling ficticious state: 99.85%\n",
      "==========\n",
      "beginning of epoch:  816\n",
      "available: 4.357 GB, used: 24.676 GB, free: 440.836 MB\n",
      "EPOCH: 816\n",
      "Speed: train: 1141.0, buffer_add: 289.7, buffer_size: 100043\n",
      "Total Time: 12H 37M 03S, 45423s\n",
      "Total Sample: train: 52.288M, buffer: 13.066M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.96%\n",
      "\tsample data       : 1 MS, 1.86%\n",
      "\tforward & backward: 36 MS, 64.64%\n",
      "\tupdate model      : 16 MS, 29.45%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.03 ms\n",
      "[816] Time spent = 56.09 s\n",
      "816:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "816:grad_norm  [1000]: avg:   2.2480, min:   0.4217[ 691], max:   6.2525[ 349]\n",
      "816:loss       [1000]: avg:   0.6526, min:   0.2297[ 748], max:   0.9591[ 541]\n",
      "816:rl_loss    [1000]: avg:   0.1165, min:   0.0591[ 546], max:   0.3355[  13]\n",
      "epoch 816, eval score: 6.7740, perfect: 0.10, model saved: False\n",
      "epoch 816, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  817\n",
      "available: 4.349 GB, used: 24.684 GB, free: 432.301 MB\n",
      "EPOCH: 817\n",
      "Speed: train: 1155.3, buffer_add: 288.5, buffer_size: 100008\n",
      "Total Time: 12H 37M 58S, 45478s\n",
      "Total Sample: train: 52.352M, buffer: 13.082M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.79%\n",
      "\tsample data       : 1 MS, 1.93%\n",
      "\tforward & backward: 35 MS, 64.43%\n",
      "\tupdate model      : 16 MS, 29.75%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.31 ms\n",
      "[817] Time spent = 55.40 s\n",
      "817:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "817:grad_norm  [1000]: avg:   2.2083, min:   0.6901[ 939], max:   5.4347[ 554]\n",
      "817:loss       [1000]: avg:   0.6455, min:   0.2147[ 939], max:   0.9422[  98]\n",
      "817:rl_loss    [1000]: avg:   0.1141, min:   0.0606[ 174], max:   0.2928[ 987]\n",
      "epoch 817, eval score: 6.8680, perfect: 0.20, model saved: False\n",
      "epoch 817, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  818\n",
      "available: 4.349 GB, used: 24.684 GB, free: 432.426 MB\n",
      "EPOCH: 818\n",
      "Speed: train: 1131.9, buffer_add: 287.8, buffer_size: 100009\n",
      "Total Time: 12H 38M 55S, 45535s\n",
      "Total Sample: train: 52.416M, buffer: 13.098M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.75%\n",
      "\tsample data       : 1 MS, 2.01%\n",
      "\tforward & backward: 36 MS, 64.78%\n",
      "\tupdate model      : 16 MS, 29.32%\n",
      "\tupdating priority : 0 MS, 0.14%\n",
      "@@@total time per iter: 56.47 ms\n",
      "[818] Time spent = 56.54 s\n",
      "818:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "818:grad_norm  [1000]: avg:   2.2763, min:   0.5283[ 700], max:   5.8029[ 727]\n",
      "818:loss       [1000]: avg:   0.6393, min:   0.2077[ 572], max:   0.9382[ 193]\n",
      "818:rl_loss    [1000]: avg:   0.1135, min:   0.0538[ 543], max:   0.2777[ 316]\n",
      "epoch 818, eval score: 6.7610, perfect: 0.00, model saved: False\n",
      "epoch 818, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  819\n",
      "available: 4.357 GB, used: 24.676 GB, free: 440.395 MB\n",
      "EPOCH: 819\n",
      "Speed: train: 1151.5, buffer_add: 287.6, buffer_size: 100002\n",
      "Total Time: 12H 39M 50S, 45590s\n",
      "Total Sample: train: 52.48M, buffer: 13.114M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.73%\n",
      "\tsample data       : 0 MS, 1.74%\n",
      "\tforward & backward: 36 MS, 64.88%\n",
      "\tupdate model      : 16 MS, 29.55%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.50 ms\n",
      "[819] Time spent = 55.58 s\n",
      "819:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "819:grad_norm  [1000]: avg:   2.1867, min:   0.4454[ 579], max:   5.6902[ 477]\n",
      "819:loss       [1000]: avg:   0.6356, min:   0.1677[ 138], max:   0.9930[   9]\n",
      "819:rl_loss    [1000]: avg:   0.1141, min:   0.0540[ 787], max:   0.2748[ 851]\n",
      "epoch 819, eval score: 6.8540, perfect: 0.00, model saved: False\n",
      "epoch 819, success rate for sampling ficticious state: 99.85%\n",
      "==========\n",
      "beginning of epoch:  820\n",
      "available: 4.341 GB, used: 24.692 GB, free: 423.504 MB\n",
      "EPOCH: 820\n",
      "Speed: train: 1152.3, buffer_add: 285.1, buffer_size: 100034\n",
      "Total Time: 12H 40M 46S, 45646s\n",
      "Total Sample: train: 52.544M, buffer: 13.13M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.84%\n",
      "\tsample data       : 0 MS, 1.78%\n",
      "\tforward & backward: 36 MS, 65.22%\n",
      "\tupdate model      : 16 MS, 29.07%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.47 ms\n",
      "[820] Time spent = 55.54 s\n",
      "820:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "820:grad_norm  [1000]: avg:   2.1509, min:   0.8463[ 511], max:   6.4524[ 439]\n",
      "820:loss       [1000]: avg:   0.6541, min:   0.3353[ 687], max:   1.0414[  65]\n",
      "820:rl_loss    [1000]: avg:   0.1142, min:   0.0542[ 148], max:   0.2515[ 813]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 820, eval score: 6.9080, perfect: 0.10, model saved: False\n",
      "epoch 820, success rate for sampling ficticious state: 99.85%\n",
      "==========\n",
      "beginning of epoch:  821\n",
      "available: 4.350 GB, used: 24.683 GB, free: 433.109 MB\n",
      "EPOCH: 821\n",
      "Speed: train: 1154.3, buffer_add: 287.4, buffer_size: 100010\n",
      "Total Time: 12H 41M 41S, 45701s\n",
      "Total Sample: train: 52.608M, buffer: 13.146M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.93%\n",
      "\tsample data       : 1 MS, 1.86%\n",
      "\tforward & backward: 36 MS, 65.12%\n",
      "\tupdate model      : 16 MS, 28.99%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.36 ms\n",
      "[821] Time spent = 55.45 s\n",
      "821:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "821:grad_norm  [1000]: avg:   2.2166, min:   0.6861[ 785], max:   5.8253[ 300]\n",
      "821:loss       [1000]: avg:   0.6419, min:   0.2055[  94], max:   1.0655[ 597]\n",
      "821:rl_loss    [1000]: avg:   0.1121, min:   0.0534[ 104], max:   0.3030[ 327]\n",
      "epoch 821, eval score: 6.9090, perfect: 0.00, model saved: False\n",
      "epoch 821, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  822\n",
      "available: 4.348 GB, used: 24.686 GB, free: 430.734 MB\n",
      "EPOCH: 822\n",
      "Speed: train: 1135.5, buffer_add: 282.4, buffer_size: 100008\n",
      "Total Time: 12H 42M 38S, 45758s\n",
      "Total Sample: train: 52.672M, buffer: 13.162M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.61%\n",
      "\tsample data       : 1 MS, 1.93%\n",
      "\tforward & backward: 37 MS, 66.12%\n",
      "\tupdate model      : 15 MS, 28.23%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 56.29 ms\n",
      "[822] Time spent = 56.37 s\n",
      "822:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "822:grad_norm  [1000]: avg:   2.1498, min:   0.7987[ 431], max:   5.3278[ 759]\n",
      "822:loss       [1000]: avg:   0.6425, min:   0.1896[ 203], max:   1.0058[ 374]\n",
      "822:rl_loss    [1000]: avg:   0.1131, min:   0.0566[ 847], max:   0.3283[ 436]\n",
      "epoch 822, eval score: 6.9370, perfect: 0.30, model saved: False\n",
      "epoch 822, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  823\n",
      "available: 4.345 GB, used: 24.688 GB, free: 428.227 MB\n",
      "EPOCH: 823\n",
      "Speed: train: 1153.6, buffer_add: 286.1, buffer_size: 100010\n",
      "Total Time: 12H 43M 33S, 45813s\n",
      "Total Sample: train: 52.736M, buffer: 13.178M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.80%\n",
      "\tsample data       : 0 MS, 1.79%\n",
      "\tforward & backward: 36 MS, 65.19%\n",
      "\tupdate model      : 16 MS, 29.10%\n",
      "\tupdating priority : 0 MS, 0.13%\n",
      "@@@total time per iter: 55.41 ms\n",
      "[823] Time spent = 55.48 s\n",
      "823:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "823:grad_norm  [1000]: avg:   2.1471, min:   0.5389[ 476], max:   5.0124[ 899]\n",
      "823:loss       [1000]: avg:   0.6409, min:   0.2387[  85], max:   0.9304[  36]\n",
      "823:rl_loss    [1000]: avg:   0.1125, min:   0.0587[  85], max:   0.2838[ 394]\n",
      "epoch 823, eval score: 6.7780, perfect: 0.00, model saved: False\n",
      "epoch 823, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  824\n",
      "available: 4.357 GB, used: 24.677 GB, free: 439.258 MB\n",
      "EPOCH: 824\n",
      "Speed: train: 1144.3, buffer_add: 285.6, buffer_size: 100013\n",
      "Total Time: 12H 44M 29S, 45869s\n",
      "Total Sample: train: 52.8M, buffer: 13.194M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.77%\n",
      "\tsample data       : 1 MS, 2.23%\n",
      "\tforward & backward: 36 MS, 64.48%\n",
      "\tupdate model      : 16 MS, 29.40%\n",
      "\tupdating priority : 0 MS, 0.12%\n",
      "@@@total time per iter: 55.84 ms\n",
      "[824] Time spent = 55.93 s\n",
      "824:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "824:grad_norm  [1000]: avg:   2.1241, min:   0.6655[ 552], max:   6.7925[ 850]\n",
      "824:loss       [1000]: avg:   0.6388, min:   0.2368[ 251], max:   1.0460[ 945]\n",
      "824:rl_loss    [1000]: avg:   0.1133, min:   0.0582[ 929], max:   0.3099[  60]\n",
      "epoch 824, eval score: 6.9240, perfect: 0.00, model saved: False\n",
      "epoch 824, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  825\n",
      "available: 4.356 GB, used: 24.677 GB, free: 438.469 MB\n",
      "EPOCH: 825\n",
      "Speed: train: 1140.5, buffer_add: 288.9, buffer_size: 100036\n",
      "Total Time: 12H 45M 25S, 45925s\n",
      "Total Sample: train: 52.864M, buffer: 13.21M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.56%\n",
      "\tsample data       : 1 MS, 1.86%\n",
      "\tforward & backward: 36 MS, 65.01%\n",
      "\tupdate model      : 16 MS, 29.46%\n",
      "\tupdating priority : 0 MS, 0.12%\n",
      "@@@total time per iter: 56.04 ms\n",
      "[825] Time spent = 56.12 s\n",
      "825:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "825:grad_norm  [1000]: avg:   2.1551, min:   0.6647[ 154], max:   5.3793[ 110]\n",
      "825:loss       [1000]: avg:   0.6446, min:   0.2884[ 154], max:   0.9305[ 789]\n",
      "825:rl_loss    [1000]: avg:   0.1118, min:   0.0515[  68], max:   0.2518[ 852]\n",
      "epoch 825, eval score: 6.8120, perfect: 0.20, model saved: False\n",
      "epoch 825, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  826\n",
      "available: 4.352 GB, used: 24.682 GB, free: 433.988 MB\n",
      "EPOCH: 826\n",
      "Speed: train: 1143.4, buffer_add: 286.2, buffer_size: 100010\n",
      "Total Time: 12H 46M 21S, 45981s\n",
      "Total Sample: train: 52.928M, buffer: 13.226M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.71%\n",
      "\tsample data       : 1 MS, 1.83%\n",
      "\tforward & backward: 36 MS, 64.96%\n",
      "\tupdate model      : 16 MS, 29.41%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.90 ms\n",
      "[826] Time spent = 55.98 s\n",
      "826:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "826:grad_norm  [1000]: avg:   2.1491, min:   0.8418[ 890], max:   5.8339[ 272]\n",
      "826:loss       [1000]: avg:   0.6349, min:   0.1987[ 332], max:   0.9863[ 248]\n",
      "826:rl_loss    [1000]: avg:   0.1114, min:   0.0575[ 640], max:   0.3038[ 438]\n",
      "epoch 826, eval score: 6.8580, perfect: 0.00, model saved: False\n",
      "epoch 826, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  827\n",
      "available: 4.350 GB, used: 24.683 GB, free: 432.430 MB\n",
      "EPOCH: 827\n",
      "Speed: train: 1155.6, buffer_add: 285.7, buffer_size: 100036\n",
      "Total Time: 12H 47M 16S, 46036s\n",
      "Total Sample: train: 52.992M, buffer: 13.242M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.05%\n",
      "\tsample data       : 1 MS, 1.94%\n",
      "\tforward & backward: 35 MS, 64.64%\n",
      "\tupdate model      : 16 MS, 29.25%\n",
      "\tupdating priority : 0 MS, 0.12%\n",
      "@@@total time per iter: 55.31 ms\n",
      "[827] Time spent = 55.39 s\n",
      "827:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "827:grad_norm  [1000]: avg:   2.0983, min:   0.7699[ 111], max:   6.1755[ 923]\n",
      "827:loss       [1000]: avg:   0.6358, min:   0.1843[ 921], max:   1.1012[ 869]\n",
      "827:rl_loss    [1000]: avg:   0.1097, min:   0.0540[ 365], max:   0.3033[ 399]\n",
      "epoch 827, eval score: 6.7890, perfect: 0.00, model saved: False\n",
      "epoch 827, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  828\n",
      "available: 4.347 GB, used: 24.686 GB, free: 429.480 MB\n",
      "EPOCH: 828\n",
      "Speed: train: 1145.2, buffer_add: 285.0, buffer_size: 100028\n",
      "Total Time: 12H 48M 12S, 46092s\n",
      "Total Sample: train: 53.056M, buffer: 13.257M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.54%\n",
      "\tsample data       : 1 MS, 1.97%\n",
      "\tforward & backward: 36 MS, 65.26%\n",
      "\tupdate model      : 16 MS, 29.12%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.81 ms\n",
      "[828] Time spent = 55.89 s\n",
      "828:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "828:grad_norm  [1000]: avg:   2.1447, min:   0.6640[ 106], max:   5.5588[ 141]\n",
      "828:loss       [1000]: avg:   0.6380, min:   0.2453[ 506], max:   0.9326[ 508]\n",
      "828:rl_loss    [1000]: avg:   0.1103, min:   0.0584[ 909], max:   0.3047[  34]\n",
      "epoch 828, eval score: 6.8240, perfect: 0.30, model saved: False\n",
      "epoch 828, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  829\n",
      "available: 4.356 GB, used: 24.678 GB, free: 437.758 MB\n",
      "EPOCH: 829\n",
      "Speed: train: 1142.3, buffer_add: 289.5, buffer_size: 100022\n",
      "Total Time: 12H 49M 08S, 46148s\n",
      "Total Sample: train: 53.12M, buffer: 13.274M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.21%\n",
      "\tsample data       : 1 MS, 1.82%\n",
      "\tforward & backward: 35 MS, 64.05%\n",
      "\tupdate model      : 16 MS, 29.83%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.96 ms\n",
      "[829] Time spent = 56.03 s\n",
      "829:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "829:grad_norm  [1000]: avg:   2.1636, min:   0.6118[ 941], max:   5.4959[ 978]\n",
      "829:loss       [1000]: avg:   0.6402, min:   0.1875[ 941], max:   0.9638[  68]\n",
      "829:rl_loss    [1000]: avg:   0.1139, min:   0.0591[ 754], max:   0.3004[ 704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 829, eval score: 6.6930, perfect: 0.10, model saved: False\n",
      "epoch 829, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  830\n",
      "available: 4.351 GB, used: 24.682 GB, free: 433.047 MB\n",
      "EPOCH: 830\n",
      "Speed: train: 1141.6, buffer_add: 287.8, buffer_size: 100014\n",
      "Total Time: 12H 50M 04S, 46204s\n",
      "Total Sample: train: 53.184M, buffer: 13.29M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.90%\n",
      "\tsample data       : 1 MS, 1.86%\n",
      "\tforward & backward: 36 MS, 65.50%\n",
      "\tupdate model      : 16 MS, 28.63%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.99 ms\n",
      "[830] Time spent = 56.09 s\n",
      "830:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "830:grad_norm  [1000]: avg:   2.0885, min:   0.3519[ 416], max:   5.5418[ 604]\n",
      "830:loss       [1000]: avg:   0.6445, min:   0.2119[ 416], max:   1.0454[ 929]\n",
      "830:rl_loss    [1000]: avg:   0.1124, min:   0.0528[ 229], max:   0.2866[ 210]\n",
      "epoch 830, eval score: 6.8860, perfect: 0.00, model saved: False\n",
      "epoch 830, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  831\n",
      "available: 4.352 GB, used: 24.682 GB, free: 433.602 MB\n",
      "EPOCH: 831\n",
      "Speed: train: 1152.1, buffer_add: 284.1, buffer_size: 100000\n",
      "Total Time: 12H 51M 00S, 46260s\n",
      "Total Sample: train: 53.248M, buffer: 13.306M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.56%\n",
      "\tsample data       : 1 MS, 1.85%\n",
      "\tforward & backward: 36 MS, 66.02%\n",
      "\tupdate model      : 15 MS, 28.48%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.49 ms\n",
      "[831] Time spent = 55.56 s\n",
      "831:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "831:grad_norm  [1000]: avg:   2.2732, min:   0.4674[ 910], max:   6.9342[ 585]\n",
      "831:loss       [1000]: avg:   0.6486, min:   0.1402[ 886], max:   0.9975[ 720]\n",
      "831:rl_loss    [1000]: avg:   0.1134, min:   0.0548[ 947], max:   0.2973[ 735]\n",
      "epoch 831, eval score: 6.8480, perfect: 0.10, model saved: False\n",
      "epoch 831, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  832\n",
      "available: 4.346 GB, used: 24.688 GB, free: 427.414 MB\n",
      "EPOCH: 832\n",
      "Speed: train: 1151.8, buffer_add: 286.2, buffer_size: 100023\n",
      "Total Time: 12H 51M 55S, 46315s\n",
      "Total Sample: train: 53.312M, buffer: 13.322M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.74%\n",
      "\tsample data       : 0 MS, 1.72%\n",
      "\tforward & backward: 35 MS, 64.82%\n",
      "\tupdate model      : 16 MS, 29.61%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.48 ms\n",
      "[832] Time spent = 55.57 s\n",
      "832:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "832:grad_norm  [1000]: avg:   2.0949, min:   0.5775[ 983], max:   5.9323[ 893]\n",
      "832:loss       [1000]: avg:   0.6445, min:   0.2793[ 983], max:   1.0587[ 596]\n",
      "832:rl_loss    [1000]: avg:   0.1167, min:   0.0606[ 324], max:   0.3157[ 122]\n",
      "epoch 832, eval score: 6.8020, perfect: 0.10, model saved: False\n",
      "epoch 832, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  833\n",
      "available: 4.349 GB, used: 24.685 GB, free: 430.340 MB\n",
      "EPOCH: 833\n",
      "Speed: train: 1139.9, buffer_add: 286.6, buffer_size: 100000\n",
      "Total Time: 12H 52M 52S, 46372s\n",
      "Total Sample: train: 53.376M, buffer: 13.338M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.88%\n",
      "\tsample data       : 1 MS, 1.87%\n",
      "\tforward & backward: 36 MS, 65.53%\n",
      "\tupdate model      : 16 MS, 28.61%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 56.08 ms\n",
      "[833] Time spent = 56.15 s\n",
      "833:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "833:grad_norm  [1000]: avg:   2.1540, min:   0.7126[ 486], max:   5.0781[ 309]\n",
      "833:loss       [1000]: avg:   0.6424, min:   0.2219[ 251], max:   0.9649[ 726]\n",
      "833:rl_loss    [1000]: avg:   0.1152, min:   0.0544[ 290], max:   0.2729[ 577]\n",
      "epoch 833, eval score: 6.8110, perfect: 0.30, model saved: False\n",
      "epoch 833, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  834\n",
      "available: 4.336 GB, used: 24.698 GB, free: 416.734 MB\n",
      "EPOCH: 834\n",
      "Speed: train: 1149.7, buffer_add: 285.6, buffer_size: 100060\n",
      "Total Time: 12H 53M 47S, 46427s\n",
      "Total Sample: train: 53.44M, buffer: 13.353M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.74%\n",
      "\tsample data       : 1 MS, 1.97%\n",
      "\tforward & backward: 36 MS, 65.09%\n",
      "\tupdate model      : 16 MS, 29.12%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.59 ms\n",
      "[834] Time spent = 55.67 s\n",
      "834:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "834:grad_norm  [1000]: avg:   2.1420, min:   0.7210[  16], max:   5.8861[ 620]\n",
      "834:loss       [1000]: avg:   0.6396, min:   0.3156[  99], max:   0.9889[ 133]\n",
      "834:rl_loss    [1000]: avg:   0.1173, min:   0.0600[ 669], max:   0.2974[ 439]\n",
      "epoch 834, eval score: 6.8890, perfect: 0.30, model saved: False\n",
      "epoch 834, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  835\n",
      "available: 4.350 GB, used: 24.683 GB, free: 431.566 MB\n",
      "EPOCH: 835\n",
      "Speed: train: 1132.2, buffer_add: 286.5, buffer_size: 100012\n",
      "Total Time: 12H 54M 44S, 46484s\n",
      "Total Sample: train: 53.504M, buffer: 13.37M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.83%\n",
      "\tsample data       : 1 MS, 2.19%\n",
      "\tforward & backward: 36 MS, 65.08%\n",
      "\tupdate model      : 16 MS, 28.80%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 56.45 ms\n",
      "[835] Time spent = 56.53 s\n",
      "835:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "835:grad_norm  [1000]: avg:   2.1396, min:   0.6788[ 639], max:   5.2437[ 165]\n",
      "835:loss       [1000]: avg:   0.6413, min:   0.2781[ 205], max:   0.9146[ 222]\n",
      "835:rl_loss    [1000]: avg:   0.1157, min:   0.0645[ 622], max:   0.3025[ 680]\n",
      "epoch 835, eval score: 6.8630, perfect: 0.10, model saved: False\n",
      "epoch 835, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  836\n",
      "available: 4.352 GB, used: 24.681 GB, free: 433.496 MB\n",
      "EPOCH: 836\n",
      "Speed: train: 1133.2, buffer_add: 285.3, buffer_size: 100007\n",
      "Total Time: 12H 55M 40S, 46540s\n",
      "Total Sample: train: 53.568M, buffer: 13.386M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.94%\n",
      "\tsample data       : 1 MS, 2.24%\n",
      "\tforward & backward: 36 MS, 64.46%\n",
      "\tupdate model      : 16 MS, 29.27%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.40 ms\n",
      "[836] Time spent = 56.48 s\n",
      "836:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "836:grad_norm  [1000]: avg:   2.2040, min:   0.5083[ 239], max:   7.3967[ 690]\n",
      "836:loss       [1000]: avg:   0.6428, min:   0.2318[ 239], max:   0.9797[ 691]\n",
      "836:rl_loss    [1000]: avg:   0.1165, min:   0.0554[ 440], max:   0.2968[ 807]\n",
      "epoch 836, eval score: 6.9240, perfect: 0.00, model saved: False\n",
      "epoch 836, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  837\n",
      "available: 4.349 GB, used: 24.685 GB, free: 430.082 MB\n",
      "EPOCH: 837\n",
      "Speed: train: 1143.5, buffer_add: 282.1, buffer_size: 100000\n",
      "Total Time: 12H 56M 36S, 46596s\n",
      "Total Sample: train: 53.632M, buffer: 13.402M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.78%\n",
      "\tsample data       : 1 MS, 2.12%\n",
      "\tforward & backward: 36 MS, 64.50%\n",
      "\tupdate model      : 16 MS, 29.51%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.89 ms\n",
      "[837] Time spent = 55.97 s\n",
      "837:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "837:grad_norm  [1000]: avg:   2.2364, min:   0.8625[ 251], max:   6.9431[ 387]\n",
      "837:loss       [1000]: avg:   0.6394, min:   0.2632[ 526], max:   0.9711[ 670]\n",
      "837:rl_loss    [1000]: avg:   0.1155, min:   0.0539[ 809], max:   0.3203[ 808]\n",
      "epoch 837, eval score: 6.8510, perfect: 0.00, model saved: False\n",
      "epoch 837, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  838\n",
      "available: 4.343 GB, used: 24.690 GB, free: 424.148 MB\n",
      "EPOCH: 838\n",
      "Speed: train: 1140.5, buffer_add: 286.0, buffer_size: 100038\n",
      "Total Time: 12H 57M 32S, 46652s\n",
      "Total Sample: train: 53.696M, buffer: 13.418M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.08%\n",
      "\tsample data       : 1 MS, 1.79%\n",
      "\tforward & backward: 36 MS, 64.81%\n",
      "\tupdate model      : 16 MS, 29.22%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.05 ms\n",
      "[838] Time spent = 56.13 s\n",
      "838:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "838:grad_norm  [1000]: avg:   2.1612, min:   0.8538[ 698], max:   5.3774[ 923]\n",
      "838:loss       [1000]: avg:   0.6398, min:   0.2763[ 146], max:   0.9717[ 864]\n",
      "838:rl_loss    [1000]: avg:   0.1154, min:   0.0577[ 209], max:   0.3261[ 520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 838, eval score: 6.8340, perfect: 0.10, model saved: False\n",
      "epoch 838, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  839\n",
      "available: 4.351 GB, used: 24.683 GB, free: 431.660 MB\n",
      "EPOCH: 839\n",
      "Speed: train: 1157.6, buffer_add: 283.5, buffer_size: 100010\n",
      "Total Time: 12H 58M 28S, 46708s\n",
      "Total Sample: train: 53.76M, buffer: 13.433M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.77%\n",
      "\tsample data       : 1 MS, 1.93%\n",
      "\tforward & backward: 35 MS, 65.12%\n",
      "\tupdate model      : 16 MS, 29.08%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.21 ms\n",
      "[839] Time spent = 55.29 s\n",
      "839:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "839:grad_norm  [1000]: avg:   2.2048, min:   0.5023[ 832], max:   5.4654[ 569]\n",
      "839:loss       [1000]: avg:   0.6413, min:   0.1449[ 861], max:   0.9042[ 306]\n",
      "839:rl_loss    [1000]: avg:   0.1135, min:   0.0565[ 328], max:   0.3062[ 655]\n",
      "epoch 839, eval score: 6.8860, perfect: 0.00, model saved: False\n",
      "epoch 839, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  840\n",
      "available: 4.353 GB, used: 24.680 GB, free: 433.863 MB\n",
      "EPOCH: 840\n",
      "Speed: train: 1168.2, buffer_add: 283.7, buffer_size: 100014\n",
      "Total Time: 12H 59M 22S, 46762s\n",
      "Total Sample: train: 53.824M, buffer: 13.449M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.58%\n",
      "\tsample data       : 1 MS, 1.91%\n",
      "\tforward & backward: 35 MS, 65.27%\n",
      "\tupdate model      : 15 MS, 29.14%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 54.72 ms\n",
      "[840] Time spent = 54.79 s\n",
      "840:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "840:grad_norm  [1000]: avg:   2.2537, min:   0.6806[  31], max:   6.8621[ 432]\n",
      "840:loss       [1000]: avg:   0.6344, min:   0.1999[  31], max:   1.0233[ 945]\n",
      "840:rl_loss    [1000]: avg:   0.1153, min:   0.0571[ 439], max:   0.2954[ 929]\n",
      "epoch 840, eval score: 6.8650, perfect: 0.00, model saved: False\n",
      "epoch 840, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  841\n",
      "available: 4.351 GB, used: 24.683 GB, free: 431.262 MB\n",
      "EPOCH: 841\n",
      "Speed: train: 1158.6, buffer_add: 285.9, buffer_size: 100000\n",
      "Total Time: 13H 00M 18S, 46818s\n",
      "Total Sample: train: 53.888M, buffer: 13.465M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.91%\n",
      "\tsample data       : 0 MS, 1.80%\n",
      "\tforward & backward: 35 MS, 65.14%\n",
      "\tupdate model      : 16 MS, 29.05%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.18 ms\n",
      "[841] Time spent = 55.24 s\n",
      "841:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "841:grad_norm  [1000]: avg:   2.1698, min:   0.7124[ 258], max:   6.2266[ 785]\n",
      "841:loss       [1000]: avg:   0.6305, min:   0.2273[ 250], max:   0.9544[ 709]\n",
      "841:rl_loss    [1000]: avg:   0.1110, min:   0.0561[ 338], max:   0.2865[ 913]\n",
      "epoch 841, eval score: 6.9000, perfect: 0.20, model saved: False\n",
      "epoch 841, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  842\n",
      "available: 4.348 GB, used: 24.685 GB, free: 429.008 MB\n",
      "EPOCH: 842\n",
      "Speed: train: 1155.2, buffer_add: 285.5, buffer_size: 100013\n",
      "Total Time: 13H 01M 13S, 46873s\n",
      "Total Sample: train: 53.952M, buffer: 13.48M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.80%\n",
      "\tsample data       : 1 MS, 1.94%\n",
      "\tforward & backward: 36 MS, 65.35%\n",
      "\tupdate model      : 15 MS, 28.82%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.33 ms\n",
      "[842] Time spent = 55.40 s\n",
      "842:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "842:grad_norm  [1000]: avg:   2.1842, min:   0.6070[ 879], max:   5.4118[ 941]\n",
      "842:loss       [1000]: avg:   0.6310, min:   0.1940[ 301], max:   0.9551[ 400]\n",
      "842:rl_loss    [1000]: avg:   0.1121, min:   0.0438[ 331], max:   0.3643[ 342]\n",
      "epoch 842, eval score: 6.8650, perfect: 0.10, model saved: False\n",
      "epoch 842, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  843\n",
      "available: 4.346 GB, used: 24.688 GB, free: 426.117 MB\n",
      "EPOCH: 843\n",
      "Speed: train: 1160.9, buffer_add: 285.4, buffer_size: 100010\n",
      "Total Time: 13H 02M 08S, 46928s\n",
      "Total Sample: train: 54.016M, buffer: 13.496M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.72%\n",
      "\tsample data       : 1 MS, 1.83%\n",
      "\tforward & backward: 35 MS, 65.37%\n",
      "\tupdate model      : 15 MS, 29.00%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.07 ms\n",
      "[843] Time spent = 55.13 s\n",
      "843:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "843:grad_norm  [1000]: avg:   2.2376, min:   0.7607[ 206], max:   6.1894[ 176]\n",
      "843:loss       [1000]: avg:   0.6363, min:   0.2355[ 287], max:   0.9264[ 594]\n",
      "843:rl_loss    [1000]: avg:   0.1131, min:   0.0605[ 172], max:   0.3265[ 376]\n",
      "epoch 843, eval score: 6.9790, perfect: 0.10, model saved: True\n",
      "epoch 843, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  844\n",
      "available: 4.351 GB, used: 24.682 GB, free: 431.734 MB\n",
      "EPOCH: 844\n",
      "Speed: train: 1165.5, buffer_add: 288.2, buffer_size: 100016\n",
      "Total Time: 13H 03M 03S, 46983s\n",
      "Total Sample: train: 54.08M, buffer: 13.512M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.05%\n",
      "\tsample data       : 0 MS, 1.80%\n",
      "\tforward & backward: 35 MS, 64.65%\n",
      "\tupdate model      : 16 MS, 29.41%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 54.83 ms\n",
      "[844] Time spent = 54.92 s\n",
      "844:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "844:grad_norm  [1000]: avg:   2.2330, min:   0.5839[ 135], max:   6.2003[ 733]\n",
      "844:loss       [1000]: avg:   0.6441, min:   0.1956[ 380], max:   0.9231[ 831]\n",
      "844:rl_loss    [1000]: avg:   0.1123, min:   0.0559[ 547], max:   0.2850[ 203]\n",
      "epoch 844, eval score: 6.8280, perfect: 0.20, model saved: False\n",
      "epoch 844, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  845\n",
      "available: 4.351 GB, used: 24.682 GB, free: 431.621 MB\n",
      "EPOCH: 845\n",
      "Speed: train: 1139.5, buffer_add: 285.8, buffer_size: 100022\n",
      "Total Time: 13H 03M 59S, 47039s\n",
      "Total Sample: train: 54.144M, buffer: 13.528M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.91%\n",
      "\tsample data       : 1 MS, 2.00%\n",
      "\tforward & backward: 36 MS, 64.30%\n",
      "\tupdate model      : 16 MS, 29.69%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.08 ms\n",
      "[845] Time spent = 56.17 s\n",
      "845:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "845:grad_norm  [1000]: avg:   2.1807, min:   0.7647[ 243], max:   5.9941[ 660]\n",
      "845:loss       [1000]: avg:   0.6445, min:   0.2789[ 929], max:   0.9571[ 385]\n",
      "845:rl_loss    [1000]: avg:   0.1127, min:   0.0581[ 368], max:   0.2738[   1]\n",
      "epoch 845, eval score: 6.9200, perfect: 0.00, model saved: False\n",
      "epoch 845, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  846\n",
      "available: 4.348 GB, used: 24.685 GB, free: 428.164 MB\n",
      "EPOCH: 846\n",
      "Speed: train: 1145.3, buffer_add: 286.4, buffer_size: 100028\n",
      "Total Time: 13H 04M 55S, 47095s\n",
      "Total Sample: train: 54.208M, buffer: 13.544M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.97%\n",
      "\tsample data       : 0 MS, 1.74%\n",
      "\tforward & backward: 35 MS, 64.41%\n",
      "\tupdate model      : 16 MS, 29.77%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.81 ms\n",
      "[846] Time spent = 55.88 s\n",
      "846:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "846:grad_norm  [1000]: avg:   2.1984, min:   0.5118[ 902], max:   5.5262[  16]\n",
      "846:loss       [1000]: avg:   0.6411, min:   0.1565[ 902], max:   0.9768[ 533]\n",
      "846:rl_loss    [1000]: avg:   0.1128, min:   0.0521[ 318], max:   0.2909[ 792]\n",
      "epoch 846, eval score: 7.0230, perfect: 0.10, model saved: True\n",
      "epoch 846, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  847\n",
      "available: 4.357 GB, used: 24.676 GB, free: 437.656 MB\n",
      "EPOCH: 978\n",
      "Speed: train: 1152.7, buffer_add: 286.1, buffer_size: 100000\n",
      "Total Time: 15H 06M 55S, 54415s\n",
      "Total Sample: train: 62.656M, buffer: 15.641M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.67%\n",
      "\tsample data       : 1 MS, 1.94%\n",
      "\tforward & backward: 36 MS, 65.04%\n",
      "\tupdate model      : 16 MS, 29.26%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.46 ms\n",
      "[978] Time spent = 55.53 s\n",
      "978:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "978:grad_norm  [1000]: avg:   2.2678, min:   0.6101[ 981], max:   5.8801[ 647]\n",
      "978:loss       [1000]: avg:   0.6167, min:   0.2625[ 523], max:   0.9133[ 371]\n",
      "978:rl_loss    [1000]: avg:   0.1097, min:   0.0453[  81], max:   0.3004[ 886]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 978, eval score: 6.9560, perfect: 0.20, model saved: False\n",
      "epoch 978, success rate for sampling ficticious state: 99.85%\n",
      "==========\n",
      "beginning of epoch:  979\n",
      "available: 4.288 GB, used: 24.745 GB, free: 345.566 MB\n",
      "EPOCH: 979\n",
      "Speed: train: 1134.1, buffer_add: 286.6, buffer_size: 100014\n",
      "Total Time: 15H 07M 51S, 54471s\n",
      "Total Sample: train: 62.72M, buffer: 15.657M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.59%\n",
      "\tsample data       : 1 MS, 1.98%\n",
      "\tforward & backward: 36 MS, 64.72%\n",
      "\tupdate model      : 16 MS, 29.61%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 56.37 ms\n",
      "[979] Time spent = 56.44 s\n",
      "979:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "979:grad_norm  [1000]: avg:   2.2125, min:   0.8276[  86], max:   5.8930[ 623]\n",
      "979:loss       [1000]: avg:   0.6154, min:   0.2885[ 873], max:   0.8943[ 796]\n",
      "979:rl_loss    [1000]: avg:   0.1095, min:   0.0478[ 661], max:   0.3109[ 319]\n",
      "epoch 979, eval score: 6.9420, perfect: 0.00, model saved: False\n",
      "epoch 979, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  980\n",
      "available: 4.297 GB, used: 24.736 GB, free: 354.871 MB\n",
      "EPOCH: 980\n",
      "Speed: train: 1153.5, buffer_add: 285.8, buffer_size: 100028\n",
      "Total Time: 15H 08M 47S, 54527s\n",
      "Total Sample: train: 62.784M, buffer: 15.673M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.60%\n",
      "\tsample data       : 1 MS, 1.90%\n",
      "\tforward & backward: 36 MS, 65.19%\n",
      "\tupdate model      : 16 MS, 29.19%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.40 ms\n",
      "[980] Time spent = 55.49 s\n",
      "980:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "980:grad_norm  [1000]: avg:   2.1571, min:   0.6987[ 499], max:   6.8351[ 698]\n",
      "980:loss       [1000]: avg:   0.6169, min:   0.2461[ 303], max:   0.9104[ 197]\n",
      "980:rl_loss    [1000]: avg:   0.1084, min:   0.0569[ 724], max:   0.2942[ 690]\n",
      "epoch 980, eval score: 6.8500, perfect: 0.20, model saved: False\n",
      "epoch 980, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  981\n",
      "available: 4.298 GB, used: 24.735 GB, free: 355.598 MB\n",
      "EPOCH: 981\n",
      "Speed: train: 1146.5, buffer_add: 290.5, buffer_size: 100000\n",
      "Total Time: 15H 09M 43S, 54583s\n",
      "Total Sample: train: 62.848M, buffer: 15.69M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.64%\n",
      "\tsample data       : 1 MS, 2.27%\n",
      "\tforward & backward: 36 MS, 64.83%\n",
      "\tupdate model      : 16 MS, 29.16%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.76 ms\n",
      "[981] Time spent = 55.83 s\n",
      "981:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "981:grad_norm  [1000]: avg:   2.1392, min:   0.5429[ 814], max:   7.7345[ 414]\n",
      "981:loss       [1000]: avg:   0.6212, min:   0.2018[ 814], max:   0.9345[ 954]\n",
      "981:rl_loss    [1000]: avg:   0.1123, min:   0.0534[ 221], max:   0.2794[ 239]\n",
      "epoch 981, eval score: 6.9500, perfect: 0.10, model saved: False\n",
      "epoch 981, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  982\n",
      "available: 4.279 GB, used: 24.754 GB, free: 335.699 MB\n",
      "EPOCH: 982\n",
      "Speed: train: 1146.6, buffer_add: 288.5, buffer_size: 100034\n",
      "Total Time: 15H 10M 38S, 54638s\n",
      "Total Sample: train: 62.912M, buffer: 15.706M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.59%\n",
      "\tsample data       : 1 MS, 1.99%\n",
      "\tforward & backward: 36 MS, 65.28%\n",
      "\tupdate model      : 16 MS, 29.04%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.74 ms\n",
      "[982] Time spent = 55.82 s\n",
      "982:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "982:grad_norm  [1000]: avg:   2.1444, min:   0.6697[ 732], max:   5.6065[ 507]\n",
      "982:loss       [1000]: avg:   0.6217, min:   0.2733[ 732], max:   0.9187[ 373]\n",
      "982:rl_loss    [1000]: avg:   0.1133, min:   0.0520[ 812], max:   0.2946[  13]\n",
      "epoch 982, eval score: 6.9380, perfect: 0.00, model saved: False\n",
      "epoch 982, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  983\n",
      "available: 4.290 GB, used: 24.743 GB, free: 347.555 MB\n",
      "EPOCH: 983\n",
      "Speed: train: 1138.9, buffer_add: 286.6, buffer_size: 100024\n",
      "Total Time: 15H 11M 35S, 54695s\n",
      "Total Sample: train: 62.976M, buffer: 15.722M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.02%\n",
      "\tsample data       : 1 MS, 1.86%\n",
      "\tforward & backward: 36 MS, 65.01%\n",
      "\tupdate model      : 16 MS, 29.03%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.11 ms\n",
      "[983] Time spent = 56.20 s\n",
      "983:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "983:grad_norm  [1000]: avg:   2.2128, min:   0.6531[ 348], max:   6.6000[ 426]\n",
      "983:loss       [1000]: avg:   0.6214, min:   0.1996[ 836], max:   0.9536[ 680]\n",
      "983:rl_loss    [1000]: avg:   0.1122, min:   0.0567[ 891], max:   0.2960[ 827]\n",
      "epoch 983, eval score: 6.8890, perfect: 0.10, model saved: False\n",
      "epoch 983, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  984\n",
      "available: 4.303 GB, used: 24.730 GB, free: 360.465 MB\n",
      "EPOCH: 984\n",
      "Speed: train: 1158.1, buffer_add: 285.0, buffer_size: 100046\n",
      "Total Time: 15H 12M 30S, 54750s\n",
      "Total Sample: train: 63.04M, buffer: 15.737M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.22%\n",
      "\tsample data       : 1 MS, 1.90%\n",
      "\tforward & backward: 35 MS, 64.97%\n",
      "\tupdate model      : 15 MS, 28.80%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.17 ms\n",
      "[984] Time spent = 55.27 s\n",
      "984:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "984:grad_norm  [1000]: avg:   2.2044, min:   0.8389[ 530], max:   6.8991[ 302]\n",
      "984:loss       [1000]: avg:   0.6262, min:   0.2504[  92], max:   0.9342[ 684]\n",
      "984:rl_loss    [1000]: avg:   0.1135, min:   0.0548[  92], max:   0.2961[   5]\n",
      "epoch 984, eval score: 6.8920, perfect: 0.20, model saved: False\n",
      "epoch 984, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  985\n",
      "available: 4.297 GB, used: 24.736 GB, free: 354.266 MB\n",
      "EPOCH: 985\n",
      "Speed: train: 1153.1, buffer_add: 286.1, buffer_size: 100005\n",
      "Total Time: 15H 13M 25S, 54805s\n",
      "Total Sample: train: 63.104M, buffer: 15.753M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.33%\n",
      "\tsample data       : 1 MS, 1.90%\n",
      "\tforward & backward: 36 MS, 65.44%\n",
      "\tupdate model      : 16 MS, 29.23%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.41 ms\n",
      "[985] Time spent = 55.51 s\n",
      "985:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "985:grad_norm  [1000]: avg:   2.3105, min:   0.7064[ 261], max:   6.1125[ 797]\n",
      "985:loss       [1000]: avg:   0.6297, min:   0.1592[ 267], max:   0.9661[ 990]\n",
      "985:rl_loss    [1000]: avg:   0.1126, min:   0.0573[ 778], max:   0.2665[ 580]\n",
      "epoch 985, eval score: 6.9110, perfect: 0.00, model saved: False\n",
      "epoch 985, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  986\n",
      "available: 4.296 GB, used: 24.737 GB, free: 353.227 MB\n",
      "EPOCH: 986\n",
      "Speed: train: 1165.7, buffer_add: 287.3, buffer_size: 100032\n",
      "Total Time: 15H 14M 20S, 54860s\n",
      "Total Sample: train: 63.168M, buffer: 15.769M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.83%\n",
      "\tsample data       : 1 MS, 1.98%\n",
      "\tforward & backward: 35 MS, 65.29%\n",
      "\tupdate model      : 15 MS, 28.81%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 54.84 ms\n",
      "[986] Time spent = 54.91 s\n",
      "986:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "986:grad_norm  [1000]: avg:   2.1578, min:   0.7536[ 680], max:   5.8164[ 521]\n",
      "986:loss       [1000]: avg:   0.6276, min:   0.2271[ 676], max:   0.9831[ 400]\n",
      "986:rl_loss    [1000]: avg:   0.1113, min:   0.0487[ 501], max:   0.3148[ 867]\n",
      "epoch 986, eval score: 6.9530, perfect: 0.10, model saved: False\n",
      "epoch 986, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  987\n",
      "available: 4.284 GB, used: 24.749 GB, free: 340.617 MB\n",
      "EPOCH: 987\n",
      "Speed: train: 1148.5, buffer_add: 284.8, buffer_size: 100010\n",
      "Total Time: 15H 15M 16S, 54916s\n",
      "Total Sample: train: 63.232M, buffer: 15.785M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.75%\n",
      "\tsample data       : 1 MS, 1.98%\n",
      "\tforward & backward: 36 MS, 65.15%\n",
      "\tupdate model      : 16 MS, 29.03%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.64 ms\n",
      "[987] Time spent = 55.73 s\n",
      "987:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "987:grad_norm  [1000]: avg:   2.1979, min:   0.6598[ 160], max:   6.1945[ 547]\n",
      "987:loss       [1000]: avg:   0.6276, min:   0.2986[ 819], max:   0.9074[ 228]\n",
      "987:rl_loss    [1000]: avg:   0.1100, min:   0.0544[ 129], max:   0.3200[ 739]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 987, eval score: 6.9720, perfect: 0.10, model saved: False\n",
      "epoch 987, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  988\n",
      "available: 4.294 GB, used: 24.739 GB, free: 350.480 MB\n",
      "EPOCH: 988\n",
      "Speed: train: 1148.2, buffer_add: 286.3, buffer_size: 100018\n",
      "Total Time: 15H 16M 12S, 54972s\n",
      "Total Sample: train: 63.296M, buffer: 15.801M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.82%\n",
      "\tsample data       : 1 MS, 1.81%\n",
      "\tforward & backward: 36 MS, 64.83%\n",
      "\tupdate model      : 16 MS, 29.46%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.67 ms\n",
      "[988] Time spent = 55.74 s\n",
      "988:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "988:grad_norm  [1000]: avg:   2.1880, min:   0.6222[ 718], max:   6.1318[ 618]\n",
      "988:loss       [1000]: avg:   0.6366, min:   0.2151[ 813], max:   0.9530[ 314]\n",
      "988:rl_loss    [1000]: avg:   0.1100, min:   0.0468[ 160], max:   0.3012[ 182]\n",
      "epoch 988, eval score: 6.9880, perfect: 0.00, model saved: False\n",
      "epoch 988, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  989\n",
      "available: 4.298 GB, used: 24.735 GB, free: 339.836 MB\n",
      "EPOCH: 989\n",
      "Speed: train: 1154.3, buffer_add: 287.9, buffer_size: 100003\n",
      "Total Time: 15H 17M 07S, 55027s\n",
      "Total Sample: train: 63.36M, buffer: 15.817M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.47%\n",
      "\tsample data       : 1 MS, 1.96%\n",
      "\tforward & backward: 36 MS, 65.48%\n",
      "\tupdate model      : 16 MS, 29.00%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.38 ms\n",
      "[989] Time spent = 55.44 s\n",
      "989:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "989:grad_norm  [1000]: avg:   2.2091, min:   0.3473[ 380], max:   7.2357[  88]\n",
      "989:loss       [1000]: avg:   0.6289, min:   0.1805[ 539], max:   0.9565[ 335]\n",
      "989:rl_loss    [1000]: avg:   0.1079, min:   0.0493[ 747], max:   0.2857[ 731]\n",
      "epoch 989, eval score: 6.9460, perfect: 0.10, model saved: False\n",
      "epoch 989, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  990\n",
      "available: 4.297 GB, used: 24.736 GB, free: 338.441 MB\n",
      "EPOCH: 990\n",
      "Speed: train: 1157.7, buffer_add: 284.3, buffer_size: 100036\n",
      "Total Time: 15H 18M 02S, 55082s\n",
      "Total Sample: train: 63.424M, buffer: 15.833M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.74%\n",
      "\tsample data       : 1 MS, 1.97%\n",
      "\tforward & backward: 36 MS, 65.24%\n",
      "\tupdate model      : 15 MS, 28.90%\n",
      "\tupdating priority : 0 MS, 0.15%\n",
      "@@@total time per iter: 55.20 ms\n",
      "[990] Time spent = 55.30 s\n",
      "990:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "990:grad_norm  [1000]: avg:   2.2736, min:   0.7629[ 464], max:   7.0115[  35]\n",
      "990:loss       [1000]: avg:   0.6251, min:   0.1593[ 464], max:   0.9586[ 878]\n",
      "990:rl_loss    [1000]: avg:   0.1080, min:   0.0525[ 664], max:   0.2943[ 662]\n",
      "epoch 990, eval score: 6.8970, perfect: 0.20, model saved: False\n",
      "epoch 990, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  991\n",
      "available: 4.292 GB, used: 24.741 GB, free: 333.742 MB\n",
      "EPOCH: 991\n",
      "Speed: train: 1171.6, buffer_add: 283.2, buffer_size: 100032\n",
      "Total Time: 15H 18M 57S, 55137s\n",
      "Total Sample: train: 63.488M, buffer: 15.848M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.76%\n",
      "\tsample data       : 1 MS, 1.88%\n",
      "\tforward & backward: 35 MS, 65.77%\n",
      "\tupdate model      : 15 MS, 28.49%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 54.56 ms\n",
      "[991] Time spent = 54.63 s\n",
      "991:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "991:grad_norm  [1000]: avg:   2.2921, min:   0.5668[ 209], max:   5.9137[ 970]\n",
      "991:loss       [1000]: avg:   0.6278, min:   0.2207[ 209], max:   0.9550[ 890]\n",
      "991:rl_loss    [1000]: avg:   0.1066, min:   0.0535[ 402], max:   0.2479[ 594]\n",
      "epoch 991, eval score: 6.8970, perfect: 0.00, model saved: False\n",
      "epoch 991, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  992\n",
      "available: 4.288 GB, used: 24.745 GB, free: 328.949 MB\n",
      "EPOCH: 992\n",
      "Speed: train: 1138.8, buffer_add: 288.1, buffer_size: 100026\n",
      "Total Time: 15H 19M 53S, 55193s\n",
      "Total Sample: train: 63.552M, buffer: 15.864M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.71%\n",
      "\tsample data       : 1 MS, 2.34%\n",
      "\tforward & backward: 36 MS, 64.77%\n",
      "\tupdate model      : 16 MS, 29.07%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 56.12 ms\n",
      "[992] Time spent = 56.20 s\n",
      "992:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "992:grad_norm  [1000]: avg:   2.2825, min:   0.5438[ 170], max:   7.3637[ 602]\n",
      "992:loss       [1000]: avg:   0.6232, min:   0.1899[ 667], max:   0.9397[ 485]\n",
      "992:rl_loss    [1000]: avg:   0.1077, min:   0.0522[ 249], max:   0.2749[ 926]\n",
      "epoch 992, eval score: 7.0590, perfect: 0.00, model saved: True\n",
      "epoch 992, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  993\n",
      "available: 4.284 GB, used: 24.749 GB, free: 325.164 MB\n",
      "EPOCH: 993\n",
      "Speed: train: 1156.7, buffer_add: 285.7, buffer_size: 100023\n",
      "Total Time: 15H 20M 49S, 55249s\n",
      "Total Sample: train: 63.616M, buffer: 15.88M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.66%\n",
      "\tsample data       : 1 MS, 2.12%\n",
      "\tforward & backward: 36 MS, 65.35%\n",
      "\tupdate model      : 15 MS, 28.77%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.24 ms\n",
      "[993] Time spent = 55.33 s\n",
      "993:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "993:grad_norm  [1000]: avg:   2.2463, min:   0.5143[ 330], max:   6.7444[ 416]\n",
      "993:loss       [1000]: avg:   0.6263, min:   0.2558[ 981], max:   0.9176[ 896]\n",
      "993:rl_loss    [1000]: avg:   0.1089, min:   0.0557[ 857], max:   0.2972[ 280]\n",
      "epoch 993, eval score: 6.9270, perfect: 0.10, model saved: False\n",
      "epoch 993, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  994\n",
      "available: 4.285 GB, used: 24.748 GB, free: 326.262 MB\n",
      "EPOCH: 994\n",
      "Speed: train: 1155.1, buffer_add: 286.1, buffer_size: 100020\n",
      "Total Time: 15H 21M 44S, 55304s\n",
      "Total Sample: train: 63.68M, buffer: 15.896M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.55%\n",
      "\tsample data       : 1 MS, 2.03%\n",
      "\tforward & backward: 36 MS, 65.76%\n",
      "\tupdate model      : 15 MS, 28.55%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.34 ms\n",
      "[994] Time spent = 55.41 s\n",
      "994:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "994:grad_norm  [1000]: avg:   2.3284, min:   0.4704[ 649], max:   7.1662[ 485]\n",
      "994:loss       [1000]: avg:   0.6258, min:   0.1668[ 649], max:   0.9832[  61]\n",
      "994:rl_loss    [1000]: avg:   0.1092, min:   0.0541[ 586], max:   0.2956[ 877]\n",
      "epoch 994, eval score: 6.9350, perfect: 0.00, model saved: False\n",
      "epoch 994, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  995\n",
      "available: 4.298 GB, used: 24.735 GB, free: 339.473 MB\n",
      "EPOCH: 995\n",
      "Speed: train: 1159.5, buffer_add: 283.6, buffer_size: 100012\n",
      "Total Time: 15H 22M 39S, 55359s\n",
      "Total Sample: train: 63.744M, buffer: 15.912M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.96%\n",
      "\tsample data       : 1 MS, 1.92%\n",
      "\tforward & backward: 35 MS, 64.55%\n",
      "\tupdate model      : 16 MS, 29.48%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.13 ms\n",
      "[995] Time spent = 55.20 s\n",
      "995:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "995:grad_norm  [1000]: avg:   2.2870, min:   0.5867[ 882], max:   6.3530[ 489]\n",
      "995:loss       [1000]: avg:   0.6354, min:   0.2202[ 882], max:   1.0125[ 323]\n",
      "995:rl_loss    [1000]: avg:   0.1098, min:   0.0444[ 342], max:   0.2825[ 944]\n",
      "epoch 995, eval score: 6.8260, perfect: 0.00, model saved: False\n",
      "epoch 995, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  996\n",
      "available: 4.294 GB, used: 24.739 GB, free: 334.648 MB\n",
      "EPOCH: 996\n",
      "Speed: train: 1168.6, buffer_add: 282.1, buffer_size: 100008\n",
      "Total Time: 15H 23M 34S, 55414s\n",
      "Total Sample: train: 63.808M, buffer: 15.927M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.93%\n",
      "\tsample data       : 1 MS, 1.88%\n",
      "\tforward & backward: 35 MS, 65.26%\n",
      "\tupdate model      : 15 MS, 28.83%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 54.70 ms\n",
      "[996] Time spent = 54.77 s\n",
      "996:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "996:grad_norm  [1000]: avg:   2.2444, min:   0.5669[ 603], max:   5.7493[  61]\n",
      "996:loss       [1000]: avg:   0.6253, min:   0.1971[ 603], max:   0.9574[ 542]\n",
      "996:rl_loss    [1000]: avg:   0.1098, min:   0.0571[ 696], max:   0.3415[ 714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 996, eval score: 6.9900, perfect: 0.10, model saved: False\n",
      "epoch 996, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  997\n",
      "available: 4.289 GB, used: 24.745 GB, free: 328.773 MB\n",
      "EPOCH: 997\n",
      "Speed: train: 1145.6, buffer_add: 286.5, buffer_size: 100008\n",
      "Total Time: 15H 24M 30S, 55470s\n",
      "Total Sample: train: 63.872M, buffer: 15.943M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.62%\n",
      "\tsample data       : 1 MS, 1.81%\n",
      "\tforward & backward: 36 MS, 65.56%\n",
      "\tupdate model      : 16 MS, 28.84%\n",
      "\tupdating priority : 0 MS, 0.17%\n",
      "@@@total time per iter: 55.80 ms\n",
      "[997] Time spent = 55.87 s\n",
      "997:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "997:grad_norm  [1000]: avg:   2.3428, min:   0.7233[ 349], max:   7.6975[ 233]\n",
      "997:loss       [1000]: avg:   0.6241, min:   0.2364[ 244], max:   0.9619[ 640]\n",
      "997:rl_loss    [1000]: avg:   0.1084, min:   0.0579[ 150], max:   0.2815[ 212]\n",
      "epoch 997, eval score: 7.0120, perfect: 0.20, model saved: True\n",
      "epoch 997, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  998\n",
      "available: 4.290 GB, used: 24.744 GB, free: 330.148 MB\n",
      "EPOCH: 998\n",
      "Speed: train: 1150.9, buffer_add: 287.6, buffer_size: 100002\n",
      "Total Time: 15H 25M 25S, 55525s\n",
      "Total Sample: train: 63.936M, buffer: 15.959M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.70%\n",
      "\tsample data       : 0 MS, 1.79%\n",
      "\tforward & backward: 36 MS, 65.18%\n",
      "\tupdate model      : 16 MS, 29.22%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.52 ms\n",
      "[998] Time spent = 55.61 s\n",
      "998:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "998:grad_norm  [1000]: avg:   2.2489, min:   0.7578[ 987], max:   6.8636[ 897]\n",
      "998:loss       [1000]: avg:   0.6256, min:   0.2035[ 987], max:   0.9793[ 282]\n",
      "998:rl_loss    [1000]: avg:   0.1107, min:   0.0557[ 753], max:   0.3114[ 418]\n",
      "epoch 998, eval score: 6.9060, perfect: 0.10, model saved: False\n",
      "epoch 998, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  999\n",
      "available: 4.289 GB, used: 24.744 GB, free: 328.965 MB\n",
      "EPOCH: 999\n",
      "Speed: train: 1158.3, buffer_add: 285.0, buffer_size: 100011\n",
      "Total Time: 15H 26M 21S, 55581s\n",
      "Total Sample: train: 64M, buffer: 15.975M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.92%\n",
      "\tsample data       : 1 MS, 2.14%\n",
      "\tforward & backward: 35 MS, 65.13%\n",
      "\tupdate model      : 15 MS, 28.68%\n",
      "\tupdating priority : 0 MS, 0.12%\n",
      "@@@total time per iter: 55.19 ms\n",
      "[999] Time spent = 55.26 s\n",
      "999:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "999:grad_norm  [1000]: avg:   2.3440, min:   0.3883[  21], max:   6.5360[ 628]\n",
      "999:loss       [1000]: avg:   0.6311, min:   0.1644[  21], max:   0.9210[ 464]\n",
      "999:rl_loss    [1000]: avg:   0.1128, min:   0.0535[ 358], max:   0.4039[ 705]\n",
      "epoch 999, eval score: 6.8670, perfect: 0.00, model saved: False\n",
      "epoch 999, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1000\n",
      "available: 4.295 GB, used: 24.739 GB, free: 335.137 MB\n",
      "EPOCH: 1000\n",
      "Speed: train: 1139.8, buffer_add: 285.9, buffer_size: 100026\n",
      "Total Time: 15H 27M 17S, 55637s\n",
      "Total Sample: train: 64.064M, buffer: 15.991M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.86%\n",
      "\tsample data       : 0 MS, 1.57%\n",
      "\tforward & backward: 36 MS, 65.19%\n",
      "\tupdate model      : 16 MS, 29.28%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 56.08 ms\n",
      "[1000] Time spent = 56.15 s\n",
      "1000:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1000:grad_norm [1000]: avg:   2.3176, min:   0.6258[ 971], max:   6.6765[ 469]\n",
      "1000:loss      [1000]: avg:   0.6375, min:   0.1887[ 214], max:   0.9698[ 612]\n",
      "1000:rl_loss   [1000]: avg:   0.1116, min:   0.0568[ 729], max:   0.2553[ 947]\n",
      "epoch 1000, eval score: 6.8750, perfect: 0.00, model saved: False\n",
      "epoch 1000, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1001\n",
      "available: 4.296 GB, used: 24.737 GB, free: 331.961 MB\n",
      "EPOCH: 1001\n",
      "Speed: train: 1161.6, buffer_add: 287.4, buffer_size: 100025\n",
      "Total Time: 15H 28M 12S, 55692s\n",
      "Total Sample: train: 64.128M, buffer: 16.007M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.69%\n",
      "\tsample data       : 1 MS, 1.83%\n",
      "\tforward & backward: 36 MS, 65.76%\n",
      "\tupdate model      : 15 MS, 28.60%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.02 ms\n",
      "[1001] Time spent = 55.10 s\n",
      "1001:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1001:grad_norm [1000]: avg:   2.1578, min:   0.5525[ 921], max:   7.5555[ 138]\n",
      "1001:loss      [1000]: avg:   0.6346, min:   0.1343[ 921], max:   0.9465[ 632]\n",
      "1001:rl_loss   [1000]: avg:   0.1132, min:   0.0544[  77], max:   0.3086[ 285]\n",
      "epoch 1001, eval score: 6.7220, perfect: 0.10, model saved: False\n",
      "epoch 1001, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1002\n",
      "available: 4.291 GB, used: 24.742 GB, free: 326.254 MB\n",
      "EPOCH: 1002\n",
      "Speed: train: 1162.6, buffer_add: 286.3, buffer_size: 100016\n",
      "Total Time: 15H 29M 07S, 55747s\n",
      "Total Sample: train: 64.192M, buffer: 16.022M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.82%\n",
      "\tsample data       : 1 MS, 1.88%\n",
      "\tforward & backward: 36 MS, 65.78%\n",
      "\tupdate model      : 15 MS, 28.44%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 54.98 ms\n",
      "[1002] Time spent = 55.05 s\n",
      "1002:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1002:grad_norm [1000]: avg:   2.1892, min:   0.2225[  76], max:   5.8928[ 643]\n",
      "1002:loss      [1000]: avg:   0.6380, min:   0.1406[  76], max:   1.0308[ 377]\n",
      "1002:rl_loss   [1000]: avg:   0.1148, min:   0.0541[ 313], max:   0.3051[  90]\n",
      "epoch 1002, eval score: 6.8770, perfect: 0.10, model saved: False\n",
      "epoch 1002, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  1003\n",
      "available: 4.288 GB, used: 24.745 GB, free: 323.109 MB\n",
      "EPOCH: 1003\n",
      "Speed: train: 1169.1, buffer_add: 285.1, buffer_size: 100006\n",
      "Total Time: 15H 30M 02S, 55802s\n",
      "Total Sample: train: 64.256M, buffer: 16.038M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.74%\n",
      "\tsample data       : 1 MS, 1.88%\n",
      "\tforward & backward: 35 MS, 65.21%\n",
      "\tupdate model      : 15 MS, 29.07%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 54.67 ms\n",
      "[1003] Time spent = 54.75 s\n",
      "1003:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1003:grad_norm [1000]: avg:   2.3690, min:   0.6011[  81], max:   7.4197[ 292]\n",
      "1003:loss      [1000]: avg:   0.6394, min:   0.1895[  81], max:   0.9436[ 106]\n",
      "1003:rl_loss   [1000]: avg:   0.1124, min:   0.0549[ 531], max:   0.2390[ 466]\n",
      "epoch 1003, eval score: 6.9280, perfect: 0.30, model saved: False\n",
      "epoch 1003, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  1004\n",
      "available: 4.284 GB, used: 24.749 GB, free: 318.641 MB\n",
      "EPOCH: 1004\n",
      "Speed: train: 1158.9, buffer_add: 284.9, buffer_size: 100000\n",
      "Total Time: 15H 30M 57S, 55857s\n",
      "Total Sample: train: 64.32M, buffer: 16.054M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.66%\n",
      "\tsample data       : 1 MS, 1.97%\n",
      "\tforward & backward: 35 MS, 65.19%\n",
      "\tupdate model      : 16 MS, 29.08%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.16 ms\n",
      "[1004] Time spent = 55.23 s\n",
      "1004:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1004:grad_norm [1000]: avg:   2.3593, min:   0.6905[ 328], max:   6.7673[ 614]\n",
      "1004:loss      [1000]: avg:   0.6309, min:   0.1989[ 328], max:   0.9392[ 825]\n",
      "1004:rl_loss   [1000]: avg:   0.1128, min:   0.0563[ 271], max:   0.3814[ 894]\n",
      "epoch 1004, eval score: 6.8610, perfect: 0.20, model saved: False\n",
      "epoch 1004, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  1005\n",
      "available: 4.292 GB, used: 24.742 GB, free: 326.105 MB\n",
      "EPOCH: 1005\n",
      "Speed: train: 1167.1, buffer_add: 287.8, buffer_size: 100020\n",
      "Total Time: 15H 31M 52S, 55912s\n",
      "Total Sample: train: 64.384M, buffer: 16.07M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.94%\n",
      "\tsample data       : 0 MS, 1.76%\n",
      "\tforward & backward: 35 MS, 65.28%\n",
      "\tupdate model      : 15 MS, 28.93%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 54.75 ms\n",
      "[1005] Time spent = 54.84 s\n",
      "1005:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1005:grad_norm [1000]: avg:   2.3482, min:   0.5078[ 293], max:   6.5582[ 654]\n",
      "1005:loss      [1000]: avg:   0.6284, min:   0.2434[ 893], max:   0.9827[ 229]\n",
      "1005:rl_loss   [1000]: avg:   0.1120, min:   0.0523[ 140], max:   0.2871[ 124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1005, eval score: 6.8930, perfect: 0.00, model saved: False\n",
      "epoch 1005, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1006\n",
      "available: 4.296 GB, used: 24.737 GB, free: 331.172 MB\n",
      "EPOCH: 1006\n",
      "Speed: train: 1148.5, buffer_add: 286.4, buffer_size: 100065\n",
      "Total Time: 15H 32M 48S, 55968s\n",
      "Total Sample: train: 64.448M, buffer: 16.086M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.79%\n",
      "\tsample data       : 1 MS, 2.03%\n",
      "\tforward & backward: 36 MS, 65.99%\n",
      "\tupdate model      : 15 MS, 28.08%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.65 ms\n",
      "[1006] Time spent = 55.73 s\n",
      "1006:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1006:grad_norm [1000]: avg:   2.2540, min:   0.7517[ 378], max:   6.9646[ 990]\n",
      "1006:loss      [1000]: avg:   0.6251, min:   0.2481[ 326], max:   0.9171[ 597]\n",
      "1006:rl_loss   [1000]: avg:   0.1117, min:   0.0452[ 695], max:   0.2552[ 142]\n",
      "epoch 1006, eval score: 7.0140, perfect: 0.10, model saved: True\n",
      "epoch 1006, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  1007\n",
      "available: 4.294 GB, used: 24.739 GB, free: 329.316 MB\n",
      "EPOCH: 1007\n",
      "Speed: train: 1175.5, buffer_add: 288.8, buffer_size: 100000\n",
      "Total Time: 15H 33M 42S, 56022s\n",
      "Total Sample: train: 64.512M, buffer: 16.101M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.73%\n",
      "\tsample data       : 1 MS, 1.92%\n",
      "\tforward & backward: 35 MS, 65.64%\n",
      "\tupdate model      : 15 MS, 28.61%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 54.37 ms\n",
      "[1007] Time spent = 54.45 s\n",
      "1007:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1007:grad_norm [1000]: avg:   2.3489, min:   0.4811[ 638], max:   7.2612[ 395]\n",
      "1007:loss      [1000]: avg:   0.6199, min:   0.2058[  24], max:   0.9876[ 261]\n",
      "1007:rl_loss   [1000]: avg:   0.1093, min:   0.0552[ 237], max:   0.3107[ 142]\n",
      "epoch 1007, eval score: 7.0010, perfect: 0.10, model saved: False\n",
      "epoch 1007, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1008\n",
      "available: 4.295 GB, used: 24.739 GB, free: 329.625 MB\n",
      "EPOCH: 1008\n",
      "Speed: train: 1165.1, buffer_add: 289.8, buffer_size: 100000\n",
      "Total Time: 15H 34M 37S, 56077s\n",
      "Total Sample: train: 64.576M, buffer: 16.117M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.00%\n",
      "\tsample data       : 0 MS, 1.60%\n",
      "\tforward & backward: 35 MS, 65.14%\n",
      "\tupdate model      : 15 MS, 29.17%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 54.85 ms\n",
      "[1008] Time spent = 54.93 s\n",
      "1008:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1008:grad_norm [1000]: avg:   2.2834, min:   0.7459[ 748], max:   6.7088[ 817]\n",
      "1008:loss      [1000]: avg:   0.6217, min:   0.2444[ 748], max:   0.9691[ 935]\n",
      "1008:rl_loss   [1000]: avg:   0.1130, min:   0.0534[ 271], max:   0.3133[ 364]\n",
      "epoch 1008, eval score: 6.8780, perfect: 0.20, model saved: False\n",
      "epoch 1008, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1009\n",
      "available: 4.289 GB, used: 24.745 GB, free: 323.453 MB\n",
      "EPOCH: 1009\n",
      "Speed: train: 1137.7, buffer_add: 287.5, buffer_size: 100004\n",
      "Total Time: 15H 35M 33S, 56133s\n",
      "Total Sample: train: 64.64M, buffer: 16.133M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.62%\n",
      "\tsample data       : 1 MS, 2.08%\n",
      "\tforward & backward: 36 MS, 65.60%\n",
      "\tupdate model      : 16 MS, 28.58%\n",
      "\tupdating priority : 0 MS, 0.12%\n",
      "@@@total time per iter: 56.19 ms\n",
      "[1009] Time spent = 56.26 s\n",
      "1009:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1009:grad_norm [1000]: avg:   2.2932, min:   0.6250[   7], max:   7.3898[ 169]\n",
      "1009:loss      [1000]: avg:   0.6265, min:   0.2068[ 691], max:   0.9486[ 131]\n",
      "1009:rl_loss   [1000]: avg:   0.1143, min:   0.0526[  52], max:   0.3108[ 491]\n",
      "epoch 1009, eval score: 6.8750, perfect: 0.20, model saved: False\n",
      "epoch 1009, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1010\n",
      "available: 4.293 GB, used: 24.740 GB, free: 341.059 MB\n",
      "EPOCH: 1010\n",
      "Speed: train: 1141.5, buffer_add: 290.3, buffer_size: 100014\n",
      "Total Time: 15H 36M 29S, 56189s\n",
      "Total Sample: train: 64.704M, buffer: 16.15M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.97%\n",
      "\tsample data       : 1 MS, 2.04%\n",
      "\tforward & backward: 36 MS, 64.41%\n",
      "\tupdate model      : 16 MS, 29.47%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.99 ms\n",
      "[1010] Time spent = 56.07 s\n",
      "1010:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1010:grad_norm [1000]: avg:   2.3100, min:   0.4000[ 240], max:   6.8636[  76]\n",
      "1010:loss      [1000]: avg:   0.6253, min:   0.1700[ 240], max:   0.9185[ 304]\n",
      "1010:rl_loss   [1000]: avg:   0.1147, min:   0.0567[ 481], max:   0.2968[ 382]\n",
      "epoch 1010, eval score: 6.8660, perfect: 0.10, model saved: False\n",
      "epoch 1010, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  1011\n",
      "available: 4.296 GB, used: 24.737 GB, free: 343.535 MB\n",
      "EPOCH: 1011\n",
      "Speed: train: 1167.3, buffer_add: 287.4, buffer_size: 100028\n",
      "Total Time: 15H 37M 24S, 56244s\n",
      "Total Sample: train: 64.768M, buffer: 16.165M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.78%\n",
      "\tsample data       : 1 MS, 1.91%\n",
      "\tforward & backward: 35 MS, 65.25%\n",
      "\tupdate model      : 15 MS, 28.96%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 54.75 ms\n",
      "[1011] Time spent = 54.83 s\n",
      "1011:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1011:grad_norm [1000]: avg:   2.2956, min:   0.7536[ 972], max:   6.7842[ 381]\n",
      "1011:loss      [1000]: avg:   0.6355, min:   0.2922[ 522], max:   0.9878[ 997]\n",
      "1011:rl_loss   [1000]: avg:   0.1150, min:   0.0529[  95], max:   0.2752[ 658]\n",
      "epoch 1011, eval score: 7.0300, perfect: 0.10, model saved: True\n",
      "epoch 1011, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1012\n",
      "available: 4.292 GB, used: 24.742 GB, free: 339.055 MB\n",
      "EPOCH: 1012\n",
      "Speed: train: 1146.4, buffer_add: 286.3, buffer_size: 100000\n",
      "Total Time: 15H 38M 20S, 56300s\n",
      "Total Sample: train: 64.832M, buffer: 16.181M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.62%\n",
      "\tsample data       : 1 MS, 2.01%\n",
      "\tforward & backward: 36 MS, 65.29%\n",
      "\tupdate model      : 16 MS, 28.99%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.76 ms\n",
      "[1012] Time spent = 55.83 s\n",
      "1012:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1012:grad_norm [1000]: avg:   2.2781, min:   0.8271[ 529], max:   6.7729[ 881]\n",
      "1012:loss      [1000]: avg:   0.6296, min:   0.1896[ 191], max:   0.9788[ 881]\n",
      "1012:rl_loss   [1000]: avg:   0.1173, min:   0.0535[ 321], max:   0.3144[ 953]\n",
      "epoch 1012, eval score: 6.8970, perfect: 0.30, model saved: False\n",
      "epoch 1012, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1013\n",
      "available: 4.288 GB, used: 24.746 GB, free: 334.930 MB\n",
      "EPOCH: 1013\n",
      "Speed: train: 1155.8, buffer_add: 287.8, buffer_size: 100002\n",
      "Total Time: 15H 39M 15S, 56355s\n",
      "Total Sample: train: 64.896M, buffer: 16.197M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.82%\n",
      "\tsample data       : 1 MS, 1.84%\n",
      "\tforward & backward: 36 MS, 65.34%\n",
      "\tupdate model      : 15 MS, 28.90%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.29 ms\n",
      "[1013] Time spent = 55.38 s\n",
      "1013:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1013:grad_norm [1000]: avg:   2.3172, min:   0.8034[ 432], max:   6.7181[ 899]\n",
      "1013:loss      [1000]: avg:   0.6433, min:   0.1758[ 623], max:   0.9682[ 152]\n",
      "1013:rl_loss   [1000]: avg:   0.1158, min:   0.0549[ 215], max:   0.3406[ 804]\n",
      "epoch 1013, eval score: 7.0330, perfect: 0.10, model saved: True\n",
      "epoch 1013, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1014\n",
      "available: 4.293 GB, used: 24.741 GB, free: 339.910 MB\n",
      "EPOCH: 1014\n",
      "Speed: train: 1178.3, buffer_add: 288.9, buffer_size: 100006\n",
      "Total Time: 15H 40M 10S, 56410s\n",
      "Total Sample: train: 64.96M, buffer: 16.213M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.62%\n",
      "\tsample data       : 0 MS, 1.77%\n",
      "\tforward & backward: 35 MS, 65.86%\n",
      "\tupdate model      : 15 MS, 28.65%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 54.25 ms\n",
      "[1014] Time spent = 54.32 s\n",
      "1014:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1014:grad_norm [1000]: avg:   2.1883, min:   0.7780[ 561], max:   6.3795[ 970]\n",
      "1014:loss      [1000]: avg:   0.6363, min:   0.2341[ 916], max:   1.0191[ 693]\n",
      "1014:rl_loss   [1000]: avg:   0.1129, min:   0.0552[ 109], max:   0.2729[ 626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1014, eval score: 6.9040, perfect: 0.00, model saved: False\n",
      "epoch 1014, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1015\n",
      "available: 4.296 GB, used: 24.737 GB, free: 343.719 MB\n",
      "EPOCH: 1015\n",
      "Speed: train: 1144.2, buffer_add: 284.1, buffer_size: 100014\n",
      "Total Time: 15H 41M 06S, 56466s\n",
      "Total Sample: train: 65.024M, buffer: 16.229M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.87%\n",
      "\tsample data       : 1 MS, 1.93%\n",
      "\tforward & backward: 36 MS, 64.51%\n",
      "\tupdate model      : 16 MS, 29.56%\n",
      "\tupdating priority : 0 MS, 0.13%\n",
      "@@@total time per iter: 55.86 ms\n",
      "[1015] Time spent = 55.94 s\n",
      "1015:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1015:grad_norm [1000]: avg:   2.2685, min:   0.7200[ 923], max:   9.7932[ 557]\n",
      "1015:loss      [1000]: avg:   0.6335, min:   0.2742[  64], max:   0.9550[  79]\n",
      "1015:rl_loss   [1000]: avg:   0.1133, min:   0.0478[  59], max:   0.2772[ 858]\n",
      "epoch 1015, eval score: 6.9460, perfect: 0.10, model saved: False\n",
      "epoch 1015, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  1016\n",
      "available: 4.299 GB, used: 24.734 GB, free: 346.195 MB\n",
      "EPOCH: 1016\n",
      "Speed: train: 1167.9, buffer_add: 287.0, buffer_size: 100014\n",
      "Total Time: 15H 42M 00S, 56520s\n",
      "Total Sample: train: 65.088M, buffer: 16.245M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.92%\n",
      "\tsample data       : 0 MS, 1.83%\n",
      "\tforward & backward: 35 MS, 65.51%\n",
      "\tupdate model      : 15 MS, 28.65%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 54.73 ms\n",
      "[1016] Time spent = 54.80 s\n",
      "1016:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1016:grad_norm [1000]: avg:   2.3270, min:   0.5104[ 401], max:   7.3649[ 398]\n",
      "1016:loss      [1000]: avg:   0.6345, min:   0.2187[ 401], max:   0.9503[ 265]\n",
      "1016:rl_loss   [1000]: avg:   0.1124, min:   0.0583[ 478], max:   0.2741[  85]\n",
      "epoch 1016, eval score: 6.9320, perfect: 0.10, model saved: False\n",
      "epoch 1016, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1017\n",
      "available: 4.297 GB, used: 24.737 GB, free: 343.793 MB\n",
      "EPOCH: 1017\n",
      "Speed: train: 1170.3, buffer_add: 285.8, buffer_size: 100015\n",
      "Total Time: 15H 42M 55S, 56575s\n",
      "Total Sample: train: 65.152M, buffer: 16.26M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.73%\n",
      "\tsample data       : 0 MS, 1.78%\n",
      "\tforward & backward: 35 MS, 65.91%\n",
      "\tupdate model      : 15 MS, 28.49%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 54.62 ms\n",
      "[1017] Time spent = 54.69 s\n",
      "1017:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1017:grad_norm [1000]: avg:   2.2443, min:   0.4428[ 871], max:   6.6219[ 952]\n",
      "1017:loss      [1000]: avg:   0.6273, min:   0.2186[  67], max:   0.9794[ 323]\n",
      "1017:rl_loss   [1000]: avg:   0.1119, min:   0.0480[ 595], max:   0.2956[ 552]\n",
      "epoch 1017, eval score: 6.9760, perfect: 0.40, model saved: False\n",
      "epoch 1017, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1018\n",
      "available: 4.292 GB, used: 24.741 GB, free: 339.414 MB\n",
      "EPOCH: 1018\n",
      "Speed: train: 1142.8, buffer_add: 287.9, buffer_size: 100004\n",
      "Total Time: 15H 43M 51S, 56631s\n",
      "Total Sample: train: 65.216M, buffer: 16.276M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.92%\n",
      "\tsample data       : 0 MS, 1.75%\n",
      "\tforward & backward: 36 MS, 65.12%\n",
      "\tupdate model      : 16 MS, 29.11%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.92 ms\n",
      "[1018] Time spent = 56.01 s\n",
      "1018:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1018:grad_norm [1000]: avg:   2.3089, min:   0.6261[ 652], max:   6.8867[ 834]\n",
      "1018:loss      [1000]: avg:   0.6278, min:   0.1152[ 652], max:   0.9634[  34]\n",
      "1018:rl_loss   [1000]: avg:   0.1118, min:   0.0575[ 821], max:   0.2973[ 766]\n",
      "epoch 1018, eval score: 6.9920, perfect: 0.10, model saved: False\n",
      "epoch 1018, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1019\n",
      "available: 4.280 GB, used: 24.753 GB, free: 326.410 MB\n",
      "EPOCH: 1019\n",
      "Speed: train: 1176.6, buffer_add: 283.6, buffer_size: 100000\n",
      "Total Time: 15H 44M 45S, 56685s\n",
      "Total Sample: train: 65.28M, buffer: 16.292M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.75%\n",
      "\tsample data       : 1 MS, 1.91%\n",
      "\tforward & backward: 35 MS, 65.44%\n",
      "\tupdate model      : 15 MS, 28.80%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 54.33 ms\n",
      "[1019] Time spent = 54.40 s\n",
      "1019:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1019:grad_norm [1000]: avg:   2.2398, min:   0.6686[ 260], max:   5.9733[ 871]\n",
      "1019:loss      [1000]: avg:   0.6198, min:   0.2663[ 218], max:   0.9259[ 920]\n",
      "1019:rl_loss   [1000]: avg:   0.1115, min:   0.0564[ 998], max:   0.3392[ 755]\n",
      "epoch 1019, eval score: 6.9690, perfect: 0.00, model saved: False\n",
      "epoch 1019, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  1020\n",
      "available: 4.291 GB, used: 24.742 GB, free: 338.242 MB\n",
      "EPOCH: 1020\n",
      "Speed: train: 1142.3, buffer_add: 287.8, buffer_size: 100016\n",
      "Total Time: 15H 45M 41S, 56741s\n",
      "Total Sample: train: 65.344M, buffer: 16.308M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.05%\n",
      "\tsample data       : 1 MS, 1.92%\n",
      "\tforward & backward: 36 MS, 65.24%\n",
      "\tupdate model      : 16 MS, 28.70%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.96 ms\n",
      "[1020] Time spent = 56.03 s\n",
      "1020:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1020:grad_norm [1000]: avg:   2.3116, min:   0.4739[ 379], max:   5.9259[ 837]\n",
      "1020:loss      [1000]: avg:   0.6243, min:   0.2545[ 379], max:   0.9358[ 795]\n",
      "1020:rl_loss   [1000]: avg:   0.1102, min:   0.0553[ 842], max:   0.2927[ 259]\n",
      "epoch 1020, eval score: 6.8450, perfect: 0.00, model saved: False\n",
      "epoch 1020, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1021\n",
      "available: 4.278 GB, used: 24.755 GB, free: 324.523 MB\n",
      "EPOCH: 1021\n",
      "Speed: train: 1139.3, buffer_add: 286.9, buffer_size: 100012\n",
      "Total Time: 15H 46M 38S, 56798s\n",
      "Total Sample: train: 65.408M, buffer: 16.324M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.38%\n",
      "\tsample data       : 1 MS, 2.10%\n",
      "\tforward & backward: 36 MS, 64.44%\n",
      "\tupdate model      : 16 MS, 28.95%\n",
      "\tupdating priority : 0 MS, 0.14%\n",
      "@@@total time per iter: 56.09 ms\n",
      "[1021] Time spent = 56.18 s\n",
      "1021:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1021:grad_norm [1000]: avg:   2.2010, min:   0.5753[ 241], max:   6.3869[ 795]\n",
      "1021:loss      [1000]: avg:   0.6186, min:   0.2391[ 241], max:   0.9797[ 934]\n",
      "1021:rl_loss   [1000]: avg:   0.1125, min:   0.0511[ 307], max:   0.2969[ 749]\n",
      "epoch 1021, eval score: 6.9670, perfect: 0.30, model saved: False\n",
      "epoch 1021, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  1022\n",
      "available: 4.285 GB, used: 24.748 GB, free: 331.996 MB\n",
      "EPOCH: 1022\n",
      "Speed: train: 1134.1, buffer_add: 289.4, buffer_size: 100008\n",
      "Total Time: 15H 47M 34S, 56854s\n",
      "Total Sample: train: 65.472M, buffer: 16.34M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.74%\n",
      "\tsample data       : 1 MS, 1.83%\n",
      "\tforward & backward: 36 MS, 65.59%\n",
      "\tupdate model      : 16 MS, 28.73%\n",
      "\tupdating priority : 0 MS, 0.12%\n",
      "@@@total time per iter: 56.37 ms\n",
      "[1022] Time spent = 56.43 s\n",
      "1022:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1022:grad_norm [1000]: avg:   2.2373, min:   0.5629[ 886], max:   6.6860[ 976]\n",
      "1022:loss      [1000]: avg:   0.6182, min:   0.3195[ 539], max:   0.9358[ 217]\n",
      "1022:rl_loss   [1000]: avg:   0.1105, min:   0.0489[ 300], max:   0.2953[ 609]\n",
      "epoch 1022, eval score: 6.9520, perfect: 0.10, model saved: False\n",
      "epoch 1022, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1023\n",
      "available: 4.291 GB, used: 24.742 GB, free: 337.785 MB\n",
      "EPOCH: 1023\n",
      "Speed: train: 1140.8, buffer_add: 285.0, buffer_size: 100000\n",
      "Total Time: 15H 48M 30S, 56910s\n",
      "Total Sample: train: 65.536M, buffer: 16.356M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.83%\n",
      "\tsample data       : 0 MS, 1.62%\n",
      "\tforward & backward: 36 MS, 65.85%\n",
      "\tupdate model      : 16 MS, 28.59%\n",
      "\tupdating priority : 0 MS, 0.12%\n",
      "@@@total time per iter: 56.02 ms\n",
      "[1023] Time spent = 56.10 s\n",
      "1023:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1023:grad_norm [1000]: avg:   2.2764, min:   0.5433[ 588], max:   6.4398[ 877]\n",
      "1023:loss      [1000]: avg:   0.6278, min:   0.1768[ 588], max:   0.9028[  51]\n",
      "1023:rl_loss   [1000]: avg:   0.1144, min:   0.0494[  55], max:   0.3047[ 822]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1023, eval score: 6.9210, perfect: 0.00, model saved: False\n",
      "epoch 1023, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  1024\n",
      "available: 4.281 GB, used: 24.752 GB, free: 327.480 MB\n",
      "EPOCH: 1024\n",
      "Speed: train: 1146.1, buffer_add: 287.1, buffer_size: 100000\n",
      "Total Time: 15H 49M 26S, 56966s\n",
      "Total Sample: train: 65.6M, buffer: 16.372M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.68%\n",
      "\tsample data       : 1 MS, 2.28%\n",
      "\tforward & backward: 36 MS, 65.28%\n",
      "\tupdate model      : 15 MS, 28.66%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.78 ms\n",
      "[1024] Time spent = 55.84 s\n",
      "1024:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1024:grad_norm [1000]: avg:   2.2581, min:   0.4337[  24], max:   6.3881[ 613]\n",
      "1024:loss      [1000]: avg:   0.6296, min:   0.2942[ 200], max:   0.9396[ 358]\n",
      "1024:rl_loss   [1000]: avg:   0.1148, min:   0.0367[ 125], max:   0.2897[ 609]\n",
      "epoch 1024, eval score: 6.8660, perfect: 0.00, model saved: False\n",
      "epoch 1024, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  1025\n",
      "available: 4.284 GB, used: 24.749 GB, free: 330.457 MB\n",
      "EPOCH: 1025\n",
      "Speed: train: 1154.8, buffer_add: 286.3, buffer_size: 100000\n",
      "Total Time: 15H 50M 21S, 57021s\n",
      "Total Sample: train: 65.664M, buffer: 16.388M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.63%\n",
      "\tsample data       : 1 MS, 1.93%\n",
      "\tforward & backward: 36 MS, 65.34%\n",
      "\tupdate model      : 16 MS, 29.00%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.34 ms\n",
      "[1025] Time spent = 55.42 s\n",
      "1025:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1025:grad_norm [1000]: avg:   2.2766, min:   0.5288[ 658], max:   6.4838[ 259]\n",
      "1025:loss      [1000]: avg:   0.6312, min:   0.3169[ 751], max:   0.9544[ 339]\n",
      "1025:rl_loss   [1000]: avg:   0.1152, min:   0.0561[ 973], max:   0.3764[ 799]\n",
      "epoch 1025, eval score: 6.8370, perfect: 0.00, model saved: False\n",
      "epoch 1025, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  1026\n",
      "available: 4.287 GB, used: 24.746 GB, free: 333.230 MB\n",
      "EPOCH: 1026\n",
      "Speed: train: 1164.6, buffer_add: 289.4, buffer_size: 100020\n",
      "Total Time: 15H 51M 16S, 57076s\n",
      "Total Sample: train: 65.728M, buffer: 16.404M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.85%\n",
      "\tsample data       : 1 MS, 2.02%\n",
      "\tforward & backward: 35 MS, 64.53%\n",
      "\tupdate model      : 16 MS, 29.51%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 54.88 ms\n",
      "[1026] Time spent = 54.96 s\n",
      "1026:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1026:grad_norm [1000]: avg:   2.3093, min:   0.7503[ 515], max:   6.5258[ 441]\n",
      "1026:loss      [1000]: avg:   0.6319, min:   0.2663[  12], max:   0.9229[ 588]\n",
      "1026:rl_loss   [1000]: avg:   0.1125, min:   0.0530[ 136], max:   0.2799[ 374]\n",
      "epoch 1026, eval score: 6.8990, perfect: 0.20, model saved: False\n",
      "epoch 1026, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1027\n",
      "available: 4.290 GB, used: 24.743 GB, free: 336.113 MB\n",
      "EPOCH: 1027\n",
      "Speed: train: 1153.4, buffer_add: 286.2, buffer_size: 100012\n",
      "Total Time: 15H 52M 12S, 57132s\n",
      "Total Sample: train: 65.792M, buffer: 16.42M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.75%\n",
      "\tsample data       : 1 MS, 1.97%\n",
      "\tforward & backward: 35 MS, 64.84%\n",
      "\tupdate model      : 16 MS, 29.35%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.42 ms\n",
      "[1027] Time spent = 55.51 s\n",
      "1027:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1027:grad_norm [1000]: avg:   2.2958, min:   0.6829[ 404], max:   6.5301[ 146]\n",
      "1027:loss      [1000]: avg:   0.6315, min:   0.1454[ 404], max:   1.0244[ 349]\n",
      "1027:rl_loss   [1000]: avg:   0.1113, min:   0.0614[ 442], max:   0.3871[ 467]\n",
      "epoch 1027, eval score: 6.8630, perfect: 0.10, model saved: False\n",
      "epoch 1027, success rate for sampling ficticious state: 99.85%\n",
      "==========\n",
      "beginning of epoch:  1028\n",
      "available: 4.291 GB, used: 24.743 GB, free: 336.305 MB\n",
      "EPOCH: 1028\n",
      "Speed: train: 1168.4, buffer_add: 284.9, buffer_size: 100038\n",
      "Total Time: 15H 53M 07S, 57187s\n",
      "Total Sample: train: 65.856M, buffer: 16.436M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.76%\n",
      "\tsample data       : 1 MS, 1.95%\n",
      "\tforward & backward: 35 MS, 65.67%\n",
      "\tupdate model      : 15 MS, 28.53%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 54.70 ms\n",
      "[1028] Time spent = 54.78 s\n",
      "1028:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1028:grad_norm [1000]: avg:   2.2504, min:   0.5668[ 228], max:   7.4164[ 534]\n",
      "1028:loss      [1000]: avg:   0.6425, min:   0.2441[ 291], max:   0.9573[ 823]\n",
      "1028:rl_loss   [1000]: avg:   0.1140, min:   0.0577[ 691], max:   0.3049[ 161]\n",
      "epoch 1028, eval score: 6.8740, perfect: 0.00, model saved: False\n",
      "epoch 1028, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  1029\n",
      "available: 4.287 GB, used: 24.746 GB, free: 332.758 MB\n",
      "EPOCH: 1029\n",
      "Speed: train: 1151.9, buffer_add: 288.3, buffer_size: 100011\n",
      "Total Time: 15H 54M 02S, 57242s\n",
      "Total Sample: train: 65.92M, buffer: 16.452M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.66%\n",
      "\tsample data       : 1 MS, 2.20%\n",
      "\tforward & backward: 36 MS, 65.48%\n",
      "\tupdate model      : 15 MS, 28.57%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.48 ms\n",
      "[1029] Time spent = 55.57 s\n",
      "1029:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1029:grad_norm [1000]: avg:   2.2942, min:   0.5898[ 629], max:   5.9848[ 229]\n",
      "1029:loss      [1000]: avg:   0.6351, min:   0.2529[ 380], max:   0.9499[ 533]\n",
      "1029:rl_loss   [1000]: avg:   0.1125, min:   0.0516[ 782], max:   0.3002[ 995]\n",
      "epoch 1029, eval score: 6.8140, perfect: 0.10, model saved: False\n",
      "epoch 1029, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1030\n",
      "available: 4.289 GB, used: 24.744 GB, free: 334.660 MB\n",
      "EPOCH: 1030\n",
      "Speed: train: 1160.3, buffer_add: 288.4, buffer_size: 100040\n",
      "Total Time: 15H 54M 57S, 57297s\n",
      "Total Sample: train: 65.984M, buffer: 16.468M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.76%\n",
      "\tsample data       : 1 MS, 2.19%\n",
      "\tforward & backward: 35 MS, 64.75%\n",
      "\tupdate model      : 16 MS, 29.21%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.10 ms\n",
      "[1030] Time spent = 55.16 s\n",
      "1030:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1030:grad_norm [1000]: avg:   2.3214, min:   0.6418[ 955], max:   8.4068[ 156]\n",
      "1030:loss      [1000]: avg:   0.6345, min:   0.1952[ 382], max:   0.9889[ 573]\n",
      "1030:rl_loss   [1000]: avg:   0.1112, min:   0.0614[ 824], max:   0.2434[ 250]\n",
      "epoch 1030, eval score: 6.9170, perfect: 0.00, model saved: False\n",
      "epoch 1030, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1031\n",
      "available: 4.292 GB, used: 24.741 GB, free: 337.434 MB\n",
      "EPOCH: 1031\n",
      "Speed: train: 1147.0, buffer_add: 287.8, buffer_size: 100034\n",
      "Total Time: 15H 55M 53S, 57353s\n",
      "Total Sample: train: 66.048M, buffer: 16.484M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.81%\n",
      "\tsample data       : 1 MS, 1.89%\n",
      "\tforward & backward: 36 MS, 65.37%\n",
      "\tupdate model      : 16 MS, 28.84%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.71 ms\n",
      "[1031] Time spent = 55.80 s\n",
      "1031:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1031:grad_norm [1000]: avg:   2.2683, min:   0.5246[   4], max:   6.7969[ 614]\n",
      "1031:loss      [1000]: avg:   0.6336, min:   0.2129[  76], max:   0.8986[ 141]\n",
      "1031:rl_loss   [1000]: avg:   0.1143, min:   0.0561[ 527], max:   0.2962[ 804]\n",
      "epoch 1031, eval score: 7.0540, perfect: 0.20, model saved: True\n",
      "epoch 1031, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  1032\n",
      "available: 4.291 GB, used: 24.742 GB, free: 336.570 MB\n",
      "EPOCH: 1032\n",
      "Speed: train: 1146.7, buffer_add: 294.7, buffer_size: 100014\n",
      "Total Time: 15H 56M 49S, 57409s\n",
      "Total Sample: train: 66.112M, buffer: 16.5M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.60%\n",
      "\tsample data       : 1 MS, 1.92%\n",
      "\tforward & backward: 36 MS, 65.20%\n",
      "\tupdate model      : 16 MS, 29.18%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.74 ms\n",
      "[1032] Time spent = 55.82 s\n",
      "1032:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1032:grad_norm [1000]: avg:   2.2728, min:   0.7471[ 151], max:   6.6619[ 576]\n",
      "1032:loss      [1000]: avg:   0.6374, min:   0.2760[ 122], max:   0.9579[  75]\n",
      "1032:rl_loss   [1000]: avg:   0.1129, min:   0.0559[ 593], max:   0.3220[ 719]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1032, eval score: 6.9700, perfect: 0.20, model saved: False\n",
      "epoch 1032, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1033\n",
      "available: 4.293 GB, used: 24.741 GB, free: 337.969 MB\n",
      "EPOCH: 1033\n",
      "Speed: train: 1134.5, buffer_add: 291.1, buffer_size: 100048\n",
      "Total Time: 15H 57M 45S, 57465s\n",
      "Total Sample: train: 66.176M, buffer: 16.517M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.99%\n",
      "\tsample data       : 1 MS, 1.89%\n",
      "\tforward & backward: 36 MS, 64.37%\n",
      "\tupdate model      : 16 MS, 29.66%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.35 ms\n",
      "[1033] Time spent = 56.42 s\n",
      "1033:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1033:grad_norm [1000]: avg:   2.4002, min:   0.5452[ 157], max:   7.1883[ 117]\n",
      "1033:loss      [1000]: avg:   0.6375, min:   0.1535[ 157], max:   0.9736[ 249]\n",
      "1033:rl_loss   [1000]: avg:   0.1149, min:   0.0541[ 688], max:   0.3033[ 497]\n",
      "epoch 1033, eval score: 6.8660, perfect: 0.00, model saved: False\n",
      "epoch 1033, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  1034\n",
      "available: 4.287 GB, used: 24.746 GB, free: 331.930 MB\n",
      "EPOCH: 1034\n",
      "Speed: train: 1157.6, buffer_add: 286.9, buffer_size: 100038\n",
      "Total Time: 15H 58M 41S, 57521s\n",
      "Total Sample: train: 66.24M, buffer: 16.532M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.73%\n",
      "\tsample data       : 1 MS, 1.91%\n",
      "\tforward & backward: 36 MS, 65.22%\n",
      "\tupdate model      : 16 MS, 29.06%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.23 ms\n",
      "[1034] Time spent = 55.29 s\n",
      "1034:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1034:grad_norm [1000]: avg:   2.3351, min:   0.6223[ 589], max:   7.7533[ 186]\n",
      "1034:loss      [1000]: avg:   0.6352, min:   0.2272[ 195], max:   1.0407[ 231]\n",
      "1034:rl_loss   [1000]: avg:   0.1134, min:   0.0539[ 822], max:   0.2535[ 519]\n",
      "epoch 1034, eval score: 6.8640, perfect: 0.00, model saved: False\n",
      "epoch 1034, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1035\n",
      "available: 4.288 GB, used: 24.745 GB, free: 332.863 MB\n",
      "EPOCH: 1035\n",
      "Speed: train: 1151.7, buffer_add: 286.0, buffer_size: 100018\n",
      "Total Time: 15H 59M 36S, 57576s\n",
      "Total Sample: train: 66.304M, buffer: 16.548M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.88%\n",
      "\tsample data       : 1 MS, 1.85%\n",
      "\tforward & backward: 36 MS, 65.14%\n",
      "\tupdate model      : 16 MS, 29.02%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.50 ms\n",
      "[1035] Time spent = 55.57 s\n",
      "1035:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1035:grad_norm [1000]: avg:   2.3101, min:   0.7241[ 369], max:   7.1358[  17]\n",
      "1035:loss      [1000]: avg:   0.6243, min:   0.2454[ 898], max:   0.9592[ 126]\n",
      "1035:rl_loss   [1000]: avg:   0.1111, min:   0.0541[ 685], max:   0.2824[ 430]\n",
      "epoch 1035, eval score: 6.9350, perfect: 0.40, model saved: False\n",
      "epoch 1035, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  1036\n",
      "available: 4.289 GB, used: 24.745 GB, free: 333.523 MB\n",
      "EPOCH: 1036\n",
      "Speed: train: 1140.4, buffer_add: 282.3, buffer_size: 100004\n",
      "Total Time: 16H 00M 32S, 57632s\n",
      "Total Sample: train: 66.368M, buffer: 16.564M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.81%\n",
      "\tsample data       : 1 MS, 1.97%\n",
      "\tforward & backward: 36 MS, 65.02%\n",
      "\tupdate model      : 16 MS, 29.11%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.04 ms\n",
      "[1036] Time spent = 56.12 s\n",
      "1036:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1036:grad_norm [1000]: avg:   2.4094, min:   0.5735[ 388], max:   6.5945[ 207]\n",
      "1036:loss      [1000]: avg:   0.6274, min:   0.2458[ 388], max:   0.9377[ 424]\n",
      "1036:rl_loss   [1000]: avg:   0.1104, min:   0.0499[ 443], max:   0.3020[ 249]\n",
      "epoch 1036, eval score: 6.9100, perfect: 0.10, model saved: False\n",
      "epoch 1036, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1037\n",
      "available: 4.290 GB, used: 24.743 GB, free: 334.977 MB\n",
      "EPOCH: 1037\n",
      "Speed: train: 1159.6, buffer_add: 286.2, buffer_size: 100012\n",
      "Total Time: 16H 01M 28S, 57688s\n",
      "Total Sample: train: 66.432M, buffer: 16.58M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.93%\n",
      "\tsample data       : 1 MS, 1.91%\n",
      "\tforward & backward: 36 MS, 65.43%\n",
      "\tupdate model      : 15 MS, 28.64%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.11 ms\n",
      "[1037] Time spent = 55.19 s\n",
      "1037:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1037:grad_norm [1000]: avg:   2.3539, min:   0.5288[ 368], max:   8.2698[ 755]\n",
      "1037:loss      [1000]: avg:   0.6226, min:   0.2263[ 368], max:   0.9287[  58]\n",
      "1037:rl_loss   [1000]: avg:   0.1076, min:   0.0509[ 629], max:   0.2709[ 633]\n",
      "epoch 1037, eval score: 6.8120, perfect: 0.00, model saved: False\n",
      "epoch 1037, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1038\n",
      "available: 4.288 GB, used: 24.745 GB, free: 332.680 MB\n",
      "EPOCH: 1038\n",
      "Speed: train: 1173.6, buffer_add: 284.9, buffer_size: 100002\n",
      "Total Time: 16H 02M 22S, 57742s\n",
      "Total Sample: train: 66.496M, buffer: 16.595M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.71%\n",
      "\tsample data       : 1 MS, 1.89%\n",
      "\tforward & backward: 35 MS, 65.34%\n",
      "\tupdate model      : 15 MS, 28.94%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 54.43 ms\n",
      "[1038] Time spent = 54.53 s\n",
      "1038:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1038:grad_norm [1000]: avg:   2.2723, min:   0.6732[ 503], max:   7.6800[ 807]\n",
      "1038:loss      [1000]: avg:   0.6217, min:   0.2869[ 440], max:   0.9256[ 153]\n",
      "1038:rl_loss   [1000]: avg:   0.1092, min:   0.0517[ 961], max:   0.2921[  43]\n",
      "epoch 1038, eval score: 6.8010, perfect: 0.10, model saved: False\n",
      "epoch 1038, success rate for sampling ficticious state: 99.80%\n",
      "==========\n",
      "beginning of epoch:  1039\n",
      "available: 4.277 GB, used: 24.756 GB, free: 321.820 MB\n",
      "EPOCH: 1039\n",
      "Speed: train: 1153.0, buffer_add: 286.0, buffer_size: 100008\n",
      "Total Time: 16H 03M 18S, 57798s\n",
      "Total Sample: train: 66.56M, buffer: 16.611M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.87%\n",
      "\tsample data       : 1 MS, 1.81%\n",
      "\tforward & backward: 36 MS, 65.86%\n",
      "\tupdate model      : 15 MS, 28.35%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.45 ms\n",
      "[1039] Time spent = 55.51 s\n",
      "1039:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1039:grad_norm [1000]: avg:   2.2618, min:   0.6235[ 278], max:   8.8001[ 186]\n",
      "1039:loss      [1000]: avg:   0.6261, min:   0.2729[ 278], max:   0.9114[ 567]\n",
      "1039:rl_loss   [1000]: avg:   0.1135, min:   0.0547[ 268], max:   0.3368[ 623]\n",
      "epoch 1039, eval score: 6.9360, perfect: 0.20, model saved: False\n",
      "epoch 1039, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1040\n",
      "available: 4.280 GB, used: 24.753 GB, free: 324.199 MB\n",
      "EPOCH: 1040\n",
      "Speed: train: 1156.4, buffer_add: 283.7, buffer_size: 100010\n",
      "Total Time: 16H 04M 13S, 57853s\n",
      "Total Sample: train: 66.624M, buffer: 16.627M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.94%\n",
      "\tsample data       : 1 MS, 1.92%\n",
      "\tforward & backward: 36 MS, 65.27%\n",
      "\tupdate model      : 15 MS, 28.75%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.27 ms\n",
      "[1040] Time spent = 55.35 s\n",
      "1040:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1040:grad_norm [1000]: avg:   2.3640, min:   0.7011[ 596], max:   6.9501[ 802]\n",
      "1040:loss      [1000]: avg:   0.6247, min:   0.3094[ 354], max:   0.9964[  84]\n",
      "1040:rl_loss   [1000]: avg:   0.1098, min:   0.0514[ 812], max:   0.2603[ 624]\n",
      "epoch 1040, eval score: 6.9750, perfect: 0.30, model saved: False\n",
      "epoch 1040, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  1041\n",
      "available: 4.288 GB, used: 24.746 GB, free: 332.074 MB\n",
      "EPOCH: 1041\n",
      "Speed: train: 1142.7, buffer_add: 290.0, buffer_size: 100020\n",
      "Total Time: 16H 05M 09S, 57909s\n",
      "Total Sample: train: 66.688M, buffer: 16.643M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.10%\n",
      "\tsample data       : 1 MS, 1.85%\n",
      "\tforward & backward: 35 MS, 64.08%\n",
      "\tupdate model      : 16 MS, 29.88%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.93 ms\n",
      "[1041] Time spent = 56.01 s\n",
      "1041:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1041:grad_norm [1000]: avg:   2.4127, min:   0.3852[ 384], max:   7.8583[ 489]\n",
      "1041:loss      [1000]: avg:   0.6265, min:   0.1759[ 384], max:   0.9231[ 829]\n",
      "1041:rl_loss   [1000]: avg:   0.1107, min:   0.0551[ 815], max:   0.2936[ 575]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1041, eval score: 6.8400, perfect: 0.00, model saved: False\n",
      "epoch 1041, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  1042\n",
      "available: 4.286 GB, used: 24.747 GB, free: 330.758 MB\n",
      "EPOCH: 1042\n",
      "Speed: train: 1146.8, buffer_add: 284.6, buffer_size: 100004\n",
      "Total Time: 16H 06M 05S, 57965s\n",
      "Total Sample: train: 66.752M, buffer: 16.659M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.68%\n",
      "\tsample data       : 1 MS, 2.09%\n",
      "\tforward & backward: 36 MS, 65.00%\n",
      "\tupdate model      : 16 MS, 29.14%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.74 ms\n",
      "[1042] Time spent = 55.81 s\n",
      "1042:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1042:grad_norm [1000]: avg:   2.3318, min:   0.5457[ 404], max:   7.0598[ 747]\n",
      "1042:loss      [1000]: avg:   0.6335, min:   0.2626[ 254], max:   0.9360[  16]\n",
      "1042:rl_loss   [1000]: avg:   0.1148, min:   0.0513[  50], max:   0.3088[  92]\n",
      "epoch 1042, eval score: 6.9160, perfect: 0.20, model saved: False\n",
      "epoch 1042, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1043\n",
      "available: 4.283 GB, used: 24.751 GB, free: 326.766 MB\n",
      "EPOCH: 1043\n",
      "Speed: train: 1151.8, buffer_add: 289.1, buffer_size: 100008\n",
      "Total Time: 16H 07M 00S, 58020s\n",
      "Total Sample: train: 66.816M, buffer: 16.675M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.89%\n",
      "\tsample data       : 1 MS, 2.29%\n",
      "\tforward & backward: 35 MS, 64.58%\n",
      "\tupdate model      : 16 MS, 29.14%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.50 ms\n",
      "[1043] Time spent = 55.57 s\n",
      "1043:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1043:grad_norm [1000]: avg:   2.3206, min:   0.3077[ 257], max:   8.3983[ 680]\n",
      "1043:loss      [1000]: avg:   0.6353, min:   0.1107[ 257], max:   0.9491[ 690]\n",
      "1043:rl_loss   [1000]: avg:   0.1180, min:   0.0540[ 900], max:   0.4415[ 735]\n",
      "epoch 1043, eval score: 6.9360, perfect: 0.30, model saved: False\n",
      "epoch 1043, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1044\n",
      "available: 4.283 GB, used: 24.751 GB, free: 326.613 MB\n",
      "EPOCH: 1044\n",
      "Speed: train: 1141.6, buffer_add: 287.1, buffer_size: 100008\n",
      "Total Time: 16H 07M 56S, 58076s\n",
      "Total Sample: train: 66.88M, buffer: 16.691M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.91%\n",
      "\tsample data       : 1 MS, 2.33%\n",
      "\tforward & backward: 36 MS, 64.44%\n",
      "\tupdate model      : 16 MS, 29.22%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.99 ms\n",
      "[1044] Time spent = 56.06 s\n",
      "1044:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1044:grad_norm [1000]: avg:   2.3474, min:   0.7145[ 375], max:   5.4704[ 699]\n",
      "1044:loss      [1000]: avg:   0.6332, min:   0.2261[ 101], max:   0.9447[ 647]\n",
      "1044:rl_loss   [1000]: avg:   0.1172, min:   0.0521[ 700], max:   0.3045[ 819]\n",
      "epoch 1044, eval score: 6.9740, perfect: 0.20, model saved: False\n",
      "epoch 1044, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1045\n",
      "available: 4.279 GB, used: 24.754 GB, free: 322.930 MB\n",
      "EPOCH: 1045\n",
      "Speed: train: 1159.1, buffer_add: 284.1, buffer_size: 100016\n",
      "Total Time: 16H 08M 52S, 58132s\n",
      "Total Sample: train: 66.944M, buffer: 16.707M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.59%\n",
      "\tsample data       : 1 MS, 1.87%\n",
      "\tforward & backward: 35 MS, 64.58%\n",
      "\tupdate model      : 16 MS, 29.86%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.13 ms\n",
      "[1045] Time spent = 55.22 s\n",
      "1045:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1045:grad_norm [1000]: avg:   2.2856, min:   0.3164[ 744], max:   6.4861[ 640]\n",
      "1045:loss      [1000]: avg:   0.6312, min:   0.1000[ 744], max:   0.8964[  47]\n",
      "1045:rl_loss   [1000]: avg:   0.1175, min:   0.0527[ 638], max:   0.4513[ 312]\n",
      "epoch 1045, eval score: 6.8770, perfect: 0.00, model saved: False\n",
      "epoch 1045, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  1046\n",
      "available: 4.288 GB, used: 24.746 GB, free: 331.340 MB\n",
      "EPOCH: 1046\n",
      "Speed: train: 1174.1, buffer_add: 284.8, buffer_size: 100033\n",
      "Total Time: 16H 09M 46S, 58186s\n",
      "Total Sample: train: 67.008M, buffer: 16.722M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.72%\n",
      "\tsample data       : 1 MS, 2.07%\n",
      "\tforward & backward: 35 MS, 65.01%\n",
      "\tupdate model      : 15 MS, 29.09%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 54.43 ms\n",
      "[1046] Time spent = 54.51 s\n",
      "1046:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1046:grad_norm [1000]: avg:   2.2872, min:   0.6930[ 367], max:   7.4802[ 477]\n",
      "1046:loss      [1000]: avg:   0.6282, min:   0.2668[ 178], max:   0.9638[ 208]\n",
      "1046:rl_loss   [1000]: avg:   0.1160, min:   0.0495[ 661], max:   0.2709[ 608]\n",
      "epoch 1046, eval score: 6.9530, perfect: 0.20, model saved: False\n",
      "epoch 1046, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  1047\n",
      "available: 4.283 GB, used: 24.750 GB, free: 326.762 MB\n",
      "EPOCH: 1047\n",
      "Speed: train: 1147.4, buffer_add: 285.4, buffer_size: 100014\n",
      "Total Time: 16H 10M 42S, 58242s\n",
      "Total Sample: train: 67.072M, buffer: 16.738M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.74%\n",
      "\tsample data       : 0 MS, 1.67%\n",
      "\tforward & backward: 36 MS, 65.41%\n",
      "\tupdate model      : 16 MS, 29.08%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.69 ms\n",
      "[1047] Time spent = 55.78 s\n",
      "1047:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1047:grad_norm [1000]: avg:   2.3220, min:   0.4814[  92], max:   7.0198[ 474]\n",
      "1047:loss      [1000]: avg:   0.6417, min:   0.2202[ 956], max:   1.0304[ 780]\n",
      "1047:rl_loss   [1000]: avg:   0.1195, min:   0.0587[ 946], max:   0.3457[ 306]\n",
      "epoch 1047, eval score: 6.8080, perfect: 0.00, model saved: False\n",
      "epoch 1047, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1048\n",
      "available: 4.280 GB, used: 24.754 GB, free: 323.109 MB\n",
      "EPOCH: 1048\n",
      "Speed: train: 1143.6, buffer_add: 285.6, buffer_size: 100028\n",
      "Total Time: 16H 11M 38S, 58298s\n",
      "Total Sample: train: 67.136M, buffer: 16.754M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.62%\n",
      "\tsample data       : 1 MS, 2.02%\n",
      "\tforward & backward: 36 MS, 65.23%\n",
      "\tupdate model      : 16 MS, 29.01%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.87 ms\n",
      "[1048] Time spent = 55.97 s\n",
      "1048:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1048:grad_norm [1000]: avg:   2.3116, min:   0.7356[ 394], max:   6.0274[ 655]\n",
      "1048:loss      [1000]: avg:   0.6400, min:   0.3360[ 503], max:   0.9353[ 204]\n",
      "1048:rl_loss   [1000]: avg:   0.1164, min:   0.0570[ 786], max:   0.2974[ 703]\n",
      "epoch 1048, eval score: 6.9620, perfect: 0.00, model saved: False\n",
      "epoch 1048, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  1049\n",
      "available: 4.279 GB, used: 24.755 GB, free: 322.141 MB\n",
      "EPOCH: 1049\n",
      "Speed: train: 1173.3, buffer_add: 283.1, buffer_size: 100004\n",
      "Total Time: 16H 12M 32S, 58352s\n",
      "Total Sample: train: 67.2M, buffer: 16.77M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.84%\n",
      "\tsample data       : 1 MS, 1.96%\n",
      "\tforward & backward: 35 MS, 65.73%\n",
      "\tupdate model      : 15 MS, 28.38%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 54.49 ms\n",
      "[1049] Time spent = 54.56 s\n",
      "1049:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1049:grad_norm [1000]: avg:   2.2610, min:   0.7495[ 337], max:   6.1426[ 780]\n",
      "1049:loss      [1000]: avg:   0.6401, min:   0.2207[ 798], max:   0.9483[ 198]\n",
      "1049:rl_loss   [1000]: avg:   0.1140, min:   0.0579[ 483], max:   0.2680[ 801]\n",
      "epoch 1049, eval score: 7.0050, perfect: 0.10, model saved: False\n",
      "epoch 1049, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1050\n",
      "available: 4.264 GB, used: 24.769 GB, free: 318.262 MB\n",
      "EPOCH: 1050\n",
      "Speed: train: 1163.0, buffer_add: 288.0, buffer_size: 100006\n",
      "Total Time: 16H 13M 27S, 58407s\n",
      "Total Sample: train: 67.264M, buffer: 16.786M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.77%\n",
      "\tsample data       : 0 MS, 1.73%\n",
      "\tforward & backward: 35 MS, 64.86%\n",
      "\tupdate model      : 16 MS, 29.52%\n",
      "\tupdating priority : 0 MS, 0.12%\n",
      "@@@total time per iter: 54.97 ms\n",
      "[1050] Time spent = 55.03 s\n",
      "1050:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1050:grad_norm [1000]: avg:   2.3317, min:   0.7254[ 741], max:   6.9958[ 334]\n",
      "1050:loss      [1000]: avg:   0.6331, min:   0.2330[  99], max:   0.9224[ 674]\n",
      "1050:rl_loss   [1000]: avg:   0.1131, min:   0.0563[ 968], max:   0.3140[ 402]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1050, eval score: 6.9500, perfect: 0.10, model saved: False\n",
      "epoch 1050, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1051\n",
      "available: 4.276 GB, used: 24.758 GB, free: 330.219 MB\n",
      "EPOCH: 1051\n",
      "Speed: train: 1176.5, buffer_add: 286.2, buffer_size: 100006\n",
      "Total Time: 16H 14M 22S, 58462s\n",
      "Total Sample: train: 67.328M, buffer: 16.801M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.07%\n",
      "\tsample data       : 1 MS, 2.12%\n",
      "\tforward & backward: 35 MS, 64.64%\n",
      "\tupdate model      : 15 MS, 29.08%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 54.34 ms\n",
      "[1051] Time spent = 54.40 s\n",
      "1051:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1051:grad_norm [1000]: avg:   2.3664, min:   0.5675[ 752], max:   6.8310[ 487]\n",
      "1051:loss      [1000]: avg:   0.6396, min:   0.2708[ 146], max:   0.9193[ 367]\n",
      "1051:rl_loss   [1000]: avg:   0.1140, min:   0.0559[ 483], max:   0.3071[ 531]\n",
      "epoch 1051, eval score: 7.0100, perfect: 0.20, model saved: False\n",
      "epoch 1051, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1052\n",
      "available: 4.284 GB, used: 24.750 GB, free: 338.406 MB\n",
      "EPOCH: 1052\n",
      "Speed: train: 1145.8, buffer_add: 289.2, buffer_size: 100004\n",
      "Total Time: 16H 15M 18S, 58518s\n",
      "Total Sample: train: 67.392M, buffer: 16.817M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.71%\n",
      "\tsample data       : 1 MS, 2.19%\n",
      "\tforward & backward: 36 MS, 65.15%\n",
      "\tupdate model      : 16 MS, 28.82%\n",
      "\tupdating priority : 0 MS, 0.13%\n",
      "@@@total time per iter: 55.79 ms\n",
      "[1052] Time spent = 55.86 s\n",
      "1052:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1052:grad_norm [1000]: avg:   2.3769, min:   0.4782[ 294], max:   9.3289[ 289]\n",
      "1052:loss      [1000]: avg:   0.6442, min:   0.2258[ 942], max:   1.0330[ 657]\n",
      "1052:rl_loss   [1000]: avg:   0.1153, min:   0.0542[ 722], max:   0.3234[ 644]\n",
      "epoch 1052, eval score: 6.9470, perfect: 0.10, model saved: False\n",
      "epoch 1052, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1053\n",
      "available: 4.280 GB, used: 24.753 GB, free: 334.355 MB\n",
      "EPOCH: 1053\n",
      "Speed: train: 1148.8, buffer_add: 284.8, buffer_size: 100004\n",
      "Total Time: 16H 16M 13S, 58573s\n",
      "Total Sample: train: 67.456M, buffer: 16.833M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.86%\n",
      "\tsample data       : 1 MS, 2.13%\n",
      "\tforward & backward: 36 MS, 65.58%\n",
      "\tupdate model      : 15 MS, 28.33%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.63 ms\n",
      "[1053] Time spent = 55.71 s\n",
      "1053:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1053:grad_norm [1000]: avg:   2.3747, min:   0.6781[ 597], max:   6.4515[  80]\n",
      "1053:loss      [1000]: avg:   0.6372, min:   0.2387[ 426], max:   0.9446[ 349]\n",
      "1053:rl_loss   [1000]: avg:   0.1130, min:   0.0543[ 560], max:   0.2728[ 317]\n",
      "epoch 1053, eval score: 7.0680, perfect: 0.00, model saved: True\n",
      "epoch 1053, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1054\n",
      "available: 4.277 GB, used: 24.757 GB, free: 330.754 MB\n",
      "EPOCH: 1054\n",
      "Speed: train: 1162.2, buffer_add: 289.3, buffer_size: 100002\n",
      "Total Time: 16H 17M 08S, 58628s\n",
      "Total Sample: train: 67.52M, buffer: 16.849M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.65%\n",
      "\tsample data       : 1 MS, 1.92%\n",
      "\tforward & backward: 36 MS, 65.82%\n",
      "\tupdate model      : 15 MS, 28.49%\n",
      "\tupdating priority : 0 MS, 0.13%\n",
      "@@@total time per iter: 54.99 ms\n",
      "[1054] Time spent = 55.07 s\n",
      "1054:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1054:grad_norm [1000]: avg:   2.3472, min:   0.6333[ 104], max:   8.7591[ 742]\n",
      "1054:loss      [1000]: avg:   0.6380, min:   0.0932[ 334], max:   0.9668[ 166]\n",
      "1054:rl_loss   [1000]: avg:   0.1126, min:   0.0593[ 169], max:   0.3152[ 136]\n",
      "epoch 1054, eval score: 6.9630, perfect: 0.10, model saved: False\n",
      "epoch 1054, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1055\n",
      "available: 4.278 GB, used: 24.755 GB, free: 332.605 MB\n",
      "EPOCH: 1055\n",
      "Speed: train: 1135.7, buffer_add: 286.9, buffer_size: 100038\n",
      "Total Time: 16H 18M 05S, 58685s\n",
      "Total Sample: train: 67.584M, buffer: 16.865M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.66%\n",
      "\tsample data       : 0 MS, 1.72%\n",
      "\tforward & backward: 36 MS, 65.26%\n",
      "\tupdate model      : 16 MS, 29.26%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.29 ms\n",
      "[1055] Time spent = 56.35 s\n",
      "1055:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1055:grad_norm [1000]: avg:   2.3546, min:   0.7300[ 949], max:   8.7732[ 663]\n",
      "1055:loss      [1000]: avg:   0.6384, min:   0.3028[ 650], max:   0.9514[ 742]\n",
      "1055:rl_loss   [1000]: avg:   0.1125, min:   0.0485[ 389], max:   0.2877[ 800]\n",
      "epoch 1055, eval score: 6.9670, perfect: 0.10, model saved: False\n",
      "epoch 1055, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  1056\n",
      "available: 4.277 GB, used: 24.756 GB, free: 330.871 MB\n",
      "EPOCH: 1056\n",
      "Speed: train: 1139.2, buffer_add: 287.2, buffer_size: 100008\n",
      "Total Time: 16H 19M 01S, 58741s\n",
      "Total Sample: train: 67.648M, buffer: 16.882M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.70%\n",
      "\tsample data       : 0 MS, 1.68%\n",
      "\tforward & backward: 36 MS, 64.90%\n",
      "\tupdate model      : 16 MS, 29.61%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 56.12 ms\n",
      "[1056] Time spent = 56.19 s\n",
      "1056:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1056:grad_norm [1000]: avg:   2.3885, min:   0.5313[ 936], max:   6.4076[ 783]\n",
      "1056:loss      [1000]: avg:   0.6399, min:   0.2439[ 936], max:   0.9822[ 911]\n",
      "1056:rl_loss   [1000]: avg:   0.1135, min:   0.0499[ 515], max:   0.3028[ 745]\n",
      "epoch 1056, eval score: 6.8800, perfect: 0.20, model saved: False\n",
      "epoch 1056, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1057\n",
      "available: 4.282 GB, used: 24.751 GB, free: 335.875 MB\n",
      "EPOCH: 1057\n",
      "Speed: train: 1145.6, buffer_add: 285.8, buffer_size: 100021\n",
      "Total Time: 16H 19M 57S, 58797s\n",
      "Total Sample: train: 67.712M, buffer: 16.897M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.97%\n",
      "\tsample data       : 1 MS, 2.13%\n",
      "\tforward & backward: 36 MS, 64.88%\n",
      "\tupdate model      : 16 MS, 28.91%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.75 ms\n",
      "[1057] Time spent = 55.87 s\n",
      "1057:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1057:grad_norm [1000]: avg:   2.2823, min:   0.5966[ 457], max:   6.5257[ 935]\n",
      "1057:loss      [1000]: avg:   0.6317, min:   0.2661[ 224], max:   0.9894[ 560]\n",
      "1057:rl_loss   [1000]: avg:   0.1152, min:   0.0507[ 561], max:   0.2971[ 916]\n",
      "epoch 1057, eval score: 6.8970, perfect: 0.10, model saved: False\n",
      "epoch 1057, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1058\n",
      "available: 4.282 GB, used: 24.751 GB, free: 335.875 MB\n",
      "EPOCH: 1058\n",
      "Speed: train: 1167.8, buffer_add: 284.4, buffer_size: 100001\n",
      "Total Time: 16H 20M 52S, 58852s\n",
      "Total Sample: train: 67.776M, buffer: 16.913M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.61%\n",
      "\tsample data       : 0 MS, 1.82%\n",
      "\tforward & backward: 36 MS, 65.83%\n",
      "\tupdate model      : 15 MS, 28.63%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 54.74 ms\n",
      "[1058] Time spent = 54.81 s\n",
      "1058:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1058:grad_norm [1000]: avg:   2.2571, min:   0.7611[ 792], max:   8.2413[ 652]\n",
      "1058:loss      [1000]: avg:   0.6358, min:   0.2234[ 720], max:   0.9503[   7]\n",
      "1058:rl_loss   [1000]: avg:   0.1180, min:   0.0570[ 824], max:   0.2986[ 420]\n",
      "epoch 1058, eval score: 6.9970, perfect: 0.00, model saved: False\n",
      "epoch 1058, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1059\n",
      "available: 4.281 GB, used: 24.753 GB, free: 334.473 MB\n",
      "EPOCH: 1059\n",
      "Speed: train: 1170.7, buffer_add: 287.7, buffer_size: 100026\n",
      "Total Time: 16H 21M 46S, 58906s\n",
      "Total Sample: train: 67.84M, buffer: 16.929M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.73%\n",
      "\tsample data       : 1 MS, 2.19%\n",
      "\tforward & backward: 35 MS, 64.74%\n",
      "\tupdate model      : 15 MS, 29.20%\n",
      "\tupdating priority : 0 MS, 0.14%\n",
      "@@@total time per iter: 54.60 ms\n",
      "[1059] Time spent = 54.67 s\n",
      "1059:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1059:grad_norm [1000]: avg:   2.3161, min:   0.6109[ 174], max:   8.5213[ 911]\n",
      "1059:loss      [1000]: avg:   0.6472, min:   0.2091[ 174], max:   0.9289[ 554]\n",
      "1059:rl_loss   [1000]: avg:   0.1174, min:   0.0579[ 989], max:   0.2938[ 776]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1059, eval score: 6.7810, perfect: 0.00, model saved: False\n",
      "epoch 1059, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1060\n",
      "available: 4.278 GB, used: 24.755 GB, free: 331.949 MB\n",
      "EPOCH: 1060\n",
      "Speed: train: 1145.5, buffer_add: 285.5, buffer_size: 100010\n",
      "Total Time: 16H 22M 42S, 58962s\n",
      "Total Sample: train: 67.904M, buffer: 16.945M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.88%\n",
      "\tsample data       : 1 MS, 2.05%\n",
      "\tforward & backward: 36 MS, 65.21%\n",
      "\tupdate model      : 16 MS, 28.76%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.80 ms\n",
      "[1060] Time spent = 55.87 s\n",
      "1060:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1060:grad_norm [1000]: avg:   2.2561, min:   0.7052[ 766], max:   6.7710[ 850]\n",
      "1060:loss      [1000]: avg:   0.6474, min:   0.3304[ 178], max:   1.0052[ 587]\n",
      "1060:rl_loss   [1000]: avg:   0.1195, min:   0.0569[ 879], max:   0.3760[ 742]\n",
      "epoch 1060, eval score: 7.0010, perfect: 0.10, model saved: False\n",
      "epoch 1060, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1061\n",
      "available: 4.279 GB, used: 24.755 GB, free: 332.180 MB\n",
      "EPOCH: 1061\n",
      "Speed: train: 1144.9, buffer_add: 284.4, buffer_size: 100026\n",
      "Total Time: 16H 23M 38S, 59018s\n",
      "Total Sample: train: 67.968M, buffer: 16.961M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.12%\n",
      "\tsample data       : 1 MS, 2.20%\n",
      "\tforward & backward: 36 MS, 65.66%\n",
      "\tupdate model      : 15 MS, 27.93%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.83 ms\n",
      "[1061] Time spent = 55.91 s\n",
      "1061:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1061:grad_norm [1000]: avg:   2.2224, min:   0.7374[ 467], max:   5.9672[ 897]\n",
      "1061:loss      [1000]: avg:   0.6479, min:   0.2722[ 837], max:   0.9449[ 567]\n",
      "1061:rl_loss   [1000]: avg:   0.1203, min:   0.0626[ 283], max:   0.3096[   9]\n",
      "epoch 1061, eval score: 6.9300, perfect: 0.10, model saved: False\n",
      "epoch 1061, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1062\n",
      "available: 4.277 GB, used: 24.757 GB, free: 329.637 MB\n",
      "EPOCH: 1062\n",
      "Speed: train: 1169.4, buffer_add: 286.9, buffer_size: 100021\n",
      "Total Time: 16H 24M 33S, 59073s\n",
      "Total Sample: train: 68.032M, buffer: 16.976M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.73%\n",
      "\tsample data       : 0 MS, 1.71%\n",
      "\tforward & backward: 35 MS, 65.56%\n",
      "\tupdate model      : 15 MS, 28.90%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 54.66 ms\n",
      "[1062] Time spent = 54.73 s\n",
      "1062:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1062:grad_norm [1000]: avg:   2.1914, min:   0.4287[ 911], max:   6.8845[ 744]\n",
      "1062:loss      [1000]: avg:   0.6401, min:   0.1585[ 911], max:   0.9875[ 397]\n",
      "1062:rl_loss   [1000]: avg:   0.1193, min:   0.0591[ 792], max:   0.3428[ 326]\n",
      "epoch 1062, eval score: 6.9080, perfect: 0.00, model saved: False\n",
      "epoch 1062, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1063\n",
      "available: 4.285 GB, used: 24.748 GB, free: 338.695 MB\n",
      "EPOCH: 1063\n",
      "Speed: train: 1165.7, buffer_add: 285.2, buffer_size: 100000\n",
      "Total Time: 16H 25M 28S, 59128s\n",
      "Total Sample: train: 68.096M, buffer: 16.992M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.93%\n",
      "\tsample data       : 1 MS, 1.97%\n",
      "\tforward & backward: 35 MS, 65.56%\n",
      "\tupdate model      : 15 MS, 28.43%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 54.83 ms\n",
      "[1063] Time spent = 54.91 s\n",
      "1063:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1063:grad_norm [1000]: avg:   2.2790, min:   0.5702[ 295], max:   7.7403[  48]\n",
      "1063:loss      [1000]: avg:   0.6394, min:   0.1704[ 295], max:   0.9216[  59]\n",
      "1063:rl_loss   [1000]: avg:   0.1180, min:   0.0545[ 875], max:   0.3302[ 549]\n",
      "epoch 1063, eval score: 6.9960, perfect: 0.00, model saved: False\n",
      "epoch 1063, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1064\n",
      "available: 4.272 GB, used: 24.762 GB, free: 324.395 MB\n",
      "EPOCH: 1064\n",
      "Speed: train: 1157.5, buffer_add: 286.3, buffer_size: 100008\n",
      "Total Time: 16H 26M 23S, 59183s\n",
      "Total Sample: train: 68.16M, buffer: 17.008M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.00%\n",
      "\tsample data       : 0 MS, 1.80%\n",
      "\tforward & backward: 35 MS, 64.84%\n",
      "\tupdate model      : 16 MS, 29.26%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.21 ms\n",
      "[1064] Time spent = 55.30 s\n",
      "1064:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1064:grad_norm [1000]: avg:   2.1857, min:   0.6471[ 408], max:   5.9546[ 560]\n",
      "1064:loss      [1000]: avg:   0.6371, min:   0.2076[ 903], max:   0.9051[ 231]\n",
      "1064:rl_loss   [1000]: avg:   0.1174, min:   0.0603[ 704], max:   0.3450[ 579]\n",
      "epoch 1064, eval score: 6.9660, perfect: 0.20, model saved: False\n",
      "epoch 1064, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1065\n",
      "available: 4.278 GB, used: 24.755 GB, free: 331.605 MB\n",
      "EPOCH: 1065\n",
      "Speed: train: 1158.4, buffer_add: 283.5, buffer_size: 100000\n",
      "Total Time: 16H 27M 18S, 59238s\n",
      "Total Sample: train: 68.224M, buffer: 17.023M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.59%\n",
      "\tsample data       : 1 MS, 1.98%\n",
      "\tforward & backward: 36 MS, 65.28%\n",
      "\tupdate model      : 16 MS, 29.06%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.17 ms\n",
      "[1065] Time spent = 55.25 s\n",
      "1065:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1065:grad_norm [1000]: avg:   2.3332, min:   0.3062[ 313], max:   6.3808[ 405]\n",
      "1065:loss      [1000]: avg:   0.6308, min:   0.1278[ 313], max:   0.9563[ 484]\n",
      "1065:rl_loss   [1000]: avg:   0.1147, min:   0.0576[ 903], max:   0.2856[ 777]\n",
      "epoch 1065, eval score: 6.8900, perfect: 0.20, model saved: False\n",
      "epoch 1065, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1066\n",
      "available: 4.267 GB, used: 24.767 GB, free: 318.914 MB\n",
      "EPOCH: 1066\n",
      "Speed: train: 1150.9, buffer_add: 286.6, buffer_size: 100000\n",
      "Total Time: 16H 28M 14S, 59294s\n",
      "Total Sample: train: 68.288M, buffer: 17.039M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.64%\n",
      "\tsample data       : 1 MS, 1.89%\n",
      "\tforward & backward: 36 MS, 65.37%\n",
      "\tupdate model      : 16 MS, 29.02%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.54 ms\n",
      "[1066] Time spent = 55.61 s\n",
      "1066:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1066:grad_norm [1000]: avg:   2.2875, min:   0.5575[ 541], max:   7.2991[ 878]\n",
      "1066:loss      [1000]: avg:   0.6268, min:   0.2332[ 883], max:   0.9676[  11]\n",
      "1066:rl_loss   [1000]: avg:   0.1120, min:   0.0577[ 377], max:   0.2369[ 651]\n",
      "epoch 1066, eval score: 6.8990, perfect: 0.20, model saved: False\n",
      "epoch 1066, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1067\n",
      "available: 4.266 GB, used: 24.767 GB, free: 318.812 MB\n",
      "EPOCH: 1067\n",
      "Speed: train: 1149.2, buffer_add: 282.8, buffer_size: 100010\n",
      "Total Time: 16H 29M 10S, 59350s\n",
      "Total Sample: train: 68.352M, buffer: 17.055M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.75%\n",
      "\tsample data       : 1 MS, 1.96%\n",
      "\tforward & backward: 36 MS, 65.35%\n",
      "\tupdate model      : 16 MS, 28.85%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.62 ms\n",
      "[1067] Time spent = 55.69 s\n",
      "1067:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1067:grad_norm [1000]: avg:   2.3267, min:   0.6296[ 695], max:   7.3162[ 499]\n",
      "1067:loss      [1000]: avg:   0.6327, min:   0.2338[ 403], max:   0.9928[ 441]\n",
      "1067:rl_loss   [1000]: avg:   0.1124, min:   0.0466[  35], max:   0.2737[ 315]\n",
      "epoch 1067, eval score: 6.9170, perfect: 0.20, model saved: False\n",
      "epoch 1067, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1068\n",
      "available: 4.282 GB, used: 24.751 GB, free: 335.289 MB\n",
      "EPOCH: 1068\n",
      "Speed: train: 1160.0, buffer_add: 286.3, buffer_size: 100002\n",
      "Total Time: 16H 30M 05S, 59405s\n",
      "Total Sample: train: 68.416M, buffer: 17.071M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.96%\n",
      "\tsample data       : 1 MS, 1.93%\n",
      "\tforward & backward: 35 MS, 65.30%\n",
      "\tupdate model      : 15 MS, 28.70%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.10 ms\n",
      "[1068] Time spent = 55.18 s\n",
      "1068:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1068:grad_norm [1000]: avg:   2.2982, min:   0.7075[ 708], max:   7.5204[ 565]\n",
      "1068:loss      [1000]: avg:   0.6307, min:   0.2273[ 677], max:   1.0257[ 777]\n",
      "1068:rl_loss   [1000]: avg:   0.1121, min:   0.0603[ 700], max:   0.3255[ 970]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1068, eval score: 6.8410, perfect: 0.10, model saved: False\n",
      "epoch 1068, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1069\n",
      "available: 4.282 GB, used: 24.752 GB, free: 334.477 MB\n",
      "EPOCH: 1069\n",
      "Speed: train: 1167.3, buffer_add: 287.4, buffer_size: 100022\n",
      "Total Time: 16H 31M 00S, 59460s\n",
      "Total Sample: train: 68.48M, buffer: 17.087M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.55%\n",
      "\tsample data       : 1 MS, 1.93%\n",
      "\tforward & backward: 35 MS, 65.47%\n",
      "\tupdate model      : 15 MS, 28.96%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 54.76 ms\n",
      "[1069] Time spent = 54.84 s\n",
      "1069:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1069:grad_norm [1000]: avg:   2.3418, min:   0.8215[  68], max:   8.2096[ 317]\n",
      "1069:loss      [1000]: avg:   0.6383, min:   0.3052[   6], max:   0.9741[ 592]\n",
      "1069:rl_loss   [1000]: avg:   0.1126, min:   0.0561[ 512], max:   0.2423[ 797]\n",
      "epoch 1069, eval score: 6.9580, perfect: 0.00, model saved: False\n",
      "epoch 1069, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1070\n",
      "available: 4.281 GB, used: 24.752 GB, free: 333.699 MB\n",
      "EPOCH: 1070\n",
      "Speed: train: 1135.5, buffer_add: 288.8, buffer_size: 100014\n",
      "Total Time: 16H 31M 56S, 59516s\n",
      "Total Sample: train: 68.544M, buffer: 17.103M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.67%\n",
      "\tsample data       : 1 MS, 1.84%\n",
      "\tforward & backward: 36 MS, 64.61%\n",
      "\tupdate model      : 16 MS, 29.75%\n",
      "\tupdating priority : 0 MS, 0.13%\n",
      "@@@total time per iter: 56.28 ms\n",
      "[1070] Time spent = 56.37 s\n",
      "1070:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1070:grad_norm [1000]: avg:   2.3415, min:   0.6312[ 425], max:   6.1747[ 166]\n",
      "1070:loss      [1000]: avg:   0.6358, min:   0.1735[ 425], max:   0.9779[ 820]\n",
      "1070:rl_loss   [1000]: avg:   0.1134, min:   0.0548[ 986], max:   0.3004[ 655]\n",
      "epoch 1070, eval score: 6.8300, perfect: 0.00, model saved: False\n",
      "epoch 1070, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1071\n",
      "available: 4.279 GB, used: 24.754 GB, free: 331.445 MB\n",
      "EPOCH: 1071\n",
      "Speed: train: 1150.9, buffer_add: 284.8, buffer_size: 100034\n",
      "Total Time: 16H 32M 51S, 59571s\n",
      "Total Sample: train: 68.608M, buffer: 17.119M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.73%\n",
      "\tsample data       : 1 MS, 2.16%\n",
      "\tforward & backward: 35 MS, 64.54%\n",
      "\tupdate model      : 16 MS, 29.47%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.50 ms\n",
      "[1071] Time spent = 55.61 s\n",
      "1071:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1071:grad_norm [1000]: avg:   2.2953, min:   0.8414[ 405], max:   6.9091[  27]\n",
      "1071:loss      [1000]: avg:   0.6405, min:   0.3246[  26], max:   1.0929[ 158]\n",
      "1071:rl_loss   [1000]: avg:   0.1129, min:   0.0534[ 499], max:   0.2590[ 479]\n",
      "epoch 1071, eval score: 6.9540, perfect: 0.10, model saved: False\n",
      "epoch 1071, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1072\n",
      "available: 4.282 GB, used: 24.751 GB, free: 334.281 MB\n",
      "EPOCH: 1072\n",
      "Speed: train: 1170.2, buffer_add: 286.8, buffer_size: 100006\n",
      "Total Time: 16H 33M 46S, 59626s\n",
      "Total Sample: train: 68.672M, buffer: 17.135M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.79%\n",
      "\tsample data       : 1 MS, 2.15%\n",
      "\tforward & backward: 35 MS, 65.38%\n",
      "\tupdate model      : 15 MS, 28.58%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 54.63 ms\n",
      "[1072] Time spent = 54.70 s\n",
      "1072:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1072:grad_norm [1000]: avg:   2.2947, min:   0.7258[ 998], max:   6.6996[  27]\n",
      "1072:loss      [1000]: avg:   0.6398, min:   0.2811[ 517], max:   0.9208[ 789]\n",
      "1072:rl_loss   [1000]: avg:   0.1127, min:   0.0610[  19], max:   0.2475[ 773]\n",
      "epoch 1072, eval score: 6.9870, perfect: 0.20, model saved: False\n",
      "epoch 1072, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1073\n",
      "available: 4.277 GB, used: 24.756 GB, free: 329.586 MB\n",
      "EPOCH: 1073\n",
      "Speed: train: 1179.1, buffer_add: 284.4, buffer_size: 100016\n",
      "Total Time: 16H 34M 40S, 59680s\n",
      "Total Sample: train: 68.736M, buffer: 17.15M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.68%\n",
      "\tsample data       : 1 MS, 2.04%\n",
      "\tforward & backward: 35 MS, 65.17%\n",
      "\tupdate model      : 15 MS, 28.99%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 54.22 ms\n",
      "[1073] Time spent = 54.29 s\n",
      "1073:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1073:grad_norm [1000]: avg:   2.2160, min:   0.7107[ 178], max:   6.1109[ 114]\n",
      "1073:loss      [1000]: avg:   0.6416, min:   0.2330[ 514], max:   1.0236[ 232]\n",
      "1073:rl_loss   [1000]: avg:   0.1152, min:   0.0577[ 978], max:   0.3041[ 674]\n",
      "epoch 1073, eval score: 6.8670, perfect: 0.20, model saved: False\n",
      "epoch 1073, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1074\n",
      "available: 4.280 GB, used: 24.754 GB, free: 331.871 MB\n",
      "EPOCH: 1074\n",
      "Speed: train: 1163.0, buffer_add: 283.0, buffer_size: 100012\n",
      "Total Time: 16H 35M 35S, 59735s\n",
      "Total Sample: train: 68.8M, buffer: 17.166M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.78%\n",
      "\tsample data       : 1 MS, 2.08%\n",
      "\tforward & backward: 35 MS, 65.11%\n",
      "\tupdate model      : 15 MS, 28.94%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 54.96 ms\n",
      "[1074] Time spent = 55.03 s\n",
      "1074:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1074:grad_norm [1000]: avg:   2.2898, min:   0.6894[ 854], max:   6.6440[ 581]\n",
      "1074:loss      [1000]: avg:   0.6402, min:   0.2952[   1], max:   1.0256[ 924]\n",
      "1074:rl_loss   [1000]: avg:   0.1156, min:   0.0598[ 448], max:   0.3077[ 333]\n",
      "epoch 1074, eval score: 6.9110, perfect: 0.00, model saved: False\n",
      "epoch 1074, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1075\n",
      "available: 4.269 GB, used: 24.764 GB, free: 320.859 MB\n",
      "EPOCH: 1075\n",
      "Speed: train: 1162.0, buffer_add: 288.2, buffer_size: 100050\n",
      "Total Time: 16H 36M 31S, 59791s\n",
      "Total Sample: train: 68.864M, buffer: 17.181M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.39%\n",
      "\tsample data       : 1 MS, 1.91%\n",
      "\tforward & backward: 36 MS, 65.94%\n",
      "\tupdate model      : 15 MS, 28.68%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.01 ms\n",
      "[1075] Time spent = 55.08 s\n",
      "1075:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1075:grad_norm [1000]: avg:   2.3418, min:   0.6179[ 297], max:   7.2577[ 749]\n",
      "1075:loss      [1000]: avg:   0.6458, min:   0.2279[ 297], max:   0.9818[  95]\n",
      "1075:rl_loss   [1000]: avg:   0.1185, min:   0.0627[ 874], max:   0.3013[ 738]\n",
      "epoch 1075, eval score: 6.8740, perfect: 0.10, model saved: False\n",
      "epoch 1075, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1076\n",
      "available: 4.273 GB, used: 24.760 GB, free: 324.781 MB\n",
      "EPOCH: 1076\n",
      "Speed: train: 1132.4, buffer_add: 286.8, buffer_size: 100044\n",
      "Total Time: 16H 37M 27S, 59847s\n",
      "Total Sample: train: 68.928M, buffer: 17.198M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.63%\n",
      "\tsample data       : 1 MS, 1.96%\n",
      "\tforward & backward: 36 MS, 64.26%\n",
      "\tupdate model      : 16 MS, 30.06%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.44 ms\n",
      "[1076] Time spent = 56.52 s\n",
      "1076:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1076:grad_norm [1000]: avg:   2.2796, min:   0.8243[ 275], max:   5.9269[ 940]\n",
      "1076:loss      [1000]: avg:   0.6379, min:   0.2770[ 733], max:   0.9304[ 644]\n",
      "1076:rl_loss   [1000]: avg:   0.1180, min:   0.0520[ 364], max:   0.3148[ 646]\n",
      "epoch 1076, eval score: 7.0580, perfect: 0.00, model saved: True\n",
      "epoch 1076, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  1077\n",
      "available: 4.271 GB, used: 24.763 GB, free: 332.660 MB\n",
      "EPOCH: 1077\n",
      "Speed: train: 1161.5, buffer_add: 287.0, buffer_size: 100019\n",
      "Total Time: 16H 38M 22S, 59902s\n",
      "Total Sample: train: 68.992M, buffer: 17.213M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.77%\n",
      "\tsample data       : 1 MS, 2.10%\n",
      "\tforward & backward: 36 MS, 65.63%\n",
      "\tupdate model      : 15 MS, 28.41%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.03 ms\n",
      "[1077] Time spent = 55.10 s\n",
      "1077:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1077:grad_norm [1000]: avg:   2.2637, min:   0.4243[ 198], max:   6.4034[ 206]\n",
      "1077:loss      [1000]: avg:   0.6399, min:   0.2360[ 198], max:   0.9762[ 577]\n",
      "1077:rl_loss   [1000]: avg:   0.1160, min:   0.0591[ 361], max:   0.3036[ 883]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1077, eval score: 6.9170, perfect: 0.00, model saved: False\n",
      "epoch 1077, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  1078\n",
      "available: 4.275 GB, used: 24.758 GB, free: 337.043 MB\n",
      "EPOCH: 1078\n",
      "Speed: train: 1122.0, buffer_add: 283.5, buffer_size: 100000\n",
      "Total Time: 16H 39M 19S, 59959s\n",
      "Total Sample: train: 69.056M, buffer: 17.23M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.03%\n",
      "\tsample data       : 0 MS, 1.73%\n",
      "\tforward & backward: 36 MS, 64.39%\n",
      "\tupdate model      : 16 MS, 29.76%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.98 ms\n",
      "[1078] Time spent = 57.04 s\n",
      "1078:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1078:grad_norm [1000]: avg:   2.3144, min:   0.4166[ 983], max:   5.9104[ 568]\n",
      "1078:loss      [1000]: avg:   0.6355, min:   0.2171[ 983], max:   0.9328[  54]\n",
      "1078:rl_loss   [1000]: avg:   0.1175, min:   0.0534[ 802], max:   0.3794[ 434]\n",
      "epoch 1078, eval score: 6.9430, perfect: 0.30, model saved: False\n",
      "epoch 1078, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  1079\n",
      "available: 4.273 GB, used: 24.760 GB, free: 334.961 MB\n",
      "EPOCH: 1079\n",
      "Speed: train: 1129.0, buffer_add: 285.1, buffer_size: 100018\n",
      "Total Time: 16H 40M 16S, 60016s\n",
      "Total Sample: train: 69.12M, buffer: 17.246M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.77%\n",
      "\tsample data       : 1 MS, 2.13%\n",
      "\tforward & backward: 36 MS, 64.59%\n",
      "\tupdate model      : 16 MS, 29.42%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.61 ms\n",
      "[1079] Time spent = 56.69 s\n",
      "1079:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1079:grad_norm [1000]: avg:   2.3247, min:   0.5821[  15], max:   9.6905[ 626]\n",
      "1079:loss      [1000]: avg:   0.6382, min:   0.2553[  19], max:   0.9628[ 154]\n",
      "1079:rl_loss   [1000]: avg:   0.1179, min:   0.0613[ 106], max:   0.2945[  47]\n",
      "epoch 1079, eval score: 6.9970, perfect: 0.10, model saved: False\n",
      "epoch 1079, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1080\n",
      "available: 4.275 GB, used: 24.758 GB, free: 336.348 MB\n",
      "EPOCH: 1080\n",
      "Speed: train: 1147.0, buffer_add: 284.8, buffer_size: 100028\n",
      "Total Time: 16H 41M 12S, 60072s\n",
      "Total Sample: train: 69.184M, buffer: 17.262M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.79%\n",
      "\tsample data       : 1 MS, 1.90%\n",
      "\tforward & backward: 36 MS, 65.19%\n",
      "\tupdate model      : 16 MS, 29.03%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.71 ms\n",
      "[1080] Time spent = 55.80 s\n",
      "1080:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1080:grad_norm [1000]: avg:   2.3135, min:   0.8032[ 743], max:   6.6863[  14]\n",
      "1080:loss      [1000]: avg:   0.6368, min:   0.2011[  98], max:   0.9810[ 797]\n",
      "1080:rl_loss   [1000]: avg:   0.1177, min:   0.0570[ 213], max:   0.3408[ 147]\n",
      "epoch 1080, eval score: 6.9560, perfect: 0.10, model saved: False\n",
      "epoch 1080, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1081\n",
      "available: 4.268 GB, used: 24.766 GB, free: 328.531 MB\n",
      "EPOCH: 1081\n",
      "Speed: train: 1161.2, buffer_add: 285.8, buffer_size: 100024\n",
      "Total Time: 16H 42M 07S, 60127s\n",
      "Total Sample: train: 69.248M, buffer: 17.277M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.89%\n",
      "\tsample data       : 1 MS, 1.94%\n",
      "\tforward & backward: 36 MS, 65.82%\n",
      "\tupdate model      : 15 MS, 28.23%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.04 ms\n",
      "[1081] Time spent = 55.12 s\n",
      "1081:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1081:grad_norm [1000]: avg:   2.3877, min:   0.7211[ 771], max:   6.9438[ 936]\n",
      "1081:loss      [1000]: avg:   0.6330, min:   0.2444[ 771], max:   1.0325[ 420]\n",
      "1081:rl_loss   [1000]: avg:   0.1138, min:   0.0465[ 863], max:   0.3863[ 953]\n",
      "epoch 1081, eval score: 6.9110, perfect: 0.20, model saved: False\n",
      "epoch 1081, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1082\n",
      "available: 4.262 GB, used: 24.771 GB, free: 323.410 MB\n",
      "EPOCH: 1082\n",
      "Speed: train: 1136.4, buffer_add: 285.7, buffer_size: 100002\n",
      "Total Time: 16H 43M 03S, 60183s\n",
      "Total Sample: train: 69.312M, buffer: 17.294M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.07%\n",
      "\tsample data       : 1 MS, 2.00%\n",
      "\tforward & backward: 36 MS, 64.07%\n",
      "\tupdate model      : 16 MS, 29.76%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 56.24 ms\n",
      "[1082] Time spent = 56.31 s\n",
      "1082:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1082:grad_norm [1000]: avg:   2.3563, min:   0.4482[ 464], max:   6.7128[ 349]\n",
      "1082:loss      [1000]: avg:   0.6366, min:   0.1824[ 464], max:   0.9780[ 446]\n",
      "1082:rl_loss   [1000]: avg:   0.1152, min:   0.0537[ 671], max:   0.3016[ 771]\n",
      "epoch 1082, eval score: 6.9910, perfect: 0.10, model saved: False\n",
      "epoch 1082, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  1083\n",
      "available: 4.267 GB, used: 24.766 GB, free: 327.840 MB\n",
      "EPOCH: 1083\n",
      "Speed: train: 1156.6, buffer_add: 286.4, buffer_size: 100028\n",
      "Total Time: 16H 43M 58S, 60238s\n",
      "Total Sample: train: 69.376M, buffer: 17.309M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.79%\n",
      "\tsample data       : 1 MS, 1.87%\n",
      "\tforward & backward: 35 MS, 64.84%\n",
      "\tupdate model      : 16 MS, 29.41%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.27 ms\n",
      "[1083] Time spent = 55.34 s\n",
      "1083:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1083:grad_norm [1000]: avg:   2.3909, min:   0.7308[ 870], max:   7.3619[ 120]\n",
      "1083:loss      [1000]: avg:   0.6368, min:   0.2422[ 963], max:   1.0027[ 130]\n",
      "1083:rl_loss   [1000]: avg:   0.1167, min:   0.0561[ 242], max:   0.3025[ 586]\n",
      "epoch 1083, eval score: 6.9590, perfect: 0.00, model saved: False\n",
      "epoch 1083, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1084\n",
      "available: 4.272 GB, used: 24.761 GB, free: 333.262 MB\n",
      "EPOCH: 1084\n",
      "Speed: train: 1153.6, buffer_add: 284.3, buffer_size: 100017\n",
      "Total Time: 16H 44M 54S, 60294s\n",
      "Total Sample: train: 69.44M, buffer: 17.325M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.88%\n",
      "\tsample data       : 0 MS, 1.76%\n",
      "\tforward & backward: 35 MS, 64.76%\n",
      "\tupdate model      : 16 MS, 29.49%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.41 ms\n",
      "[1084] Time spent = 55.48 s\n",
      "1084:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1084:grad_norm [1000]: avg:   2.3027, min:   0.5283[ 767], max:   7.1114[ 994]\n",
      "1084:loss      [1000]: avg:   0.6313, min:   0.1684[ 767], max:   0.9009[ 754]\n",
      "1084:rl_loss   [1000]: avg:   0.1170, min:   0.0557[  54], max:   0.2765[ 308]\n",
      "epoch 1084, eval score: 6.9290, perfect: 0.10, model saved: False\n",
      "epoch 1084, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  1085\n",
      "available: 4.276 GB, used: 24.758 GB, free: 336.785 MB\n",
      "EPOCH: 1085\n",
      "Speed: train: 1151.7, buffer_add: 286.5, buffer_size: 100000\n",
      "Total Time: 16H 45M 50S, 60350s\n",
      "Total Sample: train: 69.504M, buffer: 17.341M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.64%\n",
      "\tsample data       : 1 MS, 1.92%\n",
      "\tforward & backward: 36 MS, 65.18%\n",
      "\tupdate model      : 16 MS, 29.15%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.48 ms\n",
      "[1085] Time spent = 55.58 s\n",
      "1085:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1085:grad_norm [1000]: avg:   2.3902, min:   0.5599[ 285], max:   8.3534[ 267]\n",
      "1085:loss      [1000]: avg:   0.6373, min:   0.1704[ 285], max:   0.9662[ 520]\n",
      "1085:rl_loss   [1000]: avg:   0.1168, min:   0.0558[ 979], max:   0.3098[ 713]\n",
      "epoch 1085, eval score: 7.0030, perfect: 0.10, model saved: False\n",
      "epoch 1085, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1086\n",
      "available: 4.274 GB, used: 24.759 GB, free: 334.832 MB\n",
      "EPOCH: 1086\n",
      "Speed: train: 1140.1, buffer_add: 286.5, buffer_size: 100052\n",
      "Total Time: 16H 46M 46S, 60406s\n",
      "Total Sample: train: 69.568M, buffer: 17.357M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.49%\n",
      "\tsample data       : 1 MS, 2.00%\n",
      "\tforward & backward: 36 MS, 64.62%\n",
      "\tupdate model      : 16 MS, 29.79%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.07 ms\n",
      "[1086] Time spent = 56.14 s\n",
      "1086:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1086:grad_norm [1000]: avg:   2.2668, min:   0.5348[ 287], max:   6.7989[ 138]\n",
      "1086:loss      [1000]: avg:   0.6344, min:   0.2227[ 236], max:   0.9655[ 521]\n",
      "1086:rl_loss   [1000]: avg:   0.1168, min:   0.0531[ 917], max:   0.3434[  91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1086, eval score: 6.9390, perfect: 0.10, model saved: False\n",
      "epoch 1086, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1087\n",
      "available: 4.274 GB, used: 24.759 GB, free: 334.691 MB\n",
      "EPOCH: 1087\n",
      "Speed: train: 1147.5, buffer_add: 284.1, buffer_size: 100002\n",
      "Total Time: 16H 47M 41S, 60461s\n",
      "Total Sample: train: 69.632M, buffer: 17.373M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.76%\n",
      "\tsample data       : 1 MS, 1.82%\n",
      "\tforward & backward: 36 MS, 64.76%\n",
      "\tupdate model      : 16 MS, 29.56%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.71 ms\n",
      "[1087] Time spent = 55.78 s\n",
      "1087:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1087:grad_norm [1000]: avg:   2.3619, min:   0.7385[ 205], max:   8.3067[  32]\n",
      "1087:loss      [1000]: avg:   0.6338, min:   0.2694[ 774], max:   0.9407[ 842]\n",
      "1087:rl_loss   [1000]: avg:   0.1155, min:   0.0569[ 320], max:   0.3331[ 364]\n",
      "epoch 1087, eval score: 6.9850, perfect: 0.10, model saved: False\n",
      "epoch 1087, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  1088\n",
      "available: 4.277 GB, used: 24.757 GB, free: 337.391 MB\n",
      "EPOCH: 1088\n",
      "Speed: train: 1140.9, buffer_add: 286.0, buffer_size: 100009\n",
      "Total Time: 16H 48M 38S, 60518s\n",
      "Total Sample: train: 69.696M, buffer: 17.389M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.77%\n",
      "\tsample data       : 1 MS, 2.15%\n",
      "\tforward & backward: 36 MS, 65.07%\n",
      "\tupdate model      : 16 MS, 28.93%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.03 ms\n",
      "[1088] Time spent = 56.10 s\n",
      "1088:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1088:grad_norm [1000]: avg:   2.3131, min:   0.4673[ 504], max:   6.5979[ 450]\n",
      "1088:loss      [1000]: avg:   0.6377, min:   0.1619[ 504], max:   1.0872[ 507]\n",
      "1088:rl_loss   [1000]: avg:   0.1149, min:   0.0525[ 229], max:   0.3353[ 750]\n",
      "epoch 1088, eval score: 6.9500, perfect: 0.10, model saved: False\n",
      "epoch 1088, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1089\n",
      "available: 4.280 GB, used: 24.754 GB, free: 340.438 MB\n",
      "EPOCH: 1089\n",
      "Speed: train: 1162.9, buffer_add: 285.1, buffer_size: 100014\n",
      "Total Time: 16H 49M 33S, 60573s\n",
      "Total Sample: train: 69.76M, buffer: 17.405M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.71%\n",
      "\tsample data       : 1 MS, 2.05%\n",
      "\tforward & backward: 35 MS, 64.34%\n",
      "\tupdate model      : 16 MS, 29.80%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 54.96 ms\n",
      "[1089] Time spent = 55.04 s\n",
      "1089:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1089:grad_norm [1000]: avg:   2.2362, min:   0.6148[ 523], max:   6.5471[ 536]\n",
      "1089:loss      [1000]: avg:   0.6332, min:   0.2265[ 523], max:   0.9948[ 328]\n",
      "1089:rl_loss   [1000]: avg:   0.1162, min:   0.0595[  17], max:   0.3223[ 273]\n",
      "epoch 1089, eval score: 6.9830, perfect: 0.10, model saved: False\n",
      "epoch 1089, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1090\n",
      "available: 4.272 GB, used: 24.762 GB, free: 332.027 MB\n",
      "EPOCH: 1090\n",
      "Speed: train: 1126.4, buffer_add: 283.7, buffer_size: 100011\n",
      "Total Time: 16H 50M 29S, 60629s\n",
      "Total Sample: train: 69.824M, buffer: 17.421M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.72%\n",
      "\tsample data       : 1 MS, 1.94%\n",
      "\tforward & backward: 36 MS, 64.64%\n",
      "\tupdate model      : 16 MS, 29.61%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.73 ms\n",
      "[1090] Time spent = 56.82 s\n",
      "1090:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1090:grad_norm [1000]: avg:   2.3479, min:   0.4680[ 114], max:   7.6014[ 884]\n",
      "1090:loss      [1000]: avg:   0.6248, min:   0.2093[ 114], max:   0.9241[  16]\n",
      "1090:rl_loss   [1000]: avg:   0.1113, min:   0.0574[ 712], max:   0.2856[ 126]\n",
      "epoch 1090, eval score: 6.9030, perfect: 0.00, model saved: False\n",
      "epoch 1090, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1091\n",
      "available: 4.274 GB, used: 24.760 GB, free: 333.988 MB\n",
      "EPOCH: 1091\n",
      "Speed: train: 1142.4, buffer_add: 285.9, buffer_size: 100014\n",
      "Total Time: 16H 51M 25S, 60685s\n",
      "Total Sample: train: 69.888M, buffer: 17.437M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.85%\n",
      "\tsample data       : 1 MS, 1.88%\n",
      "\tforward & backward: 36 MS, 64.54%\n",
      "\tupdate model      : 16 MS, 29.64%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.96 ms\n",
      "[1091] Time spent = 56.03 s\n",
      "1091:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1091:grad_norm [1000]: avg:   2.3080, min:   0.7109[ 426], max:   8.5840[ 359]\n",
      "1091:loss      [1000]: avg:   0.6281, min:   0.1788[ 888], max:   0.9045[ 409]\n",
      "1091:rl_loss   [1000]: avg:   0.1113, min:   0.0503[ 888], max:   0.3056[ 588]\n",
      "epoch 1091, eval score: 7.0100, perfect: 0.30, model saved: False\n",
      "epoch 1091, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1092\n",
      "available: 4.268 GB, used: 24.765 GB, free: 328.121 MB\n",
      "EPOCH: 1092\n",
      "Speed: train: 1157.5, buffer_add: 284.7, buffer_size: 100010\n",
      "Total Time: 16H 52M 21S, 60741s\n",
      "Total Sample: train: 69.952M, buffer: 17.453M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.91%\n",
      "\tsample data       : 1 MS, 2.18%\n",
      "\tforward & backward: 36 MS, 65.37%\n",
      "\tupdate model      : 15 MS, 28.46%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.22 ms\n",
      "[1092] Time spent = 55.30 s\n",
      "1092:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1092:grad_norm [1000]: avg:   2.2503, min:   0.6413[ 792], max:   6.5492[ 807]\n",
      "1092:loss      [1000]: avg:   0.6241, min:   0.2706[ 609], max:   0.9634[  43]\n",
      "1092:rl_loss   [1000]: avg:   0.1114, min:   0.0592[ 161], max:   0.2742[  17]\n",
      "epoch 1092, eval score: 6.9170, perfect: 0.20, model saved: False\n",
      "epoch 1092, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  1093\n",
      "available: 4.275 GB, used: 24.758 GB, free: 335.508 MB\n",
      "EPOCH: 1093\n",
      "Speed: train: 1138.5, buffer_add: 286.5, buffer_size: 100004\n",
      "Total Time: 16H 53M 17S, 60797s\n",
      "Total Sample: train: 70.016M, buffer: 17.469M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.20%\n",
      "\tsample data       : 1 MS, 2.14%\n",
      "\tforward & backward: 36 MS, 65.19%\n",
      "\tupdate model      : 15 MS, 28.38%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 56.13 ms\n",
      "[1093] Time spent = 56.22 s\n",
      "1093:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1093:grad_norm [1000]: avg:   2.2747, min:   0.7744[ 127], max:   7.7557[ 356]\n",
      "1093:loss      [1000]: avg:   0.6261, min:   0.1973[ 671], max:   0.9402[ 905]\n",
      "1093:rl_loss   [1000]: avg:   0.1128, min:   0.0447[ 196], max:   0.2862[  99]\n",
      "epoch 1093, eval score: 6.8450, perfect: 0.20, model saved: False\n",
      "epoch 1093, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  1094\n",
      "available: 4.280 GB, used: 24.753 GB, free: 340.312 MB\n",
      "EPOCH: 1094\n",
      "Speed: train: 1144.2, buffer_add: 285.5, buffer_size: 100006\n",
      "Total Time: 16H 54M 13S, 60853s\n",
      "Total Sample: train: 70.08M, buffer: 17.485M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.77%\n",
      "\tsample data       : 1 MS, 1.92%\n",
      "\tforward & backward: 36 MS, 65.87%\n",
      "\tupdate model      : 15 MS, 28.34%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.87 ms\n",
      "[1094] Time spent = 55.94 s\n",
      "1094:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1094:grad_norm [1000]: avg:   2.4291, min:   0.4513[ 907], max:   6.5048[ 392]\n",
      "1094:loss      [1000]: avg:   0.6233, min:   0.1725[ 907], max:   0.9847[ 650]\n",
      "1094:rl_loss   [1000]: avg:   0.1123, min:   0.0547[ 639], max:   0.3169[ 375]\n",
      "epoch 1094, eval score: 7.0020, perfect: 0.20, model saved: False\n",
      "epoch 1094, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1095\n",
      "available: 4.271 GB, used: 24.762 GB, free: 331.238 MB\n",
      "EPOCH: 1095\n",
      "Speed: train: 1128.0, buffer_add: 276.8, buffer_size: 100001\n",
      "Total Time: 16H 55M 10S, 60910s\n",
      "Total Sample: train: 70.144M, buffer: 17.5M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.85%\n",
      "\tsample data       : 1 MS, 2.03%\n",
      "\tforward & backward: 36 MS, 65.17%\n",
      "\tupdate model      : 16 MS, 28.80%\n",
      "\tupdating priority : 0 MS, 0.14%\n",
      "@@@total time per iter: 56.66 ms\n",
      "[1095] Time spent = 56.74 s\n",
      "1095:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1095:grad_norm [1000]: avg:   2.3412, min:   0.4154[ 312], max:   6.4405[ 663]\n",
      "1095:loss      [1000]: avg:   0.6259, min:   0.2396[ 312], max:   0.9123[ 724]\n",
      "1095:rl_loss   [1000]: avg:   0.1138, min:   0.0433[ 153], max:   0.3431[ 459]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1095, eval score: 7.0190, perfect: 0.10, model saved: False\n",
      "epoch 1095, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1096\n",
      "available: 4.240 GB, used: 24.792 GB, free: 296.285 MB\n",
      "EPOCH: 1096\n",
      "Speed: train: 1089.1, buffer_add: 265.9, buffer_size: 100035\n",
      "Total Time: 16H 56M 08S, 60968s\n",
      "Total Sample: train: 70.208M, buffer: 17.516M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.74%\n",
      "\tsample data       : 1 MS, 1.81%\n",
      "\tforward & backward: 38 MS, 65.14%\n",
      "\tupdate model      : 17 MS, 29.20%\n",
      "\tupdating priority : 0 MS, 0.12%\n",
      "@@@total time per iter: 58.68 ms\n",
      "[1096] Time spent = 58.77 s\n",
      "1096:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1096:grad_norm [1000]: avg:   2.2276, min:   0.4182[ 345], max:   6.5032[ 236]\n",
      "1096:loss      [1000]: avg:   0.6252, min:   0.1637[ 345], max:   0.9603[ 838]\n",
      "1096:rl_loss   [1000]: avg:   0.1155, min:   0.0551[ 787], max:   0.2798[  66]\n",
      "epoch 1096, eval score: 6.9510, perfect: 0.20, model saved: False\n",
      "epoch 1096, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1097\n",
      "available: 4.265 GB, used: 24.768 GB, free: 490.121 MB\n",
      "EPOCH: 1097\n",
      "Speed: train: 1124.2, buffer_add: 279.9, buffer_size: 100038\n",
      "Total Time: 16H 57M 05S, 61025s\n",
      "Total Sample: train: 70.272M, buffer: 17.532M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.82%\n",
      "\tsample data       : 1 MS, 2.05%\n",
      "\tforward & backward: 36 MS, 64.49%\n",
      "\tupdate model      : 16 MS, 29.56%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.86 ms\n",
      "[1097] Time spent = 56.94 s\n",
      "1097:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1097:grad_norm [1000]: avg:   2.2600, min:   0.4311[ 699], max:   7.5980[ 536]\n",
      "1097:loss      [1000]: avg:   0.6238, min:   0.2061[ 699], max:   0.9662[ 136]\n",
      "1097:rl_loss   [1000]: avg:   0.1136, min:   0.0504[ 699], max:   0.2448[ 414]\n",
      "epoch 1097, eval score: 6.8550, perfect: 0.20, model saved: False\n",
      "epoch 1097, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  1098\n",
      "available: 4.281 GB, used: 24.752 GB, free: 505.531 MB\n",
      "EPOCH: 1098\n",
      "Speed: train: 1129.7, buffer_add: 281.8, buffer_size: 100026\n",
      "Total Time: 16H 58M 02S, 61082s\n",
      "Total Sample: train: 70.336M, buffer: 17.548M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.67%\n",
      "\tsample data       : 1 MS, 2.23%\n",
      "\tforward & backward: 37 MS, 65.39%\n",
      "\tupdate model      : 16 MS, 28.62%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.59 ms\n",
      "[1098] Time spent = 56.66 s\n",
      "1098:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1098:grad_norm [1000]: avg:   2.2436, min:   0.4031[ 998], max:   7.0460[ 371]\n",
      "1098:loss      [1000]: avg:   0.6206, min:   0.1769[ 998], max:   0.9508[ 377]\n",
      "1098:rl_loss   [1000]: avg:   0.1142, min:   0.0576[ 695], max:   0.2862[ 727]\n",
      "epoch 1098, eval score: 6.9750, perfect: 0.00, model saved: False\n",
      "epoch 1098, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1099\n",
      "available: 4.282 GB, used: 24.751 GB, free: 506.074 MB\n",
      "EPOCH: 1099\n",
      "Speed: train: 1126.4, buffer_add: 281.9, buffer_size: 100011\n",
      "Total Time: 16H 58M 59S, 61139s\n",
      "Total Sample: train: 70.4M, buffer: 17.564M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.72%\n",
      "\tsample data       : 1 MS, 1.99%\n",
      "\tforward & backward: 36 MS, 65.02%\n",
      "\tupdate model      : 16 MS, 29.17%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 56.75 ms\n",
      "[1099] Time spent = 56.82 s\n",
      "1099:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1099:grad_norm [1000]: avg:   2.3087, min:   0.6196[  46], max:   6.2565[ 725]\n",
      "1099:loss      [1000]: avg:   0.6269, min:   0.2489[ 160], max:   0.9763[ 964]\n",
      "1099:rl_loss   [1000]: avg:   0.1154, min:   0.0551[ 995], max:   0.2704[ 732]\n",
      "epoch 1099, eval score: 6.7210, perfect: 0.00, model saved: False\n",
      "epoch 1099, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1100\n",
      "available: 4.279 GB, used: 24.755 GB, free: 502.223 MB\n",
      "EPOCH: 1100\n",
      "Speed: train: 1137.2, buffer_add: 286.5, buffer_size: 100000\n",
      "Total Time: 16H 59M 55S, 61195s\n",
      "Total Sample: train: 70.464M, buffer: 17.58M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.93%\n",
      "\tsample data       : 1 MS, 1.98%\n",
      "\tforward & backward: 36 MS, 65.31%\n",
      "\tupdate model      : 16 MS, 28.65%\n",
      "\tupdating priority : 0 MS, 0.12%\n",
      "@@@total time per iter: 56.20 ms\n",
      "[1100] Time spent = 56.28 s\n",
      "1100:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1100:grad_norm [1000]: avg:   2.3015, min:   0.7892[ 987], max:   7.4258[ 882]\n",
      "1100:loss      [1000]: avg:   0.6207, min:   0.2254[ 973], max:   0.9670[ 488]\n",
      "1100:rl_loss   [1000]: avg:   0.1140, min:   0.0491[ 715], max:   0.3671[ 584]\n",
      "epoch 1100, eval score: 6.8530, perfect: 0.10, model saved: False\n",
      "epoch 1100, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1101\n",
      "available: 4.277 GB, used: 24.756 GB, free: 495.820 MB\n",
      "EPOCH: 1101\n",
      "Speed: train: 1099.6, buffer_add: 278.1, buffer_size: 100032\n",
      "Total Time: 17H 00M 53S, 61253s\n",
      "Total Sample: train: 70.528M, buffer: 17.596M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.57%\n",
      "\tsample data       : 1 MS, 1.92%\n",
      "\tforward & backward: 37 MS, 64.80%\n",
      "\tupdate model      : 17 MS, 29.57%\n",
      "\tupdating priority : 0 MS, 0.13%\n",
      "@@@total time per iter: 58.12 ms\n",
      "[1101] Time spent = 58.21 s\n",
      "1101:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1101:grad_norm [1000]: avg:   2.2505, min:   0.7751[ 216], max:   7.5812[ 936]\n",
      "1101:loss      [1000]: avg:   0.6285, min:   0.2604[ 216], max:   0.9824[ 283]\n",
      "1101:rl_loss   [1000]: avg:   0.1148, min:   0.0498[ 430], max:   0.2718[ 506]\n",
      "epoch 1101, eval score: 6.9630, perfect: 0.00, model saved: False\n",
      "epoch 1101, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1102\n",
      "available: 4.275 GB, used: 24.759 GB, free: 493.012 MB\n",
      "EPOCH: 1102\n",
      "Speed: train: 1146.3, buffer_add: 283.3, buffer_size: 100018\n",
      "Total Time: 17H 01M 49S, 61309s\n",
      "Total Sample: train: 70.592M, buffer: 17.612M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.82%\n",
      "\tsample data       : 1 MS, 1.98%\n",
      "\tforward & backward: 36 MS, 64.69%\n",
      "\tupdate model      : 16 MS, 29.41%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.76 ms\n",
      "[1102] Time spent = 55.83 s\n",
      "1102:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1102:grad_norm [1000]: avg:   2.3012, min:   0.3486[ 936], max:   7.5196[ 220]\n",
      "1102:loss      [1000]: avg:   0.6238, min:   0.1987[ 936], max:   0.9333[ 517]\n",
      "1102:rl_loss   [1000]: avg:   0.1137, min:   0.0555[ 294], max:   0.2913[ 888]\n",
      "epoch 1102, eval score: 6.9960, perfect: 0.10, model saved: False\n",
      "epoch 1102, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1103\n",
      "available: 4.277 GB, used: 24.756 GB, free: 495.828 MB\n",
      "EPOCH: 1103\n",
      "Speed: train: 1139.7, buffer_add: 282.8, buffer_size: 100036\n",
      "Total Time: 17H 02M 45S, 61365s\n",
      "Total Sample: train: 70.656M, buffer: 17.628M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.08%\n",
      "\tsample data       : 1 MS, 1.99%\n",
      "\tforward & backward: 36 MS, 64.58%\n",
      "\tupdate model      : 16 MS, 29.24%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 56.09 ms\n",
      "[1103] Time spent = 56.16 s\n",
      "1103:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1103:grad_norm [1000]: avg:   2.2870, min:   0.6434[ 208], max:   7.4183[ 848]\n",
      "1103:loss      [1000]: avg:   0.6315, min:   0.2193[ 843], max:   1.0020[ 249]\n",
      "1103:rl_loss   [1000]: avg:   0.1135, min:   0.0592[ 639], max:   0.3013[ 243]\n",
      "epoch 1103, eval score: 6.9420, perfect: 0.20, model saved: False\n",
      "epoch 1103, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  1104\n",
      "available: 4.282 GB, used: 24.751 GB, free: 500.621 MB\n",
      "EPOCH: 1104\n",
      "Speed: train: 1154.9, buffer_add: 283.5, buffer_size: 100002\n",
      "Total Time: 17H 03M 41S, 61421s\n",
      "Total Sample: train: 70.72M, buffer: 17.644M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.70%\n",
      "\tsample data       : 1 MS, 1.94%\n",
      "\tforward & backward: 36 MS, 65.43%\n",
      "\tupdate model      : 15 MS, 28.85%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.35 ms\n",
      "[1104] Time spent = 55.42 s\n",
      "1104:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1104:grad_norm [1000]: avg:   2.2968, min:   0.7057[ 177], max:   6.8089[ 690]\n",
      "1104:loss      [1000]: avg:   0.6405, min:   0.2320[ 177], max:   0.9587[ 489]\n",
      "1104:rl_loss   [1000]: avg:   0.1150, min:   0.0578[ 133], max:   0.2843[ 780]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1104, eval score: 6.8960, perfect: 0.10, model saved: False\n",
      "epoch 1104, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  1105\n",
      "available: 4.279 GB, used: 24.754 GB, free: 497.117 MB\n",
      "EPOCH: 1105\n",
      "Speed: train: 1151.6, buffer_add: 284.6, buffer_size: 100012\n",
      "Total Time: 17H 04M 36S, 61476s\n",
      "Total Sample: train: 70.784M, buffer: 17.659M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.63%\n",
      "\tsample data       : 0 MS, 1.79%\n",
      "\tforward & backward: 36 MS, 65.23%\n",
      "\tupdate model      : 16 MS, 29.26%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.51 ms\n",
      "[1105] Time spent = 55.58 s\n",
      "1105:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1105:grad_norm [1000]: avg:   2.3616, min:   0.6204[ 465], max:   6.7780[ 326]\n",
      "1105:loss      [1000]: avg:   0.6496, min:   0.1987[  31], max:   0.9557[ 691]\n",
      "1105:rl_loss   [1000]: avg:   0.1170, min:   0.0612[ 458], max:   0.3256[ 973]\n",
      "epoch 1105, eval score: 6.8830, perfect: 0.10, model saved: False\n",
      "epoch 1105, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1106\n",
      "available: 4.278 GB, used: 24.756 GB, free: 495.852 MB\n",
      "EPOCH: 1106\n",
      "Speed: train: 1156.8, buffer_add: 286.3, buffer_size: 100018\n",
      "Total Time: 17H 05M 32S, 61532s\n",
      "Total Sample: train: 70.848M, buffer: 17.675M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.78%\n",
      "\tsample data       : 0 MS, 1.72%\n",
      "\tforward & backward: 36 MS, 65.26%\n",
      "\tupdate model      : 16 MS, 29.15%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.27 ms\n",
      "[1106] Time spent = 55.33 s\n",
      "1106:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1106:grad_norm [1000]: avg:   2.3234, min:   0.6902[ 743], max:   6.2710[ 294]\n",
      "1106:loss      [1000]: avg:   0.6464, min:   0.2981[ 459], max:   1.0060[ 170]\n",
      "1106:rl_loss   [1000]: avg:   0.1155, min:   0.0627[ 507], max:   0.3282[ 869]\n",
      "epoch 1106, eval score: 6.8910, perfect: 0.50, model saved: False\n",
      "epoch 1106, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1107\n",
      "available: 4.275 GB, used: 24.759 GB, free: 492.676 MB\n",
      "EPOCH: 1107\n",
      "Speed: train: 1152.1, buffer_add: 285.5, buffer_size: 100010\n",
      "Total Time: 17H 06M 27S, 61587s\n",
      "Total Sample: train: 70.912M, buffer: 17.691M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.82%\n",
      "\tsample data       : 1 MS, 2.09%\n",
      "\tforward & backward: 36 MS, 64.99%\n",
      "\tupdate model      : 16 MS, 29.00%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.47 ms\n",
      "[1107] Time spent = 55.55 s\n",
      "1107:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1107:grad_norm [1000]: avg:   2.2529, min:   0.6392[ 431], max:   7.1197[ 574]\n",
      "1107:loss      [1000]: avg:   0.6458, min:   0.2203[ 461], max:   0.9762[ 222]\n",
      "1107:rl_loss   [1000]: avg:   0.1162, min:   0.0504[ 851], max:   0.3131[ 755]\n",
      "epoch 1107, eval score: 7.0200, perfect: 0.00, model saved: False\n",
      "epoch 1107, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1108\n",
      "available: 4.273 GB, used: 24.761 GB, free: 490.434 MB\n",
      "EPOCH: 1108\n",
      "Speed: train: 1157.4, buffer_add: 284.4, buffer_size: 100020\n",
      "Total Time: 17H 07M 22S, 61642s\n",
      "Total Sample: train: 70.976M, buffer: 17.707M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.61%\n",
      "\tsample data       : 0 MS, 1.81%\n",
      "\tforward & backward: 35 MS, 64.75%\n",
      "\tupdate model      : 16 MS, 29.74%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.22 ms\n",
      "[1108] Time spent = 55.30 s\n",
      "1108:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1108:grad_norm [1000]: avg:   2.3640, min:   0.6246[ 952], max:   6.5007[ 879]\n",
      "1108:loss      [1000]: avg:   0.6498, min:   0.2316[ 683], max:   0.9379[ 602]\n",
      "1108:rl_loss   [1000]: avg:   0.1172, min:   0.0596[  70], max:   0.2691[ 931]\n",
      "epoch 1108, eval score: 6.9670, perfect: 0.30, model saved: False\n",
      "epoch 1108, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1109\n",
      "available: 4.279 GB, used: 24.754 GB, free: 496.965 MB\n",
      "EPOCH: 1109\n",
      "Speed: train: 1156.7, buffer_add: 281.7, buffer_size: 100016\n",
      "Total Time: 17H 08M 18S, 61698s\n",
      "Total Sample: train: 71.04M, buffer: 17.722M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.80%\n",
      "\tsample data       : 1 MS, 2.07%\n",
      "\tforward & backward: 36 MS, 65.39%\n",
      "\tupdate model      : 15 MS, 28.65%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.25 ms\n",
      "[1109] Time spent = 55.33 s\n",
      "1109:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1109:grad_norm [1000]: avg:   2.2216, min:   0.6092[ 830], max:   7.9831[ 543]\n",
      "1109:loss      [1000]: avg:   0.6418, min:   0.2247[ 802], max:   1.0758[ 380]\n",
      "1109:rl_loss   [1000]: avg:   0.1146, min:   0.0627[ 765], max:   0.2931[ 916]\n",
      "epoch 1109, eval score: 6.8940, perfect: 0.20, model saved: False\n",
      "epoch 1109, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  1110\n",
      "available: 4.267 GB, used: 24.766 GB, free: 484.207 MB\n",
      "EPOCH: 1110\n",
      "Speed: train: 1155.6, buffer_add: 282.0, buffer_size: 100021\n",
      "Total Time: 17H 09M 13S, 61753s\n",
      "Total Sample: train: 71.104M, buffer: 17.738M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.74%\n",
      "\tsample data       : 1 MS, 2.05%\n",
      "\tforward & backward: 35 MS, 64.53%\n",
      "\tupdate model      : 16 MS, 29.58%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.30 ms\n",
      "[1110] Time spent = 55.39 s\n",
      "1110:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1110:grad_norm [1000]: avg:   2.3263, min:   0.6860[ 613], max:   7.0556[ 453]\n",
      "1110:loss      [1000]: avg:   0.6398, min:   0.2745[ 281], max:   0.9568[ 981]\n",
      "1110:rl_loss   [1000]: avg:   0.1153, min:   0.0610[  89], max:   0.3109[ 724]\n",
      "epoch 1110, eval score: 6.9160, perfect: 0.30, model saved: False\n",
      "epoch 1110, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  1111\n",
      "available: 4.278 GB, used: 24.756 GB, free: 495.242 MB\n",
      "EPOCH: 1111\n",
      "Speed: train: 1160.5, buffer_add: 279.2, buffer_size: 100000\n",
      "Total Time: 17H 10M 08S, 61808s\n",
      "Total Sample: train: 71.168M, buffer: 17.753M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.94%\n",
      "\tsample data       : 0 MS, 1.75%\n",
      "\tforward & backward: 35 MS, 64.50%\n",
      "\tupdate model      : 16 MS, 29.72%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.08 ms\n",
      "[1111] Time spent = 55.15 s\n",
      "1111:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1111:grad_norm [1000]: avg:   2.2805, min:   0.5982[ 567], max:   6.6875[ 514]\n",
      "1111:loss      [1000]: avg:   0.6325, min:   0.3151[ 438], max:   0.9411[  28]\n",
      "1111:rl_loss   [1000]: avg:   0.1149, min:   0.0464[ 979], max:   0.3122[ 673]\n",
      "epoch 1111, eval score: 6.9040, perfect: 0.00, model saved: False\n",
      "epoch 1111, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1112\n",
      "available: 4.272 GB, used: 24.762 GB, free: 488.941 MB\n",
      "EPOCH: 1112\n",
      "Speed: train: 1135.4, buffer_add: 286.2, buffer_size: 100006\n",
      "Total Time: 17H 11M 05S, 61865s\n",
      "Total Sample: train: 71.232M, buffer: 17.77M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.88%\n",
      "\tsample data       : 1 MS, 2.17%\n",
      "\tforward & backward: 36 MS, 65.04%\n",
      "\tupdate model      : 16 MS, 28.81%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 56.28 ms\n",
      "[1112] Time spent = 56.36 s\n",
      "1112:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1112:grad_norm [1000]: avg:   2.2582, min:   0.7205[ 787], max:   6.1249[ 916]\n",
      "1112:loss      [1000]: avg:   0.6355, min:   0.3031[ 436], max:   1.0349[ 775]\n",
      "1112:rl_loss   [1000]: avg:   0.1125, min:   0.0545[ 375], max:   0.2943[ 222]\n",
      "epoch 1112, eval score: 6.9180, perfect: 0.20, model saved: False\n",
      "epoch 1112, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1113\n",
      "available: 4.272 GB, used: 24.761 GB, free: 489.082 MB\n",
      "EPOCH: 1113\n",
      "Speed: train: 1140.3, buffer_add: 279.9, buffer_size: 100026\n",
      "Total Time: 17H 12M 01S, 61921s\n",
      "Total Sample: train: 71.296M, buffer: 17.785M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.74%\n",
      "\tsample data       : 1 MS, 2.15%\n",
      "\tforward & backward: 36 MS, 65.19%\n",
      "\tupdate model      : 16 MS, 28.81%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 56.06 ms\n",
      "[1113] Time spent = 56.13 s\n",
      "1113:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1113:grad_norm [1000]: avg:   2.2147, min:   0.5974[ 762], max:   5.7132[ 243]\n",
      "1113:loss      [1000]: avg:   0.6351, min:   0.2063[ 990], max:   1.0085[ 770]\n",
      "1113:rl_loss   [1000]: avg:   0.1124, min:   0.0574[ 760], max:   0.2639[  17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1113, eval score: 6.8820, perfect: 0.20, model saved: False\n",
      "epoch 1113, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1114\n",
      "available: 4.279 GB, used: 24.754 GB, free: 496.699 MB\n",
      "EPOCH: 1114\n",
      "Speed: train: 1145.4, buffer_add: 283.3, buffer_size: 100006\n",
      "Total Time: 17H 12M 57S, 61977s\n",
      "Total Sample: train: 71.36M, buffer: 17.801M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.00%\n",
      "\tsample data       : 1 MS, 1.83%\n",
      "\tforward & backward: 36 MS, 64.69%\n",
      "\tupdate model      : 16 MS, 29.37%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.80 ms\n",
      "[1114] Time spent = 55.88 s\n",
      "1114:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1114:grad_norm [1000]: avg:   2.2682, min:   0.7785[ 760], max:   7.5191[ 682]\n",
      "1114:loss      [1000]: avg:   0.6382, min:   0.2829[ 189], max:   0.9640[  19]\n",
      "1114:rl_loss   [1000]: avg:   0.1121, min:   0.0577[ 124], max:   0.3098[  74]\n",
      "epoch 1114, eval score: 6.8440, perfect: 0.10, model saved: False\n",
      "epoch 1114, success rate for sampling ficticious state: 99.84%\n",
      "==========\n",
      "beginning of epoch:  1115\n",
      "available: 4.274 GB, used: 24.760 GB, free: 490.723 MB\n",
      "EPOCH: 1115\n",
      "Speed: train: 1153.5, buffer_add: 280.5, buffer_size: 100000\n",
      "Total Time: 17H 13M 52S, 62032s\n",
      "Total Sample: train: 71.424M, buffer: 17.817M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.11%\n",
      "\tsample data       : 1 MS, 1.95%\n",
      "\tforward & backward: 35 MS, 64.41%\n",
      "\tupdate model      : 16 MS, 29.43%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.42 ms\n",
      "[1115] Time spent = 55.49 s\n",
      "1115:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1115:grad_norm [1000]: avg:   2.2454, min:   0.6833[ 740], max:   5.6817[ 347]\n",
      "1115:loss      [1000]: avg:   0.6321, min:   0.2491[ 311], max:   0.9864[ 668]\n",
      "1115:rl_loss   [1000]: avg:   0.1112, min:   0.0526[ 929], max:   0.3699[ 686]\n",
      "epoch 1115, eval score: 6.9170, perfect: 0.10, model saved: False\n",
      "epoch 1115, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1116\n",
      "available: 4.277 GB, used: 24.757 GB, free: 493.570 MB\n",
      "EPOCH: 1116\n",
      "Speed: train: 1165.2, buffer_add: 281.7, buffer_size: 100001\n",
      "Total Time: 17H 14M 47S, 62087s\n",
      "Total Sample: train: 71.488M, buffer: 17.832M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.69%\n",
      "\tsample data       : 0 MS, 1.82%\n",
      "\tforward & backward: 35 MS, 64.78%\n",
      "\tupdate model      : 16 MS, 29.62%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 54.87 ms\n",
      "[1116] Time spent = 54.93 s\n",
      "1116:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1116:grad_norm [1000]: avg:   2.2401, min:   0.5395[ 742], max:   7.1620[  48]\n",
      "1116:loss      [1000]: avg:   0.6285, min:   0.2516[ 923], max:   1.0644[ 261]\n",
      "1116:rl_loss   [1000]: avg:   0.1120, min:   0.0551[ 406], max:   0.2996[ 597]\n",
      "epoch 1116, eval score: 6.9030, perfect: 0.00, model saved: False\n",
      "epoch 1116, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  1117\n",
      "available: 4.274 GB, used: 24.759 GB, free: 490.676 MB\n",
      "EPOCH: 1117\n",
      "Speed: train: 1147.0, buffer_add: 281.5, buffer_size: 100009\n",
      "Total Time: 17H 15M 43S, 62143s\n",
      "Total Sample: train: 71.552M, buffer: 17.848M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.70%\n",
      "\tsample data       : 1 MS, 2.03%\n",
      "\tforward & backward: 36 MS, 65.13%\n",
      "\tupdate model      : 16 MS, 29.05%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.73 ms\n",
      "[1117] Time spent = 55.80 s\n",
      "1117:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1117:grad_norm [1000]: avg:   2.3094, min:   0.5509[ 215], max:   6.0439[ 544]\n",
      "1117:loss      [1000]: avg:   0.6342, min:   0.2698[ 215], max:   0.9296[ 253]\n",
      "1117:rl_loss   [1000]: avg:   0.1140, min:   0.0483[ 401], max:   0.3040[ 347]\n",
      "epoch 1117, eval score: 6.9510, perfect: 0.10, model saved: False\n",
      "epoch 1117, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1118\n",
      "available: 4.268 GB, used: 24.765 GB, free: 484.703 MB\n",
      "EPOCH: 1118\n",
      "Speed: train: 1145.7, buffer_add: 283.7, buffer_size: 100024\n",
      "Total Time: 17H 16M 39S, 62199s\n",
      "Total Sample: train: 71.616M, buffer: 17.864M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.95%\n",
      "\tsample data       : 1 MS, 2.20%\n",
      "\tforward & backward: 36 MS, 65.04%\n",
      "\tupdate model      : 16 MS, 28.71%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.79 ms\n",
      "[1118] Time spent = 55.86 s\n",
      "1118:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1118:grad_norm [1000]: avg:   2.2785, min:   0.5666[ 739], max:   7.7739[ 206]\n",
      "1118:loss      [1000]: avg:   0.6319, min:   0.1679[ 739], max:   0.9738[ 731]\n",
      "1118:rl_loss   [1000]: avg:   0.1114, min:   0.0543[ 252], max:   0.2903[ 177]\n",
      "epoch 1118, eval score: 6.9250, perfect: 0.10, model saved: False\n",
      "epoch 1118, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1119\n",
      "available: 4.277 GB, used: 24.756 GB, free: 493.902 MB\n",
      "EPOCH: 1119\n",
      "Speed: train: 1141.2, buffer_add: 282.8, buffer_size: 100000\n",
      "Total Time: 17H 17M 35S, 62255s\n",
      "Total Sample: train: 71.68M, buffer: 17.88M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.83%\n",
      "\tsample data       : 1 MS, 1.83%\n",
      "\tforward & backward: 35 MS, 64.15%\n",
      "\tupdate model      : 16 MS, 30.10%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 56.01 ms\n",
      "[1119] Time spent = 56.08 s\n",
      "1119:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1119:grad_norm [1000]: avg:   2.3019, min:   0.6037[ 815], max:   9.2301[ 326]\n",
      "1119:loss      [1000]: avg:   0.6265, min:   0.2540[ 295], max:   0.9306[ 522]\n",
      "1119:rl_loss   [1000]: avg:   0.1165, min:   0.0463[ 599], max:   0.3055[ 147]\n",
      "epoch 1119, eval score: 6.9290, perfect: 0.20, model saved: False\n",
      "epoch 1119, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1120\n",
      "available: 4.278 GB, used: 24.755 GB, free: 494.543 MB\n",
      "EPOCH: 1296\n",
      "Speed: train: 1134.0, buffer_add: 285.9, buffer_size: 100014\n",
      "Total Time: 20H 01M 23S, 72083s\n",
      "Total Sample: train: 83.008M, buffer: 20.685M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.92%\n",
      "\tsample data       : 1 MS, 1.90%\n",
      "\tforward & backward: 36 MS, 65.43%\n",
      "\tupdate model      : 16 MS, 28.66%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.37 ms\n",
      "[1296] Time spent = 56.45 s\n",
      "1296:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1296:grad_norm [1000]: avg:   2.2220, min:   0.5665[ 347], max:   8.2017[ 874]\n",
      "1296:loss      [1000]: avg:   0.6159, min:   0.2884[ 345], max:   0.9529[  47]\n",
      "1296:rl_loss   [1000]: avg:   0.1102, min:   0.0537[ 709], max:   0.3662[ 521]\n",
      "epoch 1296, eval score: 6.7960, perfect: 0.10, model saved: False\n",
      "epoch 1296, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1297\n",
      "available: 4.216 GB, used: 24.819 GB, free: 339.328 MB\n",
      "EPOCH: 1297\n",
      "Speed: train: 1137.8, buffer_add: 282.3, buffer_size: 100026\n",
      "Total Time: 20H 02M 19S, 72139s\n",
      "Total Sample: train: 83.072M, buffer: 20.701M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 4.05%\n",
      "\tsample data       : 1 MS, 1.80%\n",
      "\tforward & backward: 36 MS, 64.89%\n",
      "\tupdate model      : 16 MS, 29.17%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 56.18 ms\n",
      "[1297] Time spent = 56.25 s\n",
      "1297:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1297:grad_norm [1000]: avg:   2.2001, min:   0.4452[ 527], max:   6.9642[ 677]\n",
      "1297:loss      [1000]: avg:   0.6146, min:   0.1639[ 527], max:   0.9509[ 384]\n",
      "1297:rl_loss   [1000]: avg:   0.1131, min:   0.0465[ 344], max:   0.2779[ 245]\n",
      "epoch 1297, eval score: 7.0160, perfect: 0.10, model saved: False\n",
      "epoch 1297, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1298\n",
      "available: 4.220 GB, used: 24.815 GB, free: 343.168 MB\n",
      "EPOCH: 1298\n",
      "Speed: train: 1133.8, buffer_add: 280.0, buffer_size: 100000\n",
      "Total Time: 20H 03M 16S, 72196s\n",
      "Total Sample: train: 83.136M, buffer: 20.717M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.86%\n",
      "\tsample data       : 1 MS, 2.02%\n",
      "\tforward & backward: 36 MS, 65.31%\n",
      "\tupdate model      : 16 MS, 28.70%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 56.37 ms\n",
      "[1298] Time spent = 56.45 s\n",
      "1298:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1298:grad_norm [1000]: avg:   2.1686, min:   0.5702[ 734], max:   6.5002[ 809]\n",
      "1298:loss      [1000]: avg:   0.6152, min:   0.2739[ 705], max:   0.9148[ 147]\n",
      "1298:rl_loss   [1000]: avg:   0.1125, min:   0.0555[ 158], max:   0.3184[ 133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1298, eval score: 7.0290, perfect: 0.10, model saved: False\n",
      "epoch 1298, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1299\n",
      "available: 4.213 GB, used: 24.821 GB, free: 336.570 MB\n",
      "EPOCH: 1299\n",
      "Speed: train: 1138.0, buffer_add: 285.5, buffer_size: 100028\n",
      "Total Time: 20H 04M 12S, 72252s\n",
      "Total Sample: train: 83.2M, buffer: 20.733M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.65%\n",
      "\tsample data       : 1 MS, 2.21%\n",
      "\tforward & backward: 36 MS, 64.64%\n",
      "\tupdate model      : 16 MS, 29.41%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.18 ms\n",
      "[1299] Time spent = 56.24 s\n",
      "1299:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1299:grad_norm [1000]: avg:   2.1836, min:   0.7767[  83], max:   6.4232[ 248]\n",
      "1299:loss      [1000]: avg:   0.6148, min:   0.2242[ 344], max:   0.9320[ 178]\n",
      "1299:rl_loss   [1000]: avg:   0.1135, min:   0.0520[ 952], max:   0.2839[ 189]\n",
      "epoch 1299, eval score: 7.0210, perfect: 0.10, model saved: False\n",
      "epoch 1299, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1300\n",
      "available: 4.216 GB, used: 24.818 GB, free: 339.445 MB\n",
      "EPOCH: 1300\n",
      "Speed: train: 1141.9, buffer_add: 280.0, buffer_size: 100012\n",
      "Total Time: 20H 05M 08S, 72308s\n",
      "Total Sample: train: 83.264M, buffer: 20.749M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.89%\n",
      "\tsample data       : 1 MS, 1.79%\n",
      "\tforward & backward: 36 MS, 65.02%\n",
      "\tupdate model      : 16 MS, 29.20%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.97 ms\n",
      "[1300] Time spent = 56.05 s\n",
      "1300:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1300:grad_norm [1000]: avg:   2.1887, min:   0.6994[ 566], max:   6.8898[ 871]\n",
      "1300:loss      [1000]: avg:   0.6223, min:   0.2962[ 640], max:   1.1341[ 588]\n",
      "1300:rl_loss   [1000]: avg:   0.1130, min:   0.0532[ 120], max:   0.3155[ 149]\n",
      "epoch 1300, eval score: 7.0200, perfect: 0.00, model saved: False\n",
      "epoch 1300, success rate for sampling ficticious state: 99.80%\n",
      "==========\n",
      "beginning of epoch:  1301\n",
      "available: 4.220 GB, used: 24.815 GB, free: 338.066 MB\n",
      "EPOCH: 1301\n",
      "Speed: train: 1128.7, buffer_add: 283.4, buffer_size: 100004\n",
      "Total Time: 20H 06M 05S, 72365s\n",
      "Total Sample: train: 83.328M, buffer: 20.765M\n",
      "@@@Time\n",
      "\tsync and updating : 1 MS, 3.51%\n",
      "\tsample data       : 1 MS, 1.87%\n",
      "\tforward & backward: 37 MS, 65.50%\n",
      "\tupdate model      : 16 MS, 29.04%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.63 ms\n",
      "[1301] Time spent = 56.70 s\n",
      "1301:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1301:grad_norm [1000]: avg:   2.2113, min:   0.1718[ 390], max:   5.5401[ 809]\n",
      "1301:loss      [1000]: avg:   0.6110, min:   0.0615[ 390], max:   0.9107[ 600]\n",
      "1301:rl_loss   [1000]: avg:   0.1113, min:   0.0519[  32], max:   0.2922[ 437]\n",
      "epoch 1301, eval score: 7.0500, perfect: 0.10, model saved: False\n",
      "epoch 1301, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  1302\n",
      "available: 4.222 GB, used: 24.813 GB, free: 339.922 MB\n",
      "EPOCH: 1302\n",
      "Speed: train: 1129.1, buffer_add: 279.6, buffer_size: 100018\n",
      "Total Time: 20H 07M 01S, 72421s\n",
      "Total Sample: train: 83.392M, buffer: 20.781M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.81%\n",
      "\tsample data       : 1 MS, 1.93%\n",
      "\tforward & backward: 36 MS, 65.01%\n",
      "\tupdate model      : 16 MS, 29.16%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 56.60 ms\n",
      "[1302] Time spent = 56.68 s\n",
      "1302:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1302:grad_norm [1000]: avg:   2.1355, min:   0.3999[ 270], max:   7.6265[ 745]\n",
      "1302:loss      [1000]: avg:   0.6210, min:   0.2176[ 270], max:   0.9473[ 847]\n",
      "1302:rl_loss   [1000]: avg:   0.1158, min:   0.0562[ 893], max:   0.3460[ 805]\n",
      "epoch 1302, eval score: 6.8420, perfect: 0.10, model saved: False\n",
      "epoch 1302, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1303\n",
      "available: 4.216 GB, used: 24.819 GB, free: 333.949 MB\n",
      "EPOCH: 1303\n",
      "Speed: train: 1155.3, buffer_add: 281.5, buffer_size: 100004\n",
      "Total Time: 20H 07M 57S, 72477s\n",
      "Total Sample: train: 83.456M, buffer: 20.796M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.91%\n",
      "\tsample data       : 1 MS, 1.95%\n",
      "\tforward & backward: 35 MS, 64.84%\n",
      "\tupdate model      : 16 MS, 29.21%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 55.31 ms\n",
      "[1303] Time spent = 55.40 s\n",
      "1303:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1303:grad_norm [1000]: avg:   2.2665, min:   0.6284[ 858], max:   7.3867[ 993]\n",
      "1303:loss      [1000]: avg:   0.6139, min:   0.1454[ 858], max:   0.9202[ 116]\n",
      "1303:rl_loss   [1000]: avg:   0.1118, min:   0.0472[  52], max:   0.2943[ 270]\n",
      "epoch 1303, eval score: 6.9580, perfect: 0.20, model saved: False\n",
      "epoch 1303, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  1304\n",
      "available: 4.213 GB, used: 24.822 GB, free: 330.477 MB\n",
      "EPOCH: 1304\n",
      "Speed: train: 1147.0, buffer_add: 280.6, buffer_size: 100005\n",
      "Total Time: 20H 08M 53S, 72533s\n",
      "Total Sample: train: 83.52M, buffer: 20.812M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.83%\n",
      "\tsample data       : 1 MS, 2.50%\n",
      "\tforward & backward: 36 MS, 64.77%\n",
      "\tupdate model      : 16 MS, 28.81%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.73 ms\n",
      "[1304] Time spent = 55.80 s\n",
      "1304:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1304:grad_norm [1000]: avg:   2.2961, min:   0.6309[ 215], max:   8.0293[  44]\n",
      "1304:loss      [1000]: avg:   0.6086, min:   0.2558[ 220], max:   0.9846[ 372]\n",
      "1304:rl_loss   [1000]: avg:   0.1131, min:   0.0536[ 648], max:   0.3540[ 744]\n",
      "epoch 1304, eval score: 6.9860, perfect: 0.00, model saved: False\n",
      "epoch 1304, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1305\n",
      "available: 4.210 GB, used: 24.825 GB, free: 326.723 MB\n",
      "EPOCH: 1305\n",
      "Speed: train: 1125.2, buffer_add: 280.0, buffer_size: 100000\n",
      "Total Time: 20H 09M 49S, 72589s\n",
      "Total Sample: train: 83.584M, buffer: 20.828M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.67%\n",
      "\tsample data       : 1 MS, 1.76%\n",
      "\tforward & backward: 37 MS, 65.48%\n",
      "\tupdate model      : 16 MS, 28.99%\n",
      "\tupdating priority : 0 MS, 0.09%\n",
      "@@@total time per iter: 56.79 ms\n",
      "[1305] Time spent = 56.88 s\n",
      "1305:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1305:grad_norm [1000]: avg:   2.1916, min:   0.5619[ 209], max:   6.7920[ 355]\n",
      "1305:loss      [1000]: avg:   0.6138, min:   0.2680[ 209], max:   0.9012[ 934]\n",
      "1305:rl_loss   [1000]: avg:   0.1147, min:   0.0494[ 127], max:   0.3089[ 661]\n",
      "epoch 1305, eval score: 6.9430, perfect: 0.00, model saved: False\n",
      "epoch 1305, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1306\n",
      "available: 4.219 GB, used: 24.815 GB, free: 337.297 MB\n",
      "EPOCH: 1306\n",
      "Speed: train: 1150.3, buffer_add: 279.0, buffer_size: 100018\n",
      "Total Time: 20H 10M 45S, 72645s\n",
      "Total Sample: train: 83.648M, buffer: 20.843M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.73%\n",
      "\tsample data       : 1 MS, 1.99%\n",
      "\tforward & backward: 36 MS, 65.39%\n",
      "\tupdate model      : 15 MS, 28.79%\n",
      "\tupdating priority : 0 MS, 0.11%\n",
      "@@@total time per iter: 55.56 ms\n",
      "[1306] Time spent = 55.64 s\n",
      "1306:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1306:grad_norm [1000]: avg:   2.2053, min:   0.6971[ 808], max:   7.1721[ 147]\n",
      "1306:loss      [1000]: avg:   0.6074, min:   0.2053[ 628], max:   0.8740[ 307]\n",
      "1306:rl_loss   [1000]: avg:   0.1143, min:   0.0572[ 895], max:   0.3289[ 887]\n",
      "epoch 1306, eval score: 6.9440, perfect: 0.00, model saved: False\n",
      "epoch 1306, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  1307\n",
      "available: 4.220 GB, used: 24.814 GB, free: 338.004 MB\n",
      "EPOCH: 1307\n",
      "Speed: train: 1149.4, buffer_add: 279.5, buffer_size: 100012\n",
      "Total Time: 20H 11M 41S, 72701s\n",
      "Total Sample: train: 83.712M, buffer: 20.859M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.88%\n",
      "\tsample data       : 1 MS, 2.18%\n",
      "\tforward & backward: 36 MS, 65.12%\n",
      "\tupdate model      : 15 MS, 28.72%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 55.59 ms\n",
      "[1307] Time spent = 55.68 s\n",
      "1307:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1307:grad_norm [1000]: avg:   2.1636, min:   0.5567[ 543], max:   7.5301[ 553]\n",
      "1307:loss      [1000]: avg:   0.6099, min:   0.2406[ 543], max:   0.9178[ 490]\n",
      "1307:rl_loss   [1000]: avg:   0.1112, min:   0.0522[  63], max:   0.3241[ 778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1307, eval score: 6.9170, perfect: 0.00, model saved: False\n",
      "epoch 1307, success rate for sampling ficticious state: 99.82%\n",
      "==========\n",
      "beginning of epoch:  1308\n",
      "available: 4.209 GB, used: 24.825 GB, free: 326.238 MB\n",
      "EPOCH: 1308\n",
      "Speed: train: 1154.8, buffer_add: 277.7, buffer_size: 100005\n",
      "Total Time: 20H 12M 36S, 72756s\n",
      "Total Sample: train: 83.776M, buffer: 20.874M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.79%\n",
      "\tsample data       : 0 MS, 1.78%\n",
      "\tforward & backward: 36 MS, 65.30%\n",
      "\tupdate model      : 16 MS, 29.01%\n",
      "\tupdating priority : 0 MS, 0.13%\n",
      "@@@total time per iter: 55.32 ms\n",
      "[1308] Time spent = 55.42 s\n",
      "1308:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1308:grad_norm [1000]: avg:   2.2510, min:   0.4533[ 543], max:   8.2123[ 233]\n",
      "1308:loss      [1000]: avg:   0.6147, min:   0.2302[ 543], max:   0.8916[ 720]\n",
      "1308:rl_loss   [1000]: avg:   0.1099, min:   0.0434[ 204], max:   0.3012[ 198]\n",
      "epoch 1308, eval score: 6.9370, perfect: 0.10, model saved: False\n",
      "epoch 1308, success rate for sampling ficticious state: 99.81%\n",
      "==========\n",
      "beginning of epoch:  1309\n",
      "available: 4.211 GB, used: 24.823 GB, free: 328.801 MB\n",
      "EPOCH: 1309\n",
      "Speed: train: 1168.5, buffer_add: 280.2, buffer_size: 100006\n",
      "Total Time: 20H 13M 31S, 72811s\n",
      "Total Sample: train: 83.84M, buffer: 20.89M\n",
      "@@@Time\n",
      "\tsync and updating : 2 MS, 3.66%\n",
      "\tsample data       : 1 MS, 1.91%\n",
      "\tforward & backward: 35 MS, 65.70%\n",
      "\tupdate model      : 15 MS, 28.63%\n",
      "\tupdating priority : 0 MS, 0.10%\n",
      "@@@total time per iter: 54.70 ms\n",
      "[1309] Time spent = 54.78 s\n",
      "1309:boltzmann_t[1000]: avg:   0.0000, min:   0.0000[   0], max:   0.0000[   0]\n",
      "1309:grad_norm [1000]: avg:   2.2132, min:   0.6804[ 227], max:   7.2440[ 405]\n",
      "1309:loss      [1000]: avg:   0.6084, min:   0.2766[ 125], max:   0.9338[  51]\n",
      "1309:rl_loss   [1000]: avg:   0.1114, min:   0.0533[ 751], max:   0.3035[ 700]\n",
      "epoch 1309, eval score: 6.8970, perfect: 0.00, model saved: False\n",
      "epoch 1309, success rate for sampling ficticious state: 99.83%\n",
      "==========\n",
      "beginning of epoch:  1310\n",
      "available: 4.220 GB, used: 24.814 GB, free: 337.844 MB\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"selfplay.py\", line 285, in <module>\n",
      "    loss, priority, online_q = agent.loss(batch, args.aux_weight, stat)\n",
      "  File \"/notebooks/off-belief-small/pyhanabi/r2d2.py\", line 391, in loss\n",
      "    batch.seq_len,\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!sh scripts/obl1.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
